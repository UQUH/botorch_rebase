

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>botorch.optim &mdash; BoTorch  documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="_static/custom.css?v=ca3e82f4" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=5929fcd5"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="botorch.fit" href="fit.html" />
    <link rel="prev" title="botorch.posteriors" href="posteriors.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            BoTorch
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="acquisition.html">botorch.acquisition</a></li>
<li class="toctree-l1"><a class="reference internal" href="models.html">botorch.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="generation.html">botorch.generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="posteriors.html">botorch.posteriors</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">botorch.optim</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#optimization">Optimization</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.optim.core">Core</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.core.OptimizationStatus"><code class="docutils literal notranslate"><span class="pre">OptimizationStatus</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.core.OptimizationResult"><code class="docutils literal notranslate"><span class="pre">OptimizationResult</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.core.scipy_minimize"><code class="docutils literal notranslate"><span class="pre">scipy_minimize()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.core.torch_minimize"><code class="docutils literal notranslate"><span class="pre">torch_minimize()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.optim.optimize">Acquisition Function Optimization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.optimize.OptimizeAcqfInputs"><code class="docutils literal notranslate"><span class="pre">OptimizeAcqfInputs</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.optimize.optimize_acqf"><code class="docutils literal notranslate"><span class="pre">optimize_acqf()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.optimize.optimize_acqf_cyclic"><code class="docutils literal notranslate"><span class="pre">optimize_acqf_cyclic()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.optimize.optimize_acqf_list"><code class="docutils literal notranslate"><span class="pre">optimize_acqf_list()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.optimize.optimize_acqf_mixed"><code class="docutils literal notranslate"><span class="pre">optimize_acqf_mixed()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.optimize.optimize_acqf_discrete"><code class="docutils literal notranslate"><span class="pre">optimize_acqf_discrete()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.optimize.optimize_acqf_discrete_local_search"><code class="docutils literal notranslate"><span class="pre">optimize_acqf_discrete_local_search()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.optim.fit">Model Fitting Optimization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.fit.fit_gpytorch_mll_scipy"><code class="docutils literal notranslate"><span class="pre">fit_gpytorch_mll_scipy()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.fit.fit_gpytorch_mll_torch"><code class="docutils literal notranslate"><span class="pre">fit_gpytorch_mll_torch()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.optim.initializers">Initialization Helpers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.initializers.transform_constraints"><code class="docutils literal notranslate"><span class="pre">transform_constraints()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.initializers.transform_intra_point_constraint"><code class="docutils literal notranslate"><span class="pre">transform_intra_point_constraint()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.initializers.transform_inter_point_constraint"><code class="docutils literal notranslate"><span class="pre">transform_inter_point_constraint()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.initializers.sample_q_batches_from_polytope"><code class="docutils literal notranslate"><span class="pre">sample_q_batches_from_polytope()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.initializers.gen_batch_initial_conditions"><code class="docutils literal notranslate"><span class="pre">gen_batch_initial_conditions()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.initializers.gen_one_shot_kg_initial_conditions"><code class="docutils literal notranslate"><span class="pre">gen_one_shot_kg_initial_conditions()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.initializers.gen_one_shot_hvkg_initial_conditions"><code class="docutils literal notranslate"><span class="pre">gen_one_shot_hvkg_initial_conditions()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.initializers.gen_value_function_initial_conditions"><code class="docutils literal notranslate"><span class="pre">gen_value_function_initial_conditions()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.initializers.initialize_q_batch"><code class="docutils literal notranslate"><span class="pre">initialize_q_batch()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.initializers.initialize_q_batch_nonneg"><code class="docutils literal notranslate"><span class="pre">initialize_q_batch_nonneg()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.initializers.initialize_q_batch_topn"><code class="docutils literal notranslate"><span class="pre">initialize_q_batch_topn()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.initializers.sample_points_around_best"><code class="docutils literal notranslate"><span class="pre">sample_points_around_best()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.initializers.is_nonnegative"><code class="docutils literal notranslate"><span class="pre">is_nonnegative()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.optim.stopping">Stopping Criteria</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.stopping.StoppingCriterion"><code class="docutils literal notranslate"><span class="pre">StoppingCriterion</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.stopping.ExpMAStoppingCriterion"><code class="docutils literal notranslate"><span class="pre">ExpMAStoppingCriterion</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.optim.optimize_homotopy">Acquisition Function Optimization with Homotopy</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.optimize_homotopy.prune_candidates"><code class="docutils literal notranslate"><span class="pre">prune_candidates()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.optimize_homotopy.optimize_acqf_homotopy"><code class="docutils literal notranslate"><span class="pre">optimize_acqf_homotopy()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.optim.optimize_mixed">Acquisition Function Optimization with Mixed Integer Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.optimize_mixed.get_nearest_neighbors"><code class="docutils literal notranslate"><span class="pre">get_nearest_neighbors()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.optimize_mixed.get_spray_points"><code class="docutils literal notranslate"><span class="pre">get_spray_points()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.optimize_mixed.sample_feasible_points"><code class="docutils literal notranslate"><span class="pre">sample_feasible_points()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.optimize_mixed.generate_starting_points"><code class="docutils literal notranslate"><span class="pre">generate_starting_points()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.optimize_mixed.discrete_step"><code class="docutils literal notranslate"><span class="pre">discrete_step()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.optimize_mixed.continuous_step"><code class="docutils literal notranslate"><span class="pre">continuous_step()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.optimize_mixed.optimize_acqf_mixed_alternating"><code class="docutils literal notranslate"><span class="pre">optimize_acqf_mixed_alternating()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.optimize_mixed.complement_indices_like"><code class="docutils literal notranslate"><span class="pre">complement_indices_like()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.optimize_mixed.complement_indices"><code class="docutils literal notranslate"><span class="pre">complement_indices()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#closures">Closures</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id1">Core</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.closures.core.ForwardBackwardClosure"><code class="docutils literal notranslate"><span class="pre">ForwardBackwardClosure</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.closures.core.NdarrayOptimizationClosure"><code class="docutils literal notranslate"><span class="pre">NdarrayOptimizationClosure</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.optim.closures.model_closures">Model Fitting Closures</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.closures.model_closures.get_loss_closure"><code class="docutils literal notranslate"><span class="pre">get_loss_closure()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.closures.model_closures.get_loss_closure_with_grads"><code class="docutils literal notranslate"><span class="pre">get_loss_closure_with_grads()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#utilities">Utilities</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.optim.utils.common">General Optimization Utilities</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.optim.utils.acquisition_utils">Acquisition Optimization Utilities</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.utils.acquisition_utils.columnwise_clamp"><code class="docutils literal notranslate"><span class="pre">columnwise_clamp()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.utils.acquisition_utils.fix_features"><code class="docutils literal notranslate"><span class="pre">fix_features()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.utils.acquisition_utils.get_X_baseline"><code class="docutils literal notranslate"><span class="pre">get_X_baseline()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.optim.utils.model_utils">Model Fitting Utilities</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.utils.model_utils.TorchAttr"><code class="docutils literal notranslate"><span class="pre">TorchAttr</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.utils.model_utils.get_data_loader"><code class="docutils literal notranslate"><span class="pre">get_data_loader()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.utils.model_utils.get_parameters"><code class="docutils literal notranslate"><span class="pre">get_parameters()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.utils.model_utils.get_parameters_and_bounds"><code class="docutils literal notranslate"><span class="pre">get_parameters_and_bounds()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.utils.model_utils.get_name_filter"><code class="docutils literal notranslate"><span class="pre">get_name_filter()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.utils.model_utils.sample_all_priors"><code class="docutils literal notranslate"><span class="pre">sample_all_priors()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.optim.utils.numpy_utils">Numpy - Torch Conversion Tools</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.utils.numpy_utils.as_ndarray"><code class="docutils literal notranslate"><span class="pre">as_ndarray()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.utils.numpy_utils.get_tensors_as_ndarray_1d"><code class="docutils literal notranslate"><span class="pre">get_tensors_as_ndarray_1d()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.utils.numpy_utils.set_tensors_from_ndarray_1d"><code class="docutils literal notranslate"><span class="pre">set_tensors_from_ndarray_1d()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.utils.numpy_utils.get_bounds_as_ndarray"><code class="docutils literal notranslate"><span class="pre">get_bounds_as_ndarray()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.optim.utils.timeout">Optimization with Timeouts</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.utils.timeout.minimize_with_timeout"><code class="docutils literal notranslate"><span class="pre">minimize_with_timeout()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.optim.parameter_constraints">Parameter Constraint Utilities</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.parameter_constraints.make_scipy_bounds"><code class="docutils literal notranslate"><span class="pre">make_scipy_bounds()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.parameter_constraints.make_scipy_linear_constraints"><code class="docutils literal notranslate"><span class="pre">make_scipy_linear_constraints()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.parameter_constraints.eval_lin_constraint"><code class="docutils literal notranslate"><span class="pre">eval_lin_constraint()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.parameter_constraints.lin_constraint_jac"><code class="docutils literal notranslate"><span class="pre">lin_constraint_jac()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.parameter_constraints.nonlinear_constraint_is_feasible"><code class="docutils literal notranslate"><span class="pre">nonlinear_constraint_is_feasible()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.parameter_constraints.make_scipy_nonlinear_inequality_constraints"><code class="docutils literal notranslate"><span class="pre">make_scipy_nonlinear_inequality_constraints()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.parameter_constraints.evaluate_feasibility"><code class="docutils literal notranslate"><span class="pre">evaluate_feasibility()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.optim.homotopy">Homotopy Utilities</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.homotopy.FixedHomotopySchedule"><code class="docutils literal notranslate"><span class="pre">FixedHomotopySchedule</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.homotopy.LinearHomotopySchedule"><code class="docutils literal notranslate"><span class="pre">LinearHomotopySchedule</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.homotopy.LogLinearHomotopySchedule"><code class="docutils literal notranslate"><span class="pre">LogLinearHomotopySchedule</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.homotopy.HomotopyParameter"><code class="docutils literal notranslate"><span class="pre">HomotopyParameter</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.optim.homotopy.Homotopy"><code class="docutils literal notranslate"><span class="pre">Homotopy</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="fit.html">botorch.fit</a></li>
<li class="toctree-l1"><a class="reference internal" href="sampling.html">botorch.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="cross_validation.html">botorch.cross_validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="settings.html">botorch.settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="logging.html">botorch.logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_functions.html">botorch.test_functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_utils.html">botorch.test_utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="exceptions.html">botorch.exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">botorch.utils</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">BoTorch</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">botorch.optim</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/optim.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-botorch.optim">
<span id="botorch-optim"></span><h1>botorch.optim<a class="headerlink" href="#module-botorch.optim" title="Link to this heading"></a></h1>
<section id="optimization">
<h2>Optimization<a class="headerlink" href="#optimization" title="Link to this heading"></a></h2>
<section id="module-botorch.optim.core">
<span id="core"></span><h3>Core<a class="headerlink" href="#module-botorch.optim.core" title="Link to this heading"></a></h3>
<p>Core abstractions and generic optimizers.</p>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.optim.core.OptimizationStatus">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.optim.core.</span></span><span class="sig-name descname"><span class="pre">OptimizationStatus</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/core.html#OptimizationStatus"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.core.OptimizationStatus" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Enum</span></code></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.core.OptimizationStatus.RUNNING">
<span class="sig-name descname"><span class="pre">RUNNING</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1</span></em><a class="headerlink" href="#botorch.optim.core.OptimizationStatus.RUNNING" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.core.OptimizationStatus.SUCCESS">
<span class="sig-name descname"><span class="pre">SUCCESS</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">2</span></em><a class="headerlink" href="#botorch.optim.core.OptimizationStatus.SUCCESS" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.core.OptimizationStatus.FAILURE">
<span class="sig-name descname"><span class="pre">FAILURE</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">3</span></em><a class="headerlink" href="#botorch.optim.core.OptimizationStatus.FAILURE" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.core.OptimizationStatus.STOPPED">
<span class="sig-name descname"><span class="pre">STOPPED</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">4</span></em><a class="headerlink" href="#botorch.optim.core.OptimizationStatus.STOPPED" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.optim.core.OptimizationResult">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.optim.core.</span></span><span class="sig-name descname"><span class="pre">OptimizationResult</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">step</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="s"><span class="pre">'int'</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fval</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="s"><span class="pre">'float</span> <span class="pre">|</span> <span class="pre">int'</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">status</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="s"><span class="pre">'OptimizationStatus'</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">runtime</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="s"><span class="pre">'float</span> <span class="pre">|</span> <span class="pre">None'</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">message</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="s"><span class="pre">'str</span> <span class="pre">|</span> <span class="pre">None'</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/core.html#OptimizationResult"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.core.OptimizationResult" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>step</strong> (<em>int</em>)</p></li>
<li><p><strong>fval</strong> (<em>float</em><em> | </em><em>int</em>)</p></li>
<li><p><strong>status</strong> (<a class="reference internal" href="#botorch.optim.core.OptimizationStatus" title="botorch.optim.core.OptimizationStatus"><em>OptimizationStatus</em></a>)</p></li>
<li><p><strong>runtime</strong> (<em>float</em><em> | </em><em>None</em>)</p></li>
<li><p><strong>message</strong> (<em>str</em><em> | </em><em>None</em>)</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.core.OptimizationResult.step">
<span class="sig-name descname"><span class="pre">step</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#botorch.optim.core.OptimizationResult.step" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.core.OptimizationResult.fval">
<span class="sig-name descname"><span class="pre">fval</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#botorch.optim.core.OptimizationResult.fval" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.core.OptimizationResult.status">
<span class="sig-name descname"><span class="pre">status</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="#botorch.optim.core.OptimizationStatus" title="botorch.optim.core.OptimizationStatus"><span class="pre">OptimizationStatus</span></a></em><a class="headerlink" href="#botorch.optim.core.OptimizationResult.status" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.core.OptimizationResult.runtime">
<span class="sig-name descname"><span class="pre">runtime</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#botorch.optim.core.OptimizationResult.runtime" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.core.OptimizationResult.message">
<span class="sig-name descname"><span class="pre">message</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#botorch.optim.core.OptimizationResult.message" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.core.scipy_minimize">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.core.</span></span><span class="sig-name descname"><span class="pre">scipy_minimize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">closure</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parameters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'L-BFGS-B'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">timeout_sec</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/core.html#scipy_minimize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.core.scipy_minimize" title="Link to this definition"></a></dt>
<dd><p>Generic scipy.optimize.minimize-based optimization routine.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>closure</strong> (<em>Callable</em><em>[</em><em>[</em><em>]</em><em>, </em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Sequence</em><em>[</em><em>Tensor</em><em> | </em><em>None</em><em>]</em><em>]</em><em>] </em><em>| </em><a class="reference internal" href="#botorch.optim.closures.core.NdarrayOptimizationClosure" title="botorch.optim.closures.core.NdarrayOptimizationClosure"><em>NdarrayOptimizationClosure</em></a>) – Callable that returns a tensor and an iterable of gradient tensors or
NdarrayOptimizationClosure instance.</p></li>
<li><p><strong>parameters</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>) – A dictionary of tensors to be optimized.</p></li>
<li><p><strong>bounds</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>tuple</em><em>[</em><em>float</em><em> | </em><em>None</em><em>, </em><em>float</em><em> | </em><em>None</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A dictionary mapping parameter names to lower and upper bounds.</p></li>
<li><p><strong>callback</strong> (<em>Callable</em><em>[</em><em>[</em><em>dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em><em>, </em><a class="reference internal" href="#botorch.optim.core.OptimizationResult" title="botorch.optim.core.OptimizationResult"><em>OptimizationResult</em></a><em>]</em><em>, </em><em>None</em><em>] </em><em>| </em><em>None</em>) – A callable taking <cite>parameters</cite> and an OptimizationResult as arguments.</p></li>
<li><p><strong>x0</strong> (<em>ndarray</em><em>[</em><em>tuple</em><em>[</em><em>int</em><em>, </em><em>...</em><em>]</em><em>, </em><em>dtype</em><em>[</em><em>_ScalarType_co</em><em>]</em><em>] </em><em>| </em><em>None</em>) – An optional initialization vector passed to scipy.optimize.minimize.</p></li>
<li><p><strong>method</strong> (<em>str</em>) – Solver type, passed along to scipy.minimize.</p></li>
<li><p><strong>options</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Dictionary of solver options, passed along to scipy.minimize.</p></li>
<li><p><strong>timeout_sec</strong> (<em>float</em><em> | </em><em>None</em>) – Timeout in seconds to wait before aborting the optimization loop
if not converged (will return the best found solution thus far).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An OptimizationResult summarizing the final state of the run.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.optim.core.OptimizationResult" title="botorch.optim.core.OptimizationResult"><em>OptimizationResult</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.core.torch_minimize">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.core.</span></span><span class="sig-name descname"><span class="pre">torch_minimize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">closure</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parameters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer=&lt;class</span> <span class="pre">'torch.optim.adam.Adam'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scheduler=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">step_limit=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">timeout_sec=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopping_criterion=None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/core.html#torch_minimize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.core.torch_minimize" title="Link to this definition"></a></dt>
<dd><p>Generic torch.optim-based optimization routine.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>closure</strong> (<em>Callable</em><em>[</em><em>[</em><em>]</em><em>, </em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Sequence</em><em>[</em><em>Tensor</em><em> | </em><em>None</em><em>]</em><em>]</em><em>]</em>) – Callable that returns a tensor and an iterable of gradient tensors.
Responsible for setting relevant parameters’ <cite>grad</cite> attributes.</p></li>
<li><p><strong>parameters</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>) – A dictionary of tensors to be optimized.</p></li>
<li><p><strong>bounds</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>tuple</em><em>[</em><em>float</em><em> | </em><em>None</em><em>, </em><em>float</em><em> | </em><em>None</em><em>]</em><em>] </em><em>| </em><em>None</em>) – An optional dictionary of bounds for elements of <cite>parameters</cite>.</p></li>
<li><p><strong>callback</strong> (<em>Callable</em><em>[</em><em>[</em><em>dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em><em>, </em><a class="reference internal" href="#botorch.optim.core.OptimizationResult" title="botorch.optim.core.OptimizationResult"><em>OptimizationResult</em></a><em>]</em><em>, </em><em>None</em><em>] </em><em>| </em><em>None</em>) – A callable taking <cite>parameters</cite> and an OptimizationResult as arguments.</p></li>
<li><p><strong>optimizer</strong> (<em>Optimizer</em><em> | </em><em>Callable</em><em>[</em><em>[</em><em>list</em><em>[</em><em>Tensor</em><em>]</em><em>]</em><em>, </em><em>Optimizer</em><em>]</em>) – A <cite>torch.optim.Optimizer</cite> instance or a factory that takes
a list of parameters and returns an <cite>Optimizer</cite> instance.</p></li>
<li><p><strong>scheduler</strong> (<em>LRScheduler</em><em> | </em><em>Callable</em><em>[</em><em>[</em><em>Optimizer</em><em>]</em><em>, </em><em>LRScheduler</em><em>] </em><em>| </em><em>None</em>) – A <cite>torch.optim.lr_scheduler._LRScheduler</cite> instance or a factory
that takes a <cite>Optimizer</cite> instance and returns a <cite>_LRSchedule</cite> instance.</p></li>
<li><p><strong>step_limit</strong> (<em>int</em><em> | </em><em>None</em>) – Integer specifying a maximum number of optimization steps.
One of <cite>step_limit</cite>, <cite>stopping_criterion</cite>, or <cite>timeout_sec</cite> must be passed.</p></li>
<li><p><strong>timeout_sec</strong> (<em>float</em><em> | </em><em>None</em>) – Timeout in seconds before terminating the optimization loop.
One of <cite>step_limit</cite>, <cite>stopping_criterion</cite>, or <cite>timeout_sec</cite> must be passed.</p></li>
<li><p><strong>stopping_criterion</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>bool</em><em>] </em><em>| </em><em>None</em>) – A StoppingCriterion for the optimization loop.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An OptimizationResult summarizing the final state of the run.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.optim.core.OptimizationResult" title="botorch.optim.core.OptimizationResult"><em>OptimizationResult</em></a></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-botorch.optim.optimize">
<span id="acquisition-function-optimization"></span><h3>Acquisition Function Optimization<a class="headerlink" href="#module-botorch.optim.optimize" title="Link to this heading"></a></h3>
<p>Methods for optimizing acquisition functions.</p>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.optim.optimize.</span></span><span class="sig-name descname"><span class="pre">OptimizeAcqfInputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_restarts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raw_samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inequality_constraints</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">equality_constraints</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nonlinear_inequality_constraints</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post_processing_func</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_initial_conditions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_best_only</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gen_candidates</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sequential</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ic_generator=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">timeout_sec=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_full_tree=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retry_on_optimization_warning=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ic_gen_kwargs=&lt;factory&gt;</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/optimize.html#OptimizeAcqfInputs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Container for inputs to <cite>optimize_acqf</cite>.</p>
<p>See docstring for <cite>optimize_acqf</cite> for explanation of parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<a class="reference internal" href="acquisition.html#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><em>AcquisitionFunction</em></a>)</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>)</p></li>
<li><p><strong>q</strong> (<em>int</em>)</p></li>
<li><p><strong>num_restarts</strong> (<em>int</em>)</p></li>
<li><p><strong>raw_samples</strong> (<em>int</em><em> | </em><em>None</em>)</p></li>
<li><p><strong>options</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>bool</em><em> | </em><em>float</em><em> | </em><em>int</em><em> | </em><em>str</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>inequality_constraints</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>equality_constraints</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>nonlinear_inequality_constraints</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>Callable</em><em>, </em><em>bool</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>fixed_features</strong> (<em>dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>post_processing_func</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>batch_initial_conditions</strong> (<em>Tensor</em><em> | </em><em>None</em>)</p></li>
<li><p><strong>return_best_only</strong> (<em>bool</em>)</p></li>
<li><p><strong>gen_candidates</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>, </em><a class="reference internal" href="acquisition.html#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><em>AcquisitionFunction</em></a><em>, </em><em>Any</em><em>]</em><em>, </em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>]</em><em>]</em>)</p></li>
<li><p><strong>sequential</strong> (<em>bool</em>)</p></li>
<li><p><strong>ic_generator</strong> (<em>Callable</em><em>[</em><em>[</em><a class="reference internal" href="acquisition.html#botorch.acquisition.knowledge_gradient.qKnowledgeGradient" title="botorch.acquisition.knowledge_gradient.qKnowledgeGradient"><em>qKnowledgeGradient</em></a><em>, </em><em>Tensor</em><em>, </em><em>int</em><em>, </em><em>int</em><em>, </em><em>int</em><em>, </em><em>dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>] </em><em>| </em><em>None</em><em>, </em><em>dict</em><em>[</em><em>str</em><em>, </em><em>bool</em><em> | </em><em>float</em><em> | </em><em>int</em><em>] </em><em>| </em><em>None</em><em>, </em><em>list</em><em>[</em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em><em>, </em><em>list</em><em>[</em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em><em>]</em><em>, </em><em>Tensor</em><em> | </em><em>None</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>timeout_sec</strong> (<em>float</em><em> | </em><em>None</em>)</p></li>
<li><p><strong>return_full_tree</strong> (<em>bool</em>)</p></li>
<li><p><strong>retry_on_optimization_warning</strong> (<em>bool</em>)</p></li>
<li><p><strong>ic_gen_kwargs</strong> (<em>dict</em>)</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.acq_function">
<span class="sig-name descname"><span class="pre">acq_function</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="acquisition.html#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><span class="pre">AcquisitionFunction</span></a></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.acq_function" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.bounds">
<span class="sig-name descname"><span class="pre">bounds</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tensor</span></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.bounds" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.q">
<span class="sig-name descname"><span class="pre">q</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.q" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.num_restarts">
<span class="sig-name descname"><span class="pre">num_restarts</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.num_restarts" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.raw_samples">
<span class="sig-name descname"><span class="pre">raw_samples</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.raw_samples" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.options">
<span class="sig-name descname"><span class="pre">options</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">bool</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.options" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.inequality_constraints">
<span class="sig-name descname"><span class="pre">inequality_constraints</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.inequality_constraints" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.equality_constraints">
<span class="sig-name descname"><span class="pre">equality_constraints</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.equality_constraints" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.nonlinear_inequality_constraints">
<span class="sig-name descname"><span class="pre">nonlinear_inequality_constraints</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Callable</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.nonlinear_inequality_constraints" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.fixed_features">
<span class="sig-name descname"><span class="pre">fixed_features</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.fixed_features" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.post_processing_func">
<span class="sig-name descname"><span class="pre">post_processing_func</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.post_processing_func" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.batch_initial_conditions">
<span class="sig-name descname"><span class="pre">batch_initial_conditions</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.batch_initial_conditions" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.return_best_only">
<span class="sig-name descname"><span class="pre">return_best_only</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.return_best_only" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.gen_candidates">
<span class="sig-name descname"><span class="pre">gen_candidates</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="acquisition.html#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><span class="pre">AcquisitionFunction</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.gen_candidates" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.sequential">
<span class="sig-name descname"><span class="pre">sequential</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.sequential" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.ic_generator">
<span class="sig-name descname"><span class="pre">ic_generator</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="acquisition.html#botorch.acquisition.knowledge_gradient.qKnowledgeGradient" title="botorch.acquisition.knowledge_gradient.qKnowledgeGradient"><span class="pre">qKnowledgeGradient</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">bool</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.ic_generator" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.timeout_sec">
<span class="sig-name descname"><span class="pre">timeout_sec</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.timeout_sec" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.return_full_tree">
<span class="sig-name descname"><span class="pre">return_full_tree</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.return_full_tree" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.retry_on_optimization_warning">
<span class="sig-name descname"><span class="pre">retry_on_optimization_warning</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.retry_on_optimization_warning" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.ic_gen_kwargs">
<span class="sig-name descname"><span class="pre">ic_gen_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">dict</span></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.ic_gen_kwargs" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.full_tree">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">full_tree</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.full_tree" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.get_ic_generator">
<span class="sig-name descname"><span class="pre">get_ic_generator</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/optimize.html#OptimizeAcqfInputs.get_ic_generator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.get_ic_generator" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Callable</em>[[<a class="reference internal" href="acquisition.html#botorch.acquisition.knowledge_gradient.qKnowledgeGradient" title="botorch.acquisition.knowledge_gradient.qKnowledgeGradient"><em>qKnowledgeGradient</em></a>, <em>Tensor</em>, int, int, int, dict[int, float] | None, dict[str, bool | float | int] | None, list[tuple[<em>Tensor</em>, <em>Tensor</em>, float]] | None, list[tuple[<em>Tensor</em>, <em>Tensor</em>, float]] | None], <em>Tensor</em> | None]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.optimize.optimize_acqf">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.optimize.</span></span><span class="sig-name descname"><span class="pre">optimize_acqf</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_restarts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raw_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inequality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">equality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nonlinear_inequality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post_processing_func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_initial_conditions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_best_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gen_candidates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sequential</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="keyword-only-separator o"><abbr title="Keyword-only parameters separator (PEP 3102)"><span class="pre">*</span></abbr></span></em>, <em class="sig-param"><span class="n"><span class="pre">ic_generator</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">timeout_sec</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_full_tree</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retry_on_optimization_warning</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">ic_gen_kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/optimize.html#optimize_acqf"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.optimize.optimize_acqf" title="Link to this definition"></a></dt>
<dd><p>Generate a set of candidates via multi-start optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<a class="reference internal" href="acquisition.html#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><em>AcquisitionFunction</em></a>) – An AcquisitionFunction.</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – A <cite>2 x d</cite> tensor of lower and upper bounds for each column of <cite>X</cite>
(if inequality_constraints is provided, these bounds can be -inf and
+inf, respectively).</p></li>
<li><p><strong>q</strong> (<em>int</em>) – The number of candidates.</p></li>
<li><p><strong>num_restarts</strong> (<em>int</em>) – The number of starting points for multistart acquisition
function optimization.</p></li>
<li><p><strong>raw_samples</strong> (<em>int</em><em> | </em><em>None</em>) – The number of samples for initialization. This is required
if <cite>batch_initial_conditions</cite> is not specified.</p></li>
<li><p><strong>options</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>bool</em><em> | </em><em>float</em><em> | </em><em>int</em><em> | </em><em>str</em><em>] </em><em>| </em><em>None</em>) – Options for candidate generation.</p></li>
<li><p><strong>inequality_constraints</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) &gt;= rhs</cite>. <cite>indices</cite> and
<cite>coefficients</cite> should be torch tensors. See the docstring of
<cite>make_scipy_linear_constraints</cite> for an example. When q=1, or when
applying the same constraint to each candidate in the batch
(intra-point constraint), <cite>indices</cite> should be a 1-d tensor.
For inter-point constraints, in which the constraint is applied to the
whole batch of candidates, <cite>indices</cite> must be a 2-d tensor, where
in each row <cite>indices[i] =(k_i, l_i)</cite> the first index <cite>k_i</cite> corresponds
to the <cite>k_i</cite>-th element of the <cite>q</cite>-batch and the second index <cite>l_i</cite>
corresponds to the <cite>l_i</cite>-th feature of that element.</p></li>
<li><p><strong>equality_constraints</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an equality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) = rhs</cite>. See the docstring of
<cite>make_scipy_linear_constraints</cite> for an example.</p></li>
<li><p><strong>nonlinear_inequality_constraints</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>Callable</em><em>, </em><em>bool</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of tuples representing the nonlinear
inequality constraints. The first element in the tuple is a callable
representing a constraint of the form <cite>callable(x) &gt;= 0</cite>. In case of an
intra-point constraint, <cite>callable()`takes in an one-dimensional tensor of
shape `d</cite> and returns a scalar. In case of an inter-point constraint,
<cite>callable()</cite> takes a two dimensional tensor of shape <cite>q x d</cite> and again
returns a scalar. The second element is a boolean, indicating if it is an
intra-point or inter-point constraint (<cite>True</cite> for intra-point. <cite>False</cite> for
inter-point). For more information on intra-point vs inter-point
constraints, see the docstring of the <cite>inequality_constraints</cite> argument to
<cite>optimize_acqf()</cite>. The constraints will later be passed to the scipy
solver. You need to pass in <cite>batch_initial_conditions</cite> in this case.
Using non-linear inequality constraints also requires that <cite>batch_limit</cite>
is set to 1, which will be done automatically if not specified in
<cite>options</cite>.</p></li>
<li><p><strong>fixed_features</strong> (<em>dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>] </em><em>| </em><em>None</em>) – A map <cite>{feature_index: value}</cite> for features that
should be fixed to a particular value during generation. All indices
should be non-negative.</p></li>
<li><p><strong>post_processing_func</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – A function that post-processes an optimization
result appropriately (i.e., according to <cite>round-trip</cite>
transformations).</p></li>
<li><p><strong>batch_initial_conditions</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A tensor to specify the initial conditions. Set
this if you do not want to use default initialization strategy.</p></li>
<li><p><strong>return_best_only</strong> (<em>bool</em>) – If False, outputs the solutions corresponding to all
random restart initializations of the optimization.</p></li>
<li><p><strong>gen_candidates</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>, </em><a class="reference internal" href="acquisition.html#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><em>AcquisitionFunction</em></a><em>, </em><em>Any</em><em>]</em><em>, </em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A callable for generating candidates (and their associated
acquisition values) given a tensor of initial conditions and an
acquisition function. Other common inputs include lower and upper bounds
and a dictionary of options, but refer to the documentation of specific
generation functions (e.g gen_candidates_scipy and gen_candidates_torch)
for method-specific inputs. Default: <cite>gen_candidates_scipy</cite></p></li>
<li><p><strong>sequential</strong> (<em>bool</em>) – If False, uses joint optimization, otherwise uses sequential
optimization.</p></li>
<li><p><strong>ic_generator</strong> (<em>Callable</em><em>[</em><em>[</em><a class="reference internal" href="acquisition.html#botorch.acquisition.knowledge_gradient.qKnowledgeGradient" title="botorch.acquisition.knowledge_gradient.qKnowledgeGradient"><em>qKnowledgeGradient</em></a><em>, </em><em>Tensor</em><em>, </em><em>int</em><em>, </em><em>int</em><em>, </em><em>int</em><em>, </em><em>dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>] </em><em>| </em><em>None</em><em>, </em><em>dict</em><em>[</em><em>str</em><em>, </em><em>bool</em><em> | </em><em>float</em><em> | </em><em>int</em><em>] </em><em>| </em><em>None</em><em>, </em><em>list</em><em>[</em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em><em>, </em><em>list</em><em>[</em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em><em>]</em><em>, </em><em>Tensor</em><em> | </em><em>None</em><em>] </em><em>| </em><em>None</em>) – Function for generating initial conditions. Not needed when
<cite>batch_initial_conditions</cite> are provided. Defaults to
<cite>gen_one_shot_kg_initial_conditions</cite> for <cite>qKnowledgeGradient</cite> acquisition
functions and <cite>gen_batch_initial_conditions</cite> otherwise. Must be specified
for nonlinear inequality constraints.</p></li>
<li><p><strong>timeout_sec</strong> (<em>float</em><em> | </em><em>None</em>) – Max amount of time optimization can run for.</p></li>
<li><p><strong>return_full_tree</strong> (<em>bool</em>) – Return the full tree of optimizers of the previous
iteration.</p></li>
<li><p><strong>retry_on_optimization_warning</strong> (<em>bool</em>) – Whether to retry candidate generation with a new
set of initial conditions when it fails with an <cite>OptimizationWarning</cite>.</p></li>
<li><p><strong>ic_gen_kwargs</strong> (<em>Any</em>) – Additional keyword arguments passed to function specified by
<cite>ic_generator</cite></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>A two-element tuple containing</p>
<ul class="simple">
<li><dl class="simple">
<dt>A tensor of generated candidates. The shape is</dt><dd><p>– <cite>q x d</cite> if <cite>return_best_only</cite> is True (default)
– <cite>num_restarts x q x d</cite> if <cite>return_best_only</cite> is False</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>a tensor of associated acquisition values. If <cite>sequential=False</cite>,</dt><dd><p>this is a <cite>(num_restarts)</cite>-dim tensor of joint acquisition values
(with explicit restart dimension if <cite>return_best_only=False</cite>). If
<cite>sequential=True</cite>, this is a <cite>q</cite>-dim tensor of expected acquisition
values conditional on having observed candidates <cite>0,1,…,i-1</cite>.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple[<em>Tensor</em>, <em>Tensor</em>]</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># generate `q=2` candidates jointly using 20 random restarts</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># and 512 raw samples</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">candidates</span><span class="p">,</span> <span class="n">acq_value</span> <span class="o">=</span> <span class="n">optimize_acqf</span><span class="p">(</span><span class="n">qEI</span><span class="p">,</span> <span class="n">bounds</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span>&gt;&gt;&gt; generate `q=3` candidates sequentially using 15 random restarts
&gt;&gt;&gt; # and 256 raw samples
&gt;&gt;&gt; qEI = qExpectedImprovement(model, best_f=0.2)
&gt;&gt;&gt; bounds = torch.tensor([[0.], [1.]])
&gt;&gt;&gt; candidates, acq_value_list = optimize_acqf(
&gt;&gt;&gt;     qEI, bounds, 3, 15, 256, sequential=True
&gt;&gt;&gt; )
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.optimize.optimize_acqf_cyclic">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.optimize.</span></span><span class="sig-name descname"><span class="pre">optimize_acqf_cyclic</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_restarts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raw_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inequality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">equality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post_processing_func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_initial_conditions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cyclic_options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="keyword-only-separator o"><abbr title="Keyword-only parameters separator (PEP 3102)"><span class="pre">*</span></abbr></span></em>, <em class="sig-param"><span class="n"><span class="pre">ic_generator</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">timeout_sec</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_full_tree</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retry_on_optimization_warning</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">ic_gen_kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/optimize.html#optimize_acqf_cyclic"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.optimize.optimize_acqf_cyclic" title="Link to this definition"></a></dt>
<dd><p>Generate a set of <cite>q</cite> candidates via cyclic optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<a class="reference internal" href="acquisition.html#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><em>AcquisitionFunction</em></a>) – An AcquisitionFunction</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – A <cite>2 x d</cite> tensor of lower and upper bounds for each column of <cite>X</cite>
(if inequality_constraints is provided, these bounds can be -inf and
+inf, respectively).</p></li>
<li><p><strong>q</strong> (<em>int</em>) – The number of candidates.</p></li>
<li><p><strong>num_restarts</strong> (<em>int</em>) – Number of starting points for multistart acquisition
function optimization.</p></li>
<li><p><strong>raw_samples</strong> (<em>int</em><em> | </em><em>None</em>) – Number of samples for initialization. This is required
if <cite>batch_initial_conditions</cite> is not specified.</p></li>
<li><p><strong>options</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>bool</em><em> | </em><em>float</em><em> | </em><em>int</em><em> | </em><em>str</em><em>] </em><em>| </em><em>None</em>) – Options for candidate generation.</p></li>
<li><p><strong>constraints</strong> (<em>equality</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) &gt;= rhs</cite></p></li>
<li><p><strong>constraints</strong> – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) = rhs</cite></p></li>
<li><p><strong>fixed_features</strong> (<em>dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>] </em><em>| </em><em>None</em>) – A map <cite>{feature_index: value}</cite> for features that
should be fixed to a particular value during generation. All indices
should be non-negative.</p></li>
<li><p><strong>post_processing_func</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – A function that post-processes an optimization
result appropriately (i.e., according to <cite>round-trip</cite>
transformations).</p></li>
<li><p><strong>batch_initial_conditions</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A tensor to specify the initial conditions.
If no initial conditions are provided, the default initialization will
be used.</p></li>
<li><p><strong>cyclic_options</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>bool</em><em> | </em><em>float</em><em> | </em><em>int</em><em> | </em><em>str</em><em>] </em><em>| </em><em>None</em>) – Options for stopping criterion for outer cyclic optimization.</p></li>
<li><p><strong>ic_generator</strong> (<em>Callable</em><em>[</em><em>[</em><a class="reference internal" href="acquisition.html#botorch.acquisition.knowledge_gradient.qKnowledgeGradient" title="botorch.acquisition.knowledge_gradient.qKnowledgeGradient"><em>qKnowledgeGradient</em></a><em>, </em><em>Tensor</em><em>, </em><em>int</em><em>, </em><em>int</em><em>, </em><em>int</em><em>, </em><em>dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>] </em><em>| </em><em>None</em><em>, </em><em>dict</em><em>[</em><em>str</em><em>, </em><em>bool</em><em> | </em><em>float</em><em> | </em><em>int</em><em>] </em><em>| </em><em>None</em><em>, </em><em>list</em><em>[</em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em><em>, </em><em>list</em><em>[</em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em><em>]</em><em>, </em><em>Tensor</em><em> | </em><em>None</em><em>] </em><em>| </em><em>None</em>) – Function for generating initial conditions. Not needed when
<cite>batch_initial_conditions</cite> are provided. Defaults to
<cite>gen_one_shot_kg_initial_conditions</cite> for <cite>qKnowledgeGradient</cite> acquisition
functions and <cite>gen_batch_initial_conditions</cite> otherwise. Must be specified
for nonlinear inequality constraints.</p></li>
<li><p><strong>timeout_sec</strong> (<em>float</em><em> | </em><em>None</em>) – Max amount of time optimization can run for.</p></li>
<li><p><strong>return_full_tree</strong> (<em>bool</em>) – Return the full tree of optimizers of the previous
iteration.</p></li>
<li><p><strong>retry_on_optimization_warning</strong> (<em>bool</em>) – Whether to retry candidate generation with a new
set of initial conditions when it fails with an <cite>OptimizationWarning</cite>.</p></li>
<li><p><strong>ic_gen_kwargs</strong> (<em>Any</em>) – Additional keyword arguments passed to function specified by
<cite>ic_generator</cite></p></li>
<li><p><strong>inequality_constraints</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>equality_constraints</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>A two-element tuple containing</p>
<ul class="simple">
<li><p>a <cite>q x d</cite>-dim tensor of generated candidates.</p></li>
<li><dl class="simple">
<dt>a <cite>q</cite>-dim tensor of expected acquisition values, where the value at</dt><dd><p>index <cite>i</cite> is the acquisition value conditional on having observed
all candidates except candidate <cite>i</cite>.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple[<em>Tensor</em>, <em>Tensor</em>]</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># generate `q=3` candidates cyclically using 15 random restarts</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 256 raw samples, and 4 cycles</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qEI</span> <span class="o">=</span> <span class="n">qExpectedImprovement</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">best_f</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bounds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">candidates</span><span class="p">,</span> <span class="n">acq_value_list</span> <span class="o">=</span> <span class="n">optimize_acqf_cyclic</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">qEI</span><span class="p">,</span> <span class="n">bounds</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">cyclic_options</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;maxiter&quot;</span><span class="p">:</span> <span class="mi">4</span><span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.optimize.optimize_acqf_list">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.optimize.</span></span><span class="sig-name descname"><span class="pre">optimize_acqf_list</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function_list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_restarts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raw_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inequality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">equality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nonlinear_inequality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_features_list</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post_processing_func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ic_generator</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ic_gen_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/optimize.html#optimize_acqf_list"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.optimize.optimize_acqf_list" title="Link to this definition"></a></dt>
<dd><p>Generate a list of candidates from a list of acquisition functions.</p>
<p>The acquisition functions are optimized in sequence, with previous candidates
set as <cite>X_pending</cite>. This is also known as sequential greedy optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function_list</strong> (<em>list</em><em>[</em><a class="reference internal" href="acquisition.html#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><em>AcquisitionFunction</em></a><em>]</em>) – A list of acquisition functions.</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – A <cite>2 x d</cite> tensor of lower and upper bounds for each column of <cite>X</cite>
(if inequality_constraints is provided, these bounds can be -inf and
+inf, respectively).</p></li>
<li><p><strong>num_restarts</strong> (<em>int</em>) – Number of starting points for multistart acquisition
function optimization.</p></li>
<li><p><strong>raw_samples</strong> (<em>int</em><em> | </em><em>None</em>) – Number of samples for initialization. This is required
if <cite>batch_initial_conditions</cite> is not specified.</p></li>
<li><p><strong>options</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>bool</em><em> | </em><em>float</em><em> | </em><em>int</em><em> | </em><em>str</em><em>] </em><em>| </em><em>None</em>) – Options for candidate generation.</p></li>
<li><p><strong>constraints</strong> (<em>equality</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) &gt;= rhs</cite></p></li>
<li><p><strong>constraints</strong> – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) = rhs</cite></p></li>
<li><p><strong>nonlinear_inequality_constraints</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>Callable</em><em>, </em><em>bool</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of tuples representing the nonlinear
inequality constraints. The first element in the tuple is a callable
representing a constraint of the form <cite>callable(x) &gt;= 0</cite>. In case of an
intra-point constraint, <cite>callable()`takes in an one-dimensional tensor of
shape `d</cite> and returns a scalar. In case of an inter-point constraint,
<cite>callable()</cite> takes a two dimensional tensor of shape <cite>q x d</cite> and again
returns a scalar. The second element is a boolean, indicating if it is an
intra-point or inter-point constraint (<cite>True</cite> for intra-point. <cite>False</cite> for
inter-point). For more information on intra-point vs inter-point
constraints, see the docstring of the <cite>inequality_constraints</cite> argument to
<cite>optimize_acqf()</cite>. The constraints will later be passed to the scipy
solver. You need to pass in <cite>batch_initial_conditions</cite> in this case.
Using non-linear inequality constraints also requires that <cite>batch_limit</cite>
is set to 1, which will be done automatically if not specified in
<cite>options</cite>.</p></li>
<li><p><strong>fixed_features</strong> (<em>dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>] </em><em>| </em><em>None</em>) – A map <cite>{feature_index: value}</cite> for features that should
be fixed to a particular value during generation. All indices
(<cite>feature_index</cite>) should be non-negative.</p></li>
<li><p><strong>fixed_features_list</strong> (<em>list</em><em>[</em><em>dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of maps <cite>{feature_index: value}</cite>. The i-th
item represents the fixed_feature for the i-th optimization. If
<cite>fixed_features_list</cite> is provided, <cite>optimize_acqf_mixed</cite> is invoked.
All indices (<cite>feature_index</cite>) should be non-negative.</p></li>
<li><p><strong>post_processing_func</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – A function that post-processes an optimization
result appropriately (i.e., according to <cite>round-trip</cite>
transformations).</p></li>
<li><p><strong>ic_generator</strong> (<em>Callable</em><em>[</em><em>[</em><a class="reference internal" href="acquisition.html#botorch.acquisition.knowledge_gradient.qKnowledgeGradient" title="botorch.acquisition.knowledge_gradient.qKnowledgeGradient"><em>qKnowledgeGradient</em></a><em>, </em><em>Tensor</em><em>, </em><em>int</em><em>, </em><em>int</em><em>, </em><em>int</em><em>, </em><em>dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>] </em><em>| </em><em>None</em><em>, </em><em>dict</em><em>[</em><em>str</em><em>, </em><em>bool</em><em> | </em><em>float</em><em> | </em><em>int</em><em>] </em><em>| </em><em>None</em><em>, </em><em>list</em><em>[</em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em><em>, </em><em>list</em><em>[</em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em><em>]</em><em>, </em><em>Tensor</em><em> | </em><em>None</em><em>] </em><em>| </em><em>None</em>) – Function for generating initial conditions. Not needed when
<cite>batch_initial_conditions</cite> are provided. Defaults to
<cite>gen_one_shot_kg_initial_conditions</cite> for <cite>qKnowledgeGradient</cite> acquisition
functions and <cite>gen_batch_initial_conditions</cite> otherwise. Must be specified
for nonlinear inequality constraints.</p></li>
<li><p><strong>ic_gen_kwargs</strong> (<em>dict</em><em> | </em><em>None</em>) – Additional keyword arguments passed to function specified by
<cite>ic_generator</cite></p></li>
<li><p><strong>inequality_constraints</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>equality_constraints</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>A two-element tuple containing</p>
<ul class="simple">
<li><p>a <cite>q x d</cite>-dim tensor of generated candidates.</p></li>
<li><dl class="simple">
<dt>a <cite>q</cite>-dim tensor of expected acquisition values, where the value at</dt><dd><p>index <cite>i</cite> is the acquisition value conditional on having observed
all candidates except candidate <cite>i</cite>.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple[<em>Tensor</em>, <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.optimize.optimize_acqf_mixed">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.optimize.</span></span><span class="sig-name descname"><span class="pre">optimize_acqf_mixed</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_restarts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_features_list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raw_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inequality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">equality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nonlinear_inequality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post_processing_func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_initial_conditions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_best_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gen_candidates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ic_generator</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">timeout_sec</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retry_on_optimization_warning</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ic_gen_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/optimize.html#optimize_acqf_mixed"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.optimize.optimize_acqf_mixed" title="Link to this definition"></a></dt>
<dd><p>Optimize over a list of fixed_features and returns the best solution.</p>
<p>This is useful for optimizing over mixed continuous and discrete domains.
For q &gt; 1 this function always performs sequential greedy optimization (with
proper conditioning on generated candidates).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<a class="reference internal" href="acquisition.html#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><em>AcquisitionFunction</em></a>) – An AcquisitionFunction</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – A <cite>2 x d</cite> tensor of lower and upper bounds for each column of <cite>X</cite>
(if inequality_constraints is provided, these bounds can be -inf and
+inf, respectively).</p></li>
<li><p><strong>q</strong> (<em>int</em>) – The number of candidates.</p></li>
<li><p><strong>num_restarts</strong> (<em>int</em>) – Number of starting points for multistart acquisition
function optimization.</p></li>
<li><p><strong>raw_samples</strong> (<em>int</em><em> | </em><em>None</em>) – Number of samples for initialization. This is required
if <cite>batch_initial_conditions</cite> is not specified.</p></li>
<li><p><strong>fixed_features_list</strong> (<em>list</em><em>[</em><em>dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>]</em><em>]</em>) – A list of maps <cite>{feature_index: value}</cite>. The i-th
item represents the fixed_feature for the i-th optimization. All
indices (<cite>feature_index</cite>) should be non-negative.</p></li>
<li><p><strong>options</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>bool</em><em> | </em><em>float</em><em> | </em><em>int</em><em> | </em><em>str</em><em>] </em><em>| </em><em>None</em>) – Options for candidate generation.</p></li>
<li><p><strong>constraints</strong> (<em>equality</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) &gt;= rhs</cite></p></li>
<li><p><strong>constraints</strong> – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) = rhs</cite></p></li>
<li><p><strong>nonlinear_inequality_constraints</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>Callable</em><em>, </em><em>bool</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of tuples representing the nonlinear
inequality constraints. The first element in the tuple is a callable
representing a constraint of the form <cite>callable(x) &gt;= 0</cite>. In case of an
intra-point constraint, <cite>callable()`takes in an one-dimensional tensor of
shape `d</cite> and returns a scalar. In case of an inter-point constraint,
<cite>callable()</cite> takes a two dimensional tensor of shape <cite>q x d</cite> and again
returns a scalar. The second element is a boolean, indicating if it is an
intra-point or inter-point constraint (<cite>True</cite> for intra-point. <cite>False</cite> for
inter-point). For more information on intra-point vs inter-point
constraints, see the docstring of the <cite>inequality_constraints</cite> argument to
<cite>optimize_acqf()</cite>. The constraints will later be passed to the scipy
solver. You need to pass in <cite>batch_initial_conditions</cite> in this case.
Using non-linear inequality constraints also requires that <cite>batch_limit</cite>
is set to 1, which will be done automatically if not specified in
<cite>options</cite>.</p></li>
<li><p><strong>post_processing_func</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – A function that post-processes an optimization
result appropriately (i.e., according to <cite>round-trip</cite>
transformations).</p></li>
<li><p><strong>batch_initial_conditions</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A tensor to specify the initial conditions. Set
this if you do not want to use default initialization strategy.</p></li>
<li><p><strong>return_best_only</strong> (<em>bool</em>) – If False, outputs the solutions corresponding to all
random restart initializations of the optimization. Setting this keyword
to False is only allowed for <cite>q=1</cite>. Defaults to True.</p></li>
<li><p><strong>gen_candidates</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>, </em><a class="reference internal" href="acquisition.html#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><em>AcquisitionFunction</em></a><em>, </em><em>Any</em><em>]</em><em>, </em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A callable for generating candidates (and their associated
acquisition values) given a tensor of initial conditions and an
acquisition function. Other common inputs include lower and upper bounds
and a dictionary of options, but refer to the documentation of specific
generation functions (e.g gen_candidates_scipy and gen_candidates_torch)
for method-specific inputs. Default: <cite>gen_candidates_scipy</cite></p></li>
<li><p><strong>ic_generator</strong> (<em>Callable</em><em>[</em><em>[</em><a class="reference internal" href="acquisition.html#botorch.acquisition.knowledge_gradient.qKnowledgeGradient" title="botorch.acquisition.knowledge_gradient.qKnowledgeGradient"><em>qKnowledgeGradient</em></a><em>, </em><em>Tensor</em><em>, </em><em>int</em><em>, </em><em>int</em><em>, </em><em>int</em><em>, </em><em>dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>] </em><em>| </em><em>None</em><em>, </em><em>dict</em><em>[</em><em>str</em><em>, </em><em>bool</em><em> | </em><em>float</em><em> | </em><em>int</em><em>] </em><em>| </em><em>None</em><em>, </em><em>list</em><em>[</em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em><em>, </em><em>list</em><em>[</em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em><em>]</em><em>, </em><em>Tensor</em><em> | </em><em>None</em><em>] </em><em>| </em><em>None</em>) – Function for generating initial conditions. Not needed when
<cite>batch_initial_conditions</cite> are provided. Defaults to
<cite>gen_one_shot_kg_initial_conditions</cite> for <cite>qKnowledgeGradient</cite> acquisition
functions and <cite>gen_batch_initial_conditions</cite> otherwise. Must be specified
for nonlinear inequality constraints.</p></li>
<li><p><strong>timeout_sec</strong> (<em>float</em><em> | </em><em>None</em>) – Max amount of time optimization can run for.</p></li>
<li><p><strong>retry_on_optimization_warning</strong> (<em>bool</em>) – Whether to retry candidate generation with a new
set of initial conditions when it fails with an <cite>OptimizationWarning</cite>.</p></li>
<li><p><strong>ic_gen_kwargs</strong> (<em>dict</em><em> | </em><em>None</em>) – Additional keyword arguments passed to function specified by
<cite>ic_generator</cite></p></li>
<li><p><strong>inequality_constraints</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>equality_constraints</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>A two-element tuple containing</p>
<ul class="simple">
<li><dl class="simple">
<dt>A tensor of generated candidates. The shape is</dt><dd><p>– <cite>q x d</cite> if <cite>return_best_only</cite> is True (default)
– <cite>num_restarts x q x d</cite> if <cite>return_best_only</cite> is False</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>a tensor of associated acquisition values of dim <cite>num_restarts</cite></dt><dd><p>if <cite>return_best_only=False</cite> else a scalar acquisition value.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple[<em>Tensor</em>, <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.optimize.optimize_acqf_discrete">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.optimize.</span></span><span class="sig-name descname"><span class="pre">optimize_acqf_discrete</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">choices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2048</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unique</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_avoid</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inequality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/optimize.html#optimize_acqf_discrete"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.optimize.optimize_acqf_discrete" title="Link to this definition"></a></dt>
<dd><p>Optimize over a discrete set of points using batch evaluation.</p>
<p>For <cite>q &gt; 1</cite> this function generates candidates by means of sequential
conditioning (rather than joint optimization), since for all but the
smalles number of choices the set <cite>choices^q</cite> of discrete points to
evaluate quickly explodes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<a class="reference internal" href="acquisition.html#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><em>AcquisitionFunction</em></a>) – An AcquisitionFunction.</p></li>
<li><p><strong>q</strong> (<em>int</em>) – The number of candidates.</p></li>
<li><p><strong>choices</strong> (<em>Tensor</em>) – A <cite>num_choices x d</cite> tensor of possible choices.</p></li>
<li><p><strong>max_batch_size</strong> (<em>int</em>) – The maximum number of choices to evaluate in batch.
A large limit can cause excessive memory usage if the model has
a large training set.</p></li>
<li><p><strong>unique</strong> (<em>bool</em>) – If True return unique choices, o/w choices may be repeated
(only relevant if <cite>q &gt; 1</cite>).</p></li>
<li><p><strong>X_avoid</strong> (<em>Tensor</em><em> | </em><em>None</em>) – An <cite>n x d</cite> tensor of candidates that we aren’t allowed to pick.
These will be removed from the set of choices.</p></li>
<li><p><strong>constraints</strong> (<em>inequality</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) &gt;= rhs</cite>.
Infeasible points will be removed from the set of choices.</p></li>
<li><p><strong>inequality_constraints</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>A two-element tuple containing</p>
<ul class="simple">
<li><p>a <cite>q x d</cite>-dim tensor of generated candidates.</p></li>
<li><p>an associated acquisition value.</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple[<em>Tensor</em>, <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.optimize.optimize_acqf_discrete_local_search">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.optimize.</span></span><span class="sig-name descname"><span class="pre">optimize_acqf_discrete_local_search</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discrete_choices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_restarts</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raw_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4096</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inequality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_avoid</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_initial_conditions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2048</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_tries</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unique</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/optimize.html#optimize_acqf_discrete_local_search"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.optimize.optimize_acqf_discrete_local_search" title="Link to this definition"></a></dt>
<dd><p>Optimize acquisition function over a lattice.</p>
<p>This is useful when d is large and enumeration of the search space
isn’t possible. For q &gt; 1 this function always performs sequential
greedy optimization (with proper conditioning on generated candidates).</p>
<p>NOTE: While this method supports arbitrary lattices, it has only been
thoroughly tested for {0, 1}^d. Consider it to be in alpha stage for
the more general case.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<a class="reference internal" href="acquisition.html#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><em>AcquisitionFunction</em></a>) – An AcquisitionFunction</p></li>
<li><p><strong>discrete_choices</strong> (<em>list</em><em>[</em><em>Tensor</em><em>]</em>) – A list of possible discrete choices for each dimension.
Each element in the list is expected to be a torch tensor.</p></li>
<li><p><strong>q</strong> (<em>int</em>) – The number of candidates.</p></li>
<li><p><strong>num_restarts</strong> (<em>int</em>) – Number of starting points for multistart acquisition
function optimization.</p></li>
<li><p><strong>raw_samples</strong> (<em>int</em>) – Number of samples for initialization. This is required
if <cite>batch_initial_conditions</cite> is not specified.</p></li>
<li><p><strong>inequality_constraints</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) &gt;= rhs</cite></p></li>
<li><p><strong>X_avoid</strong> (<em>Tensor</em><em> | </em><em>None</em>) – An <cite>n x d</cite> tensor of candidates that we aren’t allowed to pick.</p></li>
<li><p><strong>batch_initial_conditions</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A tensor of size <cite>n x 1 x d</cite> to specify the
initial conditions. Set this if you do not want to use default
initialization strategy.</p></li>
<li><p><strong>max_batch_size</strong> (<em>int</em>) – The maximum number of choices to evaluate in batch.
A large limit can cause excessive memory usage if the model has
a large training set.</p></li>
<li><p><strong>max_tries</strong> (<em>int</em>) – Maximum number of iterations to try when generating initial
conditions.</p></li>
<li><p><strong>unique</strong> (<em>bool</em>) – If True return unique choices, o/w choices may be repeated
(only relevant if <cite>q &gt; 1</cite>).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>A two-element tuple containing</p>
<ul class="simple">
<li><p>a <cite>q x d</cite>-dim tensor of generated candidates.</p></li>
<li><p>an associated acquisition value.</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple[<em>Tensor</em>, <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-botorch.optim.fit">
<span id="model-fitting-optimization"></span><h3>Model Fitting Optimization<a class="headerlink" href="#module-botorch.optim.fit" title="Link to this heading"></a></h3>
<p>Tools for model fitting.</p>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.fit.fit_gpytorch_mll_scipy">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.fit.</span></span><span class="sig-name descname"><span class="pre">fit_gpytorch_mll_scipy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mll</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parameters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">closure</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">closure_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'L-BFGS-B'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">timeout_sec</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/fit.html#fit_gpytorch_mll_scipy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.fit.fit_gpytorch_mll_scipy" title="Link to this definition"></a></dt>
<dd><p>Generic scipy.optimized-based fitting routine for GPyTorch MLLs.</p>
<p>The model and likelihood in mll must already be in train mode.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mll</strong> (<em>MarginalLogLikelihood</em>) – MarginalLogLikelihood to be maximized.</p></li>
<li><p><strong>parameters</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – Optional dictionary of parameters to be optimized. Defaults
to all parameters of <cite>mll</cite> that require gradients.</p></li>
<li><p><strong>bounds</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>tuple</em><em>[</em><em>float</em><em> | </em><em>None</em><em>, </em><em>float</em><em> | </em><em>None</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A dictionary of user-specified bounds for <cite>parameters</cite>. Used to update
default parameter bounds obtained from <cite>mll</cite>.</p></li>
<li><p><strong>closure</strong> (<em>Callable</em><em>[</em><em>[</em><em>]</em><em>, </em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Sequence</em><em>[</em><em>Tensor</em><em> | </em><em>None</em><em>]</em><em>]</em><em>] </em><em>| </em><em>None</em>) – Callable that returns a tensor and an iterable of gradient tensors.
Responsible for setting the <cite>grad</cite> attributes of <cite>parameters</cite>. If no closure
is provided, one will be obtained by calling <cite>get_loss_closure_with_grads</cite>.</p></li>
<li><p><strong>closure_kwargs</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Keyword arguments passed to <cite>closure</cite>.</p></li>
<li><p><strong>method</strong> (<em>str</em>) – Solver type, passed along to scipy.minimize.</p></li>
<li><p><strong>options</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Dictionary of solver options, passed along to scipy.minimize.</p></li>
<li><p><strong>callback</strong> (<em>Callable</em><em>[</em><em>[</em><em>dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em><em>, </em><a class="reference internal" href="#botorch.optim.core.OptimizationResult" title="botorch.optim.core.OptimizationResult"><em>OptimizationResult</em></a><em>]</em><em>, </em><em>None</em><em>] </em><em>| </em><em>None</em>) – Optional callback taking <cite>parameters</cite> and an OptimizationResult as its
sole arguments.</p></li>
<li><p><strong>timeout_sec</strong> (<em>float</em><em> | </em><em>None</em>) – Timeout in seconds after which to terminate the fitting loop
(note that timing out can result in bad fits!).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The final OptimizationResult.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.optim.core.OptimizationResult" title="botorch.optim.core.OptimizationResult"><em>OptimizationResult</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.fit.fit_gpytorch_mll_torch">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.fit.</span></span><span class="sig-name descname"><span class="pre">fit_gpytorch_mll_torch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mll</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parameters=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">closure=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">closure_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">step_limit=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopping_criterion=&lt;class</span> <span class="pre">'botorch.utils.types.DEFAULT'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer=&lt;class</span> <span class="pre">'torch.optim.adam.Adam'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scheduler=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">timeout_sec=None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/fit.html#fit_gpytorch_mll_torch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.fit.fit_gpytorch_mll_torch" title="Link to this definition"></a></dt>
<dd><p>Generic torch.optim-based fitting routine for GPyTorch MLLs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mll</strong> (<em>MarginalLogLikelihood</em>) – MarginalLogLikelihood to be maximized.</p></li>
<li><p><strong>parameters</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – Optional dictionary of parameters to be optimized. Defaults
to all parameters of <cite>mll</cite> that require gradients.</p></li>
<li><p><strong>bounds</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>tuple</em><em>[</em><em>float</em><em> | </em><em>None</em><em>, </em><em>float</em><em> | </em><em>None</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A dictionary of user-specified bounds for <cite>parameters</cite>. Used to update
default parameter bounds obtained from <cite>mll</cite>.</p></li>
<li><p><strong>closure</strong> (<em>Callable</em><em>[</em><em>[</em><em>]</em><em>, </em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Sequence</em><em>[</em><em>Tensor</em><em> | </em><em>None</em><em>]</em><em>]</em><em>] </em><em>| </em><em>None</em>) – Callable that returns a tensor and an iterable of gradient tensors.
Responsible for setting the <cite>grad</cite> attributes of <cite>parameters</cite>. If no closure
is provided, one will be obtained by calling <cite>get_loss_closure_with_grads</cite>.</p></li>
<li><p><strong>closure_kwargs</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Keyword arguments passed to <cite>closure</cite>.</p></li>
<li><p><strong>step_limit</strong> (<em>int</em><em> | </em><em>None</em>) – Optional upper bound on the number of optimization steps.</p></li>
<li><p><strong>stopping_criterion</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>bool</em><em>] </em><em>| </em><em>None</em>) – A StoppingCriterion for the optimization loop.</p></li>
<li><p><strong>optimizer</strong> (<em>Optimizer</em><em> | </em><em>Callable</em><em>[</em><em>[</em><em>...</em><em>]</em><em>, </em><em>Optimizer</em><em>]</em>) – A <cite>torch.optim.Optimizer</cite> instance or a factory that takes
a list of parameters and returns an <cite>Optimizer</cite> instance.</p></li>
<li><p><strong>scheduler</strong> (<em>_LRScheduler</em><em> | </em><em>Callable</em><em>[</em><em>[</em><em>...</em><em>]</em><em>, </em><em>_LRScheduler</em><em>] </em><em>| </em><em>None</em>) – A <cite>torch.optim.lr_scheduler._LRScheduler</cite> instance or a factory
that takes an <cite>Optimizer</cite> instance and returns an <cite>_LRSchedule</cite>.</p></li>
<li><p><strong>callback</strong> (<em>Callable</em><em>[</em><em>[</em><em>dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em><em>, </em><a class="reference internal" href="#botorch.optim.core.OptimizationResult" title="botorch.optim.core.OptimizationResult"><em>OptimizationResult</em></a><em>]</em><em>, </em><em>None</em><em>] </em><em>| </em><em>None</em>) – Optional callback taking <cite>parameters</cite> and an OptimizationResult as its
sole arguments.</p></li>
<li><p><strong>timeout_sec</strong> (<em>float</em><em> | </em><em>None</em>) – Timeout in seconds after which to terminate the fitting loop
(note that timing out can result in bad fits!).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The final OptimizationResult.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.optim.core.OptimizationResult" title="botorch.optim.core.OptimizationResult"><em>OptimizationResult</em></a></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-botorch.optim.initializers">
<span id="initialization-helpers"></span><h3>Initialization Helpers<a class="headerlink" href="#module-botorch.optim.initializers" title="Link to this heading"></a></h3>
<p>References</p>
<div role="list" class="citation-list">
<div class="citation" id="regis" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Regis<span class="fn-bracket">]</span></span>
<p>R. G. Regis, C. A. Shoemaker. Combining radial basis function
surrogates and dynamic coordinate search in high-dimensional
expensive black-box optimization, Engineering Optimization, 2013.</p>
</div>
</div>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.initializers.transform_constraints">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.initializers.</span></span><span class="sig-name descname"><span class="pre">transform_constraints</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">constraints</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/initializers.html#transform_constraints"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.initializers.transform_constraints" title="Link to this definition"></a></dt>
<dd><p>Transform constraints to sample from a d*q-dimensional space instead of a
d-dimensional state.</p>
<p>This function assumes that constraints are the same for each input batch,
and broadcasts the constraints accordingly to the input batch shape.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>constraints</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of tuples (indices, coefficients, rhs), with each tuple
encoding an (in-)equality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) (&gt;)= rhs</cite>.
If <cite>indices</cite> is a 2-d Tensor, this supports specifying constraints across
the points in the <cite>q</cite>-batch (inter-point constraints). If <cite>None</cite>, this
function is a nullop and simply returns <cite>None</cite>.</p></li>
<li><p><strong>q</strong> (<em>int</em>) – Size of the <cite>q</cite>-batch.</p></li>
<li><p><strong>d</strong> (<em>int</em>) – Dimensionality of the problem.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of transformed constraints, if
there are constraints. Returns <cite>None</cite> otherwise.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[Tuple[Tensor, Tensor, float]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.initializers.transform_intra_point_constraint">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.initializers.</span></span><span class="sig-name descname"><span class="pre">transform_intra_point_constraint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">constraint</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/initializers.html#transform_intra_point_constraint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.initializers.transform_intra_point_constraint" title="Link to this definition"></a></dt>
<dd><p>Transforms an intra-point/pointwise constraint from
d-dimensional space to a d*q-dimesional space.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>constraints</strong> – A list of tuples (indices, coefficients, rhs), with each tuple
encoding an (in-)equality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) (&gt;)= rhs</cite>. Here <cite>indices</cite> must
be one-dimensional, and the constraint is applied to all points within the
<cite>q</cite>-batch.</p></li>
<li><p><strong>d</strong> (<em>int</em>) – Dimensionality of the problem.</p></li>
<li><p><strong>constraint</strong> (<em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em>)</p></li>
<li><p><strong>q</strong> (<em>int</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If indices in the constraints are larger than the
    dimensionality d of the problem.</p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>List of transformed constraints.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>List[Tuple[Tensor, Tensor, float]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.initializers.transform_inter_point_constraint">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.initializers.</span></span><span class="sig-name descname"><span class="pre">transform_inter_point_constraint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">constraint</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/initializers.html#transform_inter_point_constraint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.initializers.transform_inter_point_constraint" title="Link to this definition"></a></dt>
<dd><p>Transforms an inter-point constraint from
d-dimensional space to a d*q dimesional space.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>constraints</strong> – A list of tuples (indices, coefficients, rhs), with each tuple
encoding an (in-)equality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) (&gt;)= rhs</cite>. <cite>indices</cite> must be a
2-d Tensor, where in each row <cite>indices[i] = (k_i, l_i)</cite> the first index
<cite>k_i</cite> corresponds to the <cite>k_i</cite>-th element of the <cite>q</cite>-batch and the second
index <cite>l_i</cite> corresponds to the <cite>l_i</cite>-th feature of that element.</p></li>
<li><p><strong>constraint</strong> (<em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em>)</p></li>
<li><p><strong>d</strong> (<em>int</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If indices in the constraints are larger than the
    dimensionality d of the problem.</p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Transformed constraint.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>List[Tuple[Tensor, Tensor, float]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.initializers.sample_q_batches_from_polytope">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.initializers.</span></span><span class="sig-name descname"><span class="pre">sample_q_batches_from_polytope</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_burnin</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_thinning</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inequality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">equality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/initializers.html#sample_q_batches_from_polytope"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.initializers.sample_q_batches_from_polytope" title="Link to this definition"></a></dt>
<dd><p>Samples <cite>n</cite> q-baches from a polytope of dimension <cite>d</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n</strong> (<em>int</em>) – Number of q-batches to sample.</p></li>
<li><p><strong>q</strong> (<em>int</em>) – Number of samples per q-batch</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – A <cite>2 x d</cite> tensor of lower and upper bounds for each column of <cite>X</cite>.</p></li>
<li><p><strong>n_burnin</strong> (<em>int</em>) – The number of burn-in samples for the Markov chain sampler.</p></li>
<li><p><strong>n_thinning</strong> (<em>int</em>) – The amount of thinning. The sampler will return every
<cite>n_thinning</cite> sample (after burn-in).</p></li>
<li><p><strong>seed</strong> (<em>int</em><em> | </em><em>None</em>) – The random seed.</p></li>
<li><p><strong>inequality_constraints</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) &gt;= rhs</cite>.</p></li>
<li><p><strong>equality_constraints</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) = rhs</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>n x q x d</cite>-dim tensor of samples.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.initializers.gen_batch_initial_conditions">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.initializers.</span></span><span class="sig-name descname"><span class="pre">gen_batch_initial_conditions</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_restarts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raw_samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inequality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">equality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">generator</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_X_fantasies</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/initializers.html#gen_batch_initial_conditions"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.initializers.gen_batch_initial_conditions" title="Link to this definition"></a></dt>
<dd><p>Generate a batch of initial conditions for random-restart optimziation.</p>
<p>TODO: Support t-batches of initial conditions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<a class="reference internal" href="acquisition.html#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><em>AcquisitionFunction</em></a>) – The acquisition function to be optimized.</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – A <cite>2 x d</cite> tensor of lower and upper bounds for each column of <cite>X</cite>.</p></li>
<li><p><strong>q</strong> (<em>int</em>) – The number of candidates to consider.</p></li>
<li><p><strong>num_restarts</strong> (<em>int</em>) – The number of starting points for multistart acquisition
function optimization.</p></li>
<li><p><strong>raw_samples</strong> (<em>int</em>) – The number of raw samples to consider in the initialization
heuristic. Note: if <cite>sample_around_best</cite> is True (the default is False),
then <cite>2 * raw_samples</cite> samples are used.</p></li>
<li><p><strong>fixed_features</strong> (<em>dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>] </em><em>| </em><em>None</em>) – A map <cite>{feature_index: value}</cite> for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>options</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>bool</em><em> | </em><em>float</em><em> | </em><em>int</em><em>] </em><em>| </em><em>None</em>) – Options for initial condition generation. For valid options see
<cite>initialize_q_batch_topn</cite>, <cite>initialize_q_batch_nonneg</cite>, and
<cite>initialize_q_batch</cite>. If <cite>options</cite> contains a <cite>topn=True</cite> then
<cite>initialize_q_batch_topn</cite> will be used. Else if <cite>options</cite> contains a
<cite>nonnegative=True</cite> entry, then <cite>acq_function</cite> is assumed to be
non-negative (useful when using custom acquisition functions).
<cite>initialize_q_batch</cite> will be used otherwise. In addition, an
“init_batch_limit” option can be passed to specify the batch limit
for the initialization. This is useful for avoiding memory limits
when computing the batch posterior over raw samples.</p></li>
<li><p><strong>constraints</strong> (<em>equality</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) &gt;= rhs</cite>.</p></li>
<li><p><strong>constraints</strong> – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) = rhs</cite>.</p></li>
<li><p><strong>generator</strong> (<em>Callable</em><em>[</em><em>[</em><em>int</em><em>, </em><em>int</em><em>, </em><em>int</em><em> | </em><em>None</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – Callable for generating samples that are then further
processed. It receives <cite>n</cite>, <cite>q</cite> and <cite>seed</cite> as arguments
and returns a tensor of shape <cite>n x q x d</cite>.</p></li>
<li><p><strong>fixed_X_fantasies</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A fixed set of fantasy points to concatenate to
the <cite>q</cite> candidates being initialized along the <cite>-2</cite> dimension. The
shape should be <cite>num_pseudo_points x d</cite>. E.g., this should be
<cite>num_fantasies x d</cite> for KG and <cite>num_fantasies*num_pareto x d</cite>
for HVKG.</p></li>
<li><p><strong>inequality_constraints</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>equality_constraints</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>num_restarts x q x d</cite> tensor of initial conditions.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">qEI</span> <span class="o">=</span> <span class="n">qExpectedImprovement</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">best_f</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bounds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Xinit</span> <span class="o">=</span> <span class="n">gen_batch_initial_conditions</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">qEI</span><span class="p">,</span> <span class="n">bounds</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">num_restarts</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">raw_samples</span><span class="o">=</span><span class="mi">500</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.initializers.gen_one_shot_kg_initial_conditions">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.initializers.</span></span><span class="sig-name descname"><span class="pre">gen_one_shot_kg_initial_conditions</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_restarts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raw_samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inequality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">equality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/initializers.html#gen_one_shot_kg_initial_conditions"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.initializers.gen_one_shot_kg_initial_conditions" title="Link to this definition"></a></dt>
<dd><p>Generate a batch of smart initializations for qKnowledgeGradient.</p>
<p>This function generates initial conditions for optimizing one-shot KG using
the maximizer of the posterior objective. Intutively, the maximizer of the
fantasized posterior will often be close to a maximizer of the current
posterior. This function uses that fact to generate the initial conditions
for the fantasy points. Specifically, a fraction of <cite>1 - frac_random</cite> (see
options) is generated by sampling from the set of maximizers of the
posterior objective (obtained via random restart optimization) according to
a softmax transformation of their respective values. This means that this
initialization strategy internally solves an acquisition function
maximization problem. The remaining <cite>frac_random</cite> fantasy points as well as
all <cite>q</cite> candidate points are chosen according to the standard initialization
strategy in <cite>gen_batch_initial_conditions</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<a class="reference internal" href="acquisition.html#botorch.acquisition.knowledge_gradient.qKnowledgeGradient" title="botorch.acquisition.knowledge_gradient.qKnowledgeGradient"><em>qKnowledgeGradient</em></a>) – The qHypervolumeKnowledgeGradient instance to be optimized.</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – A <cite>2 x d</cite> tensor of lower and upper bounds for each column of
task features.</p></li>
<li><p><strong>q</strong> (<em>int</em>) – The number of candidates to consider.</p></li>
<li><p><strong>num_restarts</strong> (<em>int</em>) – The number of starting points for multistart acquisition
function optimization.</p></li>
<li><p><strong>raw_samples</strong> (<em>int</em>) – The number of raw samples to consider in the initialization
heuristic.</p></li>
<li><p><strong>fixed_features</strong> (<em>dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>] </em><em>| </em><em>None</em>) – A map <cite>{feature_index: value}</cite> for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>options</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>bool</em><em> | </em><em>float</em><em> | </em><em>int</em><em>] </em><em>| </em><em>None</em>) – Options for initial condition generation. These contain all
settings for the standard heuristic initialization from
<cite>gen_batch_initial_conditions</cite>. In addition, they contain
<cite>frac_random</cite> (the fraction of fully random fantasy points),
<cite>num_inner_restarts</cite> and <cite>raw_inner_samples</cite> (the number of random
restarts and raw samples for solving the posterior objective
maximization problem, respectively) and <cite>eta</cite> (temperature parameter
for sampling heuristic from posterior objective maximizers).</p></li>
<li><p><strong>constraints</strong> (<em>equality</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) &gt;= rhs</cite>.</p></li>
<li><p><strong>constraints</strong> – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) = rhs</cite>.</p></li>
<li><p><strong>inequality_constraints</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>equality_constraints</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>num_restarts x q’ x d</cite> tensor that can be used as initial conditions
for <cite>optimize_acqf()</cite>. Here <cite>q’ = q + num_fantasies</cite> is the total number
of points (candidate points plus fantasy points).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em> | None</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">qHVKG</span> <span class="o">=</span> <span class="n">qHypervolumeKnowledgeGradient</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">ref_point</span><span class="o">=</span><span class="n">num_fantasies</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bounds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Xinit</span> <span class="o">=</span> <span class="n">gen_one_shot_hvkg_initial_conditions</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">qHVKG</span><span class="p">,</span> <span class="n">bounds</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">num_restarts</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">raw_samples</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;frac_random&quot;</span><span class="p">:</span> <span class="mf">0.25</span><span class="p">},</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.initializers.gen_one_shot_hvkg_initial_conditions">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.initializers.</span></span><span class="sig-name descname"><span class="pre">gen_one_shot_hvkg_initial_conditions</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_restarts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raw_samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inequality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">equality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/initializers.html#gen_one_shot_hvkg_initial_conditions"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.initializers.gen_one_shot_hvkg_initial_conditions" title="Link to this definition"></a></dt>
<dd><p>Generate a batch of smart initializations for qHypervolumeKnowledgeGradient.</p>
<p>This function generates initial conditions for optimizing one-shot HVKG using
the hypervolume maximizing set (of fixed size) under the posterior mean.
Intutively, the hypervolume maximizing set of the fantasized posterior mean
will often be close to a hypervolume maximizing set under the current posterior
mean. This function uses that fact to generate the initial conditions
for the fantasy points. Specifically, a fraction of <cite>1 - frac_random</cite> (see
options) of the restarts are generated by learning the hypervolume maximizing sets
under the current posterior mean, where each hypervolume maximizing set is
obtained from maximizing the hypervolume from a different starting point. Given
a hypervolume maximizing set, the <cite>q</cite> candidate points are selected using to the
standard initialization strategy in <cite>gen_batch_initial_conditions</cite>, with the fixed
hypervolume maximizing set. The remaining <cite>frac_random</cite> restarts fantasy points
as well as all <cite>q</cite> candidate points are chosen according to the standard
initialization strategy in <cite>gen_batch_initial_conditions</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<a class="reference internal" href="acquisition.html#botorch.acquisition.multi_objective.hypervolume_knowledge_gradient.qHypervolumeKnowledgeGradient" title="botorch.acquisition.multi_objective.hypervolume_knowledge_gradient.qHypervolumeKnowledgeGradient"><em>qHypervolumeKnowledgeGradient</em></a>) – The qKnowledgeGradient instance to be optimized.</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – A <cite>2 x d</cite> tensor of lower and upper bounds for each column of
task features.</p></li>
<li><p><strong>q</strong> (<em>int</em>) – The number of candidates to consider.</p></li>
<li><p><strong>num_restarts</strong> (<em>int</em>) – The number of starting points for multistart acquisition
function optimization.</p></li>
<li><p><strong>raw_samples</strong> (<em>int</em>) – The number of raw samples to consider in the initialization
heuristic.</p></li>
<li><p><strong>fixed_features</strong> (<em>dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>] </em><em>| </em><em>None</em>) – A map <cite>{feature_index: value}</cite> for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>options</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>bool</em><em> | </em><em>float</em><em> | </em><em>int</em><em>] </em><em>| </em><em>None</em>) – Options for initial condition generation. These contain all
settings for the standard heuristic initialization from
<cite>gen_batch_initial_conditions</cite>. In addition, they contain
<cite>frac_random</cite> (the fraction of fully random fantasy points),
<cite>num_inner_restarts</cite> and <cite>raw_inner_samples</cite> (the number of random
restarts and raw samples for solving the posterior objective
maximization problem, respectively) and <cite>eta</cite> (temperature parameter
for sampling heuristic from posterior objective maximizers).</p></li>
<li><p><strong>constraints</strong> (<em>equality</em>) – Optionally, list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) &gt;= rhs</cite>. Each
tensor of indices must be one-dimensional, since inter-point
constraints are not supported here.</p></li>
<li><p><strong>constraints</strong> – Optionally, a list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) = rhs</cite>.</p></li>
<li><p><strong>inequality_constraints</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>equality_constraints</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>num_restarts x q’ x d</cite> tensor that can be used as initial conditions
for <cite>optimize_acqf()</cite>. Here <cite>q’ = q + num_fantasies</cite> is the total number
of points (candidate points plus fantasy points).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em> | None</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">qHVKG</span> <span class="o">=</span> <span class="n">qHypervolumeKnowledgeGradient</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">ref_point</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bounds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Xinit</span> <span class="o">=</span> <span class="n">gen_one_shot_hvkg_initial_conditions</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">qHVKG</span><span class="p">,</span> <span class="n">bounds</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">num_restarts</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">raw_samples</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;frac_random&quot;</span><span class="p">:</span> <span class="mf">0.25</span><span class="p">},</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.initializers.gen_value_function_initial_conditions">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.initializers.</span></span><span class="sig-name descname"><span class="pre">gen_value_function_initial_conditions</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_restarts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raw_samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">current_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/initializers.html#gen_value_function_initial_conditions"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.initializers.gen_value_function_initial_conditions" title="Link to this definition"></a></dt>
<dd><p>Generate a batch of smart initializations for optimizing
the value function of qKnowledgeGradient.</p>
<p>This function generates initial conditions for optimizing the inner problem of
KG, i.e. its value function, using the maximizer of the posterior objective.
Intutively, the maximizer of the fantasized posterior will often be close to a
maximizer of the current posterior. This function uses that fact to generate the
initital conditions for the fantasy points. Specifically, a fraction of <cite>1 -
frac_random</cite> (see options) of raw samples is generated by sampling from the set of
maximizers of the posterior objective (obtained via random restart optimization)
according to a softmax transformation of their respective values. This means that
this initialization strategy internally solves an acquisition function
maximization problem. The remaining raw samples are generated using
<cite>draw_sobol_samples</cite>. All raw samples are then evaluated, and the initial
conditions are selected according to the standard initialization strategy in
‘initialize_q_batch’ individually for each inner problem.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<a class="reference internal" href="acquisition.html#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><em>AcquisitionFunction</em></a>) – The value function instance to be optimized.</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – A <cite>2 x d</cite> tensor of lower and upper bounds for each column of
task features.</p></li>
<li><p><strong>num_restarts</strong> (<em>int</em>) – The number of starting points for multistart acquisition
function optimization.</p></li>
<li><p><strong>raw_samples</strong> (<em>int</em>) – The number of raw samples to consider in the initialization
heuristic.</p></li>
<li><p><strong>current_model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – The model of the KG acquisition function that was used to
generate the fantasy model of the value function.</p></li>
<li><p><strong>fixed_features</strong> (<em>dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>] </em><em>| </em><em>None</em>) – A map <cite>{feature_index: value}</cite> for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>options</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>bool</em><em> | </em><em>float</em><em> | </em><em>int</em><em>] </em><em>| </em><em>None</em>) – Options for initial condition generation. These contain all
settings for the standard heuristic initialization from
<cite>gen_batch_initial_conditions</cite>. In addition, they contain
<cite>frac_random</cite> (the fraction of fully random fantasy points),
<cite>num_inner_restarts</cite> and <cite>raw_inner_samples</cite> (the number of random
restarts and raw samples for solving the posterior objective
maximization problem, respectively) and <cite>eta</cite> (temperature parameter
for sampling heuristic from posterior objective maximizers).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>num_restarts x batch_shape x q x d</cite> tensor that can be used as initial
conditions for <cite>optimize_acqf()</cite>. Here <cite>batch_shape</cite> is the batch shape
of value function model.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">fant_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fantasy_model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fantasize</span><span class="p">(</span><span class="n">fant_X</span><span class="p">,</span> <span class="n">SobolQMCNormalSampler</span><span class="p">(</span><span class="mi">16</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">value_function</span> <span class="o">=</span> <span class="n">PosteriorMean</span><span class="p">(</span><span class="n">fantasy_model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bounds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Xinit</span> <span class="o">=</span> <span class="n">gen_value_function_initial_conditions</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">value_function</span><span class="p">,</span> <span class="n">bounds</span><span class="p">,</span> <span class="n">num_restarts</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">raw_samples</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;frac_random&quot;</span><span class="p">:</span> <span class="mf">0.25</span><span class="p">},</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.initializers.initialize_q_batch">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.initializers.</span></span><span class="sig-name descname"><span class="pre">initialize_q_batch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">acq_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/initializers.html#initialize_q_batch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.initializers.initialize_q_batch" title="Link to this definition"></a></dt>
<dd><p>Heuristic for selecting initial conditions for candidate generation.</p>
<p>This heuristic selects points from <cite>X</cite> (without replacement) with probability
proportional to <cite>exp(eta * Z)</cite>, where
<cite>Z = (acq_vals - mean(acq_vals)) / std(acq_vals)</cite>
and <cite>eta</cite> is a temperature parameter.</p>
<p>When using an acquisiton function that is non-negative and possibly zero
over large areas of the feature space (e.g. qEI), you should use
<cite>initialize_q_batch_nonneg</cite> instead.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>b x batch_shape x q x d</cite> tensor of <cite>b</cite> - <cite>batch_shape</cite> samples of
<cite>q</cite>-batches from a d`-dim feature space. Typically, these are generated
using qMC sampling.</p></li>
<li><p><strong>acq_vals</strong> (<em>Tensor</em>) – A tensor of <cite>b x batch_shape</cite> outcomes associated with the samples.
Typically, this is the value of the batch acquisition function to be
maximized.</p></li>
<li><p><strong>n</strong> (<em>int</em>) – The number of initial condition to be generated. Must be less than <cite>b</cite>.</p></li>
<li><p><strong>eta</strong> (<em>float</em>) – Temperature parameter for weighting samples.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>An <cite>n x batch_shape x q x d</cite> tensor of <cite>n</cite> - <cite>batch_shape</cite> <cite>q</cite>-batch initial
conditions, where each batch of <cite>n x q x d</cite> samples is selected independently.</p></li>
<li><p>An <cite>n x batch_shape</cite> tensor of the corresponding acquisition values.</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple[<em>Tensor</em>, <em>Tensor</em>]</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># To get `n=10` starting points of q-batch size `q=3`</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># for model with `d=6`:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qUCB</span> <span class="o">=</span> <span class="n">qUpperConfidenceBound</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_rnd</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_init</span><span class="p">,</span> <span class="n">acq_init</span> <span class="o">=</span> <span class="n">initialize_q_batch</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X_rnd</span><span class="p">,</span> <span class="n">acq_vals</span><span class="o">=</span><span class="n">qUCB</span><span class="p">(</span><span class="n">X_rnd</span><span class="p">),</span> <span class="n">n</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.initializers.initialize_q_batch_nonneg">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.initializers.</span></span><span class="sig-name descname"><span class="pre">initialize_q_batch_nonneg</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">acq_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/initializers.html#initialize_q_batch_nonneg"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.initializers.initialize_q_batch_nonneg" title="Link to this definition"></a></dt>
<dd><p>Heuristic for selecting initial conditions for non-neg. acquisition functions.</p>
<p>This function is similar to <cite>initialize_q_batch</cite>, but designed specifically
for acquisition functions that are non-negative and possibly zero over
large areas of the feature space (e.g. qEI). All samples for which
<cite>acq_vals &lt; alpha * max(acq_vals)</cite> will be ignored (assuming that <cite>acq_vals</cite>
contains at least one positive value).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>b x q x d</cite> tensor of <cite>b</cite> samples of <cite>q</cite>-batches from a <cite>d</cite>-dim.
feature space. Typically, these are generated using qMC.</p></li>
<li><p><strong>acq_vals</strong> (<em>Tensor</em>) – A tensor of <cite>b</cite> outcomes associated with the samples. Typically, this
is the value of the batch acquisition function to be maximized.</p></li>
<li><p><strong>n</strong> (<em>int</em>) – The number of initial condition to be generated. Must be less than <cite>b</cite>.</p></li>
<li><p><strong>eta</strong> (<em>float</em>) – Temperature parameter for weighting samples.</p></li>
<li><p><strong>alpha</strong> (<em>float</em>) – The threshold (as a fraction of the maximum observed value) under
which to ignore samples. All input samples for which
<cite>Y &lt; alpha * max(Y)</cite> will be ignored.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>An <cite>n x q x d</cite> tensor of <cite>n</cite> <cite>q</cite>-batch initial conditions.</p></li>
<li><p>An <cite>n</cite> tensor of the corresponding acquisition values.</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple[<em>Tensor</em>, <em>Tensor</em>]</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># To get `n=10` starting points of q-batch size `q=3`</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># for model with `d=6`:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qEI</span> <span class="o">=</span> <span class="n">qExpectedImprovement</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">best_f</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_rnd</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_init</span><span class="p">,</span> <span class="n">acq_init</span> <span class="o">=</span> <span class="n">initialize_q_batch_nonneg</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">X</span><span class="o">=</span><span class="n">X_rnd</span><span class="p">,</span> <span class="n">acq_vals</span><span class="o">=</span><span class="n">qEI</span><span class="p">(</span><span class="n">X_rnd</span><span class="p">),</span> <span class="n">n</span><span class="o">=</span><span class="mi">10</span>
<span class="gp">... </span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.initializers.initialize_q_batch_topn">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.initializers.</span></span><span class="sig-name descname"><span class="pre">initialize_q_batch_topn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">acq_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">largest</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sorted</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/initializers.html#initialize_q_batch_topn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.initializers.initialize_q_batch_topn" title="Link to this definition"></a></dt>
<dd><p>Take the top <cite>n</cite> initial conditions for candidate generation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>b x q x d</cite> tensor of <cite>b</cite> samples of <cite>q</cite>-batches from a <cite>d</cite>-dim.
feature space. Typically, these are generated using qMC.</p></li>
<li><p><strong>acq_vals</strong> (<em>Tensor</em>) – A tensor of <cite>b</cite> outcomes associated with the samples. Typically, this
is the value of the batch acquisition function to be maximized.</p></li>
<li><p><strong>n</strong> (<em>int</em>) – The number of initial condition to be generated. Must be less than <cite>b</cite>.</p></li>
<li><p><strong>largest</strong> (<em>bool</em>)</p></li>
<li><p><strong>sorted</strong> (<em>bool</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>An <cite>n x q x d</cite> tensor of <cite>n</cite> <cite>q</cite>-batch initial conditions.</p></li>
<li><p>An <cite>n</cite> tensor of the corresponding acquisition values.</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple[<em>Tensor</em>, <em>Tensor</em>]</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># To get `n=10` starting points of q-batch size `q=3`</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># for model with `d=6`:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qUCB</span> <span class="o">=</span> <span class="n">qUpperConfidenceBound</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_rnd</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_init</span><span class="p">,</span> <span class="n">acq_init</span> <span class="o">=</span> <span class="n">initialize_q_batch_topn</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">X</span><span class="o">=</span><span class="n">X_rnd</span><span class="p">,</span> <span class="n">acq_vals</span><span class="o">=</span><span class="n">qUCB</span><span class="p">(</span><span class="n">X_rnd</span><span class="p">),</span> <span class="n">n</span><span class="o">=</span><span class="mi">10</span>
<span class="gp">... </span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.initializers.sample_points_around_best">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.initializers.</span></span><span class="sig-name descname"><span class="pre">sample_points_around_best</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_discrete_points</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">best_pct</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subset_sigma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prob_perturb</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/initializers.html#sample_points_around_best"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.initializers.sample_points_around_best" title="Link to this definition"></a></dt>
<dd><p>Find best points and sample nearby points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<a class="reference internal" href="acquisition.html#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><em>AcquisitionFunction</em></a>) – The acquisition function.</p></li>
<li><p><strong>n_discrete_points</strong> (<em>int</em>) – The number of points to sample.</p></li>
<li><p><strong>sigma</strong> (<em>float</em>) – The standard deviation of the additive gaussian noise for
perturbing the best points.</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – A <cite>2 x d</cite>-dim tensor containing the bounds.</p></li>
<li><p><strong>best_pct</strong> (<em>float</em>) – The percentage of best points to perturb.</p></li>
<li><p><strong>subset_sigma</strong> (<em>float</em>) – The standard deviation of the additive gaussian
noise for perturbing a subset of dimensions of the best points.</p></li>
<li><p><strong>prob_perturb</strong> (<em>float</em><em> | </em><em>None</em>) – The probability of perturbing each dimension.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>An optional <cite>n_discrete_points x d</cite>-dim tensor containing the</dt><dd><p>sampled points. This is None if no baseline points are found.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em> | None</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.initializers.is_nonnegative">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.initializers.</span></span><span class="sig-name descname"><span class="pre">is_nonnegative</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/initializers.html#is_nonnegative"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.initializers.is_nonnegative" title="Link to this definition"></a></dt>
<dd><p>Determine whether a given acquisition function is non-negative.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>acq_function</strong> (<a class="reference internal" href="acquisition.html#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><em>AcquisitionFunction</em></a>) – The <cite>AcquisitionFunction</cite> instance.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>True if <cite>acq_function</cite> is non-negative, False if not, or if the behavior
is unknown (for custom acquisition functions).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">qEI</span> <span class="o">=</span> <span class="n">qExpectedImprovement</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">best_f</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">is_nonnegative</span><span class="p">(</span><span class="n">qEI</span><span class="p">)</span>  <span class="c1"># returns True</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="module-botorch.optim.stopping">
<span id="stopping-criteria"></span><h3>Stopping Criteria<a class="headerlink" href="#module-botorch.optim.stopping" title="Link to this heading"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.optim.stopping.StoppingCriterion">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.optim.stopping.</span></span><span class="sig-name descname"><span class="pre">StoppingCriterion</span></span><a class="reference internal" href="_modules/botorch/optim/stopping.html#StoppingCriterion"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.stopping.StoppingCriterion" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>Base class for evaluating optimization convergence.</p>
<p>Stopping criteria are implemented as a objects rather than a function, so that they
can keep track of past function values between optimization steps.</p>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.optim.stopping.StoppingCriterion.evaluate">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fvals</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/stopping.html#StoppingCriterion.evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.stopping.StoppingCriterion.evaluate" title="Link to this definition"></a></dt>
<dd><p>Evaluate the stopping criterion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>fvals</strong> (<em>Tensor</em>) – tensor containing function values for the current iteration. If
<cite>fvals</cite> contains more than one element, then the stopping criterion is
evaluated element-wise and True is returned if the stopping criterion is
true for all elements.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Stopping indicator (if True, stop the optimziation).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.optim.stopping.ExpMAStoppingCriterion">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.optim.stopping.</span></span><span class="sig-name descname"><span class="pre">ExpMAStoppingCriterion</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">maxiter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">minimize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_window</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rel_tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/stopping.html#ExpMAStoppingCriterion"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.stopping.ExpMAStoppingCriterion" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.optim.stopping.StoppingCriterion" title="botorch.optim.stopping.StoppingCriterion"><code class="xref py py-class docutils literal notranslate"><span class="pre">StoppingCriterion</span></code></a></p>
<p>Exponential moving average stopping criterion.</p>
<p>Computes an exponentially weighted moving average over window length <cite>n_window</cite>
and checks whether the relative decrease in this moving average between steps
is less than a provided tolerance level. That is, in iteration <cite>i</cite>, it computes</p>
<blockquote>
<div><p>v[i,j] := fvals[i - n_window + j] * w[j]</p>
</div></blockquote>
<p>for all <cite>j = 0, …, n_window</cite>, where <cite>w[j] = exp(-eta * (1 - j / n_window))</cite>.
Letting <cite>ma[i] := sum_j(v[i,j])</cite>, the criterion evaluates to <cite>True</cite> whenever</p>
<blockquote>
<div><p>(ma[i-1] - ma[i]) / abs(ma[i-1]) &lt; rel_tol (if minimize=True)
(ma[i] - ma[i-1]) / abs(ma[i-1]) &lt; rel_tol (if minimize=False)</p>
</div></blockquote>
<p>Exponential moving average stopping criterion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>maxiter</strong> (<em>int</em>) – Maximum number of iterations.</p></li>
<li><p><strong>minimize</strong> (<em>bool</em>) – If True, assume minimization.</p></li>
<li><p><strong>n_window</strong> (<em>int</em>) – The size of the exponential moving average window.</p></li>
<li><p><strong>eta</strong> (<em>float</em>) – The exponential decay factor in the weights.</p></li>
<li><p><strong>rel_tol</strong> (<em>float</em>) – Relative tolerance for termination.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.optim.stopping.ExpMAStoppingCriterion.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fvals</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/stopping.html#ExpMAStoppingCriterion.evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.stopping.ExpMAStoppingCriterion.evaluate" title="Link to this definition"></a></dt>
<dd><p>Evaluate the stopping criterion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>fvals</strong> (<em>Tensor</em>) – tensor containing function values for the current iteration. If
<cite>fvals</cite> contains more than one element, then the stopping criterion is
evaluated element-wise and True is returned if the stopping criterion is
true for all elements.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
<p>TODO: add support for utilizing gradient information</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Stopping indicator (if True, stop the optimziation).</p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>fvals</strong> (<em>Tensor</em>)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-botorch.optim.optimize_homotopy">
<span id="acquisition-function-optimization-with-homotopy"></span><h3>Acquisition Function Optimization with Homotopy<a class="headerlink" href="#module-botorch.optim.optimize_homotopy" title="Link to this heading"></a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.optimize_homotopy.prune_candidates">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.optimize_homotopy.</span></span><span class="sig-name descname"><span class="pre">prune_candidates</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">candidates</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">acq_values</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prune_tolerance</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/optimize_homotopy.html#prune_candidates"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.optimize_homotopy.prune_candidates" title="Link to this definition"></a></dt>
<dd><p>Prune candidates based on their distance to other candidates.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>candidates</strong> (<em>Tensor</em>) – An <cite>n x d</cite> tensor of candidates.</p></li>
<li><p><strong>acq_values</strong> (<em>Tensor</em>) – An <cite>n</cite> tensor of candidate values.</p></li>
<li><p><strong>prune_tolerance</strong> (<em>float</em>) – The minimum distance to prune candidates.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An <cite>m x d</cite> tensor of pruned candidates.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.optimize_homotopy.optimize_acqf_homotopy">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.optimize_homotopy.</span></span><span class="sig-name descname"><span class="pre">optimize_acqf_homotopy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_restarts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">homotopy</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prune_tolerance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raw_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">final_options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inequality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">equality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nonlinear_inequality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_features_list</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post_processing_func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_initial_conditions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gen_candidates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="keyword-only-separator o"><abbr title="Keyword-only parameters separator (PEP 3102)"><span class="pre">*</span></abbr></span></em>, <em class="sig-param"><span class="n"><span class="pre">ic_generator</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">timeout_sec</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retry_on_optimization_warning</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">ic_gen_kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/optimize_homotopy.html#optimize_acqf_homotopy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.optimize_homotopy.optimize_acqf_homotopy" title="Link to this definition"></a></dt>
<dd><p>Generate a set of candidates via multi-start optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<a class="reference internal" href="acquisition.html#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><em>AcquisitionFunction</em></a>) – An AcquisitionFunction.</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – A <cite>2 x d</cite> tensor of lower and upper bounds for each column of <cite>X</cite>
(if inequality_constraints is provided, these bounds can be -inf and
+inf, respectively).</p></li>
<li><p><strong>q</strong> (<em>int</em>) – The number of candidates.</p></li>
<li><p><strong>homotopy</strong> (<a class="reference internal" href="#botorch.optim.homotopy.Homotopy" title="botorch.optim.homotopy.Homotopy"><em>Homotopy</em></a>) – Homotopy object that will make the necessary modifications to the
problem when calling <cite>step()</cite>.</p></li>
<li><p><strong>prune_tolerance</strong> (<em>float</em>) – The minimum distance to prune candidates.</p></li>
<li><p><strong>num_restarts</strong> (<em>int</em>) – The number of starting points for multistart acquisition
function optimization.</p></li>
<li><p><strong>raw_samples</strong> (<em>int</em><em> | </em><em>None</em>) – The number of samples for initialization. This is required
if <cite>batch_initial_conditions</cite> is not specified.</p></li>
<li><p><strong>options</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>bool</em><em> | </em><em>float</em><em> | </em><em>int</em><em> | </em><em>str</em><em>] </em><em>| </em><em>None</em>) – Options for candidate generation in the initial step of the homotopy.</p></li>
<li><p><strong>final_options</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>bool</em><em> | </em><em>float</em><em> | </em><em>int</em><em> | </em><em>str</em><em>] </em><em>| </em><em>None</em>) – Options for candidate generation in the final step of
the homotopy.</p></li>
<li><p><strong>inequality_constraints</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) &gt;= rhs</cite>. <cite>indices</cite> and
<cite>coefficients</cite> should be torch tensors. See the docstring of
<cite>make_scipy_linear_constraints</cite> for an example. When q=1, or when
applying the same constraint to each candidate in the batch
(intra-point constraint), <cite>indices</cite> should be a 1-d tensor.
For inter-point constraints, in which the constraint is applied to the
whole batch of candidates, <cite>indices</cite> must be a 2-d tensor, where
in each row <cite>indices[i] =(k_i, l_i)</cite> the first index <cite>k_i</cite> corresponds
to the <cite>k_i</cite>-th element of the <cite>q</cite>-batch and the second index <cite>l_i</cite>
corresponds to the <cite>l_i</cite>-th feature of that element.</p></li>
<li><p><strong>equality_constraints</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an equality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) = rhs</cite>. See the docstring of
<cite>make_scipy_linear_constraints</cite> for an example.</p></li>
<li><p><strong>nonlinear_inequality_constraints</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>Callable</em><em>, </em><em>bool</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of tuples representing the nonlinear
inequality constraints. The first element in the tuple is a callable
representing a constraint of the form <cite>callable(x) &gt;= 0</cite>. In case of an
intra-point constraint, <cite>callable()`takes in an one-dimensional tensor of
shape `d</cite> and returns a scalar. In case of an inter-point constraint,
<cite>callable()</cite> takes a two dimensional tensor of shape <cite>q x d</cite> and again
returns a scalar. The second element is a boolean, indicating if it is an
intra-point or inter-point constraint (<cite>True</cite> for intra-point. <cite>False</cite> for
inter-point). For more information on intra-point vs inter-point
constraints, see the docstring of the <cite>inequality_constraints</cite> argument to
<cite>optimize_acqf()</cite>. The constraints will later be passed to the scipy
solver. You need to pass in <cite>batch_initial_conditions</cite> in this case.
Using non-linear inequality constraints also requires that <cite>batch_limit</cite>
is set to 1, which will be done automatically if not specified in
<cite>options</cite>.</p></li>
<li><p><strong>fixed_features</strong> (<em>dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>] </em><em>| </em><em>None</em>) – A map <cite>{feature_index: value}</cite> for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>fixed_features_list</strong> (<em>list</em><em>[</em><em>dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of maps <cite>{feature_index: value}</cite>. The i-th
item represents the fixed_feature for the i-th optimization. If
<cite>fixed_features_list</cite> is provided, <cite>optimize_acqf_mixed</cite> is invoked.
All indices (<cite>feature_index</cite>) should be non-negative.</p></li>
<li><p><strong>post_processing_func</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – A function that post-processes an optimization
result appropriately (i.e., according to <cite>round-trip</cite>
transformations).</p></li>
<li><p><strong>batch_initial_conditions</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A tensor to specify the initial conditions. Set
this if you do not want to use default initialization strategy.</p></li>
<li><p><strong>gen_candidates</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>, </em><a class="reference internal" href="acquisition.html#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><em>AcquisitionFunction</em></a><em>, </em><em>Any</em><em>]</em><em>, </em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A callable for generating candidates (and their associated
acquisition values) given a tensor of initial conditions and an
acquisition function. Other common inputs include lower and upper bounds
and a dictionary of options, but refer to the documentation of specific
generation functions (e.g gen_candidates_scipy and gen_candidates_torch)
for method-specific inputs. Default: <cite>gen_candidates_scipy</cite></p></li>
<li><p><strong>ic_generator</strong> (<em>Callable</em><em>[</em><em>[</em><a class="reference internal" href="acquisition.html#botorch.acquisition.knowledge_gradient.qKnowledgeGradient" title="botorch.acquisition.knowledge_gradient.qKnowledgeGradient"><em>qKnowledgeGradient</em></a><em>, </em><em>Tensor</em><em>, </em><em>int</em><em>, </em><em>int</em><em>, </em><em>int</em><em>, </em><em>dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>] </em><em>| </em><em>None</em><em>, </em><em>dict</em><em>[</em><em>str</em><em>, </em><em>bool</em><em> | </em><em>float</em><em> | </em><em>int</em><em>] </em><em>| </em><em>None</em><em>, </em><em>list</em><em>[</em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em><em>, </em><em>list</em><em>[</em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em><em>]</em><em>, </em><em>Tensor</em><em> | </em><em>None</em><em>] </em><em>| </em><em>None</em>) – Function for generating initial conditions. Not needed when
<cite>batch_initial_conditions</cite> are provided. Defaults to
<cite>gen_one_shot_kg_initial_conditions</cite> for <cite>qKnowledgeGradient</cite> acquisition
functions and <cite>gen_batch_initial_conditions</cite> otherwise. Must be specified
for nonlinear inequality constraints.</p></li>
<li><p><strong>timeout_sec</strong> (<em>float</em><em> | </em><em>None</em>) – Max amount of time optimization can run for.</p></li>
<li><p><strong>retry_on_optimization_warning</strong> (<em>bool</em>) – Whether to retry candidate generation with a new
set of initial conditions when it fails with an <cite>OptimizationWarning</cite>.</p></li>
<li><p><strong>ic_gen_kwargs</strong> (<em>Any</em>) – Additional keyword arguments passed to function specified by
<cite>ic_generator</cite></p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>tuple[<em>Tensor</em>, <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-botorch.optim.optimize_mixed">
<span id="acquisition-function-optimization-with-mixed-integer-variables"></span><h3>Acquisition Function Optimization with Mixed Integer Variables<a class="headerlink" href="#module-botorch.optim.optimize_mixed" title="Link to this heading"></a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.optimize_mixed.get_nearest_neighbors">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.optimize_mixed.</span></span><span class="sig-name descname"><span class="pre">get_nearest_neighbors</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">current_x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discrete_dims</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/optimize_mixed.html#get_nearest_neighbors"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.optimize_mixed.get_nearest_neighbors" title="Link to this definition"></a></dt>
<dd><p>Generate all 1-Manhattan distance neighbors of a given input. The neighbors
are generated for the discrete dimensions only.</p>
<p>NOTE: This assumes that <cite>current_x</cite> is detached and uses in-place operations,
which are known to be incompatible with autograd.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>current_x</strong> (<em>Tensor</em>) – The design to find the neighbors of. A tensor of shape <cite>d</cite>.</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – A <cite>2 x d</cite> tensor of lower and upper bounds for each column of <cite>X</cite>.</p></li>
<li><p><strong>discrete_dims</strong> (<em>Tensor</em>) – A tensor of indices corresponding to binary and
integer parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor of shape <cite>num_neighbors x d</cite>, denoting all unique 1-Manhattan
distance neighbors.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.optimize_mixed.get_spray_points">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.optimize_mixed.</span></span><span class="sig-name descname"><span class="pre">get_spray_points</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X_baseline</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cont_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discrete_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_spray_points</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">std_cont_perturbation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/optimize_mixed.html#get_spray_points"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.optimize_mixed.get_spray_points" title="Link to this definition"></a></dt>
<dd><p>Generate spray points by perturbing the Pareto optimal points.</p>
<p>Given the points on the Pareto frontier, we create perturbations (spray points)
by adding Gaussian perturbation to the continuous parameters and 1-Manhattan
distance neighbors of the discrete (binary and integer) parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X_baseline</strong> (<em>Tensor</em>) – Tensor of best acquired points across BO run.</p></li>
<li><p><strong>cont_dims</strong> (<em>Tensor</em>) – Indices of continuous parameters/input dimensions.</p></li>
<li><p><strong>discrete_dims</strong> (<em>Tensor</em>) – Indices of binary/integer parameters/input dimensions.</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – A <cite>2 x d</cite> tensor of lower and upper bounds for each column of <cite>X</cite>.</p></li>
<li><p><strong>num_spray_points</strong> (<em>int</em>) – Number of spray points to return.</p></li>
<li><p><strong>std_cont_perturbation</strong> (<em>float</em>) – standard deviation of Normal perturbations of
continuous dimensions. Default is STD_CONT_PERTURBATION = 0.2.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A (num_spray_points x d)-dim tensor of perturbed points.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.optimize_mixed.sample_feasible_points">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.optimize_mixed.</span></span><span class="sig-name descname"><span class="pre">sample_feasible_points</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">opt_inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discrete_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_points</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/optimize_mixed.html#sample_feasible_points"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.optimize_mixed.sample_feasible_points" title="Link to this definition"></a></dt>
<dd><p>Sample feasible points from the optimization domain.</p>
<p>Feasibility is determined according to the discrete dimensions taking
integer values and the inequality constraints being satisfied.</p>
<p>If there are no inequality constraints, Sobol is used to generate the base points.
Otherwise, we use the polytope sampler to generate the base points. The base points
are then rounded to the nearest integer values for the discrete dimensions, and
the infeasible points are filtered out (in case rounding leads to infeasibility).</p>
<p>This method will do 10 attempts to generate <cite>num_points</cite> feasible points, and
return the points generated so far. If no points are generated, it will error out.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>opt_inputs</strong> (<a class="reference internal" href="#botorch.optim.optimize.OptimizeAcqfInputs" title="botorch.optim.optimize.OptimizeAcqfInputs"><em>OptimizeAcqfInputs</em></a>) – Common set of arguments for acquisition optimization.</p></li>
<li><p><strong>discrete_dims</strong> (<em>Tensor</em>) – A tensor of indices corresponding to binary and
integer parameters.</p></li>
<li><p><strong>num_points</strong> (<em>int</em>) – The number of points to sample.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor of shape <cite>num_points x d</cite> containing the sampled points.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.optimize_mixed.generate_starting_points">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.optimize_mixed.</span></span><span class="sig-name descname"><span class="pre">generate_starting_points</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">opt_inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discrete_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cont_dims</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/optimize_mixed.html#generate_starting_points"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.optimize_mixed.generate_starting_points" title="Link to this definition"></a></dt>
<dd><p>Generate initial starting points for the alternating optimization.</p>
<p>This method attempts to generate the initial points using the specified
options and completes any missing points using <cite>sample_feasible_points</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>opt_inputs</strong> (<a class="reference internal" href="#botorch.optim.optimize.OptimizeAcqfInputs" title="botorch.optim.optimize.OptimizeAcqfInputs"><em>OptimizeAcqfInputs</em></a>) – Common set of arguments for acquisition optimization.
This function utilizes <cite>acq_function</cite>, <cite>bounds</cite>, <cite>num_restarts</cite>,
<cite>raw_samples</cite>, <cite>options</cite>, <cite>fixed_features</cite> and constraints
from <cite>opt_inputs</cite>.</p></li>
<li><p><strong>discrete_dims</strong> (<em>Tensor</em>) – A tensor of indices corresponding to integer and
binary parameters.</p></li>
<li><p><strong>cont_dims</strong> (<em>Tensor</em>) – A tensor of indices corresponding to continuous parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>a (num_restarts x d)-dim tensor of starting points
and a (num_restarts)-dim tensor of their respective acquisition values.
In rare cases, this method may return fewer than <cite>num_restarts</cite> points.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>A tuple of two tensors</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.optimize_mixed.discrete_step">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.optimize_mixed.</span></span><span class="sig-name descname"><span class="pre">discrete_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">opt_inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discrete_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">current_x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/optimize_mixed.html#discrete_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.optimize_mixed.discrete_step" title="Link to this definition"></a></dt>
<dd><p>Discrete nearest neighbour search.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>opt_inputs</strong> (<a class="reference internal" href="#botorch.optim.optimize.OptimizeAcqfInputs" title="botorch.optim.optimize.OptimizeAcqfInputs"><em>OptimizeAcqfInputs</em></a>) – Common set of arguments for acquisition optimization.
This function utilizes <cite>acq_function</cite>, <cite>bounds</cite>, <cite>options</cite>
and constraints from <cite>opt_inputs</cite>.</p></li>
<li><p><strong>discrete_dims</strong> (<em>Tensor</em>) – A tensor of indices corresponding to binary and
integer parameters.</p></li>
<li><p><strong>current_x</strong> (<em>Tensor</em>) – Starting point. A tensor of shape <cite>d</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>a (d)-dim tensor of optimized point</dt><dd><p>and a scalar tensor of correspondins acquisition value.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>A tuple of two tensors</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.optimize_mixed.continuous_step">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.optimize_mixed.</span></span><span class="sig-name descname"><span class="pre">continuous_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">opt_inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discrete_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">current_x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/optimize_mixed.html#continuous_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.optimize_mixed.continuous_step" title="Link to this definition"></a></dt>
<dd><p>Continuous search using L-BFGS-B through optimize_acqf.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>opt_inputs</strong> (<a class="reference internal" href="#botorch.optim.optimize.OptimizeAcqfInputs" title="botorch.optim.optimize.OptimizeAcqfInputs"><em>OptimizeAcqfInputs</em></a>) – Common set of arguments for acquisition optimization.
This function utilizes <cite>acq_function</cite>, <cite>bounds</cite>, <cite>options</cite>,
<cite>fixed_features</cite> and constraints from <cite>opt_inputs</cite>.</p></li>
<li><p><strong>discrete_dims</strong> (<em>Tensor</em>) – A tensor of indices corresponding to binary and
integer parameters.</p></li>
<li><p><strong>current_x</strong> (<em>Tensor</em>) – Starting point. A tensor of shape <cite>d</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>a (1 x d)-dim tensor of optimized points</dt><dd><p>and a (1)-dim tensor of acquisition values.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>A tuple of two tensors</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.optimize_mixed.optimize_acqf_mixed_alternating">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.optimize_mixed.</span></span><span class="sig-name descname"><span class="pre">optimize_acqf_mixed_alternating</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discrete_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raw_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1024</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_restarts</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post_processing_func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sequential</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inequality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/optimize_mixed.html#optimize_acqf_mixed_alternating"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.optimize_mixed.optimize_acqf_mixed_alternating" title="Link to this definition"></a></dt>
<dd><p>Optimizes acquisition function over mixed binary and continuous input spaces.
Multiple random restarting starting points are picked by evaluating a large set
of initial candidates. From each starting point, alternating discrete local search
and continuous optimization via (L-BFGS) is performed for a fixed number of
iterations.</p>
<p>NOTE: This method assumes that all discrete variables are integer valued.
The discrete dimensions that have more than
<cite>options.get(“max_discrete_values”, MAX_DISCRETE_VALUES)</cite> values will
be optimized using continuous relaxation.</p>
<p># TODO: Support categorical variables.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<a class="reference internal" href="acquisition.html#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><em>AcquisitionFunction</em></a>) – BoTorch Acquisition function.</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – A <cite>2 x d</cite> tensor of lower and upper bounds for each column of <cite>X</cite>.</p></li>
<li><p><strong>discrete_dims</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – A list of indices corresponding to integer and binary parameters.</p></li>
<li><p><strong>options</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Dictionary specifying optimization options. Supports the following:</p></li>
<li><p><strong>&quot;initialization_strategy&quot;</strong> (<em>-</em>) – Strategy used to generate the initial candidates.
“random”, “continuous_relaxation” or “equally_spaced” (linspace style).</p></li>
<li><p><strong>&quot;tol&quot;</strong> (<em>-</em>) – The algorithm terminates if the absolute improvement in acquisition
value of one iteration is smaller than this number.</p></li>
<li><p><strong>&quot;maxiter_alternating&quot;</strong> (<em>-</em>) – Number of alternating steps. Defaults to 64.</p></li>
<li><p><strong>&quot;maxiter_discrete&quot;</strong> (<em>-</em>) – Maximum number of iterations in each discrete step.
Defaults to 4.</p></li>
<li><p><strong>&quot;maxiter_continuous&quot;</strong> (<em>-</em>) – Maximum number of iterations in each continuous step.
Defaults to 8.</p></li>
<li><p><strong>&quot;max_discrete_values&quot;</strong> (<em>-</em>) – Maximum number of values for a discrete dimension
to be optimized using discrete step / local search. The discrete dimensions
with more values will be optimized using continuous relaxation.</p></li>
<li><p><strong>&quot;num_spray_points&quot;</strong> (<em>-</em>) – Number of spray points (around <cite>X_baseline</cite>) to add to
the points generated by the initialization strategy. Defaults to 20 if
all discrete variables are binary and to 0 otherwise.</p></li>
<li><p><strong>&quot;std_cont_perturbation&quot;</strong> (<em>-</em>) – Standard deviation of the normal perturbations of
the continuous variables used to generate the spray points.
Defaults to 0.1.</p></li>
<li><p><strong>&quot;batch_limit&quot;</strong> (<em>-</em>) – The maximum batch size for jointly evaluating candidates
during optimization.</p></li>
<li><p><strong>&quot;init_batch_limit&quot;</strong> (<em>-</em>) – The maximum batch size for jointly evaluating candidates
during initialization. During initialization, candidates are evaluated
in a <cite>no_grad</cite> context, which reduces memory usage. As a result,
<cite>init_batch_limit</cite> can be set to a larger value than <cite>batch_limit</cite>.
Defaults to <cite>batch_limit</cite>, if given.</p></li>
<li><p><strong>q</strong> (<em>int</em>) – Number of candidates.</p></li>
<li><p><strong>raw_samples</strong> (<em>int</em>) – Number of initial candidates used to select starting points from.
Defaults to 1024.</p></li>
<li><p><strong>num_restarts</strong> (<em>int</em>) – Number of random restarts. Defaults to 20.</p></li>
<li><p><strong>post_processing_func</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – A function that post-processes an optimization result
appropriately (i.e., according to <cite>round-trip</cite> transformations).</p></li>
<li><p><strong>sequential</strong> (<em>bool</em>) – Whether to use joint or sequential optimization across q-batch.
This currently only supports sequential optimization.</p></li>
<li><p><strong>fixed_features</strong> (<em>dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>] </em><em>| </em><em>None</em>) – A map <cite>{feature_index: value}</cite> for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>inequality_constraints</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) &gt;= rhs</cite>. <cite>indices</cite> and
<cite>coefficients</cite> should be torch tensors. See the docstring of
<cite>make_scipy_linear_constraints</cite> for an example.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>a (q x d)-dim tensor of optimized points</dt><dd><p>and a (q)-dim tensor of their respective acquisition values.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>A tuple of two tensors</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.optimize_mixed.complement_indices_like">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.optimize_mixed.</span></span><span class="sig-name descname"><span class="pre">complement_indices_like</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/optimize_mixed.html#complement_indices_like"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.optimize_mixed.complement_indices_like" title="Link to this definition"></a></dt>
<dd><p>Computes a tensor of complement indices: {range(d) \ indices}.
Same as complement_indices but returns an integer tensor like indices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>indices</strong> (<em>Tensor</em>)</p></li>
<li><p><strong>d</strong> (<em>int</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.optimize_mixed.complement_indices">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.optimize_mixed.</span></span><span class="sig-name descname"><span class="pre">complement_indices</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/optimize_mixed.html#complement_indices"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.optimize_mixed.complement_indices" title="Link to this definition"></a></dt>
<dd><p>Computes a list of complement indices: {range(d) \ indices}.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>indices</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – a list of integers.</p></li>
<li><p><strong>d</strong> (<em>int</em>) – an integer dimension in which to compute the complement.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of integer indices.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list[int]</p>
</dd>
</dl>
</dd></dl>

</section>
</section>
<section id="closures">
<h2>Closures<a class="headerlink" href="#closures" title="Link to this heading"></a></h2>
<section id="id1">
<h3>Core<a class="headerlink" href="#id1" title="Link to this heading"></a></h3>
<p id="module-botorch.optim.closures.core">Core methods for building closures in torch and interfacing with numpy.</p>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.optim.closures.core.ForwardBackwardClosure">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.optim.closures.core.</span></span><span class="sig-name descname"><span class="pre">ForwardBackwardClosure</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parameters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">backward=&lt;function</span> <span class="pre">Tensor.backward&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reducer=&lt;built-in</span> <span class="pre">method</span> <span class="pre">sum</span> <span class="pre">of</span> <span class="pre">type</span> <span class="pre">object&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_manager=None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/closures/core.html#ForwardBackwardClosure"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.closures.core.ForwardBackwardClosure" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Wrapper for fused forward and backward closures.</p>
<p>Initializes a ForwardBackwardClosure instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>closure</strong> – Callable that returns a tensor.</p></li>
<li><p><strong>parameters</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>) – A dictionary of tensors whose <cite>grad</cite> fields are to be returned.</p></li>
<li><p><strong>backward</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>None</em><em>]</em>) – Callable that takes the (reduced) output of <cite>forward</cite> and sets the
<cite>grad</cite> attributes of tensors in <cite>parameters</cite>.</p></li>
<li><p><strong>reducer</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – Optional callable used to reduce the output of the forward pass.</p></li>
<li><p><strong>callback</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>, </em><em>Sequence</em><em>[</em><em>Tensor</em><em> | </em><em>None</em><em>]</em><em>]</em><em>, </em><em>None</em><em>] </em><em>| </em><em>None</em>) – Optional callable that takes the reduced output of <cite>forward</cite> and
the gradients of <cite>parameters</cite> as positional arguments.</p></li>
<li><p><strong>context_manager</strong> (<em>Callable</em>) – A ContextManager used to wrap each forward-backward call.
When passed as <cite>None</cite>, <cite>context_manager</cite> defaults to a <cite>zero_grad_ctx</cite>
that zeroes the gradients of <cite>parameters</cite> upon entry.</p></li>
<li><p><strong>forward</strong> (<em>Callable</em><em>[</em><em>[</em><em>]</em><em>, </em><em>Tensor</em><em>]</em>)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.optim.closures.core.NdarrayOptimizationClosure">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.optim.closures.core.</span></span><span class="sig-name descname"><span class="pre">NdarrayOptimizationClosure</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">closure</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parameters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">as_array</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">get_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">set_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fill_value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">persistent</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/closures/core.html#NdarrayOptimizationClosure"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.closures.core.NdarrayOptimizationClosure" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Adds stateful behavior and a numpy.ndarray-typed API to a closure with an
expected return type Tuple[Tensor, Union[Tensor, Sequence[Optional[Tensor]]]].</p>
<p>Initializes a NdarrayOptimizationClosure instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>closure</strong> (<em>Callable</em><em>[</em><em>[</em><em>]</em><em>, </em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Sequence</em><em>[</em><em>Tensor</em><em> | </em><em>None</em><em>]</em><em>]</em><em>]</em>) – A ForwardBackwardClosure instance.</p></li>
<li><p><strong>parameters</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>) – A dictionary of tensors representing the closure’s state.
Expected to correspond with the first <cite>len(parameters)</cite> optional
gradient tensors returned by <cite>closure</cite>.</p></li>
<li><p><strong>as_array</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>npt.NDArray</em><em>]</em>) – Callable used to convert tensors to ndarrays.</p></li>
<li><p><strong>get_state</strong> (<em>Callable</em><em>[</em><em>[</em><em>]</em><em>, </em><em>npt.NDArray</em><em>]</em>) – Callable that returns the closure’s state as an ndarray. When
passed as <cite>None</cite>, defaults to calling <cite>get_tensors_as_ndarray_1d</cite>
on <cite>closure.parameters</cite> while passing <cite>as_array</cite> (if given by the user).</p></li>
<li><p><strong>set_state</strong> (<em>Callable</em><em>[</em><em>[</em><em>npt.NDArray</em><em>]</em><em>, </em><em>None</em><em>]</em>) – Callable that takes a 1-dimensional ndarray and sets the
closure’s state. When passed as <cite>None</cite>, <cite>set_state</cite> defaults to
calling <cite>set_tensors_from_ndarray_1d</cite> with <cite>closure.parameters</cite> and
a given ndarray.</p></li>
<li><p><strong>fill_value</strong> (<em>float</em>) – Fill value for parameters whose gradients are None. In most
cases, <cite>fill_value</cite> should either be zero or NaN.</p></li>
<li><p><strong>persistent</strong> (<em>bool</em>) – Boolean specifying whether an ndarray should be retained
as a persistent buffer for gradients.</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="botorch.optim.closures.core.NdarrayOptimizationClosure.state">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">state</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">ndarray</span><span class="p"><span class="pre">[</span></span><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">dtype</span><span class="p"><span class="pre">[</span></span><span class="pre">_ScalarType_co</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#botorch.optim.closures.core.NdarrayOptimizationClosure.state" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-botorch.optim.closures.model_closures">
<span id="model-fitting-closures"></span><h3>Model Fitting Closures<a class="headerlink" href="#module-botorch.optim.closures.model_closures" title="Link to this heading"></a></h3>
<p>Utilities for building model-based closures.</p>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.closures.model_closures.get_loss_closure">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.closures.model_closures.</span></span><span class="sig-name descname"><span class="pre">get_loss_closure</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mll</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_loader</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/closures/model_closures.html#get_loss_closure"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.closures.model_closures.get_loss_closure" title="Link to this definition"></a></dt>
<dd><p>Public API for GetLossClosure dispatcher.</p>
<p>This method, and the dispatcher that powers it, acts as a clearing house
for factory functions that define how <cite>mll</cite> is evaluated.</p>
<p>Users may specify custom evaluation routines by registering a factory function
with GetLossClosure. These factories should be registered using the type signature</p>
<blockquote>
<div><p><cite>Type[MarginalLogLikeLihood], Type[Likelihood], Type[Model], Type[DataLoader]</cite>.</p>
</div></blockquote>
<p>The final argument, Type[DataLoader], is optional. Evaluation routines that obtain
training data from, e.g., <cite>mll.model</cite> should register this argument as <cite>type(None)</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mll</strong> (<em>MarginalLogLikelihood</em>) – A MarginalLogLikelihood instance whose negative defines the loss.</p></li>
<li><p><strong>data_loader</strong> (<em>DataLoader</em><em> | </em><em>None</em>) – An optional DataLoader instance for cases where training
data is passed in rather than obtained from <cite>mll.model</cite>.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A closure that takes zero positional arguments and returns the negated
value of <cite>mll</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Callable</em>[[], <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.closures.model_closures.get_loss_closure_with_grads">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.closures.model_closures.</span></span><span class="sig-name descname"><span class="pre">get_loss_closure_with_grads</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mll</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parameters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_loader=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">backward=&lt;function</span> <span class="pre">Tensor.backward&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reducer=&lt;method</span> <span class="pre">'sum'</span> <span class="pre">of</span> <span class="pre">'torch._C.TensorBase'</span> <span class="pre">objects&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_manager=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">**kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/closures/model_closures.html#get_loss_closure_with_grads"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.closures.model_closures.get_loss_closure_with_grads" title="Link to this definition"></a></dt>
<dd><p>Public API for GetLossClosureWithGrads dispatcher.</p>
<p>In most cases, this method simply adds a backward pass to a loss closure obtained by
calling <cite>get_loss_closure</cite>. For further details, see <cite>get_loss_closure</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mll</strong> (<em>MarginalLogLikelihood</em>) – A MarginalLogLikelihood instance whose negative defines the loss.</p></li>
<li><p><strong>parameters</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>) – A dictionary of tensors whose <cite>grad</cite> fields are to be returned.</p></li>
<li><p><strong>reducer</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – Optional callable used to reduce the output of the forward pass.</p></li>
<li><p><strong>data_loader</strong> (<em>DataLoader</em><em> | </em><em>None</em>) – An optional DataLoader instance for cases where training
data is passed in rather than obtained from <cite>mll.model</cite>.</p></li>
<li><p><strong>context_manager</strong> (<em>Callable</em><em> | </em><em>None</em>) – An optional ContextManager used to wrap each forward-backward
pass. Defaults to a <cite>zero_grad_ctx</cite> that zeroes the gradients of
<cite>parameters</cite> upon entry. None may be passed as an alias for <cite>nullcontext</cite>.</p></li>
<li><p><strong>backward</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>None</em><em>]</em>)</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A closure that takes zero positional arguments and returns the reduced and
negated value of <cite>mll</cite> along with the gradients of <cite>parameters</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Callable</em>[[], tuple[<em>Tensor</em>, tuple[<em>Tensor</em>, …]]]</p>
</dd>
</dl>
</dd></dl>

</section>
</section>
<section id="utilities">
<h2>Utilities<a class="headerlink" href="#utilities" title="Link to this heading"></a></h2>
<section id="module-botorch.optim.utils.common">
<span id="general-optimization-utilities"></span><h3>General Optimization Utilities<a class="headerlink" href="#module-botorch.optim.utils.common" title="Link to this heading"></a></h3>
<p>General-purpose optimization utilities.</p>
</section>
<section id="module-botorch.optim.utils.acquisition_utils">
<span id="acquisition-optimization-utilities"></span><h3>Acquisition Optimization Utilities<a class="headerlink" href="#module-botorch.optim.utils.acquisition_utils" title="Link to this heading"></a></h3>
<p>Utilities for maximizing acquisition functions.</p>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.utils.acquisition_utils.columnwise_clamp">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.acquisition_utils.</span></span><span class="sig-name descname"><span class="pre">columnwise_clamp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lower</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">upper</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raise_on_violation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/acquisition_utils.html#columnwise_clamp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.acquisition_utils.columnwise_clamp" title="Link to this definition"></a></dt>
<dd><p>Clamp values of a Tensor in column-wise fashion (with support for t-batches).</p>
<p>This function is useful in conjunction with optimizers from the torch.optim
package, which don’t natively handle constraints. If you apply this after
a gradient step you can be fancy and call it “projected gradient descent”.
This funtion is also useful for post-processing candidates generated by the
scipy optimizer that satisfy bounds only up to numerical accuracy.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – The <cite>b x n x d</cite> input tensor. If 2-dimensional, <cite>b</cite> is assumed to be 1.</p></li>
<li><p><strong>lower</strong> (<em>float</em><em> | </em><em>Tensor</em><em> | </em><em>None</em>) – The column-wise lower bounds. If scalar, apply bound to all columns.</p></li>
<li><p><strong>upper</strong> (<em>float</em><em> | </em><em>Tensor</em><em> | </em><em>None</em>) – The column-wise upper bounds. If scalar, apply bound to all columns.</p></li>
<li><p><strong>raise_on_violation</strong> (<em>bool</em>) – If <cite>True</cite>, raise an exception when the elments in <cite>X</cite>
are out of the specified bounds (up to numerical accuracy). This is
useful for post-processing candidates generated by optimizers that
satisfy imposed bounds only up to numerical accuracy.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The clamped tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.utils.acquisition_utils.fix_features">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.acquisition_utils.</span></span><span class="sig-name descname"><span class="pre">fix_features</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/acquisition_utils.html#fix_features"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.acquisition_utils.fix_features" title="Link to this definition"></a></dt>
<dd><p>Fix feature values in a Tensor.</p>
<p>The fixed features will have zero gradient in downstream calculations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – input Tensor with shape <cite>… x p</cite>, where <cite>p</cite> is the number of features</p></li>
<li><p><strong>fixed_features</strong> (<em>Mapping</em><em>[</em><em>int</em><em>, </em><em>float</em><em> | </em><em>None</em><em>] </em><em>| </em><em>None</em>) – A mapping with keys as column indices and values
equal to what the feature should be set to in <cite>X</cite>. If the value is
None, that column is just considered fixed. Keys should be in the
range <cite>[0, p - 1]</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The tensor X with fixed features.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.utils.acquisition_utils.get_X_baseline">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.acquisition_utils.</span></span><span class="sig-name descname"><span class="pre">get_X_baseline</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/acquisition_utils.html#get_X_baseline"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.acquisition_utils.get_X_baseline" title="Link to this definition"></a></dt>
<dd><p>Extract X_baseline from an acquisition function.</p>
<p>This tries to find the baseline set of points. First, this checks if the
acquisition function has an <cite>X_baseline</cite> attribute. If it does not,
then this method attempts to use the model’s <cite>train_inputs</cite> as <cite>X_baseline</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>acq_function</strong> (<a class="reference internal" href="acquisition.html#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><em>AcquisitionFunction</em></a>) – The acquisition function.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em> | None</p>
</dd>
</dl>
<dl class="simple">
<dt>Returns</dt><dd><dl class="simple">
<dt>An optional <cite>n x d</cite>-dim tensor of baseline points. This is None if no</dt><dd><p>baseline points are found.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-botorch.optim.utils.model_utils">
<span id="model-fitting-utilities"></span><h3>Model Fitting Utilities<a class="headerlink" href="#module-botorch.optim.utils.model_utils" title="Link to this heading"></a></h3>
<p>Utilities for fitting and manipulating models.</p>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.optim.utils.model_utils.TorchAttr">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.model_utils.</span></span><span class="sig-name descname"><span class="pre">TorchAttr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/model_utils.html#TorchAttr"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.model_utils.TorchAttr" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">NamedTuple</span></code></p>
<p>Create new instance of TorchAttr(shape, dtype, device)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>shape</strong> (<em>Size</em>)</p></li>
<li><p><strong>dtype</strong> (<em>dtype</em>)</p></li>
<li><p><strong>device</strong> (<em>device</em>)</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.utils.model_utils.TorchAttr.shape">
<span class="sig-name descname"><span class="pre">shape</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Size</span></em><a class="headerlink" href="#botorch.optim.utils.model_utils.TorchAttr.shape" title="Link to this definition"></a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.utils.model_utils.TorchAttr.dtype">
<span class="sig-name descname"><span class="pre">dtype</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">dtype</span></em><a class="headerlink" href="#botorch.optim.utils.model_utils.TorchAttr.dtype" title="Link to this definition"></a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.utils.model_utils.TorchAttr.device">
<span class="sig-name descname"><span class="pre">device</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">device</span></em><a class="headerlink" href="#botorch.optim.utils.model_utils.TorchAttr.device" title="Link to this definition"></a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.utils.model_utils.get_data_loader">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.model_utils.</span></span><span class="sig-name descname"><span class="pre">get_data_loader</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1024</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/model_utils.html#get_data_loader"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.model_utils.get_data_loader" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.gpytorch.GPyTorchModel" title="botorch.models.gpytorch.GPyTorchModel"><em>GPyTorchModel</em></a>)</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>)</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>DataLoader</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.utils.model_utils.get_parameters">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.model_utils.</span></span><span class="sig-name descname"><span class="pre">get_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name_filter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/model_utils.html#get_parameters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.model_utils.get_parameters" title="Link to this definition"></a></dt>
<dd><p>Helper method for obtaining a module’s parameters and their respective ranges.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> (<em>Module</em>) – The target module from which parameters are to be extracted.</p></li>
<li><p><strong>requires_grad</strong> (<em>bool</em><em> | </em><em>None</em>) – Optional Boolean used to filter parameters based on whether
or not their require_grad attribute matches the user provided value.</p></li>
<li><p><strong>name_filter</strong> (<em>Callable</em><em>[</em><em>[</em><em>str</em><em>]</em><em>, </em><em>bool</em><em>] </em><em>| </em><em>None</em>) – Optional Boolean function used to filter parameters by name.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dictionary of parameters.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict[str, <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.utils.model_utils.get_parameters_and_bounds">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.model_utils.</span></span><span class="sig-name descname"><span class="pre">get_parameters_and_bounds</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name_filter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">default_bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(-inf,</span> <span class="pre">inf)</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/model_utils.html#get_parameters_and_bounds"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.model_utils.get_parameters_and_bounds" title="Link to this definition"></a></dt>
<dd><p>Helper method for obtaining a module’s parameters and their respective ranges.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> (<em>Module</em>) – The target module from which parameters are to be extracted.</p></li>
<li><p><strong>name_filter</strong> (<em>Callable</em><em>[</em><em>[</em><em>str</em><em>]</em><em>, </em><em>bool</em><em>] </em><em>| </em><em>None</em>) – Optional Boolean function used to filter parameters by name.</p></li>
<li><p><strong>requires_grad</strong> (<em>bool</em><em> | </em><em>None</em>) – Optional Boolean used to filter parameters based on whether
or not their require_grad attribute matches the user provided value.</p></li>
<li><p><strong>default_bounds</strong> (<em>tuple</em><em>[</em><em>float</em><em>, </em><em>float</em><em>]</em>) – Default lower and upper bounds for constrained parameters
with <cite>None</cite> typed bounds.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dictionary of parameters and a dictionary of parameter bounds.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple[dict[str, <em>Tensor</em>], dict[str, tuple[float | None, float | None]]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.utils.model_utils.get_name_filter">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.model_utils.</span></span><span class="sig-name descname"><span class="pre">get_name_filter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">patterns</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/model_utils.html#get_name_filter"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.model_utils.get_name_filter" title="Link to this definition"></a></dt>
<dd><p>Returns a binary function that filters strings (or iterables whose first
element is a string) according to a bank of excluded patterns. Typically, used
in conjunction with generators such as <cite>module.named_parameters()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>patterns</strong> (<em>Iterator</em><em>[</em><em>Pattern</em><em> | </em><em>str</em><em>]</em>) – A collection of regular expressions or strings that
define the set of names to be excluded.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A binary function indicating whether or not an item should be filtered.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Callable</em>[[str | tuple[str, <em>Any</em>, …]], bool]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.utils.model_utils.sample_all_priors">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.model_utils.</span></span><span class="sig-name descname"><span class="pre">sample_all_priors</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_retries</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/model_utils.html#sample_all_priors"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.model_utils.sample_all_priors" title="Link to this definition"></a></dt>
<dd><p>Sample from hyperparameter priors (in-place).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.gpytorch.GPyTorchModel" title="botorch.models.gpytorch.GPyTorchModel"><em>GPyTorchModel</em></a>) – A GPyTorchModel.</p></li>
<li><p><strong>max_retries</strong> (<em>int</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-botorch.optim.utils.numpy_utils">
<span id="numpy-torch-conversion-tools"></span><h3>Numpy - Torch Conversion Tools<a class="headerlink" href="#module-botorch.optim.utils.numpy_utils" title="Link to this heading"></a></h3>
<p>Utilities for interfacing Numpy and Torch.</p>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.utils.numpy_utils.as_ndarray">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.numpy_utils.</span></span><span class="sig-name descname"><span class="pre">as_ndarray</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">values</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inplace</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/numpy_utils.html#as_ndarray"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.numpy_utils.as_ndarray" title="Link to this definition"></a></dt>
<dd><p>Helper for going from torch.Tensor to numpy.ndarray.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>values</strong> (<em>Tensor</em>) – Tensor to be converted to ndarray.</p></li>
<li><p><strong>dtype</strong> (<em>dtype</em><em> | </em><em>None</em>) – Optional numpy.dtype for the converted tensor.</p></li>
<li><p><strong>inplace</strong> (<em>bool</em>) – Boolean indicating whether memory should be shared if possible.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An ndarray with the same data as <cite>values</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>ndarray</em>[tuple[int, …], <em>dtype</em>[<em>_ScalarType_co</em>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.utils.numpy_utils.get_tensors_as_ndarray_1d">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.numpy_utils.</span></span><span class="sig-name descname"><span class="pre">get_tensors_as_ndarray_1d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensors</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">as_array=&lt;function</span> <span class="pre">as_ndarray&gt;</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/numpy_utils.html#get_tensors_as_ndarray_1d"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.numpy_utils.get_tensors_as_ndarray_1d" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tensors</strong> (<em>Iterator</em><em>[</em><em>Tensor</em><em>] </em><em>| </em><em>dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>)</p></li>
<li><p><strong>out</strong> (<em>ndarray</em><em>[</em><em>tuple</em><em>[</em><em>int</em><em>, </em><em>...</em><em>]</em><em>, </em><em>dtype</em><em>[</em><em>_ScalarType_co</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>dtype</strong> (<em>dtype</em><em> | </em><em>str</em><em> | </em><em>None</em>)</p></li>
<li><p><strong>as_array</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>ndarray</em><em>[</em><em>tuple</em><em>[</em><em>int</em><em>, </em><em>...</em><em>]</em><em>, </em><em>dtype</em><em>[</em><em>_ScalarType_co</em><em>]</em><em>]</em><em>]</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>ndarray</em>[tuple[int, …], <em>dtype</em>[<em>_ScalarType_co</em>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.utils.numpy_utils.set_tensors_from_ndarray_1d">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.numpy_utils.</span></span><span class="sig-name descname"><span class="pre">set_tensors_from_ndarray_1d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensors</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">array</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/numpy_utils.html#set_tensors_from_ndarray_1d"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.numpy_utils.set_tensors_from_ndarray_1d" title="Link to this definition"></a></dt>
<dd><p>Sets the values of one more tensors based off of a vector of assignments.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tensors</strong> (<em>Iterator</em><em>[</em><em>Tensor</em><em>] </em><em>| </em><em>dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>)</p></li>
<li><p><strong>array</strong> (<em>ndarray</em><em>[</em><em>tuple</em><em>[</em><em>int</em><em>, </em><em>...</em><em>]</em><em>, </em><em>dtype</em><em>[</em><em>_ScalarType_co</em><em>]</em><em>]</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.utils.numpy_utils.get_bounds_as_ndarray">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.numpy_utils.</span></span><span class="sig-name descname"><span class="pre">get_bounds_as_ndarray</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">parameters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/numpy_utils.html#get_bounds_as_ndarray"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.numpy_utils.get_bounds_as_ndarray" title="Link to this definition"></a></dt>
<dd><p>Helper method for converting bounds into an ndarray.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>parameters</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>) – A dictionary of parameters.</p></li>
<li><p><strong>bounds</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>tuple</em><em>[</em><em>float</em><em> | </em><em>Tensor</em><em> | </em><em>None</em><em>, </em><em>float</em><em> | </em><em>Tensor</em><em> | </em><em>None</em><em>]</em><em>]</em>) – A dictionary of (optional) lower and upper bounds.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An ndarray of bounds.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>ndarray</em>[tuple[int, …], <em>dtype</em>[<em>_ScalarType_co</em>]] | None</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-botorch.optim.utils.timeout">
<span id="optimization-with-timeouts"></span><h3>Optimization with Timeouts<a class="headerlink" href="#module-botorch.optim.utils.timeout" title="Link to this heading"></a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.utils.timeout.minimize_with_timeout">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.timeout.</span></span><span class="sig-name descname"><span class="pre">minimize_with_timeout</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fun</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">jac</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hess</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hessp</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">timeout_sec</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/timeout.html#minimize_with_timeout"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.timeout.minimize_with_timeout" title="Link to this definition"></a></dt>
<dd><p>Wrapper around scipy.optimize.minimize to support timeout.</p>
<p>This method calls scipy.optimize.minimize with all arguments forwarded
verbatim. The only difference is that if provided a <cite>timeout_sec</cite> argument,
it will automatically stop the optimziation after the timeout is reached.</p>
<p>Internally, this is achieved by automatically constructing a wrapper callback
method that is injected to the scipy.optimize.minimize call and that keeps
track of the runtime and the optimization variables at the current iteration.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fun</strong> (<em>Callable</em><em>[</em><em>[</em><em>ndarray</em><em>[</em><em>tuple</em><em>[</em><em>int</em><em>, </em><em>...</em><em>]</em><em>, </em><em>dtype</em><em>[</em><em>_ScalarType_co</em><em>]</em><em>]</em><em>, </em><em>...</em><em>]</em><em>, </em><em>float</em><em>]</em>)</p></li>
<li><p><strong>x0</strong> (<em>ndarray</em><em>[</em><em>tuple</em><em>[</em><em>int</em><em>, </em><em>...</em><em>]</em><em>, </em><em>dtype</em><em>[</em><em>_ScalarType_co</em><em>]</em><em>]</em>)</p></li>
<li><p><strong>args</strong> (<em>tuple</em><em>[</em><em>Any</em><em>, </em><em>...</em><em>]</em>)</p></li>
<li><p><strong>method</strong> (<em>str</em><em> | </em><em>None</em>)</p></li>
<li><p><strong>jac</strong> (<em>str</em><em> | </em><em>Callable</em><em> | </em><em>bool</em><em> | </em><em>None</em>)</p></li>
<li><p><strong>hess</strong> (<em>str</em><em> | </em><em>Callable</em><em> | </em><em>HessianUpdateStrategy</em><em> | </em><em>None</em>)</p></li>
<li><p><strong>hessp</strong> (<em>Callable</em><em> | </em><em>None</em>)</p></li>
<li><p><strong>bounds</strong> (<em>Sequence</em><em>[</em><em>tuple</em><em>[</em><em>float</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>Bounds</em><em> | </em><em>None</em>)</p></li>
<li><p><strong>tol</strong> (<em>float</em><em> | </em><em>None</em>)</p></li>
<li><p><strong>callback</strong> (<em>Callable</em><em> | </em><em>None</em>)</p></li>
<li><p><strong>options</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>timeout_sec</strong> (<em>float</em><em> | </em><em>None</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>OptimizeResult</em></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-botorch.optim.parameter_constraints">
<span id="parameter-constraint-utilities"></span><h3>Parameter Constraint Utilities<a class="headerlink" href="#module-botorch.optim.parameter_constraints" title="Link to this heading"></a></h3>
<p>Utility functions for constrained optimization.</p>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.parameter_constraints.make_scipy_bounds">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.parameter_constraints.</span></span><span class="sig-name descname"><span class="pre">make_scipy_bounds</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lower_bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">upper_bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/parameter_constraints.html#make_scipy_bounds"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.parameter_constraints.make_scipy_bounds" title="Link to this definition"></a></dt>
<dd><p>Creates a scipy Bounds object for optimziation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – <cite>… x d</cite> tensor</p></li>
<li><p><strong>lower_bounds</strong> (<em>float</em><em> | </em><em>Tensor</em><em> | </em><em>None</em>) – Lower bounds on each column (last dimension) of <cite>X</cite>. If
this is a single float, then all columns have the same bound.</p></li>
<li><p><strong>upper_bounds</strong> (<em>float</em><em> | </em><em>Tensor</em><em> | </em><em>None</em>) – Lower bounds on each column (last dimension) of <cite>X</cite>. If
this is a single float, then all columns have the same bound.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A scipy <cite>Bounds</cite> object if either lower_bounds or upper_bounds is not
None, and None otherwise.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Bounds</em> | None</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scipy_bounds</span> <span class="o">=</span> <span class="n">make_scipy_bounds</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.parameter_constraints.make_scipy_linear_constraints">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.parameter_constraints.</span></span><span class="sig-name descname"><span class="pre">make_scipy_linear_constraints</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">shapeX</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inequality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">equality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/parameter_constraints.html#make_scipy_linear_constraints"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.parameter_constraints.make_scipy_linear_constraints" title="Link to this definition"></a></dt>
<dd><p>Generate scipy constraints from torch representation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>shapeX</strong> (<em>Size</em>) – The shape of the torch.Tensor to optimize over (i.e. <cite>(b) x q x d</cite>)</p></li>
<li><p><strong>constraints</strong> (<em>equality</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) &gt;= rhs</cite>, where
<cite>indices</cite> is a single-dimensional index tensor (long dtype) containing
indices into the last dimension of <cite>X</cite>, <cite>coefficients</cite> is a
single-dimensional tensor of coefficients of the same length, and
rhs is a scalar.</p></li>
<li><p><strong>constraints</strong> – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) == rhs</cite> (with <cite>indices</cite>
and <cite>coefficients</cite> of the same form as in <cite>inequality_constraints</cite>).</p></li>
<li><p><strong>inequality_constraints</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>equality_constraints</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of dictionaries containing callables for constraint function
values and Jacobians and a string indicating the associated constraint
type (“eq”, “ineq”), as expected by <cite>scipy.minimize</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list[dict[str, str | <em>Callable</em>[[<em>ndarray</em>], float] | <em>Callable</em>[[<em>ndarray</em>], <em>ndarray</em>]]]</p>
</dd>
</dl>
<p>This function assumes that constraints are the same for each input batch,
and broadcasts the constraints accordingly to the input batch shape. This
function does support constraints across elements of a q-batch if the
indices are a 2-d Tensor.</p>
<p class="rubric">Example</p>
<p>The following will enforce that <cite>x[1] + 0.5 x[3] &gt;= -0.1</cite> for each <cite>x</cite>
in both elements of the q-batch, and each of the 3 t-batches:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">constraints</span> <span class="o">=</span> <span class="n">make_scipy_linear_constraints</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">]),</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="p">[(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]),</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">)],</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
</pre></div>
</div>
<p>The following will enforce that <cite>x[0, 1] + 0.5 x[1, 3] &gt;= -0.1</cite> where
x[0, :] is the first element of the q-batch and x[1, :] is the second
element of the q-batch, for each of the 3 t-batches:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">constraints</span> <span class="o">=</span> <span class="n">make_scipy_linear_constraints</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">torch</span><span class="o">.</span><span class="n">size</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="p">[(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]),</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">)],</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.parameter_constraints.eval_lin_constraint">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.parameter_constraints.</span></span><span class="sig-name descname"><span class="pre">eval_lin_constraint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">flat_idxr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">coeffs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rhs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/parameter_constraints.html#eval_lin_constraint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.parameter_constraints.eval_lin_constraint" title="Link to this definition"></a></dt>
<dd><p>Evaluate a single linear constraint.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>ndarray</em><em>[</em><em>tuple</em><em>[</em><em>int</em><em>, </em><em>...</em><em>]</em><em>, </em><em>dtype</em><em>[</em><em>_ScalarType_co</em><em>]</em><em>]</em>) – The input array.</p></li>
<li><p><strong>flat_idxr</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – The indices in <cite>x</cite> to consider.</p></li>
<li><p><strong>coeffs</strong> (<em>ndarray</em><em>[</em><em>tuple</em><em>[</em><em>int</em><em>, </em><em>...</em><em>]</em><em>, </em><em>dtype</em><em>[</em><em>_ScalarType_co</em><em>]</em><em>]</em>) – The coefficients corresponding to the indices.</p></li>
<li><p><strong>rhs</strong> (<em>float</em>) – The right-hand-side of the constraint.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><cite>sum_i (coeffs[i] * x[i]) - rhs</cite></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>The evaluted constraint</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.parameter_constraints.lin_constraint_jac">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.parameter_constraints.</span></span><span class="sig-name descname"><span class="pre">lin_constraint_jac</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">flat_idxr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">coeffs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/parameter_constraints.html#lin_constraint_jac"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.parameter_constraints.lin_constraint_jac" title="Link to this definition"></a></dt>
<dd><p>Return the Jacobian associated with a linear constraint.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>ndarray</em><em>[</em><em>tuple</em><em>[</em><em>int</em><em>, </em><em>...</em><em>]</em><em>, </em><em>dtype</em><em>[</em><em>_ScalarType_co</em><em>]</em><em>]</em>) – The input array.</p></li>
<li><p><strong>flat_idxr</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – The indices for the elements of x that appear in the constraint.</p></li>
<li><p><strong>coeffs</strong> (<em>ndarray</em><em>[</em><em>tuple</em><em>[</em><em>int</em><em>, </em><em>...</em><em>]</em><em>, </em><em>dtype</em><em>[</em><em>_ScalarType_co</em><em>]</em><em>]</em>) – The coefficients corresponding to the indices.</p></li>
<li><p><strong>n</strong> (<em>int</em>) – number of elements</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The Jacobian.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>ndarray</em>[tuple[int, …], <em>dtype</em>[<em>_ScalarType_co</em>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.parameter_constraints.nonlinear_constraint_is_feasible">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.parameter_constraints.</span></span><span class="sig-name descname"><span class="pre">nonlinear_constraint_is_feasible</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">nonlinear_inequality_constraint</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_intrapoint</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tolerance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-06</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/parameter_constraints.html#nonlinear_constraint_is_feasible"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.parameter_constraints.nonlinear_constraint_is_feasible" title="Link to this definition"></a></dt>
<dd><p>Checks if a nonlinear inequality constraint is fulfilled (within tolerance).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>nonlinear_inequality_constraint</strong> (<em>Callable</em>) – Callable to evaluate the
constraint.</p></li>
<li><p><strong>intra</strong> – If True, the constraint is an intra-point constraint that
is applied pointwise and is broadcasted over the q-batch. Else, the
constraint has to evaluated over the whole q-batch and is a an
inter-point constraint.</p></li>
<li><p><strong>x</strong> (<em>Tensor</em>) – Tensor of shape (batch x q x d).</p></li>
<li><p><strong>tolerance</strong> (<em>float</em>) – Rather than using the exact <cite>const(x) &gt;= 0</cite> constraint, this helper
checks feasibility of <cite>const(x) &gt;= -tolerance</cite>. This avoids marking the
candidates as infeasible due to tiny violations.</p></li>
<li><p><strong>is_intrapoint</strong> (<em>bool</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A boolean tensor of shape (batch) indicating if the constraint is
satified by the corresponding batch of <cite>x</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.parameter_constraints.make_scipy_nonlinear_inequality_constraints">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.parameter_constraints.</span></span><span class="sig-name descname"><span class="pre">make_scipy_nonlinear_inequality_constraints</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">nonlinear_inequality_constraints</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">f_np_wrapper</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shapeX</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/parameter_constraints.html#make_scipy_nonlinear_inequality_constraints"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.parameter_constraints.make_scipy_nonlinear_inequality_constraints" title="Link to this definition"></a></dt>
<dd><p>Generate Scipy nonlinear inequality constraints from callables.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>nonlinear_inequality_constraints</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>Callable</em><em>, </em><em>bool</em><em>]</em><em>]</em>) – A list of tuples representing the nonlinear
inequality constraints. The first element in the tuple is a callable
representing a constraint of the form <cite>callable(x) &gt;= 0</cite>. In case of an
intra-point constraint, <cite>callable()`takes in an one-dimensional tensor of
shape `d</cite> and returns a scalar. In case of an inter-point constraint,
<cite>callable()</cite> takes a two dimensional tensor of shape <cite>q x d</cite> and again
returns a scalar. The second element is a boolean, indicating if it is an
intra-point or inter-point constraint (<cite>True</cite> for intra-point. <cite>False</cite> for
inter-point). For more information on intra-point vs inter-point
constraints, see the docstring of the <cite>inequality_constraints</cite> argument to
<cite>optimize_acqf()</cite>. The constraints will later be passed to the scipy
solver.</p></li>
<li><p><strong>f_np_wrapper</strong> (<em>Callable</em>) – A wrapper function that given a constraint evaluates the value
and gradient (using autograd) of a numpy input and returns both the
objective and the gradient.</p></li>
<li><p><strong>x0</strong> (<em>Tensor</em>) – The starting point for SLSQP. We return this starting point in (rare)
cases where SLSQP fails and thus require it to be feasible.</p></li>
<li><p><strong>shapeX</strong> (<em>Size</em>) – Shape of the three-dimensional batch X, that should be optimized.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of dictionaries containing callables for constraint function
values and Jacobians and a string indicating the associated constraint
type (“eq”, “ineq”), as expected by <cite>scipy.minimize</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list[dict]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.parameter_constraints.evaluate_feasibility">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.parameter_constraints.</span></span><span class="sig-name descname"><span class="pre">evaluate_feasibility</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inequality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">equality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nonlinear_inequality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tolerance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-06</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/parameter_constraints.html#evaluate_feasibility"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.parameter_constraints.evaluate_feasibility" title="Link to this definition"></a></dt>
<dd><p>Evaluate feasibility of candidate points (within a tolerance).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – The candidate tensor of shape <cite>batch x q x d</cite>.</p></li>
<li><p><strong>inequality_constraints</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) &gt;= rhs</cite>. <cite>indices</cite> and
<cite>coefficients</cite> should be torch tensors. See the docstring of
<cite>make_scipy_linear_constraints</cite> for an example. When q=1, or when
applying the same constraint to each candidate in the batch
(intra-point constraint), <cite>indices</cite> should be a 1-d tensor.
For inter-point constraints, in which the constraint is applied to the
whole batch of candidates, <cite>indices</cite> must be a 2-d tensor, where
in each row <cite>indices[i] =(k_i, l_i)</cite> the first index <cite>k_i</cite> corresponds
to the <cite>k_i</cite>-th element of the <cite>q</cite>-batch and the second index <cite>l_i</cite>
corresponds to the <cite>l_i</cite>-th feature of that element.</p></li>
<li><p><strong>equality_constraints</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an equality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) = rhs</cite>. See the docstring of
<cite>make_scipy_linear_constraints</cite> for an example.</p></li>
<li><p><strong>nonlinear_inequality_constraints</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>Callable</em><em>, </em><em>bool</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of tuples representing the nonlinear
inequality constraints. The first element in the tuple is a callable
representing a constraint of the form <cite>callable(x) &gt;= 0</cite>. In case of an
intra-point constraint, <cite>callable()`takes in an one-dimensional tensor of
shape `d</cite> and returns a scalar. In case of an inter-point constraint,
<cite>callable()</cite> takes a two dimensional tensor of shape <cite>q x d</cite> and again
returns a scalar. The second element is a boolean, indicating if it is an
intra-point or inter-point constraint (<cite>True</cite> for intra-point. <cite>False</cite> for
inter-point). For more information on intra-point vs inter-point
constraints, see the docstring of the <cite>inequality_constraints</cite> argument.</p></li>
<li><p><strong>tolerance</strong> (<em>float</em>) – The tolerance used to check the feasibility of constraints.
For inequality constraints, we check if <cite>const(X) &gt;= rhs - tolerance</cite>.
For equality constraints, we check if <cite>abs(const(X) - rhs) &lt; tolerance</cite>.
For non-linear inequality constraints, we check if <cite>const(X) &gt;= -tolerance</cite>.
This avoids marking the candidates as infeasible due to tiny violations.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A boolean tensor of shape <cite>batch</cite> indicating if the corresponding candidate of
shape <cite>q x d</cite> is feasible.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-botorch.optim.homotopy">
<span id="homotopy-utilities"></span><h3>Homotopy Utilities<a class="headerlink" href="#module-botorch.optim.homotopy" title="Link to this heading"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.optim.homotopy.FixedHomotopySchedule">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.optim.homotopy.</span></span><span class="sig-name descname"><span class="pre">FixedHomotopySchedule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/homotopy.html#FixedHomotopySchedule"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.homotopy.FixedHomotopySchedule" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Homotopy schedule with a fixed list of values.</p>
<p>Initialize FixedHomotopySchedule.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>values</strong> (<em>list</em><em>[</em><em>float</em><em>]</em>) – A list of values used in homotopy</p>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="botorch.optim.homotopy.FixedHomotopySchedule.num_steps">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">num_steps</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#botorch.optim.homotopy.FixedHomotopySchedule.num_steps" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.optim.homotopy.FixedHomotopySchedule.value">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">value</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#botorch.optim.homotopy.FixedHomotopySchedule.value" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.optim.homotopy.FixedHomotopySchedule.should_stop">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">should_stop</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#botorch.optim.homotopy.FixedHomotopySchedule.should_stop" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.optim.homotopy.FixedHomotopySchedule.restart">
<span class="sig-name descname"><span class="pre">restart</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/homotopy.html#FixedHomotopySchedule.restart"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.homotopy.FixedHomotopySchedule.restart" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.optim.homotopy.FixedHomotopySchedule.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/homotopy.html#FixedHomotopySchedule.step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.homotopy.FixedHomotopySchedule.step" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.optim.homotopy.LinearHomotopySchedule">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.optim.homotopy.</span></span><span class="sig-name descname"><span class="pre">LinearHomotopySchedule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">start</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">end</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_steps</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/homotopy.html#LinearHomotopySchedule"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.homotopy.LinearHomotopySchedule" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.optim.homotopy.FixedHomotopySchedule" title="botorch.optim.homotopy.FixedHomotopySchedule"><code class="xref py py-class docutils literal notranslate"><span class="pre">FixedHomotopySchedule</span></code></a></p>
<p>Linear homotopy schedule.</p>
<p>Initialize LinearHomotopySchedule.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>start</strong> (<em>float</em>) – start value of homotopy</p></li>
<li><p><strong>end</strong> (<em>float</em>) – end value of homotopy</p></li>
<li><p><strong>num_steps</strong> (<em>int</em>) – number of steps in the homotopy schedule.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.optim.homotopy.LogLinearHomotopySchedule">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.optim.homotopy.</span></span><span class="sig-name descname"><span class="pre">LogLinearHomotopySchedule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">start</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">end</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_steps</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/homotopy.html#LogLinearHomotopySchedule"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.homotopy.LogLinearHomotopySchedule" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.optim.homotopy.FixedHomotopySchedule" title="botorch.optim.homotopy.FixedHomotopySchedule"><code class="xref py py-class docutils literal notranslate"><span class="pre">FixedHomotopySchedule</span></code></a></p>
<p>Log-linear homotopy schedule.</p>
<p>Initialize LogLinearHomotopySchedule.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>start</strong> (<em>float</em>) – start value of homotopy</p></li>
<li><p><strong>end</strong> (<em>float</em>) – end value of homotopy</p></li>
<li><p><strong>num_steps</strong> (<em>int</em>) – number of steps in the homotopy schedule.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.optim.homotopy.HomotopyParameter">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.optim.homotopy.</span></span><span class="sig-name descname"><span class="pre">HomotopyParameter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">parameter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">schedule</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/homotopy.html#HomotopyParameter"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.homotopy.HomotopyParameter" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Homotopy parameter.</p>
<p>The parameter is expected to either be a torch parameter or a torch tensor which may
correspond to a buffer of a module. The parameter has a corresponding schedule.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>parameter</strong> (<em>Parameter</em><em> | </em><em>Tensor</em>)</p></li>
<li><p><strong>schedule</strong> (<a class="reference internal" href="#botorch.optim.homotopy.FixedHomotopySchedule" title="botorch.optim.homotopy.FixedHomotopySchedule"><em>FixedHomotopySchedule</em></a>)</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.homotopy.HomotopyParameter.parameter">
<span class="sig-name descname"><span class="pre">parameter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Parameter</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span></em><a class="headerlink" href="#botorch.optim.homotopy.HomotopyParameter.parameter" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.homotopy.HomotopyParameter.schedule">
<span class="sig-name descname"><span class="pre">schedule</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="#botorch.optim.homotopy.FixedHomotopySchedule" title="botorch.optim.homotopy.FixedHomotopySchedule"><span class="pre">FixedHomotopySchedule</span></a></em><a class="headerlink" href="#botorch.optim.homotopy.HomotopyParameter.schedule" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.optim.homotopy.Homotopy">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.optim.homotopy.</span></span><span class="sig-name descname"><span class="pre">Homotopy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">homotopy_parameters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/homotopy.html#Homotopy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.homotopy.Homotopy" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Generic homotopy class.</p>
<p>This class is designed to be used in <cite>optimize_acqf_homotopy</cite>. Given a set of
homotopy parameters and corresponding schedules we step through the homotopies
until we have solved the final problem. We additionally support passing in a list
of callbacks that will be executed each time <cite>step</cite>, <cite>reset</cite>, and <cite>restart</cite> are
called.</p>
<p>Initialize the homotopy.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>homotopy_parameters</strong> (<em>list</em><em>[</em><a class="reference internal" href="#botorch.optim.homotopy.HomotopyParameter" title="botorch.optim.homotopy.HomotopyParameter"><em>HomotopyParameter</em></a><em>]</em>) – List of homotopy parameters</p></li>
<li><p><strong>callbacks</strong> (<em>list</em><em>[</em><em>Callable</em><em>] </em><em>| </em><em>None</em>) – Optional list of callbacks that are executed each time
<cite>restart</cite>, <cite>reset</cite>, or <cite>step</cite> are called. These may be used to, e.g.,
reinitialize the acquisition function which is needed when using qNEHVI.</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="botorch.optim.homotopy.Homotopy.should_stop">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">should_stop</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#botorch.optim.homotopy.Homotopy.should_stop" title="Link to this definition"></a></dt>
<dd><p>Returns true if all schedules have reached the end.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.optim.homotopy.Homotopy.restart">
<span class="sig-name descname"><span class="pre">restart</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/homotopy.html#Homotopy.restart"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.homotopy.Homotopy.restart" title="Link to this definition"></a></dt>
<dd><p>Restart the homotopy to use the initial value in the schedule.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.optim.homotopy.Homotopy.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/homotopy.html#Homotopy.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.homotopy.Homotopy.reset" title="Link to this definition"></a></dt>
<dd><p>Reset the homotopy parameter to their original values.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.optim.homotopy.Homotopy.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/homotopy.html#Homotopy.step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.homotopy.Homotopy.step" title="Link to this definition"></a></dt>
<dd><p>Take a step according to the schedules.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="posteriors.html" class="btn btn-neutral float-left" title="botorch.posteriors" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="fit.html" class="btn btn-neutral float-right" title="botorch.fit" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p></p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>