

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>botorch.models &mdash; BoTorch  documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="_static/custom.css?v=ca3e82f4" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=5929fcd5"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="botorch.generation" href="generation.html" />
    <link rel="prev" title="botorch.acquisition" href="acquisition.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            BoTorch
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="acquisition.html">botorch.acquisition</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">botorch.models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#model-apis">Model APIs</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.models.model">Base Model API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.model.Model"><code class="docutils literal notranslate"><span class="pre">Model</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.model.FantasizeMixin"><code class="docutils literal notranslate"><span class="pre">FantasizeMixin</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.model.ModelList"><code class="docutils literal notranslate"><span class="pre">ModelList</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.model.ModelDict"><code class="docutils literal notranslate"><span class="pre">ModelDict</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.models.gpytorch">GPyTorch Model API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.gpytorch.GPyTorchModel"><code class="docutils literal notranslate"><span class="pre">GPyTorchModel</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel"><code class="docutils literal notranslate"><span class="pre">BatchedMultiOutputGPyTorchModel</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.gpytorch.ModelListGPyTorchModel"><code class="docutils literal notranslate"><span class="pre">ModelListGPyTorchModel</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.gpytorch.MultiTaskGPyTorchModel"><code class="docutils literal notranslate"><span class="pre">MultiTaskGPyTorchModel</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.models.deterministic">Deterministic Model API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.deterministic.DeterministicModel"><code class="docutils literal notranslate"><span class="pre">DeterministicModel</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.deterministic.GenericDeterministicModel"><code class="docutils literal notranslate"><span class="pre">GenericDeterministicModel</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.deterministic.AffineDeterministicModel"><code class="docutils literal notranslate"><span class="pre">AffineDeterministicModel</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.deterministic.PosteriorMeanModel"><code class="docutils literal notranslate"><span class="pre">PosteriorMeanModel</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.deterministic.FixedSingleSampleModel"><code class="docutils literal notranslate"><span class="pre">FixedSingleSampleModel</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.models.ensemble">Ensemble Model API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.ensemble.EnsembleModel"><code class="docutils literal notranslate"><span class="pre">EnsembleModel</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#models">Models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.models.cost">Cost Models (for cost-aware optimization)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.cost.AffineFidelityCostModel"><code class="docutils literal notranslate"><span class="pre">AffineFidelityCostModel</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.cost.FixedCostModel"><code class="docutils literal notranslate"><span class="pre">FixedCostModel</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.models.contextual">Contextual GP Models with Aggregate Rewards</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.contextual.SACGP"><code class="docutils literal notranslate"><span class="pre">SACGP</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.contextual.LCEAGP"><code class="docutils literal notranslate"><span class="pre">LCEAGP</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.models.contextual_multioutput">Contextual GP Models with Context Rewards</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.contextual_multioutput.LCEMGP"><code class="docutils literal notranslate"><span class="pre">LCEMGP</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.models.fully_bayesian">Fully Bayesian GP Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.fully_bayesian.matern52_kernel"><code class="docutils literal notranslate"><span class="pre">matern52_kernel()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.fully_bayesian.linear_kernel"><code class="docutils literal notranslate"><span class="pre">linear_kernel()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.fully_bayesian.compute_dists"><code class="docutils literal notranslate"><span class="pre">compute_dists()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.fully_bayesian.reshape_and_detach"><code class="docutils literal notranslate"><span class="pre">reshape_and_detach()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.fully_bayesian.PyroModel"><code class="docutils literal notranslate"><span class="pre">PyroModel</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.fully_bayesian.SaasPyroModel"><code class="docutils literal notranslate"><span class="pre">SaasPyroModel</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.fully_bayesian.LinearPyroModel"><code class="docutils literal notranslate"><span class="pre">LinearPyroModel</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.fully_bayesian.FullyBayesianSingleTaskGP"><code class="docutils literal notranslate"><span class="pre">FullyBayesianSingleTaskGP</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.fully_bayesian.SaasFullyBayesianSingleTaskGP"><code class="docutils literal notranslate"><span class="pre">SaasFullyBayesianSingleTaskGP</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.fully_bayesian.FullyBayesianLinearSingleTaskGP"><code class="docutils literal notranslate"><span class="pre">FullyBayesianLinearSingleTaskGP</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.models.fully_bayesian_multitask">Fully Bayesian Multitask GP Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.fully_bayesian_multitask.MultitaskSaasPyroModel"><code class="docutils literal notranslate"><span class="pre">MultitaskSaasPyroModel</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.fully_bayesian_multitask.SaasFullyBayesianMultiTaskGP"><code class="docutils literal notranslate"><span class="pre">SaasFullyBayesianMultiTaskGP</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.models.gp_regression">GP Regression Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.gp_regression.SingleTaskGP"><code class="docutils literal notranslate"><span class="pre">SingleTaskGP</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.models.gp_regression_mixed">GP Regression Models for Mixed Parameter Spaces</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.gp_regression_mixed.MixedSingleTaskGP"><code class="docutils literal notranslate"><span class="pre">MixedSingleTaskGP</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.models.higher_order_gp">Higher Order GP Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.higher_order_gp.FlattenedStandardize"><code class="docutils literal notranslate"><span class="pre">FlattenedStandardize</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.higher_order_gp.HigherOrderGP"><code class="docutils literal notranslate"><span class="pre">HigherOrderGP</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.models.latent_kronecker_gp">Latent Kronecker GP Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.latent_kronecker_gp.MinMaxStandardize"><code class="docutils literal notranslate"><span class="pre">MinMaxStandardize</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.latent_kronecker_gp.LatentKroneckerGP"><code class="docutils literal notranslate"><span class="pre">LatentKroneckerGP</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.models.model_list_gp_regression">Model List GP Regression Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.model_list_gp_regression.ModelListGP"><code class="docutils literal notranslate"><span class="pre">ModelListGP</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.models.multitask">Multitask GP Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.multitask.MultiTaskGP"><code class="docutils literal notranslate"><span class="pre">MultiTaskGP</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.multitask.KroneckerMultiTaskGP"><code class="docutils literal notranslate"><span class="pre">KroneckerMultiTaskGP</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.models.gp_regression_fidelity">Multi-Fidelity GP Regression Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.gp_regression_fidelity.SingleTaskMultiFidelityGP"><code class="docutils literal notranslate"><span class="pre">SingleTaskMultiFidelityGP</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.models.pairwise_gp">Pairwise GP Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.pairwise_gp.PairwiseGP"><code class="docutils literal notranslate"><span class="pre">PairwiseGP</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.pairwise_gp.PairwiseLaplaceMarginalLogLikelihood"><code class="docutils literal notranslate"><span class="pre">PairwiseLaplaceMarginalLogLikelihood</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.models.relevance_pursuit">Relevance Pursuit Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.relevance_pursuit.RelevancePursuitMixin"><code class="docutils literal notranslate"><span class="pre">RelevancePursuitMixin</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.relevance_pursuit.forward_relevance_pursuit"><code class="docutils literal notranslate"><span class="pre">forward_relevance_pursuit()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.relevance_pursuit.backward_relevance_pursuit"><code class="docutils literal notranslate"><span class="pre">backward_relevance_pursuit()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.relevance_pursuit.get_posterior_over_support"><code class="docutils literal notranslate"><span class="pre">get_posterior_over_support()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.relevance_pursuit.initialize_dense_parameters"><code class="docutils literal notranslate"><span class="pre">initialize_dense_parameters()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.models.map_saas">Sparse Axis-Aligned Subspaces (SAAS) GP Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.map_saas.SaasPriorHelper"><code class="docutils literal notranslate"><span class="pre">SaasPriorHelper</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.map_saas.add_saas_prior"><code class="docutils literal notranslate"><span class="pre">add_saas_prior()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.map_saas.get_map_saas_model"><code class="docutils literal notranslate"><span class="pre">get_map_saas_model()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.map_saas.get_mean_module_with_normal_prior"><code class="docutils literal notranslate"><span class="pre">get_mean_module_with_normal_prior()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.map_saas.get_gaussian_likelihood_with_gamma_prior"><code class="docutils literal notranslate"><span class="pre">get_gaussian_likelihood_with_gamma_prior()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.map_saas.get_additive_map_saas_covar_module"><code class="docutils literal notranslate"><span class="pre">get_additive_map_saas_covar_module()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.map_saas.AdditiveMapSaasSingleTaskGP"><code class="docutils literal notranslate"><span class="pre">AdditiveMapSaasSingleTaskGP</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.models.robust_relevance_pursuit_model">Variational GP Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.robust_relevance_pursuit_model.RobustRelevancePursuitMixin"><code class="docutils literal notranslate"><span class="pre">RobustRelevancePursuitMixin</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.robust_relevance_pursuit_model.RobustRelevancePursuitSingleTaskGP"><code class="docutils literal notranslate"><span class="pre">RobustRelevancePursuitSingleTaskGP</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.approximate_gp.ApproximateGPyTorchModel"><code class="docutils literal notranslate"><span class="pre">ApproximateGPyTorchModel</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.approximate_gp.SingleTaskVariationalGP"><code class="docutils literal notranslate"><span class="pre">SingleTaskVariationalGP</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#model-components">Model Components</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.models.kernels.categorical">Kernels</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.kernels.categorical.CategoricalKernel"><code class="docutils literal notranslate"><span class="pre">CategoricalKernel</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.kernels.downsampling.DownsamplingKernel"><code class="docutils literal notranslate"><span class="pre">DownsamplingKernel</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.kernels.exponential_decay.ExponentialDecayKernel"><code class="docutils literal notranslate"><span class="pre">ExponentialDecayKernel</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.kernels.infinite_width_bnn.InfiniteWidthBNNKernel"><code class="docutils literal notranslate"><span class="pre">InfiniteWidthBNNKernel</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.kernels.linear_truncated_fidelity.LinearTruncatedFidelityKernel"><code class="docutils literal notranslate"><span class="pre">LinearTruncatedFidelityKernel</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.kernels.contextual_lcea.LCEAKernel"><code class="docutils literal notranslate"><span class="pre">LCEAKernel</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.kernels.contextual_sac.SACKernel"><code class="docutils literal notranslate"><span class="pre">SACKernel</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.kernels.orthogonal_additive_kernel.OrthogonalAdditiveKernel"><code class="docutils literal notranslate"><span class="pre">OrthogonalAdditiveKernel</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.models.likelihoods.pairwise">Likelihoods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.likelihoods.pairwise.PairwiseLikelihood"><code class="docutils literal notranslate"><span class="pre">PairwiseLikelihood</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.likelihoods.pairwise.PairwiseProbitLikelihood"><code class="docutils literal notranslate"><span class="pre">PairwiseProbitLikelihood</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.likelihoods.pairwise.PairwiseLogitLikelihood"><code class="docutils literal notranslate"><span class="pre">PairwiseLogitLikelihood</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.likelihoods.sparse_outlier_noise.SparseOutlierGaussianLikelihood"><code class="docutils literal notranslate"><span class="pre">SparseOutlierGaussianLikelihood</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.likelihoods.sparse_outlier_noise.SparseOutlierNoise"><code class="docutils literal notranslate"><span class="pre">SparseOutlierNoise</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#transforms">Transforms</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.models.transforms.outcome">Outcome Transforms</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform"><code class="docutils literal notranslate"><span class="pre">OutcomeTransform</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.transforms.outcome.ChainedOutcomeTransform"><code class="docutils literal notranslate"><span class="pre">ChainedOutcomeTransform</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.transforms.outcome.Standardize"><code class="docutils literal notranslate"><span class="pre">Standardize</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.transforms.outcome.StratifiedStandardize"><code class="docutils literal notranslate"><span class="pre">StratifiedStandardize</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.transforms.outcome.Log"><code class="docutils literal notranslate"><span class="pre">Log</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.transforms.outcome.Power"><code class="docutils literal notranslate"><span class="pre">Power</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.transforms.outcome.Bilog"><code class="docutils literal notranslate"><span class="pre">Bilog</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.models.transforms.input">Input Transforms</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.transforms.input.InputTransform"><code class="docutils literal notranslate"><span class="pre">InputTransform</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.transforms.input.BatchBroadcastedInputTransform"><code class="docutils literal notranslate"><span class="pre">BatchBroadcastedInputTransform</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.transforms.input.ChainedInputTransform"><code class="docutils literal notranslate"><span class="pre">ChainedInputTransform</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.transforms.input.ReversibleInputTransform"><code class="docutils literal notranslate"><span class="pre">ReversibleInputTransform</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.transforms.input.AffineInputTransform"><code class="docutils literal notranslate"><span class="pre">AffineInputTransform</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.transforms.input.Normalize"><code class="docutils literal notranslate"><span class="pre">Normalize</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.transforms.input.InputStandardize"><code class="docutils literal notranslate"><span class="pre">InputStandardize</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.transforms.input.Round"><code class="docutils literal notranslate"><span class="pre">Round</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.transforms.input.Log10"><code class="docutils literal notranslate"><span class="pre">Log10</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.transforms.input.Warp"><code class="docutils literal notranslate"><span class="pre">Warp</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.transforms.input.AppendFeatures"><code class="docutils literal notranslate"><span class="pre">AppendFeatures</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.transforms.input.InteractionFeatures"><code class="docutils literal notranslate"><span class="pre">InteractionFeatures</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.transforms.input.FilterFeatures"><code class="docutils literal notranslate"><span class="pre">FilterFeatures</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.transforms.input.InputPerturbation"><code class="docutils literal notranslate"><span class="pre">InputPerturbation</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.transforms.input.OneHotToNumeric"><code class="docutils literal notranslate"><span class="pre">OneHotToNumeric</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.models.transforms.factory">Transform Factory Methods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.transforms.factory.get_rounding_input_transform"><code class="docutils literal notranslate"><span class="pre">get_rounding_input_transform()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.models.transforms.utils">Transform Utilities</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.transforms.utils.lognorm_to_norm"><code class="docutils literal notranslate"><span class="pre">lognorm_to_norm()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.transforms.utils.norm_to_lognorm"><code class="docutils literal notranslate"><span class="pre">norm_to_lognorm()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.transforms.utils.norm_to_lognorm_mean"><code class="docutils literal notranslate"><span class="pre">norm_to_lognorm_mean()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.transforms.utils.norm_to_lognorm_variance"><code class="docutils literal notranslate"><span class="pre">norm_to_lognorm_variance()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.transforms.utils.expand_and_copy_tensor"><code class="docutils literal notranslate"><span class="pre">expand_and_copy_tensor()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.transforms.utils.subset_transform"><code class="docutils literal notranslate"><span class="pre">subset_transform()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.transforms.utils.interaction_features"><code class="docutils literal notranslate"><span class="pre">interaction_features()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.transforms.utils.nanstd"><code class="docutils literal notranslate"><span class="pre">nanstd()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.transforms.utils.kumaraswamy_warp"><code class="docutils literal notranslate"><span class="pre">kumaraswamy_warp()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.transforms.utils.inv_kumaraswamy_warp"><code class="docutils literal notranslate"><span class="pre">inv_kumaraswamy_warp()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#utilities">Utilities</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.models.utils.gpytorch_modules">GPyTorch Module Constructors</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.utils.gpytorch_modules.get_matern_kernel_with_gamma_prior"><code class="docutils literal notranslate"><span class="pre">get_matern_kernel_with_gamma_prior()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.utils.gpytorch_modules.get_gaussian_likelihood_with_gamma_prior"><code class="docutils literal notranslate"><span class="pre">get_gaussian_likelihood_with_gamma_prior()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.utils.gpytorch_modules.get_gaussian_likelihood_with_lognormal_prior"><code class="docutils literal notranslate"><span class="pre">get_gaussian_likelihood_with_lognormal_prior()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.utils.gpytorch_modules.get_covar_module_with_dim_scaled_prior"><code class="docutils literal notranslate"><span class="pre">get_covar_module_with_dim_scaled_prior()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.models.converter">Model Conversion</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.converter.model_list_to_batched"><code class="docutils literal notranslate"><span class="pre">model_list_to_batched()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.converter.set_attribute"><code class="docutils literal notranslate"><span class="pre">set_attribute()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.converter.get_attribute"><code class="docutils literal notranslate"><span class="pre">get_attribute()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.converter.batched_to_model_list"><code class="docutils literal notranslate"><span class="pre">batched_to_model_list()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.converter.batched_multi_output_to_single_output"><code class="docutils literal notranslate"><span class="pre">batched_multi_output_to_single_output()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.models.utils.inducing_point_allocators">Inducing Point Allocators</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.utils.inducing_point_allocators.InducingPointAllocator"><code class="docutils literal notranslate"><span class="pre">InducingPointAllocator</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.utils.inducing_point_allocators.QualityFunction"><code class="docutils literal notranslate"><span class="pre">QualityFunction</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.utils.inducing_point_allocators.UnitQualityFunction"><code class="docutils literal notranslate"><span class="pre">UnitQualityFunction</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.utils.inducing_point_allocators.ExpectedImprovementQualityFunction"><code class="docutils literal notranslate"><span class="pre">ExpectedImprovementQualityFunction</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.utils.inducing_point_allocators.GreedyVarianceReduction"><code class="docutils literal notranslate"><span class="pre">GreedyVarianceReduction</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.utils.inducing_point_allocators.GreedyImprovementReduction"><code class="docutils literal notranslate"><span class="pre">GreedyImprovementReduction</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.utils.inducing_point_allocators._pivoted_cholesky_init"><code class="docutils literal notranslate"><span class="pre">_pivoted_cholesky_init()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.models.utils.assorted">Other Utilties</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.utils.assorted.multioutput_to_batch_mode_transform"><code class="docutils literal notranslate"><span class="pre">multioutput_to_batch_mode_transform()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.utils.assorted.add_output_dim"><code class="docutils literal notranslate"><span class="pre">add_output_dim()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.utils.assorted.check_no_nans"><code class="docutils literal notranslate"><span class="pre">check_no_nans()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.utils.assorted.check_min_max_scaling"><code class="docutils literal notranslate"><span class="pre">check_min_max_scaling()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.utils.assorted.check_standardization"><code class="docutils literal notranslate"><span class="pre">check_standardization()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.utils.assorted.validate_input_scaling"><code class="docutils literal notranslate"><span class="pre">validate_input_scaling()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.utils.assorted.mod_batch_shape"><code class="docutils literal notranslate"><span class="pre">mod_batch_shape()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.utils.assorted.gpt_posterior_settings"><code class="docutils literal notranslate"><span class="pre">gpt_posterior_settings()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.utils.assorted.detect_duplicates"><code class="docutils literal notranslate"><span class="pre">detect_duplicates()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.utils.assorted.consolidate_duplicates"><code class="docutils literal notranslate"><span class="pre">consolidate_duplicates()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.utils.assorted.fantasize"><code class="docutils literal notranslate"><span class="pre">fantasize</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.models.utils.assorted.get_task_value_remapping"><code class="docutils literal notranslate"><span class="pre">get_task_value_remapping()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="generation.html">botorch.generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="posteriors.html">botorch.posteriors</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim.html">botorch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="fit.html">botorch.fit</a></li>
<li class="toctree-l1"><a class="reference internal" href="sampling.html">botorch.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="cross_validation.html">botorch.cross_validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="settings.html">botorch.settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="logging.html">botorch.logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_functions.html">botorch.test_functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_utils.html">botorch.test_utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="exceptions.html">botorch.exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">botorch.utils</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">BoTorch</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">botorch.models</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/models.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-botorch.models">
<span id="botorch-models"></span><h1>botorch.models<a class="headerlink" href="#module-botorch.models" title="Link to this heading"></a></h1>
<section id="model-apis">
<h2>Model APIs<a class="headerlink" href="#model-apis" title="Link to this heading"></a></h2>
<section id="module-botorch.models.model">
<span id="base-model-api"></span><h3>Base Model API<a class="headerlink" href="#module-botorch.models.model" title="Link to this heading"></a></h3>
<p>Abstract base module for all BoTorch models.</p>
<p>This module contains <cite>Model</cite>, the abstract base class for all BoTorch models,
and <cite>ModelList</cite>, a container for a list of Models.</p>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.model.Model">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.model.</span></span><span class="sig-name descname"><span class="pre">Model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/model.html#Model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.model.Model" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>Abstract base class for BoTorch models.</p>
<p>The <cite>Model</cite> base class cannot be used directly; it only defines an API for other
BoTorch models.</p>
<p><cite>Model</cite> subclasses <cite>torch.nn.Module</cite>. While a <cite>Module</cite> is most typically
encountered as a representation of a neural network layer, it can be used more
generally: see
<a class="reference external" href="https://pytorch.org/tutorials/beginner/examples_nn/polynomial_module.html">documentation</a>
on custom NN Modules.</p>
<p><cite>Module</cite> provides several pieces of useful functionality: A <cite>Model</cite>’s attributes of
<cite>Tensor</cite> or <cite>Module</cite> type are automatically registered so they can be moved and/or
cast with the <cite>to</cite> method, automatically differentiated, and used with CUDA.</p>
<dl class="field-list simple">
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.model.Model._has_transformed_inputs">
<span class="sig-name descname"><span class="pre">_has_transformed_inputs</span></span><a class="headerlink" href="#botorch.models.model.Model._has_transformed_inputs" title="Link to this definition"></a></dt>
<dd><p>A boolean denoting whether <cite>train_inputs</cite> are currently
stored as transformed or not.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.model.Model._original_train_inputs">
<span class="sig-name descname"><span class="pre">_original_train_inputs</span></span><a class="headerlink" href="#botorch.models.model.Model._original_train_inputs" title="Link to this definition"></a></dt>
<dd><p>A Tensor storing the original train inputs for use in
<cite>_revert_to_original_inputs</cite>. Note that this is necessary since
transform / untransform cycle introduces numerical errors which lead
to upstream errors during training.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor | None</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.model.Model._is_fully_bayesian">
<span class="sig-name descname"><span class="pre">_is_fully_bayesian</span></span><a class="headerlink" href="#botorch.models.model.Model._is_fully_bayesian" title="Link to this definition"></a></dt>
<dd><p>Returns <cite>True</cite> if this is a fully Bayesian model.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.model.Model._is_ensemble">
<span class="sig-name descname"><span class="pre">_is_ensemble</span></span><a class="headerlink" href="#botorch.models.model.Model._is_ensemble" title="Link to this definition"></a></dt>
<dd><p>Returns <cite>True</cite> if this model consists of multiple models
that are stored in an additional batch dimension. This is true for the fully
Bayesian models.</p>
</dd></dl>

<p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.model.Model.posterior">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">posterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observation_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/model.html#Model.posterior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.model.Model.posterior" title="Link to this definition"></a></dt>
<dd><p>Computes the posterior over model outputs at the provided points.</p>
<dl class="simple">
<dt>Note: The input transforms should be applied here using</dt><dd><p><cite>self.transform_inputs(X)</cite> after the <cite>self.eval()</cite> call and before
any <cite>model.forward</cite> or <cite>model.likelihood</cite> calls.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>b x q x d</cite>-dim Tensor, where <cite>d</cite> is the dimension of the
feature space, <cite>q</cite> is the number of points considered jointly,
and <cite>b</cite> is the batch dimension.</p></li>
<li><p><strong>output_indices</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – A list of indices, corresponding to the outputs over
which to compute the posterior (if the model is multi-output).
Can be used to speed up computation if only a subset of the
model’s outputs are required for optimization. If omitted,
computes the posterior over all model outputs.</p></li>
<li><p><strong>observation_noise</strong> (<em>bool</em><em> | </em><em>Tensor</em>) – For models with an inferred noise level, if True,
include observation noise. For models with an observed noise level,
this must be a <cite>model_batch_shape x 1 x m</cite>-dim tensor or
a <cite>model_batch_shape x n’ x m</cite>-dim tensor containing the average
noise for each batch and output. <cite>noise</cite> must be in the
outcome-transformed space if an outcome transform is used.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="acquisition.html#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – An optional PosteriorTransform.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>Posterior</cite> object, representing a batch of <cite>b</cite> joint distributions
over <cite>q</cite> points and <cite>m</cite> outputs each.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.posterior.Posterior" title="botorch.posteriors.posterior.Posterior">Posterior</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.model.Model.batch_shape">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">batch_shape</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Size</span></em><a class="headerlink" href="#botorch.models.model.Model.batch_shape" title="Link to this definition"></a></dt>
<dd><p>The batch shape of the model.</p>
<p>This is a batch shape from an I/O perspective, independent of the internal
representation of the model (as e.g. in BatchedMultiOutputGPyTorchModel).
For a model with <cite>m</cite> outputs, a <cite>test_batch_shape x q x d</cite>-shaped input <cite>X</cite>
to the <cite>posterior</cite> method returns a Posterior object over an output of
shape <cite>broadcast(test_batch_shape, model.batch_shape) x q x m</cite>.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.model.Model.num_outputs">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">num_outputs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#botorch.models.model.Model.num_outputs" title="Link to this definition"></a></dt>
<dd><p>The number of outputs of the model.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.model.Model.subset_output">
<span class="sig-name descname"><span class="pre">subset_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idcs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/model.html#Model.subset_output"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.model.Model.subset_output" title="Link to this definition"></a></dt>
<dd><p>Subset the model along the output dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>idcs</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – The output indices to subset the model to.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>Model</cite> object of the same type and with the same parameters as
the current model, subset to the specified output indices.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.model.Model.condition_on_observations">
<span class="sig-name descname"><span class="pre">condition_on_observations</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/model.html#Model.condition_on_observations"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.model.Model.condition_on_observations" title="Link to this definition"></a></dt>
<dd><p>Condition the model on new observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n’ x d</cite>-dim Tensor, where <cite>d</cite> is the dimension of
the feature space, <cite>n’</cite> is the number of points per batch, and
<cite>batch_shape</cite> is the batch shape (must be compatible with the
batch shape of the model).</p></li>
<li><p><strong>Y</strong> (<em>Tensor</em>) – A <cite>batch_shape’ x n’ x m</cite>-dim Tensor, where <cite>m</cite> is the number of
model outputs, <cite>n’</cite> is the number of points per batch, and
<cite>batch_shape’</cite> is the batch shape of the observations.
<cite>batch_shape’</cite> must be broadcastable to <cite>batch_shape</cite> using
standard broadcasting semantics. If <cite>Y</cite> has fewer batch dimensions
than <cite>X</cite>, it is assumed that the missing batch dimensions are
the same for all <cite>Y</cite>.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>Model</cite> object of the same type, representing the original model
conditioned on the new observations <cite>(X, Y)</cite> (and possibly noise
observations passed in via kwargs).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.model.Model.construct_inputs">
<em class="property"><span class="k"><span class="pre">classmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct_inputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">training_data</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/model.html#Model.construct_inputs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.model.Model.construct_inputs" title="Link to this definition"></a></dt>
<dd><p>Construct <cite>Model</cite> keyword arguments from a <cite>SupervisedDataset</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>training_data</strong> (<a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a>) – A <cite>SupervisedDataset</cite>, with attributes <cite>train_X</cite>,
<cite>train_Y</cite>, and, optionally, <cite>train_Yvar</cite>.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dict of keyword arguments that can be used to initialize a <cite>Model</cite>,
with keys <cite>train_X</cite>, <cite>train_Y</cite>, and, optionally, <cite>train_Yvar</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict[str, <a class="reference internal" href="utils.html#botorch.utils.containers.BotorchContainer" title="botorch.utils.containers.BotorchContainer"><em>BotorchContainer</em></a> | <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.model.Model.transform_inputs">
<span class="sig-name descname"><span class="pre">transform_inputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/model.html#Model.transform_inputs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.model.Model.transform_inputs" title="Link to this definition"></a></dt>
<dd><p>Transform inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A tensor of inputs</p></li>
<li><p><strong>input_transform</strong> (<em>Module</em><em> | </em><em>None</em>) – A Module that performs the input transformation.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor of transformed inputs</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.model.Model.eval">
<span class="sig-name descname"><span class="pre">eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/model.html#Model.eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.model.Model.eval" title="Link to this definition"></a></dt>
<dd><p>Puts the model in <cite>eval</cite> mode and sets the transformed inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.model.Model.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/model.html#Model.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.model.Model.train" title="Link to this definition"></a></dt>
<dd><p>Put the model in <cite>train</cite> mode. Reverts to the original inputs if in <cite>train</cite>
mode (<cite>mode=True</cite>) or sets transformed inputs if in <cite>eval</cite> mode (<cite>mode=False</cite>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>mode</strong> (<em>bool</em>) – A boolean denoting whether to put in <cite>train</cite> or <cite>eval</cite> mode.
If <cite>False</cite>, model is put in <cite>eval</cite> mode.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.model.Model.dtypes_of_buffers">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">dtypes_of_buffers</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">set</span><span class="p"><span class="pre">[</span></span><span class="pre">dtype</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#botorch.models.model.Model.dtypes_of_buffers" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.model.FantasizeMixin">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.model.</span></span><span class="sig-name descname"><span class="pre">FantasizeMixin</span></span><a class="reference internal" href="_modules/botorch/models/model.html#FantasizeMixin"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.model.FantasizeMixin" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>Mixin to add a <cite>fantasize</cite> method to a <cite>Model</cite>.</p>
<p class="rubric">Example</p>
<dl class="simple">
<dt>class BaseModel:</dt><dd><p>def __init__(self, …):
def condition_on_observations(self, …):
def posterior(self, …):
def transform_inputs(self, …):</p>
</dd>
<dt>class ModelThatCanFantasize(BaseModel, FantasizeMixin):</dt><dd><dl class="simple">
<dt>def __init__(self, args):</dt><dd><p>super().__init__(args)</p>
</dd>
</dl>
</dd>
</dl>
<p>model = ModelThatCanFantasize(…)
model.fantasize(X)</p>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.model.FantasizeMixin.condition_on_observations">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">condition_on_observations</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/model.html#FantasizeMixin.condition_on_observations"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.model.FantasizeMixin.condition_on_observations" title="Link to this definition"></a></dt>
<dd><p>Classes that inherit from <cite>FantasizeMixin</cite> must implement
a <cite>condition_on_observations</cite> method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>)</p></li>
<li><p><strong>Y</strong> (<em>Tensor</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Self</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.model.FantasizeMixin.posterior">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">posterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observation_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/model.html#FantasizeMixin.posterior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.model.FantasizeMixin.posterior" title="Link to this definition"></a></dt>
<dd><p>Classes that inherit from <cite>FantasizeMixin</cite> must implement
a <cite>posterior</cite> method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>)</p></li>
<li><p><strong>observation_noise</strong> (<em>bool</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.posterior.Posterior" title="botorch.posteriors.posterior.Posterior"><em>Posterior</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.model.FantasizeMixin.transform_inputs">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">transform_inputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/model.html#FantasizeMixin.transform_inputs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.model.FantasizeMixin.transform_inputs" title="Link to this definition"></a></dt>
<dd><p>Classes that inherit from <cite>FantasizeMixin</cite> must implement
a <cite>transform_inputs</cite> method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>)</p></li>
<li><p><strong>input_transform</strong> (<em>Module</em><em> | </em><em>None</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.model.FantasizeMixin.fantasize">
<span class="sig-name descname"><span class="pre">fantasize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observation_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/model.html#FantasizeMixin.fantasize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.model.FantasizeMixin.fantasize" title="Link to this definition"></a></dt>
<dd><p>Construct a fantasy model.</p>
<p>Constructs a fantasy model in the following fashion:
(1) compute the model posterior at <cite>X</cite>, including observation noise.
If <cite>observation_noise</cite> is a Tensor, use it directly as the observation
noise to add.
(2) sample from this posterior (using <cite>sampler</cite>) to generate “fake”
observations.
(3) condition the model on the new fake observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n’ x d</cite>-dim Tensor, where <cite>d</cite> is the dimension of
the feature space, <cite>n’</cite> is the number of points per batch, and
<cite>batch_shape</cite> is the batch shape (must be compatible with the
batch shape of the model).</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a>) – The sampler used for sampling from the posterior at <cite>X</cite>.</p></li>
<li><p><strong>observation_noise</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>model_batch_shape x 1 x m</cite>-dim tensor or
a <cite>model_batch_shape x n’ x m</cite>-dim tensor containing the average
noise for each batch and output, where <cite>m</cite> is the number of outputs.
<cite>noise</cite> must be in the outcome-transformed space if an outcome
transform is used.
If None and using an inferred noise likelihood, the noise will be the
inferred noise level. If using a fixed noise likelihood, the mean across
the observation noise in the training data is used as observation noise.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – Will be passed to <cite>model.condition_on_observations</cite></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The constructed fantasy model.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Self</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.model.ModelList">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.model.</span></span><span class="sig-name descname"><span class="pre">ModelList</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">models</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/model.html#ModelList"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.model.ModelList" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model"><code class="xref py py-class docutils literal notranslate"><span class="pre">Model</span></code></a></p>
<p>A multi-output Model represented by a list of independent models.</p>
<p>All BoTorch models are acceptable as inputs. The cost of this flexibility is
that <cite>ModelList</cite> does not support all methods that may be implemented by its
component models. One use case for <cite>ModelList</cite> is combining a regression
model and a deterministic model in one multi-output container model, e.g.
for cost-aware or multi-objective optimization where one of the outcomes is
a deterministic function of the inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>*models</strong> (<a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A variable number of models.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m_1</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m_2</span> <span class="o">=</span> <span class="n">GenericDeterministicModel</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m_12</span> <span class="o">=</span> <span class="n">ModelList</span><span class="p">(</span><span class="n">m_1</span><span class="p">,</span> <span class="n">m_2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m_12</span><span class="o">.</span><span class="n">posterior</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.model.ModelList.posterior">
<span class="sig-name descname"><span class="pre">posterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observation_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/model.html#ModelList.posterior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.model.ModelList.posterior" title="Link to this definition"></a></dt>
<dd><p>Computes the posterior over model outputs at the provided points.</p>
<dl class="simple">
<dt>Note: The input transforms should be applied here using</dt><dd><p><cite>self.transform_inputs(X)</cite> after the <cite>self.eval()</cite> call and before
any <cite>model.forward</cite> or <cite>model.likelihood</cite> calls.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>b x q x d</cite>-dim Tensor, where <cite>d</cite> is the dimension of the
feature space, <cite>q</cite> is the number of points considered jointly,
and <cite>b</cite> is the batch dimension.</p></li>
<li><p><strong>output_indices</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – A list of indices, corresponding to the outputs over
which to compute the posterior (if the model is multi-output).
Can be used to speed up computation if only a subset of the
model’s outputs are required for optimization. If omitted,
computes the posterior over all model outputs.</p></li>
<li><p><strong>observation_noise</strong> (<em>bool</em><em> | </em><em>Tensor</em>) – If True, add the observation noise from the
respective likelihoods to the posterior. If a Tensor of shape
<cite>(batch_shape) x q x m</cite>, use it directly as the observation
noise (with <cite>observation_noise[…,i]</cite> added to the posterior
of the <cite>i</cite>-th model). <cite>observation_noise</cite> is assumed
to be in the outcome-transformed space, if an outcome transform
is used by the model.</p></li>
<li><p><strong>posterior_transform</strong> (<em>Callable</em><em>[</em><em>[</em><a class="reference internal" href="posteriors.html#botorch.posteriors.posterior_list.PosteriorList" title="botorch.posteriors.posterior_list.PosteriorList"><em>PosteriorList</em></a><em>]</em><em>, </em><a class="reference internal" href="posteriors.html#botorch.posteriors.posterior.Posterior" title="botorch.posteriors.posterior.Posterior"><em>Posterior</em></a><em>] </em><em>| </em><em>None</em>) – An optional PosteriorTransform.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>Posterior</cite> object, representing a batch of <cite>b</cite> joint distributions
over <cite>q</cite> points and <cite>m</cite> outputs each.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.posterior.Posterior" title="botorch.posteriors.posterior.Posterior"><em>Posterior</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.model.ModelList.batch_shape">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">batch_shape</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Size</span></em><a class="headerlink" href="#botorch.models.model.ModelList.batch_shape" title="Link to this definition"></a></dt>
<dd><p>The batch shape of the model.</p>
<p>This is a batch shape from an I/O perspective, independent of the internal
representation of the model (as e.g. in BatchedMultiOutputGPyTorchModel).
For a model with <cite>m</cite> outputs, a <cite>test_batch_shape x q x d</cite>-shaped input <cite>X</cite>
to the <cite>posterior</cite> method returns a Posterior object over an output of
shape <cite>broadcast(test_batch_shape, model.batch_shape) x q x m</cite>.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.model.ModelList.num_outputs">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">num_outputs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#botorch.models.model.ModelList.num_outputs" title="Link to this definition"></a></dt>
<dd><p>The number of outputs of the model.</p>
<p>Equal to the sum of the number of outputs of the individual models
in the ModelList.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.model.ModelList.subset_output">
<span class="sig-name descname"><span class="pre">subset_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idcs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/model.html#ModelList.subset_output"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.model.ModelList.subset_output" title="Link to this definition"></a></dt>
<dd><p>Subset the model along the output dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>idcs</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – The output indices to subset the model to. Relative to the
overall number of outputs of the model.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>Model</cite> (either a <cite>ModelList</cite> or one of the submodels) with
the outputs subset to the indices in <cite>idcs</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a></p>
</dd>
</dl>
<p>Internally, this drops (if single-output) or subsets (if multi-output)
the constitutent models and returns them as a <cite>ModelList</cite>. If the
result is a single (possibly subset) model from the list, returns this
model (instead of forming a degenerate singe-model <cite>ModelList</cite>).
For instance, if <cite>m = ModelList(m1, m2)</cite> with <cite>m1</cite> a two-output model
and <cite>m2</cite> a single-output model, then <cite>m.subset_output([1]) ` will return
the model `m1</cite> subset to its second output.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.model.ModelList.transform_inputs">
<span class="sig-name descname"><span class="pre">transform_inputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/model.html#ModelList.transform_inputs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.model.ModelList.transform_inputs" title="Link to this definition"></a></dt>
<dd><p>Individually transform the inputs for each model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A tensor of inputs.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of tensors of transformed inputs.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list[<em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.model.ModelList.load_state_dict">
<span class="sig-name descname"><span class="pre">load_state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/model.html#ModelList.load_state_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.model.ModelList.load_state_dict" title="Link to this definition"></a></dt>
<dd><p>Initialize the fully Bayesian models before loading the state dict.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>state_dict</strong> (<em>Mapping</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>)</p></li>
<li><p><strong>strict</strong> (<em>bool</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.model.ModelList.fantasize">
<span class="sig-name descname"><span class="pre">fantasize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observation_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evaluation_mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/model.html#ModelList.fantasize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.model.ModelList.fantasize" title="Link to this definition"></a></dt>
<dd><p>Construct a fantasy model.</p>
<p>Constructs a fantasy model in the following fashion:
(1) compute the model posterior at <cite>X</cite> (including observation noise if
<cite>observation_noise=True</cite>).
(2) sample from this posterior (using <cite>sampler</cite>) to generate “fake”
observations.
(3) condition the model on the new fake observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n’ x d</cite>-dim Tensor, where <cite>d</cite> is the dimension of
the feature space, <cite>n’</cite> is the number of points per batch, and
<cite>batch_shape</cite> is the batch shape (must be compatible with the
batch shape of the model).</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a>) – The sampler used for sampling from the posterior at <cite>X</cite>. If
evaluation_mask is not None, this must be a <cite>ListSampler</cite>.</p></li>
<li><p><strong>observation_noise</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>model_batch_shape x 1 x m</cite>-dim tensor or
a <cite>model_batch_shape x n’ x m</cite>-dim tensor containing the average
noise for each batch and output, where <cite>m</cite> is the number of outputs.
<cite>noise</cite> must be in the outcome-transformed space if an outcome
transform is used. If None, then the noise will be the inferred
noise level.</p></li>
<li><p><strong>evaluation_mask</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>n’ x m</cite>-dim tensor of booleans indicating which
outputs should be fantasized for a given design. This uses the same
evaluation mask for all batches.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The constructed fantasy model.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.model.ModelDict">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.model.</span></span><span class="sig-name descname"><span class="pre">ModelDict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">models</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/model.html#ModelDict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.model.ModelDict" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">ModuleDict</span></code></p>
<p>A lightweight container mapping model names to models.</p>
<p>Initialize a <cite>ModelDict</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>models</strong> (<a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – An arbitrary number of models. Each model can be any type
of BoTorch <cite>Model</cite>, including multi-output models and <cite>ModelList</cite>.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-botorch.models.gpytorch">
<span id="gpytorch-model-api"></span><h3>GPyTorch Model API<a class="headerlink" href="#module-botorch.models.gpytorch" title="Link to this heading"></a></h3>
<p>Abstract model class for all GPyTorch-based botorch models.</p>
<p>To implement your own, simply inherit from both the provided classes and a
GPyTorch Model class such as an ExactGP.</p>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.gpytorch.GPyTorchModel">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.gpytorch.</span></span><span class="sig-name descname"><span class="pre">GPyTorchModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gpytorch.html#GPyTorchModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gpytorch.GPyTorchModel" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model"><code class="xref py py-class docutils literal notranslate"><span class="pre">Model</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>Abstract base class for models based on GPyTorch models.</p>
<p>The easiest way to use this is to subclass a model from a GPyTorch model
class (e.g. an <cite>ExactGP</cite>) and this <cite>GPyTorchModel</cite>. See e.g. <cite>SingleTaskGP</cite>.</p>
<p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="field-list simple">
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.gpytorch.GPyTorchModel.likelihood">
<span class="sig-name descname"><span class="pre">likelihood</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Likelihood</span></em><a class="headerlink" href="#botorch.models.gpytorch.GPyTorchModel.likelihood" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.gpytorch.GPyTorchModel.batch_shape">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">batch_shape</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Size</span></em><a class="headerlink" href="#botorch.models.gpytorch.GPyTorchModel.batch_shape" title="Link to this definition"></a></dt>
<dd><p>The batch shape of the model.</p>
<p>This is a batch shape from an I/O perspective, independent of the internal
representation of the model (as e.g. in BatchedMultiOutputGPyTorchModel).
For a model with <cite>m</cite> outputs, a <cite>test_batch_shape x q x d</cite>-shaped input <cite>X</cite>
to the <cite>posterior</cite> method returns a Posterior object over an output of
shape <cite>broadcast(test_batch_shape, model.batch_shape) x q x m</cite>.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.gpytorch.GPyTorchModel.num_outputs">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">num_outputs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#botorch.models.gpytorch.GPyTorchModel.num_outputs" title="Link to this definition"></a></dt>
<dd><p>The number of outputs of the model.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.gpytorch.GPyTorchModel.posterior">
<span class="sig-name descname"><span class="pre">posterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observation_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gpytorch.html#GPyTorchModel.posterior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gpytorch.GPyTorchModel.posterior" title="Link to this definition"></a></dt>
<dd><p>Computes the posterior over model outputs at the provided points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>(batch_shape) x q x d</cite>-dim Tensor, where <cite>d</cite> is the dimension
of the feature space and <cite>q</cite> is the number of points considered
jointly.</p></li>
<li><p><strong>observation_noise</strong> (<em>bool</em><em> | </em><em>Tensor</em>) – If True, add the observation noise from the
likelihood to the posterior. If a Tensor, use it directly as the
observation noise (must be of shape <cite>(batch_shape) x q</cite>). It is
assumed to be in the outcome-transformed space if an outcome
transform is used.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="acquisition.html#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – An optional PosteriorTransform.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>GPyTorchPosterior</cite> object, representing a batch of <cite>b</cite> joint
distributions over <cite>q</cite> points. Includes observation noise if
specified.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.gpytorch.GPyTorchPosterior" title="botorch.posteriors.gpytorch.GPyTorchPosterior">GPyTorchPosterior</a> | <a class="reference internal" href="posteriors.html#botorch.posteriors.transformed.TransformedPosterior" title="botorch.posteriors.transformed.TransformedPosterior">TransformedPosterior</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.gpytorch.GPyTorchModel.condition_on_observations">
<span class="sig-name descname"><span class="pre">condition_on_observations</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gpytorch.html#GPyTorchModel.condition_on_observations"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gpytorch.GPyTorchModel.condition_on_observations" title="Link to this definition"></a></dt>
<dd><p>Condition the model on new observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n’ x d</cite>-dim Tensor, where <cite>d</cite> is the dimension of
the feature space, <cite>n’</cite> is the number of points per batch, and
<cite>batch_shape</cite> is the batch shape (must be compatible with the
batch shape of the model).</p></li>
<li><p><strong>Y</strong> (<em>Tensor</em>) – A <cite>batch_shape’ x n x m</cite>-dim Tensor, where <cite>m</cite> is the number of
model outputs, <cite>n’</cite> is the number of points per batch, and
<cite>batch_shape’</cite> is the batch shape of the observations.
<cite>batch_shape’</cite> must be broadcastable to <cite>batch_shape</cite> using
standard broadcasting semantics. If <cite>Y</cite> has fewer batch dimensions
than <cite>X</cite>, its is assumed that the missing batch dimensions are
the same for all <cite>Y</cite>.</p></li>
<li><p><strong>noise</strong> (<em>Tensor</em><em> | </em><em>None</em>) – If not <cite>None</cite>, a tensor of the same shape as <cite>Y</cite> representing
the associated noise variance.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – Passed to <cite>self.get_fantasy_model</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>Model</cite> object of the same type, representing the original model
conditioned on the new observations <cite>(X, Y)</cite> (and possibly noise
observations passed in via kwargs).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">train_X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">train_X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">new_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">new_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">new_X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">new_X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">condition_on_observations</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">new_X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="n">new_Y</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.gpytorch.</span></span><span class="sig-name descname"><span class="pre">BatchedMultiOutputGPyTorchModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gpytorch.html#BatchedMultiOutputGPyTorchModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.gpytorch.GPyTorchModel" title="botorch.models.gpytorch.GPyTorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">GPyTorchModel</span></code></a></p>
<p>Base class for batched multi-output GPyTorch models with independent outputs.</p>
<p>This model should be used when the same training data is used for all outputs.
Outputs are modeled independently by using a different batch for each output.</p>
<p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="field-list simple">
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel.get_batch_dimensions">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_batch_dimensions</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gpytorch.html#BatchedMultiOutputGPyTorchModel.get_batch_dimensions"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel.get_batch_dimensions" title="Link to this definition"></a></dt>
<dd><p>Get the raw batch shape and output-augmented batch shape of the inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>Tensor</em>) – A <cite>n x d</cite> or <cite>batch_shape x n x d</cite> (batch mode) tensor of training
features.</p></li>
<li><p><strong>train_Y</strong> (<em>Tensor</em>) – A <cite>n x m</cite> or <cite>batch_shape x n x m</cite> (batch mode) tensor of
training observations.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>2-element tuple containing</p>
<ul class="simple">
<li><p>The <cite>input_batch_shape</cite></p></li>
<li><p>The output-augmented batch shape: <cite>input_batch_shape x (m)</cite></p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple[<em>Size</em>, <em>Size</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel.batch_shape">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">batch_shape</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Size</span></em><a class="headerlink" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel.batch_shape" title="Link to this definition"></a></dt>
<dd><p>The batch shape of the model.</p>
<p>This is a batch shape from an I/O perspective, independent of the internal
representation of the model (as e.g. in BatchedMultiOutputGPyTorchModel).
For a model with <cite>m</cite> outputs, a <cite>test_batch_shape x q x d</cite>-shaped input <cite>X</cite>
to the <cite>posterior</cite> method returns a Posterior object over an output of
shape <cite>broadcast(test_batch_shape, model.batch_shape) x q x m</cite>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel.posterior">
<span class="sig-name descname"><span class="pre">posterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observation_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gpytorch.html#BatchedMultiOutputGPyTorchModel.posterior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel.posterior" title="Link to this definition"></a></dt>
<dd><p>Computes the posterior over model outputs at the provided points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>(batch_shape) x q x d</cite>-dim Tensor, where <cite>d</cite> is the dimension
of the feature space and <cite>q</cite> is the number of points considered
jointly.</p></li>
<li><p><strong>output_indices</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – A list of indices, corresponding to the outputs over
which to compute the posterior (if the model is multi-output).
Can be used to speed up computation if only a subset of the
model’s outputs are required for optimization. If omitted,
computes the posterior over all model outputs.</p></li>
<li><p><strong>observation_noise</strong> (<em>bool</em><em> | </em><em>Tensor</em>) – If True, add the observation noise from the
likelihood to the posterior. If a Tensor, use it directly as the
observation noise (must be of shape <cite>(batch_shape) x q x m</cite>).</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="acquisition.html#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – An optional PosteriorTransform.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>GPyTorchPosterior</cite> object, representing <cite>batch_shape</cite> joint
distributions over <cite>q</cite> points and the outputs selected by
<cite>output_indices</cite> each. Includes observation noise if specified.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.gpytorch.GPyTorchPosterior" title="botorch.posteriors.gpytorch.GPyTorchPosterior">GPyTorchPosterior</a> | <a class="reference internal" href="posteriors.html#botorch.posteriors.transformed.TransformedPosterior" title="botorch.posteriors.transformed.TransformedPosterior">TransformedPosterior</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel.condition_on_observations">
<span class="sig-name descname"><span class="pre">condition_on_observations</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gpytorch.html#BatchedMultiOutputGPyTorchModel.condition_on_observations"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel.condition_on_observations" title="Link to this definition"></a></dt>
<dd><p>Condition the model on new observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n’ x d</cite>-dim Tensor, where <cite>d</cite> is the dimension of
the feature space, <cite>m</cite> is the number of points per batch, and
<cite>batch_shape</cite> is the batch shape (must be compatible with the
batch shape of the model).</p></li>
<li><p><strong>Y</strong> (<em>Tensor</em>) – A <cite>batch_shape’ x n’ x m</cite>-dim Tensor, where <cite>m</cite> is the number of
model outputs, <cite>n’</cite> is the number of points per batch, and
<cite>batch_shape’</cite> is the batch shape of the observations.
<cite>batch_shape’</cite> must be broadcastable to <cite>batch_shape</cite> using
standard broadcasting semantics. If <cite>Y</cite> has fewer batch dimensions
than <cite>X</cite>, its is assumed that the missing batch dimensions are
the same for all <cite>Y</cite>.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>BatchedMultiOutputGPyTorchModel</cite> object of the same type with
<cite>n + n’</cite> training examples, representing the original model
conditioned on the new observations <cite>(X, Y)</cite> (and possibly noise
observations passed in via kwargs).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel" title="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel"><em>BatchedMultiOutputGPyTorchModel</em></a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">train_X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">train_X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])],</span> <span class="o">-</span><span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">new_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">new_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">new_X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">new_X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">condition_on_observations</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">new_X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="n">new_Y</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel.subset_output">
<span class="sig-name descname"><span class="pre">subset_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idcs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gpytorch.html#BatchedMultiOutputGPyTorchModel.subset_output"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel.subset_output" title="Link to this definition"></a></dt>
<dd><p>Subset the model along the output dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>idcs</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – The output indices to subset the model to.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The current model, subset to the specified output indices.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel" title="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel"><em>BatchedMultiOutputGPyTorchModel</em></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.gpytorch.ModelListGPyTorchModel">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.gpytorch.</span></span><span class="sig-name descname"><span class="pre">ModelListGPyTorchModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">models</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gpytorch.html#ModelListGPyTorchModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gpytorch.ModelListGPyTorchModel" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.model.ModelList" title="botorch.models.model.ModelList"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelList</span></code></a>, <a class="reference internal" href="#botorch.models.gpytorch.GPyTorchModel" title="botorch.models.gpytorch.GPyTorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">GPyTorchModel</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>Abstract base class for models based on multi-output GPyTorch models.</p>
<p>This is meant to be used with a gpytorch ModelList wrapper for independent
evaluation of submodels. Those submodels can themselves be multi-output
models, in which case the task covariances will be ignored.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>*models</strong> (<a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A variable number of models.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m_1</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m_2</span> <span class="o">=</span> <span class="n">GenericDeterministicModel</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m_12</span> <span class="o">=</span> <span class="n">ModelList</span><span class="p">(</span><span class="n">m_1</span><span class="p">,</span> <span class="n">m_2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m_12</span><span class="o">.</span><span class="n">posterior</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.gpytorch.ModelListGPyTorchModel.batch_shape">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">batch_shape</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Size</span></em><a class="headerlink" href="#botorch.models.gpytorch.ModelListGPyTorchModel.batch_shape" title="Link to this definition"></a></dt>
<dd><p>The batch shape of the model.</p>
<p>This is a batch shape from an I/O perspective, independent of the internal
representation of the model (as e.g. in BatchedMultiOutputGPyTorchModel).
For a model with <cite>m</cite> outputs, a <cite>test_batch_shape x q x d</cite>-shaped input <cite>X</cite>
to the <cite>posterior</cite> method returns a Posterior object over an output of
shape <cite>broadcast(test_batch_shape, model.batch_shape) x q x m</cite>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.gpytorch.ModelListGPyTorchModel.posterior">
<span class="sig-name descname"><span class="pre">posterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observation_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gpytorch.html#ModelListGPyTorchModel.posterior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gpytorch.ModelListGPyTorchModel.posterior" title="Link to this definition"></a></dt>
<dd><p>Computes the posterior over model outputs at the provided points.
If any model returns a MultitaskMultivariateNormal posterior, then that
will be split into individual MVNs per task, with inter-task covariance
ignored.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>b x q x d</cite>-dim Tensor, where <cite>d</cite> is the dimension of the
feature space, <cite>q</cite> is the number of points considered jointly,
and <cite>b</cite> is the batch dimension.</p></li>
<li><p><strong>output_indices</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – A list of indices, corresponding to the outputs over
which to compute the posterior (if the model is multi-output).
Can be used to speed up computation if only a subset of the
model’s outputs are required for optimization. If omitted,
computes the posterior over all model outputs.</p></li>
<li><p><strong>observation_noise</strong> (<em>bool</em><em> | </em><em>Tensor</em>) – If True, add the observation noise from the
respective likelihoods to the posterior. If a Tensor of shape
<cite>(batch_shape) x q x m</cite>, use it directly as the observation
noise (with <cite>observation_noise[…,i]</cite> added to the posterior
of the <cite>i</cite>-th model).</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="acquisition.html#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – An optional PosteriorTransform.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><dl class="simple">
<dt>If no <cite>posterior_transform</cite> is provided and the component models have no</dt><dd><p><cite>outcome_transform</cite>, or if the component models only use linear outcome
transforms like <cite>Standardize</cite> (i.e. not <cite>Log</cite>), returns a
<cite>GPyTorchPosterior</cite> or <cite>GaussianMixturePosterior</cite> object,
representing <cite>batch_shape</cite> joint distributions over <cite>q</cite> points
and the outputs selected by <cite>output_indices</cite> each. Includes
measurement noise if <cite>observation_noise</cite> is specified.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>If no <cite>posterior_transform</cite> is provided and component models have</dt><dd><p>nonlinear transforms like <cite>Log</cite>, returns a <cite>PosteriorList</cite> with
sub-posteriors of type <cite>TransformedPosterior</cite></p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>If <cite>posterior_transform</cite> is provided, that posterior transform will be</dt><dd><p>applied and will determine the return type. This could potentially be
any subclass of <cite>Posterior</cite>, but common choices give a
<cite>GPyTorchPosterior</cite>.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.gpytorch.GPyTorchPosterior" title="botorch.posteriors.gpytorch.GPyTorchPosterior">GPyTorchPosterior</a> | <a class="reference internal" href="posteriors.html#botorch.posteriors.posterior_list.PosteriorList" title="botorch.posteriors.posterior_list.PosteriorList">PosteriorList</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.gpytorch.ModelListGPyTorchModel.condition_on_observations">
<span class="sig-name descname"><span class="pre">condition_on_observations</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gpytorch.html#ModelListGPyTorchModel.condition_on_observations"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gpytorch.ModelListGPyTorchModel.condition_on_observations" title="Link to this definition"></a></dt>
<dd><p>Condition the model on new observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n’ x d</cite>-dim Tensor, where <cite>d</cite> is the dimension of
the feature space, <cite>n’</cite> is the number of points per batch, and
<cite>batch_shape</cite> is the batch shape (must be compatible with the
batch shape of the model).</p></li>
<li><p><strong>Y</strong> (<em>Tensor</em>) – A <cite>batch_shape’ x n’ x m</cite>-dim Tensor, where <cite>m</cite> is the number of
model outputs, <cite>n’</cite> is the number of points per batch, and
<cite>batch_shape’</cite> is the batch shape of the observations.
<cite>batch_shape’</cite> must be broadcastable to <cite>batch_shape</cite> using
standard broadcasting semantics. If <cite>Y</cite> has fewer batch dimensions
than <cite>X</cite>, it is assumed that the missing batch dimensions are
the same for all <cite>Y</cite>.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>Model</cite> object of the same type, representing the original model
conditioned on the new observations <cite>(X, Y)</cite> (and possibly noise
observations passed in via kwargs).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.gpytorch.MultiTaskGPyTorchModel">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.gpytorch.</span></span><span class="sig-name descname"><span class="pre">MultiTaskGPyTorchModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gpytorch.html#MultiTaskGPyTorchModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gpytorch.MultiTaskGPyTorchModel" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.gpytorch.GPyTorchModel" title="botorch.models.gpytorch.GPyTorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">GPyTorchModel</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>Abstract base class for multi-task models based on GPyTorch models.</p>
<p>This class provides the <cite>posterior</cite> method to models that implement a
“long-format” multi-task GP in the style of <cite>MultiTaskGP</cite>.</p>
<p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="field-list simple">
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.gpytorch.MultiTaskGPyTorchModel.posterior">
<span class="sig-name descname"><span class="pre">posterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observation_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gpytorch.html#MultiTaskGPyTorchModel.posterior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gpytorch.MultiTaskGPyTorchModel.posterior" title="Link to this definition"></a></dt>
<dd><p>Computes the posterior over model outputs at the provided points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A tensor of shape <cite>batch_shape x q x d</cite> or <cite>batch_shape x q x (d + 1)</cite>,
where <cite>d</cite> is the dimension of the feature space (not including task
indices) and <cite>q</cite> is the number of points considered jointly. The <cite>+ 1</cite>
dimension is the optional task feature / index. If given, the model
produces the outputs for the given task indices. If omitted, the
model produces outputs for tasks in in <cite>self._output_tasks</cite> (specified
as <cite>output_tasks</cite> while constructing the model), which can overwritten
using <cite>output_indices</cite>.</p></li>
<li><p><strong>output_indices</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – A list of task values over which to compute the posterior.
Only used if <cite>X</cite> does not include the task feature. If omitted,
defaults to <cite>self._output_tasks</cite>.</p></li>
<li><p><strong>observation_noise</strong> (<em>bool</em><em> | </em><em>Tensor</em>) – If True, add observation noise from the respective
likelihoods. If a Tensor, specifies the observation noise levels
to add.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="acquisition.html#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – An optional PosteriorTransform.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>GPyTorchPosterior</cite> object, representing <cite>batch_shape</cite> joint
distributions over <cite>q</cite> points. If the task features are included in <cite>X</cite>,
the posterior will be single output. Otherwise, the posterior will be
single or multi output corresponding to the tasks included in
either the <cite>output_indices</cite> or <cite>self._output_tasks</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.gpytorch.GPyTorchPosterior" title="botorch.posteriors.gpytorch.GPyTorchPosterior">GPyTorchPosterior</a> | <a class="reference internal" href="posteriors.html#botorch.posteriors.transformed.TransformedPosterior" title="botorch.posteriors.transformed.TransformedPosterior">TransformedPosterior</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.gpytorch.MultiTaskGPyTorchModel.subset_output">
<span class="sig-name descname"><span class="pre">subset_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idcs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gpytorch.html#MultiTaskGPyTorchModel.subset_output"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gpytorch.MultiTaskGPyTorchModel.subset_output" title="Link to this definition"></a></dt>
<dd><p>Returns a new model that only outputs a subset of the outputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>idcs</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – A list of output indices, corresponding to the outputs to keep.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A new model that only outputs the requested outputs.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.gpytorch.MultiTaskGPyTorchModel" title="botorch.models.gpytorch.MultiTaskGPyTorchModel"><em>MultiTaskGPyTorchModel</em></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-botorch.models.deterministic">
<span id="deterministic-model-api"></span><h3>Deterministic Model API<a class="headerlink" href="#module-botorch.models.deterministic" title="Link to this heading"></a></h3>
<p>Deterministic Models: Simple wrappers that allow the usage of deterministic
mappings via the BoTorch Model and Posterior APIs.</p>
<p>Deterministic models are useful for expressing known input-output relationships
within the BoTorch Model API. This is useful e.g. for multi-objective
optimization with known objective functions (e.g. the number of parameters of a
Neural Network in the context of Neural Architecture Search is usually a known
function of the architecture configuration), or to encode cost functions for
cost-aware acquisition utilities. Cost-aware optimization is desirable when
evaluations have a cost that is heterogeneous, either in the inputs <cite>X</cite> or in a
particular fidelity parameter that directly encodes the fidelity of the
observation. <cite>GenericDeterministicModel</cite> supports arbitrary deterministic
functions, while <cite>AffineFidelityCostModel</cite> is a particular cost model for
multi-fidelity optimization. Other use cases of deterministic models include
representing approximate GP sample paths, e.g. Matheron paths obtained
with <cite>get_matheron_path_model</cite>, which allows them to be substituted in acquisition
functions or in other places where a <cite>Model</cite> is expected.</p>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.deterministic.DeterministicModel">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.deterministic.</span></span><span class="sig-name descname"><span class="pre">DeterministicModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/deterministic.html#DeterministicModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.deterministic.DeterministicModel" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.ensemble.EnsembleModel" title="botorch.models.ensemble.EnsembleModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">EnsembleModel</span></code></a></p>
<p>Abstract base class for deterministic models.</p>
<p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="field-list simple">
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.deterministic.DeterministicModel.forward">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/deterministic.html#DeterministicModel.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.deterministic.DeterministicModel.forward" title="Link to this definition"></a></dt>
<dd><p>Compute the (deterministic) model output at X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite>-dim input tensor <cite>X</cite>.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape x n x m</cite>-dimensional output tensor (the outcome
dimension <cite>m</cite> must be explicit if <cite>m=1</cite>).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.deterministic.GenericDeterministicModel">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.deterministic.</span></span><span class="sig-name descname"><span class="pre">GenericDeterministicModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">f</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_outputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/deterministic.html#GenericDeterministicModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.deterministic.GenericDeterministicModel" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.deterministic.DeterministicModel" title="botorch.models.deterministic.DeterministicModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">DeterministicModel</span></code></a></p>
<p>A generic deterministic model constructed from a callable.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">f</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keep_dims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">GenericDeterministicModel</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>f</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em>) – A callable mapping a <cite>batch_shape x n x d</cite>-dim input tensor <cite>X</cite>
to a <cite>batch_shape x n x m</cite>-dimensional output tensor (the
outcome dimension <cite>m</cite> must be explicit, even if <cite>m=1</cite>).</p></li>
<li><p><strong>num_outputs</strong> (<em>int</em>) – The number of outputs <cite>m</cite>.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.deterministic.GenericDeterministicModel.subset_output">
<span class="sig-name descname"><span class="pre">subset_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idcs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/deterministic.html#GenericDeterministicModel.subset_output"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.deterministic.GenericDeterministicModel.subset_output" title="Link to this definition"></a></dt>
<dd><p>Subset the model along the output dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>idcs</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – The output indices to subset the model to.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The current model, subset to the specified output indices.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.deterministic.GenericDeterministicModel" title="botorch.models.deterministic.GenericDeterministicModel"><em>GenericDeterministicModel</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.deterministic.GenericDeterministicModel.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/deterministic.html#GenericDeterministicModel.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.deterministic.GenericDeterministicModel.forward" title="Link to this definition"></a></dt>
<dd><p>Compute the (deterministic) model output at X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite>-dim input tensor <cite>X</cite>.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape x n x m</cite>-dimensional output tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.deterministic.AffineDeterministicModel">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.deterministic.</span></span><span class="sig-name descname"><span class="pre">AffineDeterministicModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/deterministic.html#AffineDeterministicModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.deterministic.AffineDeterministicModel" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.deterministic.DeterministicModel" title="botorch.models.deterministic.DeterministicModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">DeterministicModel</span></code></a></p>
<p>An affine deterministic model.</p>
<p>Affine deterministic model from weights and offset terms.</p>
<p>A simple model of the form</p>
<blockquote>
<div><p>y[…, m] = b[m] + sum_{i=1}^d a[i, m] * X[…, i]</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>Tensor</em>) – A <cite>d x m</cite>-dim tensor of linear weights, where <cite>m</cite> is the number
of outputs (must be explicit if <cite>m=1</cite>)</p></li>
<li><p><strong>b</strong> (<em>Tensor</em><em> | </em><em>float</em>) – The affine (offset) term. Either a float (for single-output
models or if the offset is shared), or a <cite>m</cite>-dim tensor (with
different offset values for for the <cite>m</cite> different outputs).</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.deterministic.AffineDeterministicModel.subset_output">
<span class="sig-name descname"><span class="pre">subset_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idcs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/deterministic.html#AffineDeterministicModel.subset_output"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.deterministic.AffineDeterministicModel.subset_output" title="Link to this definition"></a></dt>
<dd><p>Subset the model along the output dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>idcs</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – The output indices to subset the model to.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The current model, subset to the specified output indices.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.deterministic.AffineDeterministicModel" title="botorch.models.deterministic.AffineDeterministicModel"><em>AffineDeterministicModel</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.deterministic.AffineDeterministicModel.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/deterministic.html#AffineDeterministicModel.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.deterministic.AffineDeterministicModel.forward" title="Link to this definition"></a></dt>
<dd><p>Compute the (deterministic) model output at X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite>-dim input tensor <cite>X</cite>.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape x n x m</cite>-dimensional output tensor (the outcome
dimension <cite>m</cite> must be explicit if <cite>m=1</cite>).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.deterministic.PosteriorMeanModel">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.deterministic.</span></span><span class="sig-name descname"><span class="pre">PosteriorMeanModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/deterministic.html#PosteriorMeanModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.deterministic.PosteriorMeanModel" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.deterministic.DeterministicModel" title="botorch.models.deterministic.DeterministicModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">DeterministicModel</span></code></a></p>
<p>A deterministic model that always returns the posterior mean.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model</strong> (<a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – The base model.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.deterministic.PosteriorMeanModel.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/deterministic.html#PosteriorMeanModel.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.deterministic.PosteriorMeanModel.forward" title="Link to this definition"></a></dt>
<dd><p>Compute the (deterministic) model output at X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite>-dim input tensor <cite>X</cite>.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape x n x m</cite>-dimensional output tensor (the outcome
dimension <cite>m</cite> must be explicit if <cite>m=1</cite>).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.deterministic.PosteriorMeanModel.num_outputs">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">num_outputs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#botorch.models.deterministic.PosteriorMeanModel.num_outputs" title="Link to this definition"></a></dt>
<dd><p>The number of outputs of the model.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.deterministic.PosteriorMeanModel.batch_shape">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">batch_shape</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Size</span></em><a class="headerlink" href="#botorch.models.deterministic.PosteriorMeanModel.batch_shape" title="Link to this definition"></a></dt>
<dd><p>The batch shape of the model.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.deterministic.FixedSingleSampleModel">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.deterministic.</span></span><span class="sig-name descname"><span class="pre">FixedSingleSampleModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">w</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">jitter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-08</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/deterministic.html#FixedSingleSampleModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.deterministic.FixedSingleSampleModel" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.deterministic.DeterministicModel" title="botorch.models.deterministic.DeterministicModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">DeterministicModel</span></code></a></p>
<p>A deterministic model defined by a single sample <cite>w</cite>.</p>
<p>Given a base model <cite>f</cite> and a fixed sample <cite>w</cite>, the model always outputs</p>
<blockquote>
<div><p>y = f_mean(x) + f_stddev(x) * w</p>
</div></blockquote>
<p>We assume the outcomes are uncorrelated here.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – The base model.</p></li>
<li><p><strong>w</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A 1-d tensor with length model.num_outputs.
If None, draw it from a standard normal distribution.</p></li>
<li><p><strong>dim</strong> (<em>int</em><em> | </em><em>None</em>) – dimensionality of w.
If None and w is not provided, draw w samples of size model.num_outputs.</p></li>
<li><p><strong>jitter</strong> (<em>float</em><em> | </em><em>None</em>) – jitter value to be added for numerical stability, 1e-8 by default.</p></li>
<li><p><strong>dtype</strong> (<em>torch.dtype</em><em> | </em><em>None</em>) – dtype for w if specified</p></li>
<li><p><strong>device</strong> (<em>torch.dtype</em><em> | </em><em>None</em>) – device for w if specified</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.deterministic.FixedSingleSampleModel.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/deterministic.html#FixedSingleSampleModel.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.deterministic.FixedSingleSampleModel.forward" title="Link to this definition"></a></dt>
<dd><p>Compute the (deterministic) model output at X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite>-dim input tensor <cite>X</cite>.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape x n x m</cite>-dimensional output tensor (the outcome
dimension <cite>m</cite> must be explicit if <cite>m=1</cite>).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-botorch.models.ensemble">
<span id="ensemble-model-api"></span><h3>Ensemble Model API<a class="headerlink" href="#module-botorch.models.ensemble" title="Link to this heading"></a></h3>
<p>Ensemble Models: Simple wrappers that allow the usage of ensembles
via the BoTorch Model and Posterior APIs.</p>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.ensemble.EnsembleModel">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.ensemble.</span></span><span class="sig-name descname"><span class="pre">EnsembleModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/ensemble.html#EnsembleModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.ensemble.EnsembleModel" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model"><code class="xref py py-class docutils literal notranslate"><span class="pre">Model</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>Abstract base class for ensemble models.</p>
<p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="field-list simple">
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.ensemble.EnsembleModel.forward">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/ensemble.html#EnsembleModel.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.ensemble.EnsembleModel.forward" title="Link to this definition"></a></dt>
<dd><p>Compute the (ensemble) model output at X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite>-dim input tensor <cite>X</cite>.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape x s x n x m</cite>-dimensional output tensor where
<cite>s</cite> is the size of the ensemble.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.ensemble.EnsembleModel.num_outputs">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">num_outputs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#botorch.models.ensemble.EnsembleModel.num_outputs" title="Link to this definition"></a></dt>
<dd><p>The number of outputs of the model.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.ensemble.EnsembleModel.posterior">
<span class="sig-name descname"><span class="pre">posterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/ensemble.html#EnsembleModel.posterior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.ensemble.EnsembleModel.posterior" title="Link to this definition"></a></dt>
<dd><p>Compute the ensemble posterior at X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x q x d</cite>-dim input tensor <cite>X</cite>.</p></li>
<li><p><strong>output_indices</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – A list of indices, corresponding to the outputs over
which to compute the posterior. If omitted, computes the posterior
over all model outputs.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="acquisition.html#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – An optional PosteriorTransform.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An <cite>EnsemblePosterior</cite> object, representing <cite>batch_shape</cite> joint
posteriors over <cite>n</cite> points and the outputs selected by <cite>output_indices</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.ensemble.EnsemblePosterior" title="botorch.posteriors.ensemble.EnsemblePosterior"><em>EnsemblePosterior</em></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="models">
<h2>Models<a class="headerlink" href="#models" title="Link to this heading"></a></h2>
<section id="module-botorch.models.cost">
<span id="cost-models-for-cost-aware-optimization"></span><h3>Cost Models (for cost-aware optimization)<a class="headerlink" href="#module-botorch.models.cost" title="Link to this heading"></a></h3>
<p>Cost models to be used with multi-fidelity optimization.</p>
<p>Cost are useful for defining known cost functions when the cost of an evaluation
is heterogeneous in fidelity. For a full worked example, see the
<a class="reference external" href="https://botorch.org/docs/tutorials/multi_fidelity_bo">tutorial</a> on continuous
multi-fidelity Bayesian Optimization.</p>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.cost.AffineFidelityCostModel">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.cost.</span></span><span class="sig-name descname"><span class="pre">AffineFidelityCostModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fidelity_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_cost</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/cost.html#AffineFidelityCostModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.cost.AffineFidelityCostModel" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.deterministic.DeterministicModel" title="botorch.models.deterministic.DeterministicModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">DeterministicModel</span></code></a></p>
<p>Deterministic, affine cost model operating on fidelity parameters.</p>
<p>For each (q-batch) element of a candidate set <cite>X</cite>, this module computes a
cost of the form</p>
<blockquote>
<div><p>cost = fixed_cost + sum_j weights[j] * X[fidelity_dims[j]]</p>
</div></blockquote>
<p>For a full worked example, see the
<a class="reference external" href="https://botorch.org/docs/tutorials/multi_fidelity_bo">tutorial</a> on continuous
multi-fidelity Bayesian Optimization.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">botorch.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">AffineFidelityCostModel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">botorch.acquisition.cost_aware</span><span class="w"> </span><span class="kn">import</span> <span class="n">InverseCostWeightedUtility</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cost_model</span> <span class="o">=</span> <span class="n">AffineFidelityCostModel</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="n">fidelity_weights</span><span class="o">=</span><span class="p">{</span><span class="mi">6</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">},</span> <span class="n">fixed_cost</span><span class="o">=</span><span class="mf">5.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cost_aware_utility</span> <span class="o">=</span> <span class="n">InverseCostWeightedUtility</span><span class="p">(</span><span class="n">cost_model</span><span class="o">=</span><span class="n">cost_model</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fidelity_weights</strong> (<em>dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>] </em><em>| </em><em>None</em>) – A dictionary mapping a subset of columns of <cite>X</cite>
(the fidelity parameters) to its associated weight in the
affine cost expression. If omitted, assumes that the last
column of <cite>X</cite> is the fidelity parameter with a weight of 1.0.</p></li>
<li><p><strong>fixed_cost</strong> (<em>float</em>) – The fixed cost of running a single candidate point (i.e.
an element of a q-batch).</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.cost.AffineFidelityCostModel.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/cost.html#AffineFidelityCostModel.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.cost.AffineFidelityCostModel.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate the cost on a candidate set X.</p>
<p>Computes a cost of the form</p>
<blockquote>
<div><p>cost = fixed_cost + sum_j weights[j] * X[fidelity_dims[j]]</p>
</div></blockquote>
<p>for each element of the q-batch</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x q x d’</cite>-dim tensor of candidate points.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape x q x 1</cite>-dim tensor of costs.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.cost.FixedCostModel">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.cost.</span></span><span class="sig-name descname"><span class="pre">FixedCostModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fixed_cost</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/cost.html#FixedCostModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.cost.FixedCostModel" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.deterministic.DeterministicModel" title="botorch.models.deterministic.DeterministicModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">DeterministicModel</span></code></a></p>
<p>Deterministic, fixed cost model.</p>
<p>For each (q-batch) element of a candidate set <cite>X</cite>, this module computes a
fixed cost per objective.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>fixed_cost</strong> (<em>Tensor</em>) – A <cite>m</cite>-dim tensor containing the fixed cost of evaluating each
objective.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.cost.FixedCostModel.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/cost.html#FixedCostModel.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.cost.FixedCostModel.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate the cost on a candidate set X.</p>
<p>Computes the fixed cost of evaluating each objective for each element
of the q-batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x q x d’</cite>-dim tensor of candidate points.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape x q x m</cite>-dim tensor of costs.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-botorch.models.contextual">
<span id="contextual-gp-models-with-aggregate-rewards"></span><h3>Contextual GP Models with Aggregate Rewards<a class="headerlink" href="#module-botorch.models.contextual" title="Link to this heading"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.contextual.SACGP">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.contextual.</span></span><span class="sig-name descname"><span class="pre">SACGP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Yvar</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decomposition</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/contextual.html#SACGP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.contextual.SACGP" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.gp_regression.SingleTaskGP" title="botorch.models.gp_regression.SingleTaskGP"><code class="xref py py-class docutils literal notranslate"><span class="pre">SingleTaskGP</span></code></a></p>
<p>A GP using a Structural Additive Contextual(SAC) kernel.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>Tensor</em>) – (n x d) X training data.</p></li>
<li><p><strong>train_Y</strong> (<em>Tensor</em>) – (n x 1) Y training data.</p></li>
<li><p><strong>train_Yvar</strong> (<em>Tensor</em><em> | </em><em>None</em>) – (n x 1) Noise variances of each training Y. If None,
we use an inferred noise likelihood.</p></li>
<li><p><strong>decomposition</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>list</em><em>[</em><em>int</em><em>]</em><em>]</em>) – Keys are context names. Values are the indexes of
parameters belong to the context. The parameter indexes are in
the same order across contexts.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.contextual.SACGP.construct_inputs">
<em class="property"><span class="k"><span class="pre">classmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct_inputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">training_data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decomposition</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/contextual.html#SACGP.construct_inputs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.contextual.SACGP.construct_inputs" title="Link to this definition"></a></dt>
<dd><p>Construct <cite>Model</cite> keyword arguments from a dict of <cite>SupervisedDataset</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>training_data</strong> (<a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a>) – A <cite>SupervisedDataset</cite> containing the training data.</p></li>
<li><p><strong>decomposition</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>list</em><em>[</em><em>int</em><em>]</em><em>]</em>) – Dictionary of context names and their indexes of the
corresponding active context parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>dict[str, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.contextual.LCEAGP">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.contextual.</span></span><span class="sig-name descname"><span class="pre">LCEAGP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Yvar</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decomposition</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_embedding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cat_feature_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embs_feature_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embs_dim_list</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_weight_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/contextual.html#LCEAGP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.contextual.LCEAGP" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.gp_regression.SingleTaskGP" title="botorch.models.gp_regression.SingleTaskGP"><code class="xref py py-class docutils literal notranslate"><span class="pre">SingleTaskGP</span></code></a></p>
<p>A GP using a Latent Context Embedding Additive (LCE-A) Kernel.</p>
<p>Note that the model does not support batch training. Input training
data sets should have dim = 2.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>Tensor</em>) – (n x d) X training data.</p></li>
<li><p><strong>train_Y</strong> (<em>Tensor</em>) – (n x 1) Y training data.</p></li>
<li><p><strong>train_Yvar</strong> (<em>Tensor</em><em> | </em><em>None</em>) – (n x 1) Noise variance of Y. If None,
we use an inferred noise likelihood.</p></li>
<li><p><strong>decomposition</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>list</em><em>[</em><em>int</em><em>]</em><em>]</em>) – Keys are context names. Values are the indexes of
parameters belong to the context.</p></li>
<li><p><strong>train_embedding</strong> (<em>bool</em>) – Whether to train the embedding layer or not. If False,
the model will use pre-trained embeddings in embs_feature_dict.</p></li>
<li><p><strong>cat_feature_dict</strong> (<em>dict</em><em> | </em><em>None</em>) – Keys are context names and values are list of categorical
features i.e. {“context_name” : [cat_0, …, cat_k]}, where k is the
number of categorical variables. If None, we use context names in the
decomposition as the only categorical feature, i.e., k = 1.</p></li>
<li><p><strong>embs_feature_dict</strong> (<em>dict</em><em> | </em><em>None</em>) – Pre-trained continuous embedding features of each
context.</p></li>
<li><p><strong>embs_dim_list</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – Embedding dimension for each categorical variable. The length
equals the number of categorical features k. If None, the embedding
dimension is set to 1 for each categorical variable.</p></li>
<li><p><strong>context_weight_dict</strong> (<em>dict</em><em> | </em><em>None</em>) – Known population weights of each context.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.contextual.LCEAGP.construct_inputs">
<em class="property"><span class="k"><span class="pre">classmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct_inputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">training_data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decomposition</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_embedding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cat_feature_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embs_feature_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embs_dim_list</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_weight_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/contextual.html#LCEAGP.construct_inputs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.contextual.LCEAGP.construct_inputs" title="Link to this definition"></a></dt>
<dd><p>Construct <cite>Model</cite> keyword arguments from a dict of <cite>SupervisedDataset</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>training_data</strong> (<a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a>) – A <cite>SupervisedDataset</cite> containing the training data.</p></li>
<li><p><strong>decomposition</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>list</em><em>[</em><em>str</em><em>]</em><em>]</em>) – Dictionary of context names and the names of the
corresponding active context parameters.</p></li>
<li><p><strong>train_embedding</strong> (<em>bool</em>) – Whether to train the embedding layer or not.</p></li>
<li><p><strong>cat_feature_dict</strong> (<em>dict</em><em> | </em><em>None</em>) – Keys are context names and values are list of categorical
features i.e. {“context_name” : [cat_0, …, cat_k]}, where k is the
number of categorical variables. If None, we use context names in the
decomposition as the only categorical feature, i.e., k = 1.</p></li>
<li><p><strong>embs_feature_dict</strong> (<em>dict</em><em> | </em><em>None</em>) – Pre-trained continuous embedding features of each
context.</p></li>
<li><p><strong>embs_dim_list</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – Embedding dimension for each categorical variable. The length
equals the number of categorical features k. If None, the embedding
dimension is set to 1 for each categorical variable.</p></li>
<li><p><strong>context_weight_dict</strong> (<em>dict</em><em> | </em><em>None</em>) – Known population weights of each context.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>dict[str, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-botorch.models.contextual_multioutput">
<span id="contextual-gp-models-with-context-rewards"></span><h3>Contextual GP Models with Context Rewards<a class="headerlink" href="#module-botorch.models.contextual_multioutput" title="Link to this heading"></a></h3>
<p>References</p>
<div role="list" class="citation-list">
<div class="citation" id="feng2020hdcps" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">Feng2020HDCPS</a><span class="fn-bracket">]</span></span>
<p>Q. Feng, B. Latham, H. Mao and E. Backshy. High-Dimensional Contextual Policy
Search with Unknown Context Rewards using Bayesian Optimization.
Advances in Neural Information Processing Systems 33, NeurIPS 2020.</p>
</div>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.contextual_multioutput.LCEMGP">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.contextual_multioutput.</span></span><span class="sig-name descname"><span class="pre">LCEMGP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_feature</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Yvar=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean_module=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">covar_module=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">likelihood=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_cat_feature=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_emb_feature=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embs_dim_list=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_tasks=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">all_tasks=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outcome_transform=&lt;class</span> <span class="pre">'botorch.utils.types.DEFAULT'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_transform=None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/contextual_multioutput.html#LCEMGP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.contextual_multioutput.LCEMGP" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.multitask.MultiTaskGP" title="botorch.models.multitask.MultiTaskGP"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiTaskGP</span></code></a></p>
<p>The Multi-Task GP with the latent context embedding multioutput (LCE-M)
kernel. See <a class="reference internal" href="#feng2020hdcps" id="id2"><span>[Feng2020HDCPS]</span></a> for a reference on the model and its use in Bayesian
optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>Tensor</em>) – (n x d) X training data.</p></li>
<li><p><strong>train_Y</strong> (<em>Tensor</em>) – (n x 1) Y training data.</p></li>
<li><p><strong>task_feature</strong> (<em>int</em>) – Column index of train_X to get context indices.</p></li>
<li><p><strong>train_Yvar</strong> (<em>Tensor</em><em> | </em><em>None</em>) – An optional (n x 1) tensor of observed variances of each
training Y. If None, we infer the noise. Note that the inferred noise
is common across all tasks.</p></li>
<li><p><strong>mean_module</strong> (<em>Module</em><em> | </em><em>None</em>) – The mean function to be used. Defaults to <cite>ConstantMean</cite>.</p></li>
<li><p><strong>covar_module</strong> (<em>Module</em><em> | </em><em>None</em>) – The module for computing the covariance matrix between
the non-task features. Defaults to <cite>RBFKernel</cite>.</p></li>
<li><p><strong>likelihood</strong> (<em>Likelihood</em><em> | </em><em>None</em>) – A likelihood. The default is selected based on <cite>train_Yvar</cite>.
If <cite>train_Yvar</cite> is None, a standard <cite>GaussianLikelihood</cite> with inferred
noise level is used. Otherwise, a FixedNoiseGaussianLikelihood is used.</p></li>
<li><p><strong>context_cat_feature</strong> (<em>Tensor</em><em> | </em><em>None</em>) – (n_contexts x k) one-hot encoded context
features. Rows are ordered by context indices, where k is the
number of categorical variables. If None, task indices will
be used and k = 1.</p></li>
<li><p><strong>context_emb_feature</strong> (<em>Tensor</em><em> | </em><em>None</em>) – (n_contexts x m) pre-given continuous
embedding features. Rows are ordered by context indices.</p></li>
<li><p><strong>embs_dim_list</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – Embedding dimension for each categorical variable.
The length equals k. If None, the embedding dimension is set to 1
for each categorical variable.</p></li>
<li><p><strong>output_tasks</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – A list of task indices for which to compute model
outputs for. If omitted, return outputs for all task indices.</p></li>
<li><p><strong>all_tasks</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – By default, multi-task GPs infer the list of all tasks from
the task features in <cite>train_X</cite>. This is an experimental feature that
enables creation of multi-task GPs with tasks that don’t appear in the
training data. Note that when a task is not observed, the corresponding
task covariance will heavily depend on random initialization and may
behave unexpectedly.</p></li>
<li><p><strong>outcome_transform</strong> (<a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><em>OutcomeTransform</em></a><em> | </em><em>_DefaultType</em><em> | </em><em>None</em>) – An outcome transform that is applied to the
training data during instantiation and to the posterior during
inference (that is, the <cite>Posterior</cite> obtained by calling
<cite>.posterior</cite> on the model will be on the original scale). We use a
<cite>Standardize</cite> transform if no <cite>outcome_transform</cite> is specified.
Pass down <cite>None</cite> to use no outcome transform.</p></li>
<li><p><strong>input_transform</strong> (<a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>InputTransform</em></a><em> | </em><em>None</em>) – An input transform that is applied in the model’s
forward pass.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.contextual_multioutput.LCEMGP.task_covar_module">
<span class="sig-name descname"><span class="pre">task_covar_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task_idcs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/contextual_multioutput.html#LCEMGP.task_covar_module"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.contextual_multioutput.LCEMGP.task_covar_module" title="Link to this definition"></a></dt>
<dd><p>Compute the task covariance matrix for a given tensor of
task / context indices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>task_idcs</strong> (<em>Tensor</em>) – Task index tensor of shape (n x 1) or (b x n x 1).</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Task covariance matrix of shape (b x n x n).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.contextual_multioutput.LCEMGP.construct_inputs">
<em class="property"><span class="k"><span class="pre">classmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct_inputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">training_data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_feature</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_tasks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_cat_feature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_emb_feature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embs_dim_list</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/contextual_multioutput.html#LCEMGP.construct_inputs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.contextual_multioutput.LCEMGP.construct_inputs" title="Link to this definition"></a></dt>
<dd><p>Construct <cite>Model</cite> keyword arguments from a dataset and other args.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>training_data</strong> (<a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em> | </em><a class="reference internal" href="utils.html#botorch.utils.datasets.MultiTaskDataset" title="botorch.utils.datasets.MultiTaskDataset"><em>MultiTaskDataset</em></a>) – A <cite>SupervisedDataset</cite> or a <cite>MultiTaskDataset</cite>.</p></li>
<li><p><strong>task_feature</strong> (<em>int</em>) – Column index of embedded task indicator features.</p></li>
<li><p><strong>output_tasks</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – A list of task indices for which to compute model
outputs for. If omitted, return outputs for all task indices.</p></li>
<li><p><strong>context_cat_feature</strong> (<em>Tensor</em><em> | </em><em>None</em>) – (n_contexts x k) one-hot encoded context
features. Rows are ordered by context indices, where k is the
number of categorical variables. If None, task indices will
be used and k = 1.</p></li>
<li><p><strong>context_emb_feature</strong> (<em>Tensor</em><em> | </em><em>None</em>) – (n_contexts x m) pre-given continuous
embedding features. Rows are ordered by context indices.</p></li>
<li><p><strong>embs_dim_list</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – Embedding dimension for each categorical variable.
The length equals k. If None, the embedding dimension is set to 1
for each categorical variable.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>dict[str, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-botorch.models.fully_bayesian">
<span id="fully-bayesian-gp-models"></span><h3>Fully Bayesian GP Models<a class="headerlink" href="#module-botorch.models.fully_bayesian" title="Link to this heading"></a></h3>
<p>Gaussian Process Regression models with fully Bayesian inference.</p>
<p>Fully Bayesian models use Bayesian inference over model hyperparameters, such
as lengthscales and noise variance, learning a posterior distribution for the
hyperparameters using the No-U-Turn-Sampler (NUTS). This is followed by
sampling a small set of hyperparameters (often ~16) from the posterior
that we will use for model predictions and for computing acquisition function
values. By contrast, our “standard” models (e.g.
<cite>SingleTaskGP</cite>) learn only a single best value for each hyperparameter using
MAP. The fully Bayesian method generally results in a better and more
well-calibrated model, but is more computationally intensive. For a full
description, see [Eriksson2021saasbo].</p>
<p>We use a lightweight PyTorch implementation of a Matern-5/2 kernel as there are
some performance issues with running NUTS on top of standard GPyTorch models.
The resulting hyperparameter samples are loaded into a batched GPyTorch model
after fitting.</p>
<p>References:</p>
<div role="list" class="citation-list">
<div class="citation" id="eriksson2021saasbo" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Eriksson2021saasbo<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id3">1</a>,<a role="doc-backlink" href="#id4">2</a>,<a role="doc-backlink" href="#id5">3</a>)</span>
<p>D. Eriksson, M. Jankowiak. High-Dimensional Bayesian Optimization
with Sparse Axis-Aligned Subspaces. Proceedings of the Thirty-
Seventh Conference on Uncertainty in Artificial Intelligence, 2021.</p>
</div>
</div>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.matern52_kernel">
<span class="sig-prename descclassname"><span class="pre">botorch.models.fully_bayesian.</span></span><span class="sig-name descname"><span class="pre">matern52_kernel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lengthscale</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian.html#matern52_kernel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian.matern52_kernel" title="Link to this definition"></a></dt>
<dd><p>Matern-5/2 kernel.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>)</p></li>
<li><p><strong>lengthscale</strong> (<em>Tensor</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.linear_kernel">
<span class="sig-prename descclassname"><span class="pre">botorch.models.fully_bayesian.</span></span><span class="sig-name descname"><span class="pre">linear_kernel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_variance</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian.html#linear_kernel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian.linear_kernel" title="Link to this definition"></a></dt>
<dd><p>Linear kernel.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>)</p></li>
<li><p><strong>weight_variance</strong> (<em>Tensor</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.compute_dists">
<span class="sig-prename descclassname"><span class="pre">botorch.models.fully_bayesian.</span></span><span class="sig-name descname"><span class="pre">compute_dists</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lengthscale</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian.html#compute_dists"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian.compute_dists" title="Link to this definition"></a></dt>
<dd><p>Compute kernel distances.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>)</p></li>
<li><p><strong>lengthscale</strong> (<em>Tensor</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.reshape_and_detach">
<span class="sig-prename descclassname"><span class="pre">botorch.models.fully_bayesian.</span></span><span class="sig-name descname"><span class="pre">reshape_and_detach</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">new_value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian.html#reshape_and_detach"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian.reshape_and_detach" title="Link to this definition"></a></dt>
<dd><p>Detach and reshape <cite>new_value</cite> to match <cite>target</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>target</strong> (<em>Tensor</em>)</p></li>
<li><p><strong>new_value</strong> (<em>Tensor</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.PyroModel">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.fully_bayesian.</span></span><span class="sig-name descname"><span class="pre">PyroModel</span></span><a class="reference internal" href="_modules/botorch/models/fully_bayesian.html#PyroModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian.PyroModel" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Base class for a Pyro model; used to assist in learning hyperparameters.</p>
<p>This class and its subclasses are not a standard BoTorch models; instead
the subclasses are used as inputs to a <cite>SaasFullyBayesianSingleTaskGP</cite>,
which should then have its hyperparameters fit with
<cite>fit_fully_bayesian_model_nuts</cite>. (By default, its subclass <cite>SaasPyroModel</cite>
is used).  A <cite>PyroModel</cite>’s <cite>sample</cite> method should specify lightweight
PyTorch functionality, which will be used for fast model fitting with NUTS.
The utility of <cite>PyroModel</cite> is in enabling fast fitting with NUTS, since we
would otherwise need to use GPyTorch, which is computationally infeasible
in combination with Pyro.</p>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.PyroModel.set_inputs">
<span class="sig-name descname"><span class="pre">set_inputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Yvar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian.html#PyroModel.set_inputs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian.PyroModel.set_inputs" title="Link to this definition"></a></dt>
<dd><p>Set the training data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>Tensor</em>) – Training inputs (n x d)</p></li>
<li><p><strong>train_Y</strong> (<em>Tensor</em>) – Training targets (n x 1)</p></li>
<li><p><strong>train_Yvar</strong> (<em>Tensor</em><em> | </em><em>None</em>) – Observed noise variance (n x 1). Inferred if None.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.PyroModel.sample">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian.html#PyroModel.sample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian.PyroModel.sample" title="Link to this definition"></a></dt>
<dd><p>Sample from the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.PyroModel.postprocess_mcmc_samples">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">postprocess_mcmc_samples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mcmc_samples</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian.html#PyroModel.postprocess_mcmc_samples"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian.PyroModel.postprocess_mcmc_samples" title="Link to this definition"></a></dt>
<dd><p>Post-process the final MCMC samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>mcmc_samples</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>dict[str, <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.PyroModel.load_mcmc_samples">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">load_mcmc_samples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mcmc_samples</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian.html#PyroModel.load_mcmc_samples"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian.PyroModel.load_mcmc_samples" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>mcmc_samples</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>tuple[<em>Mean</em>, <em>Kernel</em>, <em>Likelihood</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.PyroModel.sample_noise">
<span class="sig-name descname"><span class="pre">sample_noise</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">tkwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian.html#PyroModel.sample_noise"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian.PyroModel.sample_noise" title="Link to this definition"></a></dt>
<dd><p>Sample the noise variance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>tkwargs</strong> (<em>Any</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.PyroModel.sample_mean">
<span class="sig-name descname"><span class="pre">sample_mean</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">tkwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian.html#PyroModel.sample_mean"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian.PyroModel.sample_mean" title="Link to this definition"></a></dt>
<dd><p>Sample the mean constant.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>tkwargs</strong> (<em>Any</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.SaasPyroModel">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.fully_bayesian.</span></span><span class="sig-name descname"><span class="pre">SaasPyroModel</span></span><a class="reference internal" href="_modules/botorch/models/fully_bayesian.html#SaasPyroModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian.SaasPyroModel" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.fully_bayesian.PyroModel" title="botorch.models.fully_bayesian.PyroModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">PyroModel</span></code></a></p>
<p>Implementation of the sparse axis-aligned subspace priors (SAAS) model.</p>
<p>The SAAS model uses sparsity-inducing priors to identify the most important
parameters. This model is suitable for high-dimensional BO with potentially
hundreds of tunable parameters. See <a class="reference internal" href="#eriksson2021saasbo" id="id3"><span>[Eriksson2021saasbo]</span></a> for more details.</p>
<p><cite>SaasPyroModel</cite> is not a standard BoTorch model; instead, it is used as
an input to <cite>SaasFullyBayesianSingleTaskGP</cite>. It is used as a default keyword
argument, and end users are not likely to need to instantiate or modify a
<cite>SaasPyroModel</cite> unless they want to customize its attributes (such as
<cite>covar_module</cite>).</p>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.SaasPyroModel.sample">
<span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian.html#SaasPyroModel.sample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian.SaasPyroModel.sample" title="Link to this definition"></a></dt>
<dd><p>Sample from the SAAS model.</p>
<p>This samples the mean, noise variance, outputscale, and lengthscales according
to the SAAS prior.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.SaasPyroModel.sample_outputscale">
<span class="sig-name descname"><span class="pre">sample_outputscale</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">concentration</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.15</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">tkwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian.html#SaasPyroModel.sample_outputscale"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian.SaasPyroModel.sample_outputscale" title="Link to this definition"></a></dt>
<dd><p>Sample the outputscale.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>concentration</strong> (<em>float</em>)</p></li>
<li><p><strong>rate</strong> (<em>float</em>)</p></li>
<li><p><strong>tkwargs</strong> (<em>Any</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.SaasPyroModel.sample_lengthscale">
<span class="sig-name descname"><span class="pre">sample_lengthscale</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">tkwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian.html#SaasPyroModel.sample_lengthscale"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian.SaasPyroModel.sample_lengthscale" title="Link to this definition"></a></dt>
<dd><p>Sample the lengthscale.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dim</strong> (<em>int</em>)</p></li>
<li><p><strong>alpha</strong> (<em>float</em>)</p></li>
<li><p><strong>tkwargs</strong> (<em>Any</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.SaasPyroModel.postprocess_mcmc_samples">
<span class="sig-name descname"><span class="pre">postprocess_mcmc_samples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mcmc_samples</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian.html#SaasPyroModel.postprocess_mcmc_samples"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian.SaasPyroModel.postprocess_mcmc_samples" title="Link to this definition"></a></dt>
<dd><p>Post-process the MCMC samples.</p>
<p>This computes the true lengthscales and removes the inverse lengthscales and
tausq (global shrinkage).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>mcmc_samples</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>dict[str, <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.SaasPyroModel.load_mcmc_samples">
<span class="sig-name descname"><span class="pre">load_mcmc_samples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mcmc_samples</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian.html#SaasPyroModel.load_mcmc_samples"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian.SaasPyroModel.load_mcmc_samples" title="Link to this definition"></a></dt>
<dd><p>Load the MCMC samples into the mean_module, covar_module, and likelihood.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>mcmc_samples</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>tuple[<em>Mean</em>, <em>Kernel</em>, <em>Likelihood</em>]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.LinearPyroModel">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.fully_bayesian.</span></span><span class="sig-name descname"><span class="pre">LinearPyroModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">use_input_warping</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices_to_warp</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-07</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian.html#LinearPyroModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian.LinearPyroModel" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.fully_bayesian.PyroModel" title="botorch.models.fully_bayesian.PyroModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">PyroModel</span></code></a></p>
<p>Implementation of a Bayesian Linear pyro model.</p>
<p><cite>LinearPyroModel</cite> is not a standard BoTorch model; instead, it is used as
an input to <cite>FullyBayesianLinearSingleTaskGP</cite>. It is used as a default keyword
argument, and end users are not likely to need to instantiate or modify a
<cite>LinearPyroModel</cite> unless they want to customize its attributes (such as
<cite>covar_module</cite>).</p>
<p>Initialize the LinearPyroModel.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>use_input_warping</strong> (<em>bool</em>) – If True, use input warping.</p></li>
<li><p><strong>indices_to_warp</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>eps</strong> (<em>float</em>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.LinearPyroModel.warp">
<span class="sig-name descname"><span class="pre">warp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian.html#LinearPyroModel.warp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian.LinearPyroModel.warp" title="Link to this definition"></a></dt>
<dd><p>Warp the input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>)</p></li>
<li><p><strong>c0</strong> (<em>Tensor</em>)</p></li>
<li><p><strong>c1</strong> (<em>Tensor</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.LinearPyroModel.sample">
<span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian.html#LinearPyroModel.sample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian.LinearPyroModel.sample" title="Link to this definition"></a></dt>
<dd><p>Sample from the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.LinearPyroModel.sample_weight_variance">
<span class="sig-name descname"><span class="pre">sample_weight_variance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">tkwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian.html#LinearPyroModel.sample_weight_variance"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian.LinearPyroModel.sample_weight_variance" title="Link to this definition"></a></dt>
<dd><p>Sample the weight variance.</p>
<p>This is a hierarchical prior is a half-Cauchy prior on the prior weight
covariance, which is diagonal with different values for each input
dimension. The prior samples a global level of sparsity (tau) and which
scales the HalfCauchy prior on the weight variance. Since the weight prior
is centered at zero, a prior variance of 0, would correspond to the
dimension being irrelevant. This choice of prior is motivated by Saas
priors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>alpha</strong> (<em>float</em>)</p></li>
<li><p><strong>tkwargs</strong> (<em>Any</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.LinearPyroModel.postprocess_mcmc_samples">
<span class="sig-name descname"><span class="pre">postprocess_mcmc_samples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mcmc_samples</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian.html#LinearPyroModel.postprocess_mcmc_samples"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian.LinearPyroModel.postprocess_mcmc_samples" title="Link to this definition"></a></dt>
<dd><p>Post-process the MCMC samples.</p>
<p>This computes the true weight variance and removes tausq (global shrinkage).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>mcmc_samples</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>dict[str, <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.LinearPyroModel.sample_concentrations">
<span class="sig-name descname"><span class="pre">sample_concentrations</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">tkwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian.html#LinearPyroModel.sample_concentrations"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian.LinearPyroModel.sample_concentrations" title="Link to this definition"></a></dt>
<dd><p>Sample concentrations for input warping.</p>
<p>The prior has a mean value of 1 for each concentration and is very
concentrated around the mean.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>tkwargs</strong> (<em>Any</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>tuple[<em>Tensor</em>, <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.LinearPyroModel.load_mcmc_samples">
<span class="sig-name descname"><span class="pre">load_mcmc_samples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mcmc_samples</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian.html#LinearPyroModel.load_mcmc_samples"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian.LinearPyroModel.load_mcmc_samples" title="Link to this definition"></a></dt>
<dd><p>Load the MCMC samples into their corresponding modules.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>mcmc_samples</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>tuple[<em>Mean</em>, <em>Kernel</em>, <em>Likelihood</em>, <a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>InputTransform</em></a>]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.FullyBayesianSingleTaskGP">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.fully_bayesian.</span></span><span class="sig-name descname"><span class="pre">FullyBayesianSingleTaskGP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Yvar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outcome_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pyro_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian.html#FullyBayesianSingleTaskGP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian.FullyBayesianSingleTaskGP" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">ExactGP</span></code>, <a class="reference internal" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel" title="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">BatchedMultiOutputGPyTorchModel</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>An abstract fully Bayesian single-task GP model.</p>
<p>This model assumes that the inputs have been normalized to [0, 1]^d and that
the output has been standardized to have zero mean and unit variance. You can
either normalize and standardize the data before constructing the model or use
an <cite>input_transform</cite> and <cite>outcome_transform</cite>.</p>
<p>You are expected to use <cite>fit_fully_bayesian_model_nuts</cite> to fit this model as it
isn’t compatible with <cite>fit_gpytorch_mll</cite>.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">saas_gp</span> <span class="o">=</span> <span class="n">SaasFullyBayesianSingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fit_fully_bayesian_model_nuts</span><span class="p">(</span><span class="n">saas_gp</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">posterior</span> <span class="o">=</span> <span class="n">saas_gp</span><span class="o">.</span><span class="n">posterior</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
</pre></div>
</div>
<p>Initialize the fully Bayesian single-task GP model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>Tensor</em>) – Training inputs (n x d)</p></li>
<li><p><strong>train_Y</strong> (<em>Tensor</em>) – Training targets (n x 1)</p></li>
<li><p><strong>train_Yvar</strong> (<em>Tensor</em><em> | </em><em>None</em>) – Observed noise variance (n x 1). Inferred if None.</p></li>
<li><p><strong>outcome_transform</strong> (<a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><em>OutcomeTransform</em></a><em> | </em><em>None</em>) – An outcome transform that is applied to the
training data during instantiation and to the posterior during
inference (that is, the <cite>Posterior</cite> obtained by calling
<cite>.posterior</cite> on the model will be on the original scale).</p></li>
<li><p><strong>input_transform</strong> (<a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>InputTransform</em></a><em> | </em><em>None</em>) – An input transform that is applied in the model’s
forward pass.</p></li>
<li><p><strong>pyro_model</strong> (<a class="reference internal" href="#botorch.models.fully_bayesian.PyroModel" title="botorch.models.fully_bayesian.PyroModel"><em>PyroModel</em></a><em> | </em><em>None</em>) – The pyro model.</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.FullyBayesianSingleTaskGP.num_mcmc_samples">
<em class="property"><span class="k"><span class="pre">abstract</span></span><span class="w"> </span><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">num_mcmc_samples</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#botorch.models.fully_bayesian.FullyBayesianSingleTaskGP.num_mcmc_samples" title="Link to this definition"></a></dt>
<dd><p>Number of MCMC samples in the model.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.FullyBayesianSingleTaskGP.batch_shape">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">batch_shape</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Size</span></em><a class="headerlink" href="#botorch.models.fully_bayesian.FullyBayesianSingleTaskGP.batch_shape" title="Link to this definition"></a></dt>
<dd><p>Batch shape of the model, equal to the number of MCMC samples.
Note that <cite>SaasFullyBayesianSingleTaskGP</cite> does not support batching
over input data at this point.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.FullyBayesianSingleTaskGP.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian.html#FullyBayesianSingleTaskGP.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian.FullyBayesianSingleTaskGP.train" title="Link to this definition"></a></dt>
<dd><p>Puts the model in <cite>train</cite> mode.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mode</strong> (<em>bool</em>) – A boolean indicating whether to put the model in training mode.</p></li>
<li><p><strong>reset</strong> (<em>bool</em>) – A boolean indicating whether to reset the model to its initial
state if mode is True. If <cite>mode</cite> is False, this argument is ignored.</p></li>
<li><p><strong>self</strong> (<em>TFullyBayesianSingleTaskGP</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The model itself.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>TFullyBayesianSingleTaskGP</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.FullyBayesianSingleTaskGP.load_mcmc_samples">
<span class="sig-name descname"><span class="pre">load_mcmc_samples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mcmc_samples</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian.html#FullyBayesianSingleTaskGP.load_mcmc_samples"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian.FullyBayesianSingleTaskGP.load_mcmc_samples" title="Link to this definition"></a></dt>
<dd><p>Load the MCMC hyperparameter samples into the model.</p>
<p>This method will be called by <cite>fit_fully_bayesian_model_nuts</cite> when the model
has been fitted in order to create a batched SingleTaskGP model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>mcmc_samples</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.FullyBayesianSingleTaskGP.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian.html#FullyBayesianSingleTaskGP.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian.FullyBayesianSingleTaskGP.forward" title="Link to this definition"></a></dt>
<dd><p>Unlike in other classes’ <cite>forward</cite> methods, there is no <cite>if self.training</cite>
block, because it ought to be unreachable: If <cite>self.train()</cite> has been called,
then <cite>self.covar_module</cite> will be None, <cite>check_if_fitted()</cite> will fail, and the
rest of this method will not run.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>MultivariateNormal</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.FullyBayesianSingleTaskGP.posterior">
<span class="sig-name descname"><span class="pre">posterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observation_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian.html#FullyBayesianSingleTaskGP.posterior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian.FullyBayesianSingleTaskGP.posterior" title="Link to this definition"></a></dt>
<dd><p>Computes the posterior over model outputs at the provided points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>(batch_shape) x q x d</cite>-dim Tensor, where <cite>d</cite> is the dimension
of the feature space and <cite>q</cite> is the number of points considered
jointly.</p></li>
<li><p><strong>output_indices</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – A list of indices, corresponding to the outputs over
which to compute the posterior (if the model is multi-output).
Can be used to speed up computation if only a subset of the
model’s outputs are required for optimization. If omitted,
computes the posterior over all model outputs.</p></li>
<li><p><strong>observation_noise</strong> (<em>bool</em>) – If True, add the observation noise from the
likelihood to the posterior. If a Tensor, use it directly as the
observation noise (must be of shape <cite>(batch_shape) x q x m</cite>).</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="acquisition.html#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – An optional PosteriorTransform.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>A <cite>GaussianMixturePosterior</cite> object. Includes observation noise</dt><dd><p>if specified.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.fully_bayesian.GaussianMixturePosterior" title="botorch.posteriors.fully_bayesian.GaussianMixturePosterior"><em>GaussianMixturePosterior</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.FullyBayesianSingleTaskGP.condition_on_observations">
<span class="sig-name descname"><span class="pre">condition_on_observations</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian.html#FullyBayesianSingleTaskGP.condition_on_observations"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian.FullyBayesianSingleTaskGP.condition_on_observations" title="Link to this definition"></a></dt>
<dd><p>Conditions on additional observations for a Fully Bayesian model (either
identical across models or unique per-model).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x num_samples x d</cite>-dim Tensor, where <cite>d</cite> is
the dimension of the feature space and <cite>batch_shape</cite> is the number of
sampled models.</p></li>
<li><p><strong>Y</strong> (<em>Tensor</em>) – A <cite>batch_shape x num_samples x 1</cite>-dim Tensor, where <cite>d</cite> is
the dimension of the feature space and <cite>batch_shape</cite> is the number of
sampled models.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>A fully bayesian model conditioned on</dt><dd><p>given observations. The returned model has <cite>batch_shape</cite> copies of the
training data in case of identical observations (and <cite>batch_shape</cite>
training datasets otherwise).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel" title="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel">BatchedMultiOutputGPyTorchModel</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.SaasFullyBayesianSingleTaskGP">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.fully_bayesian.</span></span><span class="sig-name descname"><span class="pre">SaasFullyBayesianSingleTaskGP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Yvar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outcome_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pyro_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian.html#SaasFullyBayesianSingleTaskGP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian.SaasFullyBayesianSingleTaskGP" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.fully_bayesian.FullyBayesianSingleTaskGP" title="botorch.models.fully_bayesian.FullyBayesianSingleTaskGP"><code class="xref py py-class docutils literal notranslate"><span class="pre">FullyBayesianSingleTaskGP</span></code></a></p>
<p>A fully Bayesian single-task GP model with the SAAS prior.</p>
<p>This model assumes that the inputs have been normalized to [0, 1]^d and that
the output has been standardized to have zero mean and unit variance. You can
either normalize and standardize the data before constructing the model or use
an <cite>input_transform</cite> and <cite>outcome_transform</cite>. The SAAS model <a class="reference internal" href="#eriksson2021saasbo" id="id4"><span>[Eriksson2021saasbo]</span></a>
with a Matern-5/2 kernel is used by default.</p>
<p>You are expected to use <cite>fit_fully_bayesian_model_nuts</cite> to fit this model as it
isn’t compatible with <cite>fit_gpytorch_mll</cite>.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">saas_gp</span> <span class="o">=</span> <span class="n">SaasFullyBayesianSingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fit_fully_bayesian_model_nuts</span><span class="p">(</span><span class="n">saas_gp</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">posterior</span> <span class="o">=</span> <span class="n">saas_gp</span><span class="o">.</span><span class="n">posterior</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
</pre></div>
</div>
<p>Initialize the fully Bayesian single-task GP model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>Tensor</em>) – Training inputs (n x d)</p></li>
<li><p><strong>train_Y</strong> (<em>Tensor</em>) – Training targets (n x 1)</p></li>
<li><p><strong>train_Yvar</strong> (<em>Tensor</em><em> | </em><em>None</em>) – Observed noise variance (n x 1). Inferred if None.</p></li>
<li><p><strong>outcome_transform</strong> (<a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><em>OutcomeTransform</em></a><em> | </em><em>None</em>) – An outcome transform that is applied to the
training data during instantiation and to the posterior during
inference (that is, the <cite>Posterior</cite> obtained by calling
<cite>.posterior</cite> on the model will be on the original scale).</p></li>
<li><p><strong>input_transform</strong> (<a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>InputTransform</em></a><em> | </em><em>None</em>) – An input transform that is applied in the model’s
forward pass.</p></li>
<li><p><strong>pyro_model</strong> (<a class="reference internal" href="#botorch.models.fully_bayesian.PyroModel" title="botorch.models.fully_bayesian.PyroModel"><em>PyroModel</em></a><em> | </em><em>None</em>) – The pyro model.</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.SaasFullyBayesianSingleTaskGP.num_mcmc_samples">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">num_mcmc_samples</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#botorch.models.fully_bayesian.SaasFullyBayesianSingleTaskGP.num_mcmc_samples" title="Link to this definition"></a></dt>
<dd><p>Number of MCMC samples in the model.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.SaasFullyBayesianSingleTaskGP.median_lengthscale">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">median_lengthscale</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tensor</span></em><a class="headerlink" href="#botorch.models.fully_bayesian.SaasFullyBayesianSingleTaskGP.median_lengthscale" title="Link to this definition"></a></dt>
<dd><p>Median lengthscales across the MCMC samples.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.SaasFullyBayesianSingleTaskGP.load_state_dict">
<span class="sig-name descname"><span class="pre">load_state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian.html#SaasFullyBayesianSingleTaskGP.load_state_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian.SaasFullyBayesianSingleTaskGP.load_state_dict" title="Link to this definition"></a></dt>
<dd><p>Custom logic for loading the state dict.</p>
<p>The standard approach of calling <cite>load_state_dict</cite> currently doesn’t play well
with the <cite>SaasFullyBayesianSingleTaskGP</cite> since the <cite>mean_module</cite>, <cite>covar_module</cite>
and <cite>likelihood</cite> aren’t initialized until the model has been fitted. The reason
for this is that we don’t know the number of MCMC samples until NUTS is called.
Given the state dict, we can initialize a new model with some dummy samples and
then load the state dict into this model. This currently only works for a
<cite>SaasPyroModel</cite> and supporting more Pyro models likely requires moving the model
construction logic into the Pyro model itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>state_dict</strong> (<em>Mapping</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>)</p></li>
<li><p><strong>strict</strong> (<em>bool</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.FullyBayesianLinearSingleTaskGP">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.fully_bayesian.</span></span><span class="sig-name descname"><span class="pre">FullyBayesianLinearSingleTaskGP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Yvar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outcome_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_input_warping</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices_to_warp</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian.html#FullyBayesianLinearSingleTaskGP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian.FullyBayesianLinearSingleTaskGP" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.fully_bayesian.FullyBayesianSingleTaskGP" title="botorch.models.fully_bayesian.FullyBayesianSingleTaskGP"><code class="xref py py-class docutils literal notranslate"><span class="pre">FullyBayesianSingleTaskGP</span></code></a></p>
<p>A fully Bayesian single-task GP model with a linear kernel.</p>
<p>This model assumes that the inputs have been normalized to [0, 1]^d and that
the output has been standardized to have zero mean and unit variance. You can
either normalize and standardize the data before constructing the model or use
an <cite>input_transform</cite> and <cite>outcome_transform</cite>.</p>
<p>You are expected to use <cite>fit_fully_bayesian_model_nuts</cite> to fit this model as it
isn’t compatible with <cite>fit_gpytorch_mll</cite>.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">gp</span> <span class="o">=</span> <span class="n">FullyBayesianLinearSingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fit_fully_bayesian_model_nuts</span><span class="p">(</span><span class="n">gp</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">posterior</span> <span class="o">=</span> <span class="n">gp</span><span class="o">.</span><span class="n">posterior</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
</pre></div>
</div>
<p>Initialize the fully Bayesian single-task GP model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>Tensor</em>) – Training inputs (n x d)</p></li>
<li><p><strong>train_Y</strong> (<em>Tensor</em>) – Training targets (n x 1)</p></li>
<li><p><strong>train_Yvar</strong> (<em>Tensor</em><em> | </em><em>None</em>) – Observed noise variance (n x 1). Inferred if None.</p></li>
<li><p><strong>outcome_transform</strong> (<a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><em>OutcomeTransform</em></a><em> | </em><em>None</em>) – An outcome transform that is applied to the
training data during instantiation and to the posterior during
inference (that is, the <cite>Posterior</cite> obtained by calling
<cite>.posterior</cite> on the model will be on the original scale).</p></li>
<li><p><strong>input_transform</strong> (<a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>InputTransform</em></a><em> | </em><em>None</em>) – An input transform that is applied in the model’s
forward pass.</p></li>
<li><p><strong>use_input_warping</strong> (<em>bool</em>) – A boolean indicating whether to use input warping.</p></li>
<li><p><strong>indices_to_warp</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – An optional list of indices to warp. The default
is to warp all inputs.</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.FullyBayesianLinearSingleTaskGP.num_mcmc_samples">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">num_mcmc_samples</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#botorch.models.fully_bayesian.FullyBayesianLinearSingleTaskGP.num_mcmc_samples" title="Link to this definition"></a></dt>
<dd><p>Number of MCMC samples in the model.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.FullyBayesianLinearSingleTaskGP.median_weight_variance">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">median_weight_variance</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tensor</span></em><a class="headerlink" href="#botorch.models.fully_bayesian.FullyBayesianLinearSingleTaskGP.median_weight_variance" title="Link to this definition"></a></dt>
<dd><p>Median weight variance across the MCMC samples.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.FullyBayesianLinearSingleTaskGP.load_mcmc_samples">
<span class="sig-name descname"><span class="pre">load_mcmc_samples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mcmc_samples</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian.html#FullyBayesianLinearSingleTaskGP.load_mcmc_samples"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian.FullyBayesianLinearSingleTaskGP.load_mcmc_samples" title="Link to this definition"></a></dt>
<dd><p>Load the MCMC hyperparameter samples into the model.</p>
<p>This method will be called by <cite>fit_fully_bayesian_model_nuts</cite> when the model
has been fitted in order to create a batched SingleTaskGP model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>mcmc_samples</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.FullyBayesianLinearSingleTaskGP.load_state_dict">
<span class="sig-name descname"><span class="pre">load_state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian.html#FullyBayesianLinearSingleTaskGP.load_state_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian.FullyBayesianLinearSingleTaskGP.load_state_dict" title="Link to this definition"></a></dt>
<dd><p>Custom logic for loading the state dict.</p>
<p>The standard approach of calling <cite>load_state_dict</cite> currently doesn’t play well
with the <cite>FullyBayesianLinearSingleTaskGP</cite> since the <cite>mean_module</cite>,
<cite>covar_module</cite> and <cite>likelihood</cite> aren’t initialized until the model has been
fitted. The reason for this is that we don’t know the number of MCMC samples
until NUTS is called. Given the state dict, we can initialize a new model with
some dummy samples andthen load the state dict into this model. This currently
only works for a <cite>LinearPyroModel</cite> and supporting more Pyro models likely
requires moving the model construction logic into the Pyro model itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>state_dict</strong> (<em>Mapping</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>)</p></li>
<li><p><strong>strict</strong> (<em>bool</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian.FullyBayesianLinearSingleTaskGP.construct_inputs">
<em class="property"><span class="k"><span class="pre">classmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct_inputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">training_data</span></span></em>, <em class="sig-param"><span class="keyword-only-separator o"><abbr title="Keyword-only parameters separator (PEP 3102)"><span class="pre">*</span></abbr></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_input_warping</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices_to_warp</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian.html#FullyBayesianLinearSingleTaskGP.construct_inputs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian.FullyBayesianLinearSingleTaskGP.construct_inputs" title="Link to this definition"></a></dt>
<dd><p>Construct <cite>SingleTaskGP</cite> keyword arguments from a <cite>SupervisedDataset</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>training_data</strong> (<a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a>) – A <cite>SupervisedDataset</cite>, with attributes <cite>train_X</cite>,
<cite>train_Y</cite>, and, optionally, <cite>train_Yvar</cite>.</p></li>
<li><p><strong>use_input_warping</strong> (<em>bool</em>) – A boolean indicating whether to use input warping.</p></li>
<li><p><strong>indices_to_warp</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – An optional list of indices to warp. The default
is to warp all inputs.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dict of keyword arguments that can be used to initialize a
<cite>FullyBayesianLinearSingleTaskGP</cite>, with keys <cite>train_X</cite>, <cite>train_Y</cite>,
<cite>use_input_warping</cite>, <cite>indices_to_warp</cite>, and, optionally, <cite>train_Yvar</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict[str, <a class="reference internal" href="utils.html#botorch.utils.containers.BotorchContainer" title="botorch.utils.containers.BotorchContainer"><em>BotorchContainer</em></a> | <em>Tensor</em> | None]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-botorch.models.fully_bayesian_multitask">
<span id="fully-bayesian-multitask-gp-models"></span><h3>Fully Bayesian Multitask GP Models<a class="headerlink" href="#module-botorch.models.fully_bayesian_multitask" title="Link to this heading"></a></h3>
<p>Multi-task Gaussian Process Regression models with fully Bayesian inference.</p>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian_multitask.MultitaskSaasPyroModel">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.fully_bayesian_multitask.</span></span><span class="sig-name descname"><span class="pre">MultitaskSaasPyroModel</span></span><a class="reference internal" href="_modules/botorch/models/fully_bayesian_multitask.html#MultitaskSaasPyroModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian_multitask.MultitaskSaasPyroModel" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.fully_bayesian.SaasPyroModel" title="botorch.models.fully_bayesian.SaasPyroModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">SaasPyroModel</span></code></a></p>
<p>Implementation of the multi-task sparse axis-aligned subspace priors (SAAS) model.</p>
<p>The multi-task model uses an ICM kernel. The data kernel is same as the single task
SAAS model in order to handle high-dimensional parameter spaces. The task kernel
is a Matern-5/2 kernel using learned task embeddings as the input.</p>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian_multitask.MultitaskSaasPyroModel.set_inputs">
<span class="sig-name descname"><span class="pre">set_inputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Yvar</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_feature</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_rank</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian_multitask.html#MultitaskSaasPyroModel.set_inputs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian_multitask.MultitaskSaasPyroModel.set_inputs" title="Link to this definition"></a></dt>
<dd><p>Set the training data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>Tensor</em>) – Training inputs (n x (d + 1))</p></li>
<li><p><strong>train_Y</strong> (<em>Tensor</em>) – Training targets (n x 1)</p></li>
<li><p><strong>train_Yvar</strong> (<em>Tensor</em><em> | </em><em>None</em>) – Observed noise variance (n x 1). If None, we infer the noise.
Note that the inferred noise is common across all tasks.</p></li>
<li><p><strong>task_feature</strong> (<em>int</em>) – The index of the task feature (<cite>-d &lt;= task_feature &lt;= d</cite>).</p></li>
<li><p><strong>task_rank</strong> (<em>int</em><em> | </em><em>None</em>) – The num of learned task embeddings to be used in the task kernel.
If omitted, use a full rank (i.e. number of tasks) kernel.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian_multitask.MultitaskSaasPyroModel.sample">
<span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian_multitask.html#MultitaskSaasPyroModel.sample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian_multitask.MultitaskSaasPyroModel.sample" title="Link to this definition"></a></dt>
<dd><p>Sample from the SAAS model.</p>
<p>This samples the mean, noise variance, outputscale, and lengthscales according
to the SAAS prior.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian_multitask.MultitaskSaasPyroModel.sample_latent_features">
<span class="sig-name descname"><span class="pre">sample_latent_features</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">tkwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian_multitask.html#MultitaskSaasPyroModel.sample_latent_features"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian_multitask.MultitaskSaasPyroModel.sample_latent_features" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>tkwargs</strong> (<em>Any</em>)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian_multitask.MultitaskSaasPyroModel.sample_task_lengthscale">
<span class="sig-name descname"><span class="pre">sample_task_lengthscale</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">concentration</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">6.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3.0</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">tkwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian_multitask.html#MultitaskSaasPyroModel.sample_task_lengthscale"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian_multitask.MultitaskSaasPyroModel.sample_task_lengthscale" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>concentration</strong> (<em>float</em>)</p></li>
<li><p><strong>rate</strong> (<em>float</em>)</p></li>
<li><p><strong>tkwargs</strong> (<em>Any</em>)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian_multitask.MultitaskSaasPyroModel.load_mcmc_samples">
<span class="sig-name descname"><span class="pre">load_mcmc_samples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mcmc_samples</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian_multitask.html#MultitaskSaasPyroModel.load_mcmc_samples"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian_multitask.MultitaskSaasPyroModel.load_mcmc_samples" title="Link to this definition"></a></dt>
<dd><p>Load the MCMC samples into the mean_module, covar_module, and likelihood.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>mcmc_samples</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>tuple[<em>Mean</em>, <em>Kernel</em>, <em>Likelihood</em>, <em>Kernel</em>, <em>Parameter</em>]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian_multitask.SaasFullyBayesianMultiTaskGP">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.fully_bayesian_multitask.</span></span><span class="sig-name descname"><span class="pre">SaasFullyBayesianMultiTaskGP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_feature</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Yvar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_tasks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rank</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">all_tasks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outcome_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pyro_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian_multitask.html#SaasFullyBayesianMultiTaskGP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian_multitask.SaasFullyBayesianMultiTaskGP" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.multitask.MultiTaskGP" title="botorch.models.multitask.MultiTaskGP"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiTaskGP</span></code></a></p>
<p>A fully Bayesian multi-task GP model with the SAAS prior.</p>
<p>This model assumes that the inputs have been normalized to [0, 1]^d and that the
output has been stratified standardized to have zero mean and unit variance for
each task. The SAAS model <a class="reference internal" href="#eriksson2021saasbo" id="id5"><span>[Eriksson2021saasbo]</span></a> with a Matern-5/2 is used as data
kernel by default.</p>
<p>You are expected to use <cite>fit_fully_bayesian_model_nuts</cite> to fit this model as it
isn’t compatible with <cite>fit_gpytorch_mll</cite>.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">i1</span><span class="p">,</span> <span class="n">i2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">X1</span><span class="p">,</span> <span class="n">i1</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">X2</span><span class="p">,</span> <span class="n">i2</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">f1</span><span class="p">(</span><span class="n">X1</span><span class="p">),</span> <span class="n">f2</span><span class="p">(</span><span class="n">X2</span><span class="p">))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Yvar</span> <span class="o">=</span> <span class="mf">0.01</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mtsaas_gp</span> <span class="o">=</span> <span class="n">SaasFullyBayesianMultiTaskGP</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">,</span> <span class="n">train_Yvar</span><span class="p">,</span> <span class="n">task_feature</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fit_fully_bayesian_model_nuts</span><span class="p">(</span><span class="n">mtsaas_gp</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">posterior</span> <span class="o">=</span> <span class="n">mtsaas_gp</span><span class="o">.</span><span class="n">posterior</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
</pre></div>
</div>
<p>Initialize the fully Bayesian multi-task GP model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>Tensor</em>) – Training inputs (n x (d + 1))</p></li>
<li><p><strong>train_Y</strong> (<em>Tensor</em>) – Training targets (n x 1)</p></li>
<li><p><strong>train_Yvar</strong> (<em>Tensor</em><em> | </em><em>None</em>) – Observed noise variance (n x 1). If None, we infer the noise.
Note that the inferred noise is common across all tasks.</p></li>
<li><p><strong>task_feature</strong> (<em>int</em>) – The index of the task feature (<cite>-d &lt;= task_feature &lt;= d</cite>).</p></li>
<li><p><strong>output_tasks</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – A list of task indices for which to compute model
outputs for. If omitted, return outputs for all task indices.</p></li>
<li><p><strong>rank</strong> (<em>int</em><em> | </em><em>None</em>) – The num of learned task embeddings to be used in the task kernel.
If omitted, use a full rank (i.e. number of tasks) kernel.</p></li>
<li><p><strong>all_tasks</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – NOT SUPPORTED!</p></li>
<li><p><strong>outcome_transform</strong> (<a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><em>OutcomeTransform</em></a><em> | </em><em>None</em>) – An outcome transform that is applied to the
training data during instantiation and to the posterior during
inference (that is, the <cite>Posterior</cite> obtained by calling
<cite>.posterior</cite> on the model will be on the original scale).</p></li>
<li><p><strong>input_transform</strong> (<a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>InputTransform</em></a><em> | </em><em>None</em>) – An input transform that is applied to the inputs <cite>X</cite>
in the model’s forward pass.</p></li>
<li><p><strong>pyro_model</strong> (<a class="reference internal" href="#botorch.models.fully_bayesian_multitask.MultitaskSaasPyroModel" title="botorch.models.fully_bayesian_multitask.MultitaskSaasPyroModel"><em>MultitaskSaasPyroModel</em></a><em> | </em><em>None</em>) – Optional <cite>PyroModel</cite> that has the same signature as
<cite>MultitaskSaasPyroModel</cite>. Defaults to <cite>MultitaskSaasPyroModel</cite>.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian_multitask.SaasFullyBayesianMultiTaskGP.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian_multitask.html#SaasFullyBayesianMultiTaskGP.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian_multitask.SaasFullyBayesianMultiTaskGP.train" title="Link to this definition"></a></dt>
<dd><p>Puts the model in <cite>train</cite> mode.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mode</strong> (<em>bool</em>) – A boolean indicating whether to put the model in training mode.</p></li>
<li><p><strong>reset</strong> (<em>bool</em>) – A boolean indicating whether to reset the model to its initial
state. If <cite>mode</cite> is False, this argument is ignored.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The model itself.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>TSaasFullyBayesianMultiTaskGP</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian_multitask.SaasFullyBayesianMultiTaskGP.median_lengthscale">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">median_lengthscale</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tensor</span></em><a class="headerlink" href="#botorch.models.fully_bayesian_multitask.SaasFullyBayesianMultiTaskGP.median_lengthscale" title="Link to this definition"></a></dt>
<dd><p>Median lengthscales across the MCMC samples.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian_multitask.SaasFullyBayesianMultiTaskGP.num_mcmc_samples">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">num_mcmc_samples</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#botorch.models.fully_bayesian_multitask.SaasFullyBayesianMultiTaskGP.num_mcmc_samples" title="Link to this definition"></a></dt>
<dd><p>Number of MCMC samples in the model.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian_multitask.SaasFullyBayesianMultiTaskGP.batch_shape">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">batch_shape</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Size</span></em><a class="headerlink" href="#botorch.models.fully_bayesian_multitask.SaasFullyBayesianMultiTaskGP.batch_shape" title="Link to this definition"></a></dt>
<dd><p>Batch shape of the model, equal to the number of MCMC samples.
Note that <cite>SaasFullyBayesianMultiTaskGP</cite> does not support batching
over input data at this point.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian_multitask.SaasFullyBayesianMultiTaskGP.fantasize">
<span class="sig-name descname"><span class="pre">fantasize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian_multitask.html#SaasFullyBayesianMultiTaskGP.fantasize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian_multitask.SaasFullyBayesianMultiTaskGP.fantasize" title="Link to this definition"></a></dt>
<dd><p>Construct a fantasy model.</p>
<p>Constructs a fantasy model in the following fashion:
(1) compute the model posterior at <cite>X</cite>, including observation noise.
If <cite>observation_noise</cite> is a Tensor, use it directly as the observation
noise to add.
(2) sample from this posterior (using <cite>sampler</cite>) to generate “fake”
observations.
(3) condition the model on the new fake observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> – A <cite>batch_shape x n’ x d</cite>-dim Tensor, where <cite>d</cite> is the dimension of
the feature space, <cite>n’</cite> is the number of points per batch, and
<cite>batch_shape</cite> is the batch shape (must be compatible with the
batch shape of the model).</p></li>
<li><p><strong>sampler</strong> – The sampler used for sampling from the posterior at <cite>X</cite>.</p></li>
<li><p><strong>observation_noise</strong> – A <cite>model_batch_shape x 1 x m</cite>-dim tensor or
a <cite>model_batch_shape x n’ x m</cite>-dim tensor containing the average
noise for each batch and output, where <cite>m</cite> is the number of outputs.
<cite>noise</cite> must be in the outcome-transformed space if an outcome
transform is used.
If None and using an inferred noise likelihood, the noise will be the
inferred noise level. If using a fixed noise likelihood, the mean across
the observation noise in the training data is used as observation noise.</p></li>
<li><p><strong>kwargs</strong> – Will be passed to <cite>model.condition_on_observations</cite></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The constructed fantasy model.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>NoReturn</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian_multitask.SaasFullyBayesianMultiTaskGP.load_mcmc_samples">
<span class="sig-name descname"><span class="pre">load_mcmc_samples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mcmc_samples</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian_multitask.html#SaasFullyBayesianMultiTaskGP.load_mcmc_samples"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian_multitask.SaasFullyBayesianMultiTaskGP.load_mcmc_samples" title="Link to this definition"></a></dt>
<dd><p>Load the MCMC hyperparameter samples into the model.</p>
<p>This method will be called by <cite>fit_fully_bayesian_model_nuts</cite> when the model
has been fitted in order to create a batched MultiTaskGP model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>mcmc_samples</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian_multitask.SaasFullyBayesianMultiTaskGP.posterior">
<span class="sig-name descname"><span class="pre">posterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observation_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian_multitask.html#SaasFullyBayesianMultiTaskGP.posterior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian_multitask.SaasFullyBayesianMultiTaskGP.posterior" title="Link to this definition"></a></dt>
<dd><p>Computes the posterior over model outputs at the provided points.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>A <cite>GaussianMixturePosterior</cite> object. Includes observation noise</dt><dd><p>if specified.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>)</p></li>
<li><p><strong>output_indices</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>observation_noise</strong> (<em>bool</em>)</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="acquisition.html#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>)</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>)</p></li>
</ul>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.fully_bayesian.GaussianMixturePosterior" title="botorch.posteriors.fully_bayesian.GaussianMixturePosterior"><em>GaussianMixturePosterior</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian_multitask.SaasFullyBayesianMultiTaskGP.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian_multitask.html#SaasFullyBayesianMultiTaskGP.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian_multitask.SaasFullyBayesianMultiTaskGP.forward" title="Link to this definition"></a></dt>
<dd><p>Define the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>MultivariateNormal</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.fully_bayesian_multitask.SaasFullyBayesianMultiTaskGP.load_state_dict">
<span class="sig-name descname"><span class="pre">load_state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/fully_bayesian_multitask.html#SaasFullyBayesianMultiTaskGP.load_state_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.fully_bayesian_multitask.SaasFullyBayesianMultiTaskGP.load_state_dict" title="Link to this definition"></a></dt>
<dd><p>Custom logic for loading the state dict.</p>
<p>The standard approach of calling <cite>load_state_dict</cite> currently doesn’t play well
with the <cite>SaasFullyBayesianMultiTaskGP</cite> since the <cite>mean_module</cite>, <cite>covar_module</cite>
and <cite>likelihood</cite> aren’t initialized until the model has been fitted. The reason
for this is that we don’t know the number of MCMC samples until NUTS is called.
Given the state dict, we can initialize a new model with some dummy samples and
then load the state dict into this model. This currently only works for a
<cite>MultitaskSaasPyroModel</cite> and supporting more Pyro models likely requires moving
the model construction logic into the Pyro model itself.</p>
<p>TODO: If this were to inherif from <cite>SaasFullyBayesianSingleTaskGP</cite>, we could
simplify this method and eliminate some others.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>state_dict</strong> (<em>Mapping</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>)</p></li>
<li><p><strong>strict</strong> (<em>bool</em>)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-botorch.models.gp_regression">
<span id="gp-regression-models"></span><h3>GP Regression Models<a class="headerlink" href="#module-botorch.models.gp_regression" title="Link to this heading"></a></h3>
<p>Gaussian Process Regression models based on GPyTorch models.</p>
<p>These models are often a good starting point and are further documented in the
tutorials.</p>
<p><cite>SingleTaskGP</cite> is a single-task exact GP model that uses relatively strong priors on
the Kernel hyperparameters, which work best when covariates are normalized to the unit
cube and outcomes are standardized (zero mean, unit variance). By default, this model
uses a <cite>Standardize</cite> outcome transform, which applies this standardization. However,
it does not (yet) use an input transform by default.</p>
<p><cite>SingleTaskGP</cite> model works in batch mode (each batch having its own hyperparameters).
When the training observations include multiple outputs, <cite>SingleTaskGP</cite> uses
batching to model outputs independently.</p>
<p><cite>SingleTaskGP</cite> supports multiple outputs. However, as a single-task model,
<cite>SingleTaskGP</cite> should be used only when the outputs are independent and all
use the same training inputs. If outputs are independent but they have different
training inputs, use the <cite>ModelListGP</cite>. When modeling correlations between outputs,
use a multi-task model like <cite>MultiTaskGP</cite>.</p>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.gp_regression.SingleTaskGP">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.gp_regression.</span></span><span class="sig-name descname"><span class="pre">SingleTaskGP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Yvar=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">likelihood=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">covar_module=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean_module=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outcome_transform=&lt;class</span> <span class="pre">'botorch.utils.types.DEFAULT'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_transform=None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gp_regression.html#SingleTaskGP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gp_regression.SingleTaskGP" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel" title="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">BatchedMultiOutputGPyTorchModel</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ExactGP</span></code>, <a class="reference internal" href="#botorch.models.model.FantasizeMixin" title="botorch.models.model.FantasizeMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">FantasizeMixin</span></code></a></p>
<p>A single-task exact GP model, supporting both known and inferred noise levels.</p>
<p>A single-task exact GP which, by default, utilizes hyperparameter priors
from <a class="reference internal" href="#hvarfner2024vanilla" id="id6"><span>[Hvarfner2024vanilla]</span></a>. These priors designed to perform well independently of
the dimensionality of the problem. Moreover, they suggest a moderately low level of
noise. Importantly, The model works best when covariates are normalized to the unit
cube and outcomes are standardized (zero mean, unit variance). For a detailed
discussion on the hyperparameter priors, see
<a class="reference external" href="https://github.com/pytorch/botorch/discussions/2451">https://github.com/pytorch/botorch/discussions/2451</a>.</p>
<p>This model works in batch mode (each batch having its own hyperparameters).
When the training observations include multiple outputs, this model will use
batching to model outputs independently.</p>
<p>Use this model when you have independent output(s) and all outputs use the
same training data. If outputs are independent and outputs have different
training data, use the ModelListGP. When modeling correlations between
outputs, use the MultiTaskGP.</p>
<p>An example of a case in which noise levels are known is online
experimentation, where noise can be measured using the variability of
different observations from the same arm, or provided by outside software.
Another use case is simulation optimization, where the evaluation can
provide variance estimates, perhaps from bootstrapping. In any case, these
noise levels can be provided to <cite>SingleTaskGP</cite> as <cite>train_Yvar</cite>.</p>
<p><cite>SingleTaskGP</cite> can also be used when the observations are known to be
noise-free. Noise-free observations can be modeled using arbitrarily small
noise values, such as <cite>train_Yvar=torch.full_like(train_Y, 1e-6)</cite>.</p>
<p class="rubric">Example</p>
<p>Model with inferred noise levels:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">botorch.models.gp_regression</span><span class="w"> </span><span class="kn">import</span> <span class="n">SingleTaskGP</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">botorch.models.transforms.outcome</span><span class="w"> </span><span class="kn">import</span> <span class="n">Standardize</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">train_X</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">outcome_transform</span> <span class="o">=</span> <span class="n">Standardize</span><span class="p">(</span><span class="n">m</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inferred_noise_model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">,</span> <span class="n">outcome_transform</span><span class="o">=</span><span class="n">outcome_transform</span><span class="p">,</span>
<span class="gp">... </span><span class="p">)</span>
</pre></div>
</div>
<p>Model with a known observation variance of 0.2:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_Yvar</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">train_Y</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">observed_noise_model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">,</span> <span class="n">train_Yvar</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">outcome_transform</span><span class="o">=</span><span class="n">outcome_transform</span><span class="p">,</span>
<span class="gp">... </span><span class="p">)</span>
</pre></div>
</div>
<p>With noise-free observations:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_Yvar</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">train_Y</span><span class="p">,</span> <span class="mf">1e-6</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">noise_free_model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">,</span> <span class="n">train_Yvar</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">outcome_transform</span><span class="o">=</span><span class="n">outcome_transform</span><span class="p">,</span>
<span class="gp">... </span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite> tensor of training features.</p></li>
<li><p><strong>train_Y</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x m</cite> tensor of training observations.</p></li>
<li><p><strong>train_Yvar</strong> (<em>Tensor</em><em> | </em><em>None</em>) – An optional <cite>batch_shape x n x m</cite> tensor of observed
measurement noise.</p></li>
<li><p><strong>likelihood</strong> (<em>Likelihood</em><em> | </em><em>None</em>) – A likelihood. If omitted, use a standard
<cite>GaussianLikelihood</cite> with inferred noise level if <cite>train_Yvar</cite>
is None, and a <cite>FixedNoiseGaussianLikelihood</cite> with the given
noise observations if <cite>train_Yvar</cite> is not None.</p></li>
<li><p><strong>covar_module</strong> (<em>Module</em><em> | </em><em>None</em>) – The module computing the covariance (Kernel) matrix.
If omitted, uses an <cite>RBFKernel</cite>.</p></li>
<li><p><strong>mean_module</strong> (<em>Mean</em><em> | </em><em>None</em>) – The mean function to be used. If omitted, use a
<cite>ConstantMean</cite>.</p></li>
<li><p><strong>outcome_transform</strong> (<a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><em>OutcomeTransform</em></a><em> | </em><em>_DefaultType</em><em> | </em><em>None</em>) – An outcome transform that is applied to the
training data during instantiation and to the posterior during
inference (that is, the <cite>Posterior</cite> obtained by calling
<cite>.posterior</cite> on the model will be on the original scale). We use a
<cite>Standardize</cite> transform if no <cite>outcome_transform</cite> is specified.
Pass down <cite>None</cite> to use no outcome transform.</p></li>
<li><p><strong>input_transform</strong> (<a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>InputTransform</em></a><em> | </em><em>None</em>) – An input transform that is applied in the model’s
forward pass.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.gp_regression.SingleTaskGP.construct_inputs">
<em class="property"><span class="k"><span class="pre">classmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct_inputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">training_data</span></span></em>, <em class="sig-param"><span class="keyword-only-separator o"><abbr title="Keyword-only parameters separator (PEP 3102)"><span class="pre">*</span></abbr></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_feature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gp_regression.html#SingleTaskGP.construct_inputs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gp_regression.SingleTaskGP.construct_inputs" title="Link to this definition"></a></dt>
<dd><p>Construct <cite>SingleTaskGP</cite> keyword arguments from a <cite>SupervisedDataset</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>training_data</strong> (<a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a>) – A <cite>SupervisedDataset</cite>, with attributes <cite>train_X</cite>,
<cite>train_Y</cite>, and, optionally, <cite>train_Yvar</cite>.</p></li>
<li><p><strong>task_feature</strong> (<em>int</em><em> | </em><em>None</em>) – Deprecated and allowed only for backward
compatibility; ignored.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dict of keyword arguments that can be used to initialize a <cite>SingleTaskGP</cite>,
with keys <cite>train_X</cite>, <cite>train_Y</cite>, and, optionally, <cite>train_Yvar</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict[str, <a class="reference internal" href="utils.html#botorch.utils.containers.BotorchContainer" title="botorch.utils.containers.BotorchContainer"><em>BotorchContainer</em></a> | <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.gp_regression.SingleTaskGP.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gp_regression.html#SingleTaskGP.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gp_regression.SingleTaskGP.forward" title="Link to this definition"></a></dt>
<dd><p>Define the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>MultivariateNormal</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-botorch.models.gp_regression_mixed">
<span id="gp-regression-models-for-mixed-parameter-spaces"></span><h3>GP Regression Models for Mixed Parameter Spaces<a class="headerlink" href="#module-botorch.models.gp_regression_mixed" title="Link to this heading"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.gp_regression_mixed.MixedSingleTaskGP">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.gp_regression_mixed.</span></span><span class="sig-name descname"><span class="pre">MixedSingleTaskGP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cat_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Yvar=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cont_kernel_factory=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">likelihood=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outcome_transform=&lt;class</span> <span class="pre">'botorch.utils.types.DEFAULT'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_transform=None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gp_regression_mixed.html#MixedSingleTaskGP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gp_regression_mixed.MixedSingleTaskGP" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.gp_regression.SingleTaskGP" title="botorch.models.gp_regression.SingleTaskGP"><code class="xref py py-class docutils literal notranslate"><span class="pre">SingleTaskGP</span></code></a></p>
<p>A single-task exact GP model for mixed search spaces.</p>
<p>This model is similar to <cite>SingleTaskGP</cite>, but supports mixed search spaces,
which combine discrete and continuous features, as well as solely discrete
spaces. It uses a kernel that combines a CategoricalKernel (based on
Hamming distances) and a regular kernel into a kernel of the form</p>
<blockquote>
<div><dl class="simple">
<dt>K((x1, c1), (x2, c2)) =</dt><dd><p>K_cont_1(x1, x2) + K_cat_1(c1, c2) +
K_cont_2(x1, x2) * K_cat_2(c1, c2)</p>
</dd>
</dl>
</div></blockquote>
<p>where <cite>xi</cite> and <cite>ci</cite> are the continuous and categorical features of the
input, respectively. The suffix <cite>_i</cite> indicates that we fit different
lengthscales for the kernels in the sum and product terms.</p>
<p>Since this model does not provide gradients for the categorical features,
optimization of the acquisition function will need to be performed in
a mixed fashion, i.e., treating the categorical features properly as
discrete optimization variables. We recommend using <cite>optimize_acqf_mixed.</cite></p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
<span class="go">        [torch.rand(20, 2), torch.randint(3, (20, 1))], dim=-1)</span>
<span class="go">    )</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="p">(</span>
<span class="go">        torch.sin(train_X[..., :-1]).sum(dim=1, keepdim=True)</span>
<span class="go">        + train_X[..., -1:]</span>
<span class="go">    )</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">MixedSingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">,</span> <span class="n">cat_dims</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
<p>A single-task exact GP model supporting categorical parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite> tensor of training features.</p></li>
<li><p><strong>train_Y</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x m</cite> tensor of training observations.</p></li>
<li><p><strong>cat_dims</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – A list of indices corresponding to the columns of
the input <cite>X</cite> that should be considered categorical features.</p></li>
<li><p><strong>train_Yvar</strong> (<em>Tensor</em><em> | </em><em>None</em>) – An optional <cite>batch_shape x n x m</cite> tensor of observed
measurement noise.</p></li>
<li><p><strong>cont_kernel_factory</strong> (<em>None</em><em> | </em><em>Callable</em><em>[</em><em>[</em><em>torch.Size</em><em>, </em><em>int</em><em>, </em><em>list</em><em>[</em><em>int</em><em>]</em><em>]</em><em>, </em><em>Kernel</em><em>]</em>) – A method that accepts  <cite>batch_shape</cite>, <cite>ard_num_dims</cite>,
and <cite>active_dims</cite> arguments and returns an instantiated GPyTorch
<cite>Kernel</cite> object to be used as the base kernel for the continuous
dimensions. If omitted, this model uses an <cite>RBFKernel</cite> as
the kernel for the ordinal parameters.</p></li>
<li><p><strong>likelihood</strong> (<em>Likelihood</em><em> | </em><em>None</em>) – A likelihood. If omitted, use a standard
GaussianLikelihood with inferred noise level.</p></li>
<li><p><strong>outcome_transform</strong> (<a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><em>OutcomeTransform</em></a><em> | </em><em>_DefaultType</em><em> | </em><em>None</em>) – An outcome transform that is applied to the
training data during instantiation and to the posterior during
inference (that is, the <cite>Posterior</cite> obtained by calling
<cite>.posterior</cite> on the model will be on the original scale). We use a
<cite>Standardize</cite> transform if no <cite>outcome_transform</cite> is specified.
Pass down <cite>None</cite> to use no outcome transform.</p></li>
<li><p><strong>input_transform</strong> (<a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>InputTransform</em></a><em> | </em><em>None</em>) – An input transform that is applied in the model’s
forward pass. Only input transforms are allowed which do not
transform the categorical dimensions. If you want to use it
for example in combination with a <cite>OneHotToNumeric</cite> input transform
one has to instantiate the transform with <cite>transform_on_train</cite> == False
and pass in the already transformed input.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.gp_regression_mixed.MixedSingleTaskGP.construct_inputs">
<em class="property"><span class="k"><span class="pre">classmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct_inputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">training_data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">categorical_features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">likelihood</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gp_regression_mixed.html#MixedSingleTaskGP.construct_inputs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gp_regression_mixed.MixedSingleTaskGP.construct_inputs" title="Link to this definition"></a></dt>
<dd><p>Construct <cite>Model</cite> keyword arguments from a dict of <cite>SupervisedDataset</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>training_data</strong> (<a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a>) – A <cite>SupervisedDataset</cite> containing the training data.</p></li>
<li><p><strong>categorical_features</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – Column indices of categorical features.</p></li>
<li><p><strong>likelihood</strong> (<em>Likelihood</em><em> | </em><em>None</em>) – Optional likelihood used to constuct the model.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>dict[str, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-botorch.models.higher_order_gp">
<span id="higher-order-gp-models"></span><h3>Higher Order GP Models<a class="headerlink" href="#module-botorch.models.higher_order_gp" title="Link to this heading"></a></h3>
<p>References</p>
<div role="list" class="citation-list">
<div class="citation" id="zhe2019hogp" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id7">Zhe2019hogp</a><span class="fn-bracket">]</span></span>
<p>S. Zhe, W. Xing, and R. M. Kirby. Scalable high-order gaussian process regression.
Proceedings of Machine Learning Research, volume 89, Apr 2019.</p>
</div>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.higher_order_gp.FlattenedStandardize">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.higher_order_gp.</span></span><span class="sig-name descname"><span class="pre">FlattenedStandardize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_stdv</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-08</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/higher_order_gp.html#FlattenedStandardize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.higher_order_gp.FlattenedStandardize" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.transforms.outcome.Standardize" title="botorch.models.transforms.outcome.Standardize"><code class="xref py py-class docutils literal notranslate"><span class="pre">Standardize</span></code></a></p>
<p>Standardize outcomes in a structured multi-output settings by reshaping the
batched output dimensions to be a vector. Specifically, an output dimension
of [a x b x c] will be squeezed to be a vector of [a * b * c].</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>output_shape</strong> (<em>torch.Size</em>) – A <cite>n x output_shape</cite>-dim tensor of training targets.</p></li>
<li><p><strong>batch_shape</strong> (<em>torch.Size</em><em> | </em><em>None</em>) – The batch_shape of the training targets.</p></li>
<li><p><strong>min_stddv</strong> – The minimum standard deviation for which to perform
standardization (if lower, only de-mean the data).</p></li>
<li><p><strong>min_stdv</strong> (<em>float</em>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.higher_order_gp.FlattenedStandardize.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Yvar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/higher_order_gp.html#FlattenedStandardize.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.higher_order_gp.FlattenedStandardize.forward" title="Link to this definition"></a></dt>
<dd><p>Standardize outcomes.</p>
<p>If the module is in train mode, this updates the module state (i.e. the
mean/std normalizing constants). If the module is in eval mode, simply
applies the normalization using the module state.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Y</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of training targets.</p></li>
<li><p><strong>Yvar</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of observation noises
associated with the training targets (if applicable).</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of training inputs (if applicable).
This argument is not used by this transform, but it is used by
its subclass, <cite>StratifiedStandardize</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The transformed outcome observations.</p></li>
<li><p>The transformed observation noise (if applicable).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>A two-tuple with the transformed outcomes</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.higher_order_gp.FlattenedStandardize.untransform">
<span class="sig-name descname"><span class="pre">untransform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Yvar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/higher_order_gp.html#FlattenedStandardize.untransform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.higher_order_gp.FlattenedStandardize.untransform" title="Link to this definition"></a></dt>
<dd><p>Un-standardize outcomes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Y</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of standardized targets.</p></li>
<li><p><strong>Yvar</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of standardized observation
noises associated with the targets (if applicable).</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of inputs (if applicable).
This argument is not used by this transform, but it is used by
its subclass, <cite>StratifiedStandardize</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The un-standardized outcome observations.</p></li>
<li><p>The un-standardized observation noise (if applicable).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>A two-tuple with the un-standardized outcomes</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.higher_order_gp.FlattenedStandardize.untransform_posterior">
<span class="sig-name descname"><span class="pre">untransform_posterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">posterior</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/higher_order_gp.html#FlattenedStandardize.untransform_posterior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.higher_order_gp.FlattenedStandardize.untransform_posterior" title="Link to this definition"></a></dt>
<dd><p>Un-standardize the posterior.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>posterior</strong> (<a class="reference internal" href="posteriors.html#botorch.posteriors.higher_order.HigherOrderGPPosterior" title="botorch.posteriors.higher_order.HigherOrderGPPosterior"><em>HigherOrderGPPosterior</em></a>) – A posterior in the standardized space.</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of inputs (if applicable).
This argument is not used by this transform, but it is used by
its subclass, <cite>StratifiedStandardize</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The un-standardized posterior. If the input posterior is a
<cite>GPyTorchPosterior</cite>, return a <cite>GPyTorchPosterior</cite>. Otherwise, return a
<cite>TransformedPosterior</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.transformed.TransformedPosterior" title="botorch.posteriors.transformed.TransformedPosterior"><em>TransformedPosterior</em></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.higher_order_gp.HigherOrderGP">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.higher_order_gp.</span></span><span class="sig-name descname"><span class="pre">HigherOrderGP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">likelihood=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">covar_modules=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_latent_dims=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learn_latent_pars=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">latent_init='default'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outcome_transform=&lt;class</span> <span class="pre">'botorch.utils.types.DEFAULT'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_transform=None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/higher_order_gp.html#HigherOrderGP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.higher_order_gp.HigherOrderGP" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel" title="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">BatchedMultiOutputGPyTorchModel</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ExactGP</span></code>, <a class="reference internal" href="#botorch.models.model.FantasizeMixin" title="botorch.models.model.FantasizeMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">FantasizeMixin</span></code></a></p>
<p>A model for high-dimensional output regression.</p>
<p>As described in <a class="reference internal" href="#zhe2019hogp" id="id7"><span>[Zhe2019hogp]</span></a>. “Higher-order” means that the predictions
are matrices (tensors) with at least two dimensions, such as images or
grids of images, or measurements taken from a region of at least two
dimensions.
The posterior uses Matheron’s rule <a class="reference internal" href="#doucet2010sampl" id="id8"><span>[Doucet2010sampl]</span></a>
as described in <a class="reference internal" href="#maddox2021bohdo" id="id9"><span>[Maddox2021bohdo]</span></a>.</p>
<p><cite>HigherOrderGP</cite> differs from a “vector” multi-output model in that it uses
Kronecker algebra to obtain parsimonious covariance matrices for these
outputs (see <cite>KroneckerMultiTaskGP</cite> for more information). For example,
imagine a 10 x 20 x 30 grid of images. If we were to vectorize the
resulting 6,000 data points in order to use them in a non-higher-order GP,
they would have a 6,000 x 6,000 covariance matrix, with 36 million entries.
The Kronecker structure allows representing this as a product of 10x10,
20x20, and 30x30 covariance matrices, with only 1,400 entries.</p>
<p>NOTE: This model requires the use of specialized Kronecker solves in
linear operator, which are disabled by default in BoTorch. These are enabled
by default in the <cite>HigherOrderGP.posterior</cite> call. However, they need to be
manually enabled by the user during model fitting. Note also that we’re using
<cite>fit_gpytorch_mll_torch()</cite> here instead of <cite>fit_gpytorch_mll()</cite> since the
approximate computations result in a non-smooth MLL that the default
L-BFGS-B optimizer invoked by <cite>fit_gpytorch_mll()</cite> does not handle well.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">linear_operator.settings</span><span class="w"> </span><span class="kn">import</span> <span class="n">_fast_solves</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">HigherOrderGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mll</span> <span class="o">=</span> <span class="n">ExactMarginalLogLikelihood</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">_fast_solves</span><span class="p">(</span><span class="kc">True</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">fit_gpytorch_mll_torch</span><span class="p">(</span><span class="n">mll</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">samples</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">posterior</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span><span class="o">.</span><span class="n">rsample</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of training inputs.</p></li>
<li><p><strong>train_Y</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x output_shape</cite>-dim tensor of training targets.</p></li>
<li><p><strong>likelihood</strong> (<em>Likelihood</em><em> | </em><em>None</em>) – Gaussian likelihood for the model.</p></li>
<li><p><strong>covar_modules</strong> (<em>list</em><em>[</em><em>Kernel</em><em>] </em><em>| </em><em>None</em>) – List of kernels for each output structure.</p></li>
<li><p><strong>num_latent_dims</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – Sizes for the latent dimensions.</p></li>
<li><p><strong>learn_latent_pars</strong> (<em>bool</em>) – If true, learn the latent parameters.</p></li>
<li><p><strong>latent_init</strong> (<em>str</em>) – [default or gp] how to initialize the latent parameters.</p></li>
<li><p><strong>outcome_transform</strong> (<a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><em>OutcomeTransform</em></a><em> | </em><em>_DefaultType</em><em> | </em><em>None</em>)</p></li>
<li><p><strong>input_transform</strong> (<a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>InputTransform</em></a><em> | </em><em>None</em>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.higher_order_gp.HigherOrderGP.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/higher_order_gp.html#HigherOrderGP.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.higher_order_gp.HigherOrderGP.forward" title="Link to this definition"></a></dt>
<dd><p>Define the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>MultivariateNormal</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.higher_order_gp.HigherOrderGP.get_fantasy_model">
<span class="sig-name descname"><span class="pre">get_fantasy_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/higher_order_gp.html#HigherOrderGP.get_fantasy_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.higher_order_gp.HigherOrderGP.get_fantasy_model" title="Link to this definition"></a></dt>
<dd><p>Returns a new GP model that incorporates the specified inputs and targets as new training data.</p>
<p>Using this method is more efficient than updating with <cite>set_train_data</cite> when the number of inputs is relatively
small, because any computed test-time caches will be updated in linear time rather than computed from scratch.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If <cite>targets</cite> is a batch (e.g. <cite>b x m</cite>), then the GP returned from this method will be a batch mode GP.
If <cite>inputs</cite> is of the same (or lesser) dimension as <cite>targets</cite>, then it is assumed that the fantasy points
are the same for each target batch.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>torch.Tensor</em>) – (<cite>b1 x … x bk x m x d</cite> or <cite>f x b1 x … x bk x m x d</cite>) Locations of fantasy
observations.</p></li>
<li><p><strong>targets</strong> (<em>torch.Tensor</em>) – (<cite>b1 x … x bk x m</cite> or <cite>f x b1 x … x bk x m</cite>) Labels of fantasy observations.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An <cite>ExactGP</cite> model with <cite>n + m</cite> training examples, where the <cite>m</cite> fantasy examples have been added
and all test-time caches have been updated.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>ExactGP</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.higher_order_gp.HigherOrderGP.condition_on_observations">
<span class="sig-name descname"><span class="pre">condition_on_observations</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/higher_order_gp.html#HigherOrderGP.condition_on_observations"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.higher_order_gp.HigherOrderGP.condition_on_observations" title="Link to this definition"></a></dt>
<dd><p>Condition the model on new observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n’ x d</cite>-dim Tensor, where <cite>d</cite> is the dimension of
the feature space, <cite>m</cite> is the number of points per batch, and
<cite>batch_shape</cite> is the batch shape (must be compatible with the
batch shape of the model).</p></li>
<li><p><strong>Y</strong> (<em>Tensor</em>) – A <cite>batch_shape’ x n’ x m_d</cite>-dim Tensor, where <cite>m_d</cite> is the shaping
of the model outputs, <cite>n’</cite> is the number of points per batch, and
<cite>batch_shape’</cite> is the batch shape of the observations.
<cite>batch_shape’</cite> must be broadcastable to <cite>batch_shape</cite> using
standard broadcasting semantics. If <cite>Y</cite> has fewer batch dimensions
than <cite>X</cite>, its is assumed that the missing batch dimensions are
the same for all <cite>Y</cite>.</p></li>
<li><p><strong>noise</strong> (<em>Tensor</em><em> | </em><em>None</em>) – If not None, a tensor of the same shape as <cite>Y</cite> representing
the noise variance associated with each observation.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – Passed to <cite>condition_on_observations</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>BatchedMultiOutputGPyTorchModel</cite> object of the same type with
<cite>n + n’</cite> training examples, representing the original model
conditioned on the new observations <cite>(X, Y)</cite> (and possibly noise
observations passed in via kwargs).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.higher_order_gp.HigherOrderGP" title="botorch.models.higher_order_gp.HigherOrderGP"><em>HigherOrderGP</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.higher_order_gp.HigherOrderGP.posterior">
<span class="sig-name descname"><span class="pre">posterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observation_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/higher_order_gp.html#HigherOrderGP.posterior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.higher_order_gp.HigherOrderGP.posterior" title="Link to this definition"></a></dt>
<dd><p>Computes the posterior over model outputs at the provided points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>(batch_shape) x q x d</cite>-dim Tensor, where <cite>d</cite> is the dimension
of the feature space and <cite>q</cite> is the number of points considered
jointly.</p></li>
<li><p><strong>output_indices</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – A list of indices, corresponding to the outputs over
which to compute the posterior (if the model is multi-output).
Can be used to speed up computation if only a subset of the
model’s outputs are required for optimization. If omitted,
computes the posterior over all model outputs.</p></li>
<li><p><strong>observation_noise</strong> (<em>bool</em><em> | </em><em>Tensor</em>) – If True, add the observation noise from the
likelihood to the posterior. If a Tensor, use it directly as the
observation noise (must be of shape <cite>(batch_shape) x q x m</cite>).</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="acquisition.html#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – An optional PosteriorTransform.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>GPyTorchPosterior</cite> object, representing <cite>batch_shape</cite> joint
distributions over <cite>q</cite> points and the outputs selected by
<cite>output_indices</cite> each. Includes observation noise if specified.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.gpytorch.GPyTorchPosterior" title="botorch.posteriors.gpytorch.GPyTorchPosterior"><em>GPyTorchPosterior</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.higher_order_gp.HigherOrderGP.make_posterior_variances">
<span class="sig-name descname"><span class="pre">make_posterior_variances</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">joint_covariance_matrix</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/higher_order_gp.html#HigherOrderGP.make_posterior_variances"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.higher_order_gp.HigherOrderGP.make_posterior_variances" title="Link to this definition"></a></dt>
<dd><p>Computes the posterior variances given the data points X. As currently
implemented, it computes another forwards call with the stacked data to get out
the joint covariance across all data points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>joint_covariance_matrix</strong> (<em>LinearOperator</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-botorch.models.latent_kronecker_gp">
<span id="latent-kronecker-gp-models"></span><h3>Latent Kronecker GP Models<a class="headerlink" href="#module-botorch.models.latent_kronecker_gp" title="Link to this heading"></a></h3>
<p>References</p>
<div role="list" class="citation-list">
<div class="citation" id="lin2024scaling" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id10">lin2024scaling</a><span class="fn-bracket">]</span></span>
<p>J. A. Lin, S. Ament, M. Balandat, E. Bakshy. Scaling Gaussian Processes
for Learning Curve Prediction via Latent Kronecker Structure. NeurIPS 2024
Bayesian Decision-making and Uncertainty Workshop.</p>
</div>
<div class="citation" id="lin2023sampling" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id13">lin2023sampling</a><span class="fn-bracket">]</span></span>
<p>J. A. Lin, J. Antorán, s. Padhy, D. Janz, J. M. Hernández-Lobato, A. Terenin.
Sampling from Gaussian Process Posterior using Stochastic Gradient Descent.
Advances in Neural Information Processing Systems 2023.</p>
</div>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.latent_kronecker_gp.MinMaxStandardize">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.latent_kronecker_gp.</span></span><span class="sig-name descname"><span class="pre">MinMaxStandardize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">m</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_min</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_stdv</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-08</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/latent_kronecker_gp.html#MinMaxStandardize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.latent_kronecker_gp.MinMaxStandardize" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.transforms.outcome.Standardize" title="botorch.models.transforms.outcome.Standardize"><code class="xref py py-class docutils literal notranslate"><span class="pre">Standardize</span></code></a></p>
<p>Standardize outcomes (zero mean, unit variance),
centered about the minimum (or maximum) instead of the mean.
Otherwise equivalent to ‘Standardize’.</p>
<p>Standardize outcomes (zero mean, unit variance).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>m</strong> (<em>int</em>) – The output dimension.</p></li>
<li><p><strong>use_min</strong> (<em>bool</em>) – Whether to use the minimum or maximum (instead of the mean).</p></li>
<li><p><strong>outputs</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – Which of the outputs to standardize. If omitted, all
outputs will be standardized.</p></li>
<li><p><strong>batch_shape</strong> (<em>Size</em>) – The batch_shape of the training targets.</p></li>
<li><p><strong>min_stddv</strong> – The minimum standard deviation for which to perform
standardization (if lower, only de-mean the data).</p></li>
<li><p><strong>min_stdv</strong> (<em>float</em>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.latent_kronecker_gp.MinMaxStandardize.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Yvar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/latent_kronecker_gp.html#MinMaxStandardize.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.latent_kronecker_gp.MinMaxStandardize.forward" title="Link to this definition"></a></dt>
<dd><p>Standardize outcomes.</p>
<p>If the module is in train mode, this updates the module state (i.e. the
mean/std normalizing constants). If the module is in eval mode, simply
applies the normalization using the module state.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Y</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of training targets.</p></li>
<li><p><strong>Yvar</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of observation noises
associated with the training targets (if applicable).</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of training inputs (if applicable).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The transformed outcome observations.</p></li>
<li><p>The transformed observation noise (if applicable).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>A two-tuple with the transformed outcomes</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.latent_kronecker_gp.LatentKroneckerGP">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.latent_kronecker_gp.</span></span><span class="sig-name descname"><span class="pre">LatentKroneckerGP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Y_valid=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">T=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">likelihood=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean_module_X=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean_module_T=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">covar_module_X=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">covar_module_T=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_transform=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outcome_transform=&lt;class</span> <span class="pre">'botorch.utils.types.DEFAULT'&gt;</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/latent_kronecker_gp.html#LatentKroneckerGP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.latent_kronecker_gp.LatentKroneckerGP" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.gpytorch.GPyTorchModel" title="botorch.models.gpytorch.GPyTorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">GPyTorchModel</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ExactGP</span></code>, <a class="reference internal" href="#botorch.models.model.FantasizeMixin" title="botorch.models.model.FantasizeMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">FantasizeMixin</span></code></a></p>
<p>A multi-task GP model which uses Kronecker structure despite missing entries.</p>
<p>Leverages pathwise conditioning and iterative linear system solvers to
efficiently draw samples from the GP posterior. See <a class="reference internal" href="#lin2024scaling" id="id10"><span>[lin2024scaling]</span></a>
for details.</p>
<p>For more information about pathwise conditioning, see <a class="reference internal" href="sampling.html#wilson2021pathwise" id="id11"><span>[wilson2021pathwise]</span></a>
and <a class="reference internal" href="#maddox2021bohdo" id="id12"><span>[Maddox2021bohdo]</span></a>. Details about iterative linear system solvers for GPs
with pathwise conditioning can be found in <a class="reference internal" href="#lin2023sampling" id="id13"><span>[lin2023sampling]</span></a>.</p>
<p>NOTE: This model requires iterative methods for efficient posterior inference.
To enable iterative methods, the <cite>use_iterative_methods</cite> helper function can be
used as a context manager.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">LatentKroneckerGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mll</span> <span class="o">=</span> <span class="n">ExactMarginalLogLikelihood</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">model</span><span class="o">.</span><span class="n">use_iterative_methods</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">fit_gpytorch_mll</span><span class="p">(</span><span class="n">mll</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">samples</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">posterior</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span><span class="o">.</span><span class="n">rsample</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite> tensor of training features.</p></li>
<li><p><strong>train_Y</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x t</cite> tensor of training observations.</p></li>
<li><p><strong>train_Y_valid</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>n x t</cite> boolean tensor of valid values.
True indicates that the corresponding value is valid.
False indicates that the corresponding value is missing.
Does not allow explicit <cite>batch_shape</cite> because
the mask must be shared across batch dimensions.</p></li>
<li><p><strong>T</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x t</cite> tensor of training time steps.
If omitted, use [1, …, t].</p></li>
<li><p><strong>likelihood</strong> (<em>Likelihood</em><em> | </em><em>None</em>) – A likelihood. If omitted, use a standard
<cite>GaussianLikelihood</cite> with inferred noise level.</p></li>
<li><p><strong>mean_module_X</strong> (<em>Mean</em><em> | </em><em>None</em>) – The mean function to be used for X.
If omitted, use a <cite>ConstantMean</cite>.</p></li>
<li><p><strong>mean_module_T</strong> (<em>Mean</em><em> | </em><em>None</em>) – The mean function to be used for T.
If omitted, use a <cite>ConstantMean</cite>.</p></li>
<li><p><strong>covar_module_X</strong> (<em>Module</em><em> | </em><em>None</em>) – The module computing the covariance matrix of X.
If omitted, use a <cite>MaternKernel</cite>.</p></li>
<li><p><strong>covar_module_T</strong> (<em>Module</em><em> | </em><em>None</em>) – The module computing the covariance matrix of T.
If omitted, use a <cite>MaternKernel</cite>.</p></li>
<li><p><strong>input_transform</strong> (<a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>InputTransform</em></a><em> | </em><em>None</em>) – An input transform that is applied to X.</p></li>
<li><p><strong>outcome_transform</strong> (<a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><em>OutcomeTransform</em></a><em> | </em><em>_DefaultType</em><em> | </em><em>None</em>) – An outcome transform that is applied to Y.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.latent_kronecker_gp.LatentKroneckerGP.use_iterative_methods">
<span class="sig-name descname"><span class="pre">use_iterative_methods</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">covar_root_decomposition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">solves</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/latent_kronecker_gp.html#LatentKroneckerGP.use_iterative_methods"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.latent_kronecker_gp.LatentKroneckerGP.use_iterative_methods" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tol</strong> (<em>float</em>)</p></li>
<li><p><strong>max_iter</strong> (<em>int</em>)</p></li>
<li><p><strong>covar_root_decomposition</strong> (<em>bool</em>)</p></li>
<li><p><strong>log_prob</strong> (<em>bool</em>)</p></li>
<li><p><strong>solves</strong> (<em>bool</em>)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.latent_kronecker_gp.LatentKroneckerGP.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/latent_kronecker_gp.html#LatentKroneckerGP.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.latent_kronecker_gp.LatentKroneckerGP.forward" title="Link to this definition"></a></dt>
<dd><p>Define the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>MultivariateNormal</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.latent_kronecker_gp.LatentKroneckerGP.posterior">
<span class="sig-name descname"><span class="pre">posterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observation_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/latent_kronecker_gp.html#LatentKroneckerGP.posterior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.latent_kronecker_gp.LatentKroneckerGP.posterior" title="Link to this definition"></a></dt>
<dd><p>Computes the posterior over model outputs at the provided points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>(batch_shape) x q x d</cite>-dim Tensor, where <cite>d</cite> is the dimension
of the feature space and <cite>q</cite> is the number of points considered
jointly.</p></li>
<li><p><strong>observation_noise</strong> (<em>bool</em><em> | </em><em>Tensor</em>) – If True, add the observation noise from the
likelihood to the posterior. If a Tensor, use it directly as the
observation noise (must be of shape <cite>(batch_shape) x q</cite>). It is
assumed to be in the outcome-transformed space if an outcome
transform is used.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="acquisition.html#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – An optional PosteriorTransform.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>GPyTorchPosterior</cite> object, representing a batch of <cite>b</cite> joint
distributions over <cite>q</cite> points. Includes observation noise if
specified.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.gpytorch.GPyTorchPosterior" title="botorch.posteriors.gpytorch.GPyTorchPosterior"><em>GPyTorchPosterior</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.latent_kronecker_gp.LatentKroneckerGP.condition_on_observations">
<span class="sig-name descname"><span class="pre">condition_on_observations</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/latent_kronecker_gp.html#LatentKroneckerGP.condition_on_observations"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.latent_kronecker_gp.LatentKroneckerGP.condition_on_observations" title="Link to this definition"></a></dt>
<dd><p>Condition the model on new observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n’ x d</cite>-dim Tensor, where <cite>d</cite> is the dimension of
the feature space, <cite>n’</cite> is the number of points per batch, and
<cite>batch_shape</cite> is the batch shape (must be compatible with the
batch shape of the model).</p></li>
<li><p><strong>Y</strong> (<em>Tensor</em>) – A <cite>batch_shape’ x n x m</cite>-dim Tensor, where <cite>m</cite> is the number of
model outputs, <cite>n’</cite> is the number of points per batch, and
<cite>batch_shape’</cite> is the batch shape of the observations.
<cite>batch_shape’</cite> must be broadcastable to <cite>batch_shape</cite> using
standard broadcasting semantics. If <cite>Y</cite> has fewer batch dimensions
than <cite>X</cite>, its is assumed that the missing batch dimensions are
the same for all <cite>Y</cite>.</p></li>
<li><p><strong>noise</strong> (<em>Tensor</em><em> | </em><em>None</em>) – If not <cite>None</cite>, a tensor of the same shape as <cite>Y</cite> representing
the associated noise variance.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – Passed to <cite>self.get_fantasy_model</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>Model</cite> object of the same type, representing the original model
conditioned on the new observations <cite>(X, Y)</cite> (and possibly noise
observations passed in via kwargs).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">train_X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">train_X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">new_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">new_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">new_X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">new_X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">condition_on_observations</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">new_X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="n">new_Y</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

</section>
<section id="module-botorch.models.model_list_gp_regression">
<span id="model-list-gp-regression-models"></span><h3>Model List GP Regression Models<a class="headerlink" href="#module-botorch.models.model_list_gp_regression" title="Link to this heading"></a></h3>
<p>Model List GP Regression models.</p>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.model_list_gp_regression.ModelListGP">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.model_list_gp_regression.</span></span><span class="sig-name descname"><span class="pre">ModelListGP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">gp_models</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/model_list_gp_regression.html#ModelListGP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.model_list_gp_regression.ModelListGP" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">IndependentModelList</span></code>, <a class="reference internal" href="#botorch.models.gpytorch.ModelListGPyTorchModel" title="botorch.models.gpytorch.ModelListGPyTorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelListGPyTorchModel</span></code></a>, <a class="reference internal" href="#botorch.models.model.FantasizeMixin" title="botorch.models.model.FantasizeMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">FantasizeMixin</span></code></a></p>
<p>A multi-output GP model with independent GPs for the outputs.</p>
<p>This model supports different-shaped training inputs for each of its
sub-models. It can be used with any number of single-output
<cite>GPyTorchModel</cite>s and the models can be of different types. Use this model
when you have independent outputs with different training data. When
modeling correlations between outputs, use <cite>MultiTaskGP</cite>.</p>
<p>Internally, this model is just a list of individual models, but it implements
the same input/output interface as all other BoTorch models. This makes it
very flexible and convenient to work with. The sequential evaluation comes
at a performance cost though - if you are using a block design (i.e. the
same number of training example for each output, and a similar model
structure, you should consider using a batched GP model instead, such as
<cite>SingleTaskGP</cite> with batched inputs).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>*gp_models</strong> (<a class="reference internal" href="#botorch.models.gpytorch.GPyTorchModel" title="botorch.models.gpytorch.GPyTorchModel"><em>GPyTorchModel</em></a>) – A number of single-output <cite>GPyTorchModel</cite>s.
If models have input/output transforms, these are honored
individually for each model.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model1</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X1</span><span class="p">,</span> <span class="n">train_Y1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model2</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X2</span><span class="p">,</span> <span class="n">train_Y2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ModelListGP</span><span class="p">(</span><span class="n">model1</span><span class="p">,</span> <span class="n">model2</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.model_list_gp_regression.ModelListGP.condition_on_observations">
<span class="sig-name descname"><span class="pre">condition_on_observations</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/model_list_gp_regression.html#ModelListGP.condition_on_observations"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.model_list_gp_regression.ModelListGP.condition_on_observations" title="Link to this definition"></a></dt>
<dd><p>Condition the model on new observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>list</em><em>[</em><em>Tensor</em><em>]</em>) – A <cite>m</cite>-list of <cite>batch_shape x n’ x d</cite>-dim Tensors, where <cite>d</cite> is the
dimension of the feature space, <cite>n’</cite> is the number of points
per batch, and <cite>batch_shape</cite> is the batch shape (must be compatible
with the batch shape of the model).</p></li>
<li><p><strong>Y</strong> (<em>Tensor</em>) – A <cite>batch_shape’ x n’ x m</cite>-dim Tensor, where <cite>m</cite> is the number of
model outputs, <cite>n’</cite> is the number of points per batch, and
<cite>batch_shape’</cite> is the batch shape of the observations.
<cite>batch_shape’</cite> must be broadcastable to <cite>batch_shape</cite> using
standard broadcasting semantics. If <cite>Y</cite> has fewer batch dimensions
than <cite>X</cite>, its is assumed that the missing batch dimensions are
the same for all <cite>Y</cite>.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – Keyword arguments passed to
<cite>IndependentModelList.get_fantasy_model</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>ModelListGP</cite> representing the original model
conditioned on the new observations <cite>(X, Y)</cite> (and possibly noise
observations passed in via kwargs). Here the <cite>i</cite>-th model has
<cite>n_i + n’</cite> training examples, where the <cite>n’</cite> training examples have
been added and all test-time caches have been updated.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.model_list_gp_regression.ModelListGP" title="botorch.models.model_list_gp_regression.ModelListGP"><em>ModelListGP</em></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-botorch.models.multitask">
<span id="multitask-gp-models"></span><h3>Multitask GP Models<a class="headerlink" href="#module-botorch.models.multitask" title="Link to this heading"></a></h3>
<p>Multi-Task GP models.</p>
<p>References</p>
<div role="list" class="citation-list">
<div class="citation" id="bonilla2007mtgp" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id14">Bonilla2007MTGP</a><span class="fn-bracket">]</span></span>
<p>E. Bonilla, K. Chai and C. Williams. Multi-task Gaussian Process Prediction.
Advances in Neural Information Processing Systems 20, NeurIPS 2007.</p>
</div>
<div class="citation" id="swersky2013mtbo" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id15">Swersky2013MTBO</a><span class="fn-bracket">]</span></span>
<p>K. Swersky, J. Snoek and R. Adams. Multi-Task Bayesian Optimization.
Advances in Neural Information Processing Systems 26, NeurIPS 2013.</p>
</div>
<div class="citation" id="doucet2010sampl" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id8">Doucet2010sampl</a><span class="fn-bracket">]</span></span>
<p>A. Doucet. A Note on Efficient Conditional Simulation of Gaussian Distributions.
<a class="reference external" href="http://www.stats.ox.ac.uk/~doucet/doucet_simulationconditionalgaussian.pdf">http://www.stats.ox.ac.uk/~doucet/doucet_simulationconditionalgaussian.pdf</a>,
Apr 2010.</p>
</div>
<div class="citation" id="maddox2021bohdo" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Maddox2021bohdo<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id9">1</a>,<a role="doc-backlink" href="#id12">2</a>)</span>
<p>W. Maddox, M. Balandat, A. Wilson, and E. Bakshy. Bayesian Optimization with
High-Dimensional Outputs. <a class="reference external" href="https://arxiv.org/abs/2106.12997">https://arxiv.org/abs/2106.12997</a>, Jun 2021.</p>
</div>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.multitask.MultiTaskGP">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.multitask.</span></span><span class="sig-name descname"><span class="pre">MultiTaskGP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_feature</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Yvar=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean_module=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">covar_module=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">likelihood=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_covar_prior=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_tasks=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rank=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">all_tasks=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outcome_transform=&lt;class</span> <span class="pre">'botorch.utils.types.DEFAULT'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_transform=None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/multitask.html#MultiTaskGP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.multitask.MultiTaskGP" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">ExactGP</span></code>, <a class="reference internal" href="#botorch.models.gpytorch.MultiTaskGPyTorchModel" title="botorch.models.gpytorch.MultiTaskGPyTorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiTaskGPyTorchModel</span></code></a>, <a class="reference internal" href="#botorch.models.model.FantasizeMixin" title="botorch.models.model.FantasizeMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">FantasizeMixin</span></code></a></p>
<p>Multi-Task exact GP model using an ICM (intrinsic co-regionalization model)
kernel. See <a class="reference internal" href="#bonilla2007mtgp" id="id14"><span>[Bonilla2007MTGP]</span></a> and <a class="reference internal" href="#swersky2013mtbo" id="id15"><span>[Swersky2013MTBO]</span></a> for a reference on the
model and its use in Bayesian optimization.</p>
<p>The model can be single-output or multi-output, determined by the <cite>output_tasks</cite>.
This model uses relatively strong priors on the base Kernel hyperparameters, which
work best when covariates are normalized to the unit cube and outcomes are
standardized (zero mean, unit variance) - this standardization should be applied in
a stratified fashion at the level of the tasks, rather than across all data points.</p>
<p>If the <cite>train_Yvar</cite> is None, this model infers the noise level. If you have
known observation noise, you can set <cite>train_Yvar</cite> to a tensor containing
the noise variance measurements. WARNING: This currently does not support
different noise levels for the different tasks.</p>
<p>Multi-Task GP model using an ICM kernel.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>Tensor</em>) – A <cite>n x (d + 1)</cite> or <cite>b x n x (d + 1)</cite> (batch mode) tensor
of training data. One of the columns should contain the task
features (see <cite>task_feature</cite> argument).</p></li>
<li><p><strong>train_Y</strong> (<em>Tensor</em>) – A <cite>n x 1</cite> or <cite>b x n x 1</cite> (batch mode) tensor of training
observations.</p></li>
<li><p><strong>task_feature</strong> (<em>int</em>) – The index of the task feature (<cite>-d &lt;= task_feature &lt;= d</cite>).</p></li>
<li><p><strong>train_Yvar</strong> (<em>Tensor</em><em> | </em><em>None</em>) – An optional <cite>n</cite> or <cite>b x n</cite> (batch mode) tensor of observed
measurement noise. If None, we infer the noise.
Note that the inferred noise is common across all tasks.</p></li>
<li><p><strong>mean_module</strong> (<em>Module</em><em> | </em><em>None</em>) – The mean function to be used. Defaults to <cite>ConstantMean</cite>.</p></li>
<li><p><strong>covar_module</strong> (<em>Module</em><em> | </em><em>None</em>) – The module for computing the covariance matrix between
the non-task features. Defaults to <cite>RBFKernel</cite>.</p></li>
<li><p><strong>likelihood</strong> (<em>Likelihood</em><em> | </em><em>None</em>) – A likelihood. The default is selected based on <cite>train_Yvar</cite>.
If <cite>train_Yvar</cite> is None, a standard <cite>GaussianLikelihood</cite> with inferred
noise level is used. Otherwise, a FixedNoiseGaussianLikelihood is used.</p></li>
<li><p><strong>output_tasks</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – A list of task indices for which to compute model
outputs for. If omitted, return outputs for all task indices.</p></li>
<li><p><strong>rank</strong> (<em>int</em><em> | </em><em>None</em>) – The rank to be used for the index kernel. If omitted, use a
full rank (i.e. number of tasks) kernel.</p></li>
<li><p><strong>task_covar_prior</strong> (<em>Prior</em><em> | </em><em>None</em>) – A Prior on the task covariance matrix. Must operate
on p.s.d. matrices. A common prior for this is the <cite>LKJ</cite> prior.</p></li>
<li><p><strong>all_tasks</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – By default, multi-task GPs infer the list of all tasks from
the task features in <cite>train_X</cite>. This is an experimental feature that
enables creation of multi-task GPs with tasks that don’t appear in the
training data. Note that when a task is not observed, the corresponding
task covariance will heavily depend on random initialization and may
behave unexpectedly.</p></li>
<li><p><strong>outcome_transform</strong> (<a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><em>OutcomeTransform</em></a><em> | </em><em>_DefaultType</em><em> | </em><em>None</em>) – An outcome transform that is applied to the
training data during instantiation and to the posterior during
inference (that is, the <cite>Posterior</cite> obtained by calling
<cite>.posterior</cite> on the model will be on the original scale). We use a
<cite>Standardize</cite> transform if no <cite>outcome_transform</cite> is specified.
Pass down <cite>None</cite> to use no outcome transform. NOTE: Standardization
should be applied in a stratified fashion, separately for each task.</p></li>
<li><p><strong>input_transform</strong> (<a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>InputTransform</em></a><em> | </em><em>None</em>) – An input transform that is applied in the model’s
forward pass.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">i1</span><span class="p">,</span> <span class="n">i2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">X1</span><span class="p">,</span> <span class="n">i1</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">X2</span><span class="p">,</span> <span class="n">i2</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">f1</span><span class="p">(</span><span class="n">X1</span><span class="p">),</span> <span class="n">f2</span><span class="p">(</span><span class="n">X2</span><span class="p">)])</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">MultiTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">,</span> <span class="n">task_feature</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.multitask.MultiTaskGP.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/multitask.html#MultiTaskGP.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.multitask.MultiTaskGP.forward" title="Link to this definition"></a></dt>
<dd><p>Define the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>MultivariateNormal</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.multitask.MultiTaskGP.get_all_tasks">
<em class="property"><span class="k"><span class="pre">classmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_all_tasks</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_feature</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_tasks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/multitask.html#MultiTaskGP.get_all_tasks"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.multitask.MultiTaskGP.get_all_tasks" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>Tensor</em>)</p></li>
<li><p><strong>task_feature</strong> (<em>int</em>)</p></li>
<li><p><strong>output_tasks</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>tuple[list[int], int, int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.multitask.MultiTaskGP.construct_inputs">
<em class="property"><span class="k"><span class="pre">classmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct_inputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">training_data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_feature</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_tasks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_covar_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rank</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/multitask.html#MultiTaskGP.construct_inputs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.multitask.MultiTaskGP.construct_inputs" title="Link to this definition"></a></dt>
<dd><p>Construct <cite>Model</cite> keyword arguments from a dataset and other args.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>training_data</strong> (<a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em> | </em><a class="reference internal" href="utils.html#botorch.utils.datasets.MultiTaskDataset" title="botorch.utils.datasets.MultiTaskDataset"><em>MultiTaskDataset</em></a>) – A <cite>SupervisedDataset</cite> or a <cite>MultiTaskDataset</cite>.</p></li>
<li><p><strong>task_feature</strong> (<em>int</em>) – Column index of embedded task indicator features.</p></li>
<li><p><strong>output_tasks</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – A list of task indices for which to compute model
outputs for. If omitted, return outputs for all task indices.</p></li>
<li><p><strong>task_covar_prior</strong> (<em>Prior</em><em> | </em><em>None</em>) – A GPyTorch <cite>Prior</cite> object to use as prior on
the cross-task covariance matrix,</p></li>
<li><p><strong>prior_config</strong> (<em>dict</em><em> | </em><em>None</em>) – Configuration for inter-task covariance prior.
Should only be used if <cite>task_covar_prior</cite> is not passed directly. Must
contain <cite>use_LKJ_prior</cite> indicator and should contain float value <cite>eta</cite>.</p></li>
<li><p><strong>rank</strong> (<em>int</em><em> | </em><em>None</em>) – The rank of the cross-task covariance matrix.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>dict[str, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.multitask.KroneckerMultiTaskGP">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.multitask.</span></span><span class="sig-name descname"><span class="pre">KroneckerMultiTaskGP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">likelihood</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_covar_module</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_covar_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rank</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outcome_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/multitask.html#KroneckerMultiTaskGP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.multitask.KroneckerMultiTaskGP" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">ExactGP</span></code>, <a class="reference internal" href="#botorch.models.gpytorch.GPyTorchModel" title="botorch.models.gpytorch.GPyTorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">GPyTorchModel</span></code></a>, <a class="reference internal" href="#botorch.models.model.FantasizeMixin" title="botorch.models.model.FantasizeMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">FantasizeMixin</span></code></a></p>
<p>Multi-task GP with Kronecker structure, using an ICM kernel.</p>
<p>This model assumes the “block design” case, i.e., it requires that all tasks
are observed at all data points.</p>
<p>For posterior sampling, this model uses Matheron’s rule [Doucet2010sampl] to compute
the posterior over all tasks as in [Maddox2021bohdo] by exploiting Kronecker
structure.</p>
<p>When a multi-fidelity model has Kronecker structure, this means there is one
covariance kernel over the fidelity features (call it <cite>K_f</cite>) and another over
the rest of the input parameters (call it <cite>K_i</cite>), and the resulting covariance
across inputs and fidelities is given by the Kronecker product of the two
covariance matrices. This is equivalent to saying the covariance between
two input and feature pairs is given by</p>
<dl class="simple">
<dt>K((parameter_1, fidelity_1), (parameter_2, fidelity_2))</dt><dd><p>= K_f(fidelity_1, fidelity_2) * K_i(parameter_1, parameter_2).</p>
</dd>
</dl>
<p>Then the covariance matrix of <cite>n_i</cite> parameters and <cite>n_f</cite> fidelities can be
codified as a Kronecker product of an <cite>n_i x n_i</cite> matrix and an
<cite>n_f x n_f</cite> matrix, which is far more parsimonious than specifying the
whole <cite>(n_i * n_f) x (n_i * n_f)</cite> covariance matrix.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">f_1</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">f_2</span><span class="p">(</span><span class="n">X</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">KroneckerMultiTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite> tensor of training features.</p></li>
<li><p><strong>train_Y</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x m</cite> tensor of training observations.</p></li>
<li><p><strong>likelihood</strong> (<em>MultitaskGaussianLikelihood</em><em> | </em><em>None</em>) – A <cite>MultitaskGaussianLikelihood</cite>. If omitted, uses a
<cite>MultitaskGaussianLikelihood</cite> with a <cite>GammaPrior(1.1, 0.05)</cite>
noise prior.</p></li>
<li><p><strong>data_covar_module</strong> (<em>Module</em><em> | </em><em>None</em>) – The module computing the covariance (Kernel) matrix
in data space. If omitted, uses an <cite>RBFKernel</cite>.</p></li>
<li><p><strong>task_covar_prior</strong> (<em>Prior</em><em> | </em><em>None</em>) – A Prior on the task covariance matrix. Must operate
on p.s.d. matrices. A common prior for this is the <cite>LKJ</cite> prior. If
omitted, uses <cite>LKJCovariancePrior</cite> with <cite>eta</cite> parameter as specified
in the keyword arguments (if not specified, use <cite>eta=1.5</cite>).</p></li>
<li><p><strong>rank</strong> (<em>int</em><em> | </em><em>None</em>) – The rank of the ICM kernel. If omitted, use a full rank kernel.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – Additional arguments to override default settings of priors,
including:
- eta: The eta parameter on the default LKJ task_covar_prior.
A value of 1.0 is uninformative, values &lt;1.0 favor stronger
correlations (in magnitude), correlations vanish as eta -&gt; inf.
- sd_prior: A scalar prior over nonnegative numbers, which is used
for the default LKJCovariancePrior task_covar_prior.
- likelihood_rank: The rank of the task covariance matrix to fit.
Defaults to 0 (which corresponds to a diagonal covariance matrix).</p></li>
<li><p><strong>input_transform</strong> (<a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>InputTransform</em></a><em> | </em><em>None</em>)</p></li>
<li><p><strong>outcome_transform</strong> (<a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><em>OutcomeTransform</em></a><em> | </em><em>None</em>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.multitask.KroneckerMultiTaskGP.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/multitask.html#KroneckerMultiTaskGP.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.multitask.KroneckerMultiTaskGP.forward" title="Link to this definition"></a></dt>
<dd><p>Define the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>MultitaskMultivariateNormal</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.multitask.KroneckerMultiTaskGP.train_full_covar">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">train_full_covar</span></span><a class="headerlink" href="#botorch.models.multitask.KroneckerMultiTaskGP.train_full_covar" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.multitask.KroneckerMultiTaskGP.predictive_mean_cache">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">predictive_mean_cache</span></span><a class="headerlink" href="#botorch.models.multitask.KroneckerMultiTaskGP.predictive_mean_cache" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.multitask.KroneckerMultiTaskGP.posterior">
<span class="sig-name descname"><span class="pre">posterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observation_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/multitask.html#KroneckerMultiTaskGP.posterior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.multitask.KroneckerMultiTaskGP.posterior" title="Link to this definition"></a></dt>
<dd><p>Computes the posterior over model outputs at the provided points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>(batch_shape) x q x d</cite>-dim Tensor, where <cite>d</cite> is the dimension
of the feature space and <cite>q</cite> is the number of points considered
jointly.</p></li>
<li><p><strong>observation_noise</strong> (<em>bool</em><em> | </em><em>Tensor</em>) – If True, add the observation noise from the
likelihood to the posterior. If a Tensor, use it directly as the
observation noise (must be of shape <cite>(batch_shape) x q</cite>). It is
assumed to be in the outcome-transformed space if an outcome
transform is used.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="acquisition.html#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – An optional PosteriorTransform.</p></li>
<li><p><strong>output_indices</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>GPyTorchPosterior</cite> object, representing a batch of <cite>b</cite> joint
distributions over <cite>q</cite> points. Includes observation noise if
specified.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.multitask.MultitaskGPPosterior" title="botorch.posteriors.multitask.MultitaskGPPosterior"><em>MultitaskGPPosterior</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.multitask.KroneckerMultiTaskGP.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/multitask.html#KroneckerMultiTaskGP.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.multitask.KroneckerMultiTaskGP.train" title="Link to this definition"></a></dt>
<dd><p>Put the model in <cite>train</cite> mode. Reverts to the original inputs if in <cite>train</cite>
mode (<cite>mode=True</cite>) or sets transformed inputs if in <cite>eval</cite> mode (<cite>mode=False</cite>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>mode</strong> – A boolean denoting whether to put in <cite>train</cite> or <cite>eval</cite> mode.
If <cite>False</cite>, model is put in <cite>eval</cite> mode.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-botorch.models.gp_regression_fidelity">
<span id="multi-fidelity-gp-regression-models"></span><h3>Multi-Fidelity GP Regression Models<a class="headerlink" href="#module-botorch.models.gp_regression_fidelity" title="Link to this heading"></a></h3>
<p>Multi-Fidelity Gaussian Process Regression models based on GPyTorch models.</p>
<p>For more on Multi-Fidelity BO, see the
<a class="reference external" href="https://botorch.org/docs/tutorials/discrete_multi_fidelity_bo">tutorial</a>.</p>
<p>A common use case of multi-fidelity regression modeling is optimizing a
“high-fidelity” function that is expensive to simulate when you have access to
one or more cheaper “lower-fidelity” versions that are not fully accurate but
are correlated with the high-fidelity function. The multi-fidelity model models
both the low- and high-fidelity functions together, including the correlation
between them, which can help you predict and optimize the high-fidelity function
without having to do too many expensive high-fidelity evaluations.</p>
<div role="list" class="citation-list">
<div class="citation" id="wu2019mf" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id16">Wu2019mf</a><span class="fn-bracket">]</span></span>
<p>J. Wu, S. Toscano-Palmerin, P. I. Frazier, and A. G. Wilson. Practical
multi-fidelity bayesian optimization for hyperparameter tuning. ArXiv 2019.</p>
</div>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.gp_regression_fidelity.SingleTaskMultiFidelityGP">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.gp_regression_fidelity.</span></span><span class="sig-name descname"><span class="pre">SingleTaskMultiFidelityGP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Yvar=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_fidelity=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_fidelities=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">linear_truncated=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nu=2.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">likelihood=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outcome_transform=&lt;class</span> <span class="pre">'botorch.utils.types.DEFAULT'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_transform=None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gp_regression_fidelity.html#SingleTaskMultiFidelityGP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gp_regression_fidelity.SingleTaskMultiFidelityGP" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.gp_regression.SingleTaskGP" title="botorch.models.gp_regression.SingleTaskGP"><code class="xref py py-class docutils literal notranslate"><span class="pre">SingleTaskGP</span></code></a></p>
<p>A single task multi-fidelity GP model.</p>
<p>A SingleTaskGP model using a DownsamplingKernel for the data fidelity
parameter (if present) and an ExponentialDecayKernel for the iteration
fidelity parameter (if present).</p>
<p>This kernel is described in <a class="reference internal" href="#wu2019mf" id="id16"><span>[Wu2019mf]</span></a>.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">train_X</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskMultiFidelityGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">,</span> <span class="n">data_fidelities</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x (d + s)</cite> tensor of training features,
where <cite>s</cite> is the dimension of the fidelity parameters (either one
or two).</p></li>
<li><p><strong>train_Y</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x m</cite> tensor of training observations.</p></li>
<li><p><strong>train_Yvar</strong> (<em>Tensor</em><em> | </em><em>None</em>) – An optional <cite>batch_shape x n x m</cite> tensor of observed
measurement noise.</p></li>
<li><p><strong>iteration_fidelity</strong> (<em>int</em><em> | </em><em>None</em>) – The column index for the training iteration fidelity
parameter (optional).</p></li>
<li><p><strong>data_fidelities</strong> (<em>Sequence</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – The column indices for the downsampling fidelity parameter.
If a list/tuple of indices is provided, a kernel will be constructed for
each index (optional).</p></li>
<li><p><strong>linear_truncated</strong> (<em>bool</em>) – If True, use a <cite>LinearTruncatedFidelityKernel</cite> instead
of the default kernel.</p></li>
<li><p><strong>nu</strong> (<em>float</em>) – The smoothness parameter for the Matern kernel: either 1/2, 3/2, or
5/2. Only used when <cite>linear_truncated=True</cite>.</p></li>
<li><p><strong>likelihood</strong> (<em>Likelihood</em><em> | </em><em>None</em>) – A likelihood. If omitted, use a standard GaussianLikelihood
with inferred noise level.</p></li>
<li><p><strong>outcome_transform</strong> (<a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><em>OutcomeTransform</em></a><em> | </em><em>_DefaultType</em><em> | </em><em>None</em>) – An outcome transform that is applied to the
training data during instantiation and to the posterior during
inference (that is, the <cite>Posterior</cite> obtained by calling
<cite>.posterior</cite> on the model will be on the original scale). We use a
<cite>Standardize</cite> transform if no <cite>outcome_transform</cite> is specified.
Pass down <cite>None</cite> to use no outcome transform.</p></li>
<li><p><strong>input_transform</strong> (<a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>InputTransform</em></a><em> | </em><em>None</em>) – An input transform that is applied in the model’s
forward pass.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.gp_regression_fidelity.SingleTaskMultiFidelityGP.construct_inputs">
<em class="property"><span class="k"><span class="pre">classmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct_inputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">training_data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fidelity_features</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gp_regression_fidelity.html#SingleTaskMultiFidelityGP.construct_inputs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gp_regression_fidelity.SingleTaskMultiFidelityGP.construct_inputs" title="Link to this definition"></a></dt>
<dd><p>Construct <cite>Model</cite> keyword arguments from a dict of <cite>SupervisedDataset</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>training_data</strong> (<a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a>) – Dictionary of <cite>SupervisedDataset</cite>.</p></li>
<li><p><strong>fidelity_features</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – Index of fidelity parameter as input columns.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>dict[str, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-botorch.models.pairwise_gp">
<span id="pairwise-gp-models"></span><h3>Pairwise GP Models<a class="headerlink" href="#module-botorch.models.pairwise_gp" title="Link to this heading"></a></h3>
<p>Preference Learning with Gaussian Process</p>
<div role="list" class="citation-list">
<div class="citation" id="chu2005preference" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Chu2005preference<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id17">1</a>,<a role="doc-backlink" href="#id19">2</a>,<a role="doc-backlink" href="#id20">3</a>)</span>
<p>Wei Chu, and Zoubin Ghahramani. Preference learning with Gaussian processes.
Proceedings of the 22nd international conference on Machine learning. 2005.</p>
</div>
<div class="citation" id="brochu2010tutorial" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id18">Brochu2010tutorial</a><span class="fn-bracket">]</span></span>
<p>Eric Brochu, Vlad M. Cora, and Nando De Freitas.
A tutorial on Bayesian optimization of expensive cost functions,
with application to active user modeling and hierarchical reinforcement learning.
arXiv preprint arXiv:1012.2599 (2010).</p>
</div>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.pairwise_gp.PairwiseGP">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.pairwise_gp.</span></span><span class="sig-name descname"><span class="pre">PairwiseGP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">datapoints</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">comparisons</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">likelihood</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">covar_module</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="keyword-only-separator o"><abbr title="Keyword-only parameters separator (PEP 3102)"><span class="pre">*</span></abbr></span></em>, <em class="sig-param"><span class="n"><span class="pre">jitter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-06</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xtol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">consolidate_rtol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">consolidate_atol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maxfev</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/pairwise_gp.html#PairwiseGP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.pairwise_gp.PairwiseGP" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model"><code class="xref py py-class docutils literal notranslate"><span class="pre">Model</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">GP</span></code>, <a class="reference internal" href="#botorch.models.model.FantasizeMixin" title="botorch.models.model.FantasizeMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">FantasizeMixin</span></code></a></p>
<p>Probit GP for preference learning with Laplace approximation</p>
<p>A probit-likelihood GP that learns via pairwise comparison data, using a
Laplace approximation of the posterior of the estimated utility values. By
default it uses a scaled RBF kernel.</p>
<p>Implementation is based on <a class="reference internal" href="#chu2005preference" id="id17"><span>[Chu2005preference]</span></a>.
Also see <a class="reference internal" href="#brochu2010tutorial" id="id18"><span>[Brochu2010tutorial]</span></a> for additional reference.</p>
<p>Note that in <a class="reference internal" href="#chu2005preference" id="id19"><span>[Chu2005preference]</span></a> the likelihood of a pairwise comparison
is <span class="math notranslate nohighlight">\(\left(\frac{f(x_1) - f(x_2)}{\sqrt{2}\sigma}\right)\)</span>, i.e. a scale is
used in the denominator. To maintain consistency with usage of kernels
elsewhere in BoTorch, we instead do not include <span class="math notranslate nohighlight">\(\sigma\)</span> in the code
(implicitly setting it to 1) and use ScaleKernel to scale the function.</p>
<p>In the example below, the user/decision maker has stated that they prefer
the first item over the second item and the third item over the second item,
generating comparisons [0, 1] and [2, 1].
.. rubric:: Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">botorch.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">PairwiseGP</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">datapoints</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">comparisons</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">PairwiseGP</span><span class="p">(</span><span class="n">datapoints</span><span class="p">,</span> <span class="n">comparisons</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>datapoints</strong> (<em>Tensor</em><em> | </em><em>None</em>) – Either <cite>None</cite> or a <cite>batch_shape x n x d</cite> tensor of
training features. If either <cite>datapoints</cite> or <cite>comparisons</cite> is
<cite>None</cite>, construct a prior-only model.</p></li>
<li><p><strong>comparisons</strong> (<em>Tensor</em><em> | </em><em>None</em>) – Either <cite>None</cite> or a <cite>batch_shape x m x 2</cite> tensor of
training comparisons; comparisons[i] is a noisy indicator
suggesting the utility value of comparisons[i, 0]-th is greater
than comparisons[i, 1]-th. If either <cite>comparisons</cite> or
<cite>datapoints</cite> is <cite>None</cite>, construct a prior-only model.</p></li>
<li><p><strong>likelihood</strong> (<a class="reference internal" href="#botorch.models.likelihoods.pairwise.PairwiseLikelihood" title="botorch.models.likelihoods.pairwise.PairwiseLikelihood"><em>PairwiseLikelihood</em></a><em> | </em><em>None</em>) – A PairwiseLikelihood.</p></li>
<li><p><strong>covar_module</strong> (<em>ScaleKernel</em><em> | </em><em>None</em>) – Covariance module.</p></li>
<li><p><strong>input_transform</strong> (<a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>InputTransform</em></a><em> | </em><em>None</em>) – An input transform that is applied in the model’s
forward pass.</p></li>
<li><p><strong>jitter</strong> (<em>float</em>) – Value added to diagonal for numerical stability in
<cite>psd_safe_cholesky</cite>.</p></li>
<li><p><strong>xtol</strong> (<em>float</em><em> | </em><em>None</em>) – Stopping creteria in scipy.optimize.fsolve used to find f_map
in <cite>PairwiseGP._update</cite>. If None, default behavior is handled by
<cite>PairwiseGP._update</cite>.</p></li>
<li><p><strong>consolidate_rtol</strong> (<em>float</em>) – <cite>rtol</cite> passed to <cite>consolidate_duplicates</cite>.</p></li>
<li><p><strong>consolidate_atol</strong> (<em>float</em>) – <cite>atol</cite> passed to <cite>consolidate_duplicates</cite>.</p></li>
<li><p><strong>maxfev</strong> (<em>int</em><em> | </em><em>None</em>) – The maximum number of calls to the function in
scipy.optimize.fsolve. If None, default behavior is handled by
<cite>PairwiseGP._update</cite>.</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.pairwise_gp.PairwiseGP.datapoints">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">datapoints</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tensor</span></em><a class="headerlink" href="#botorch.models.pairwise_gp.PairwiseGP.datapoints" title="Link to this definition"></a></dt>
<dd><p>Alias for consolidated datapoints</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.pairwise_gp.PairwiseGP.comparisons">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">comparisons</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tensor</span></em><a class="headerlink" href="#botorch.models.pairwise_gp.PairwiseGP.comparisons" title="Link to this definition"></a></dt>
<dd><p>Alias for consolidated comparisons</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.pairwise_gp.PairwiseGP.unconsolidated_utility">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">unconsolidated_utility</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tensor</span></em><a class="headerlink" href="#botorch.models.pairwise_gp.PairwiseGP.unconsolidated_utility" title="Link to this definition"></a></dt>
<dd><p>Utility of the unconsolidated datapoints</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.pairwise_gp.PairwiseGP.num_outputs">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">num_outputs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#botorch.models.pairwise_gp.PairwiseGP.num_outputs" title="Link to this definition"></a></dt>
<dd><p>The number of outputs of the model.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.pairwise_gp.PairwiseGP.batch_shape">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">batch_shape</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Size</span></em><a class="headerlink" href="#botorch.models.pairwise_gp.PairwiseGP.batch_shape" title="Link to this definition"></a></dt>
<dd><p>The batch shape of the model.</p>
<p>This is a batch shape from an I/O perspective, independent of the internal
representation of the model (as e.g. in BatchedMultiOutputGPyTorchModel).
For a model with <cite>m</cite> outputs, a <cite>test_batch_shape x q x d</cite>-shaped input <cite>X</cite>
to the <cite>posterior</cite> method returns a Posterior object over an output of
shape <cite>broadcast(test_batch_shape, model.batch_shape) x q x m</cite>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.pairwise_gp.PairwiseGP.construct_inputs">
<em class="property"><span class="k"><span class="pre">classmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct_inputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">training_data</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/pairwise_gp.html#PairwiseGP.construct_inputs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.pairwise_gp.PairwiseGP.construct_inputs" title="Link to this definition"></a></dt>
<dd><p>Construct <cite>Model</cite> keyword arguments from a <cite>RankingDataset</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>training_data</strong> (<a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a>) – A <cite>RankingDataset</cite>, with attributes <cite>train_X</cite>,
<cite>train_Y</cite>, and, optionally, <cite>train_Yvar</cite>.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dict of keyword arguments that can be used to initialize a
<cite>PairwiseGP</cite>, including <cite>datapoints</cite> and <cite>comparisons</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict[str, <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.pairwise_gp.PairwiseGP.set_train_data">
<span class="sig-name descname"><span class="pre">set_train_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">datapoints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">comparisons</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/pairwise_gp.html#PairwiseGP.set_train_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.pairwise_gp.PairwiseGP.set_train_data" title="Link to this definition"></a></dt>
<dd><p>Set datapoints and comparisons and update model properties if needed</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>datapoints</strong> (<em>Tensor</em><em> | </em><em>None</em>) – Either <cite>None</cite> or a <cite>batch_shape x n x d</cite> dimension
tensor X. If there are input transformations, assume the
datapoints are not transformed. If either <cite>datapoints</cite> or
<cite>comparisons</cite> is <cite>None</cite>, construct a prior-only model.</p></li>
<li><p><strong>comparisons</strong> (<em>Tensor</em><em> | </em><em>None</em>) – Either <cite>None</cite> or a tensor of size <cite>batch_shape x m x
2</cite>. (i, j) means f_i is preferred over f_j. If either
<cite>comparisons</cite> or <cite>datapoints</cite> is <cite>None</cite>, construct a prior-only
model.</p></li>
<li><p><strong>strict</strong> (<em>bool</em>) – <cite>strict</cite> argument as in gpytorch.models.exact_gp for compatibility
when using fit_gpytorch_mll with input_transform.</p></li>
<li><p><strong>update_model</strong> (<em>bool</em>) – True if we want to refit the model (see _update) after
re-setting the data.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.pairwise_gp.PairwiseGP.load_state_dict">
<span class="sig-name descname"><span class="pre">load_state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/pairwise_gp.html#PairwiseGP.load_state_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.pairwise_gp.PairwiseGP.load_state_dict" title="Link to this definition"></a></dt>
<dd><p>Removes data related buffers from the <cite>state_dict</cite> and calls
<cite>super().load_state_dict</cite> with <cite>strict=False</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>state_dict</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>) – The state dict.</p></li>
<li><p><strong>strict</strong> (<em>bool</em>) – Boolean specifying whether or not given and instance-bound
state_dicts should have identical keys. Only implemented for
<cite>strict=False</cite> since buffers will filters out when calling
<cite>_load_from_state_dict</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A named tuple <cite>_IncompatibleKeys</cite>, containing the <cite>missing_keys</cite>
and <cite>unexpected_keys</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>_IncompatibleKeys</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.pairwise_gp.PairwiseGP.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">datapoints</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/pairwise_gp.html#PairwiseGP.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.pairwise_gp.PairwiseGP.forward" title="Link to this definition"></a></dt>
<dd><p>Calculate a posterior or prior prediction.</p>
<p>During training mode, forward implemented solely for gradient-based
hyperparam opt. Essentially what it does is to re-calculate the utility
f using its analytical form at f_map so that we are able to obtain
gradients of the hyperparameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>datapoints</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite> Tensor,
should be the same as self.datapoints during training</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ol class="arabic simple">
<li><p>Posterior centered at MAP points for training data (training mode)</p></li>
<li><p>Prior predictions (prior mode)</p></li>
<li><p>Predictive posterior (eval mode)</p></li>
</ol>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>A MultivariateNormal object, being one of the followings</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.pairwise_gp.PairwiseGP.posterior">
<span class="sig-name descname"><span class="pre">posterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observation_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/pairwise_gp.html#PairwiseGP.posterior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.pairwise_gp.PairwiseGP.posterior" title="Link to this definition"></a></dt>
<dd><p>Computes the posterior over model outputs at the provided points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x q x d</cite>-dim Tensor, where <cite>d</cite> is the dimension
of the feature space and <cite>q</cite> is the number of points considered jointly.</p></li>
<li><p><strong>output_indices</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – As defined in parent Model class, not used for this model.</p></li>
<li><p><strong>observation_noise</strong> (<em>bool</em>) – Ignored (since noise is not identifiable from scale
in probit models).</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="acquisition.html#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – An optional PosteriorTransform.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>A <cite>Posterior</cite> object, representing joint</dt><dd><p>distributions over <cite>q</cite> points.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.posterior.Posterior" title="botorch.posteriors.posterior.Posterior"><em>Posterior</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.pairwise_gp.PairwiseGP.condition_on_observations">
<span class="sig-name descname"><span class="pre">condition_on_observations</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/pairwise_gp.html#PairwiseGP.condition_on_observations"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.pairwise_gp.PairwiseGP.condition_on_observations" title="Link to this definition"></a></dt>
<dd><p>Condition the model on new observations.</p>
<p>Note that unlike other BoTorch models, PairwiseGP requires Y to be
pairwise comparisons.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite> dimension tensor X</p></li>
<li><p><strong>Y</strong> (<em>Tensor</em>) – A tensor of size <cite>batch_shape x m x 2</cite>. (i, j) means
f_i is preferred over f_j</p></li>
<li><p><strong>kwargs</strong> – Not used.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A (deepcopied) <cite>Model</cite> object of the same type, representing the
original model conditioned on the new observations <cite>(X, Y)</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.pairwise_gp.PairwiseLaplaceMarginalLogLikelihood">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.pairwise_gp.</span></span><span class="sig-name descname"><span class="pre">PairwiseLaplaceMarginalLogLikelihood</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">likelihood</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/pairwise_gp.html#PairwiseLaplaceMarginalLogLikelihood"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.pairwise_gp.PairwiseLaplaceMarginalLogLikelihood" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">MarginalLogLikelihood</span></code></p>
<p>Laplace-approximated marginal log likelihood/evidence for PairwiseGP</p>
<p>See (12) from <a class="reference internal" href="#chu2005preference" id="id20"><span>[Chu2005preference]</span></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>likelihood</strong> – Used as in args to GPyTorch MarginalLogLikelihood</p></li>
<li><p><strong>model</strong> (<em>GP</em>) – Used as in args to GPyTorch MarginalLogLikelihood</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.pairwise_gp.PairwiseLaplaceMarginalLogLikelihood.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">post</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">comp</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/pairwise_gp.html#PairwiseLaplaceMarginalLogLikelihood.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.pairwise_gp.PairwiseLaplaceMarginalLogLikelihood.forward" title="Link to this definition"></a></dt>
<dd><p>Calculate approximated log evidence, i.e., log(P(D|theta))</p>
<p>Note that post will be based on the consolidated/deduped datapoints for
numerical stability, but comp will still be the unconsolidated comparisons
so that it’s still compatible with fit_gpytorch_*.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>post</strong> (<a class="reference internal" href="posteriors.html#botorch.posteriors.posterior.Posterior" title="botorch.posteriors.posterior.Posterior"><em>Posterior</em></a>) – training posterior distribution from self.model (after consolidation)</p></li>
<li><p><strong>comp</strong> (<em>Tensor</em>) – Comparisons pairs (before consolidation)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The approximated evidence, i.e., the marginal log likelihood</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-botorch.models.relevance_pursuit">
<span id="relevance-pursuit-models"></span><h3>Relevance Pursuit Models<a class="headerlink" href="#module-botorch.models.relevance_pursuit" title="Link to this heading"></a></h3>
<p>Relevance Pursuit model structure and optimization routines for the sparse optimization
of Gaussian process hyper-parameters, see <a class="reference internal" href="#ament2024pursuit" id="id21"><span>[Ament2024pursuit]</span></a> for details.</p>
<p>References</p>
<div role="list" class="citation-list">
<div class="citation" id="ament2024pursuit" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Ament2024pursuit<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id21">1</a>,<a role="doc-backlink" href="#id22">2</a>,<a role="doc-backlink" href="#id23">3</a>,<a role="doc-backlink" href="#id24">4</a>,<a role="doc-backlink" href="#id25">5</a>,<a role="doc-backlink" href="#id26">6</a>,<a role="doc-backlink" href="#id27">7</a>,<a role="doc-backlink" href="#id28">8</a>,<a role="doc-backlink" href="#id29">9</a>,<a role="doc-backlink" href="#id36">10</a>,<a role="doc-backlink" href="#id37">11</a>)</span>
<p>S. Ament, E. Santorella, D. Eriksson, B. Letham, M. Balandat, and E. Bakshy.
Robust Gaussian Processes via Relevance Pursuit. Advances in Neural Information
Processing Systems 37, 2024. Arxiv: <a class="reference external" href="https://arxiv.org/abs/2410.24222">https://arxiv.org/abs/2410.24222</a>.</p>
</div>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.relevance_pursuit.RelevancePursuitMixin">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.relevance_pursuit.</span></span><span class="sig-name descname"><span class="pre">RelevancePursuitMixin</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">support</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/relevance_pursuit.html#RelevancePursuitMixin"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.relevance_pursuit.RelevancePursuitMixin" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>Mixin class to convert between the sparse and dense representations of the
relevance pursuit modules’ sparse parameters, as well as to compute the generalized
support acquisition and support deletion criteria.</p>
<p>Constructor for the RelevancePursuitMixin class.</p>
<p>For details, see <a class="reference internal" href="#ament2024pursuit" id="id22"><span>[Ament2024pursuit]</span></a> or <a class="reference external" href="https://arxiv.org/abs/2410.24222">https://arxiv.org/abs/2410.24222</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dim</strong> (<em>int</em>) – The total number of features.</p></li>
<li><p><strong>support</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – The indices of the features in the support, subset of range(dim).</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.relevance_pursuit.RelevancePursuitMixin.dim">
<span class="sig-name descname"><span class="pre">dim</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#botorch.models.relevance_pursuit.RelevancePursuitMixin.dim" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.relevance_pursuit.RelevancePursuitMixin.sparse_parameter">
<em class="property"><span class="k"><span class="pre">abstract</span></span><span class="w"> </span><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">sparse_parameter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Parameter</span></em><a class="headerlink" href="#botorch.models.relevance_pursuit.RelevancePursuitMixin.sparse_parameter" title="Link to this definition"></a></dt>
<dd><p>The sparse parameter, required to have a single indexing dimension.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.relevance_pursuit.RelevancePursuitMixin.set_sparse_parameter">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">set_sparse_parameter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/relevance_pursuit.html#RelevancePursuitMixin.set_sparse_parameter"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.relevance_pursuit.RelevancePursuitMixin.set_sparse_parameter" title="Link to this definition"></a></dt>
<dd><p>Sets the sparse parameter.</p>
<p>NOTE: We can’t use the property setter &#64;sparse_parameter.setter because of
the special way PyTorch treats Parameter types, including custom setters that
bypass the &#64;property setters before the latter are called.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>value</strong> (<em>Parameter</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.relevance_pursuit.RelevancePursuitMixin.is_sparse">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">is_sparse</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.relevance_pursuit.RelevancePursuitMixin.is_sparse" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.relevance_pursuit.RelevancePursuitMixin.support">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">support</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#botorch.models.relevance_pursuit.RelevancePursuitMixin.support" title="Link to this definition"></a></dt>
<dd><p>The indices of the active parameters.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.relevance_pursuit.RelevancePursuitMixin.is_active">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">is_active</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tensor</span></em><a class="headerlink" href="#botorch.models.relevance_pursuit.RelevancePursuitMixin.is_active" title="Link to this definition"></a></dt>
<dd><p>A Boolean Tensor of length <cite>dim</cite>, indicating which of the <cite>dim</cite> indices of
<cite>self.sparse_parameter</cite> are in the support, i.e. active.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.relevance_pursuit.RelevancePursuitMixin.inactive_indices">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">inactive_indices</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tensor</span></em><a class="headerlink" href="#botorch.models.relevance_pursuit.RelevancePursuitMixin.inactive_indices" title="Link to this definition"></a></dt>
<dd><p>An integral Tensor of length <cite>dim - len(support)</cite>, indicating which of the
indices of <cite>self.sparse_parameter</cite> are not in the support, i.e. inactive.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.relevance_pursuit.RelevancePursuitMixin.to_sparse">
<span class="sig-name descname"><span class="pre">to_sparse</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/relevance_pursuit.html#RelevancePursuitMixin.to_sparse"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.relevance_pursuit.RelevancePursuitMixin.to_sparse" title="Link to this definition"></a></dt>
<dd><p>Converts the sparse parameter to its sparse (&lt; dim) representation.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The current object in its sparse representation.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="#botorch.models.relevance_pursuit.RelevancePursuitMixin" title="botorch.models.relevance_pursuit.RelevancePursuitMixin"><em>RelevancePursuitMixin</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.relevance_pursuit.RelevancePursuitMixin.to_dense">
<span class="sig-name descname"><span class="pre">to_dense</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/relevance_pursuit.html#RelevancePursuitMixin.to_dense"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.relevance_pursuit.RelevancePursuitMixin.to_dense" title="Link to this definition"></a></dt>
<dd><p>Converts the sparse parameter to its dense, length-<cite>dim</cite> representation.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The current object in its dense representation.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="#botorch.models.relevance_pursuit.RelevancePursuitMixin" title="botorch.models.relevance_pursuit.RelevancePursuitMixin"><em>RelevancePursuitMixin</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.relevance_pursuit.RelevancePursuitMixin.expand_support">
<span class="sig-name descname"><span class="pre">expand_support</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indices</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/relevance_pursuit.html#RelevancePursuitMixin.expand_support"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.relevance_pursuit.RelevancePursuitMixin.expand_support" title="Link to this definition"></a></dt>
<dd><p>Expands the support by a number of indices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>indices</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – A list of indices of <cite>self.sparse_parameter</cite> to add to the support.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The current object, updated with the expanded support.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.relevance_pursuit.RelevancePursuitMixin" title="botorch.models.relevance_pursuit.RelevancePursuitMixin"><em>RelevancePursuitMixin</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.relevance_pursuit.RelevancePursuitMixin.contract_support">
<span class="sig-name descname"><span class="pre">contract_support</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indices</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/relevance_pursuit.html#RelevancePursuitMixin.contract_support"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.relevance_pursuit.RelevancePursuitMixin.contract_support" title="Link to this definition"></a></dt>
<dd><p>Contracts the support by a number of indices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>indices</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – A list of indices of <cite>self.sparse_parameter</cite> to remove from
the support.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The current object, updated with the contracted support.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.relevance_pursuit.RelevancePursuitMixin" title="botorch.models.relevance_pursuit.RelevancePursuitMixin"><em>RelevancePursuitMixin</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.relevance_pursuit.RelevancePursuitMixin.full_support">
<span class="sig-name descname"><span class="pre">full_support</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/relevance_pursuit.html#RelevancePursuitMixin.full_support"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.relevance_pursuit.RelevancePursuitMixin.full_support" title="Link to this definition"></a></dt>
<dd><p>Initializes the RelevancePursuitMixin with a full, size-<cite>dim</cite> support.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The current object with full support in the dense representation.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="#botorch.models.relevance_pursuit.RelevancePursuitMixin" title="botorch.models.relevance_pursuit.RelevancePursuitMixin"><em>RelevancePursuitMixin</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.relevance_pursuit.RelevancePursuitMixin.remove_support">
<span class="sig-name descname"><span class="pre">remove_support</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/relevance_pursuit.html#RelevancePursuitMixin.remove_support"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.relevance_pursuit.RelevancePursuitMixin.remove_support" title="Link to this definition"></a></dt>
<dd><p>Initializes the RelevancePursuitMixin with an empty, size-zero support.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The current object with empty support, representation unchanged.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="#botorch.models.relevance_pursuit.RelevancePursuitMixin" title="botorch.models.relevance_pursuit.RelevancePursuitMixin"><em>RelevancePursuitMixin</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.relevance_pursuit.RelevancePursuitMixin.support_expansion">
<span class="sig-name descname"><span class="pre">support_expansion</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mll</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">modifier</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/relevance_pursuit.html#RelevancePursuitMixin.support_expansion"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.relevance_pursuit.RelevancePursuitMixin.support_expansion" title="Link to this definition"></a></dt>
<dd><p>Computes the indices of the elements that maximize the gradient of the sparse
parameter and that are not already in the support, and subsequently expands the
support to include the elements if their gradient is positive.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mll</strong> (<em>ExactMarginalLogLikelihood</em>) – The marginal likelihood, containing the model to optimize.
NOTE: Virtually all of the rest of the code is not specific to the
marginal likelihood optimization, so we could generalize this to work
with any objective.</p></li>
<li><p><strong>n</strong> (<em>int</em>) – The maximum number of elements to select. NOTE: The actual number of
elements that are added could be fewer if there are fewer than <cite>n</cite>
elements with a positive gradient.</p></li>
<li><p><strong>modifier</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – A function that modifies the gradient of the inactive elements
before computing the support expansion criterion. This can be used
to select the maximum gradient magnitude for real-valued elements
whose gradients are not non-negative, using modifier = torch.abs.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>True if the support was expanded, False otherwise.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.relevance_pursuit.RelevancePursuitMixin.expansion_objective">
<span class="sig-name descname"><span class="pre">expansion_objective</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mll</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/relevance_pursuit.html#RelevancePursuitMixin.expansion_objective"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.relevance_pursuit.RelevancePursuitMixin.expansion_objective" title="Link to this definition"></a></dt>
<dd><p>Computes an objective value for all the inactive parameters, i.e.
self.sparse_parameter[~self.is_active] since we can’t add already active
parameters to the support. This value will be used to select the parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>mll</strong> (<em>ExactMarginalLogLikelihood</em>) – The marginal likelihood, containing the model to optimize.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The expansion objective value for all the inactive parameters.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.relevance_pursuit.RelevancePursuitMixin.support_contraction">
<span class="sig-name descname"><span class="pre">support_contraction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mll</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">modifier</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/relevance_pursuit.html#RelevancePursuitMixin.support_contraction"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.relevance_pursuit.RelevancePursuitMixin.support_contraction" title="Link to this definition"></a></dt>
<dd><p>Computes the indices of the elements with the smallest magnitude,
and subsequently contracts the support by exluding the elements.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mll</strong> (<em>ExactMarginalLogLikelihood</em>) – The marginal likelihood, containing the model to optimize.
NOTE: Virtually all of the rest of the code is not specific to the
marginal likelihood optimization, so we could generalize this to work
with any objective.</p></li>
<li><p><strong>n</strong> (<em>int</em>) – The number of elements to select for removal.</p></li>
<li><p><strong>modifier</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – A function that modifies the parameter values before computing
the support contraction criterion.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>True if the support was expanded, False otherwise.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.relevance_pursuit.RelevancePursuitMixin.optimize_mll">
<span class="sig-name descname"><span class="pre">optimize_mll</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mll</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_trace</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reset_parameters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reset_dense_parameters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">closure</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">closure_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/relevance_pursuit.html#RelevancePursuitMixin.optimize_mll"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.relevance_pursuit.RelevancePursuitMixin.optimize_mll" title="Link to this definition"></a></dt>
<dd><p>Optimizes the marginal likelihood.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mll</strong> (<em>ExactMarginalLogLikelihood</em>) – The marginal likelihood, containing the model to optimize.</p></li>
<li><p><strong>model_trace</strong> (<em>list</em><em>[</em><a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a><em>] </em><em>| </em><em>None</em>) – If not None, a list to which a deepcopy of the model state is
appended. NOTE This operation is <em>in place</em>.</p></li>
<li><p><strong>reset_parameters</strong> (<em>bool</em>) – If True, initializes the sparse parameter to the all-zeros
vector before every marginal likelihood optimization step. If False, the
optimization is warm-started with the previous iteration’s parameters.</p></li>
<li><p><strong>reset_dense_parameters</strong> (<em>bool</em>) – If True, re-initializes the dense parameters, e.g.
other GP hyper-parameters that are <em>not</em> part of the Relevance Pursuit
module, to the initial values provided by their associated constraints.</p></li>
<li><p><strong>closure</strong> (<em>Callable</em><em>[</em><em>[</em><em>]</em><em>, </em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Sequence</em><em>[</em><em>Tensor</em><em> | </em><em>None</em><em>]</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A closure to use to compute the loss and the gradients, see
docstring of <cite>fit_gpytorch_mll</cite> for details.</p></li>
<li><p><strong>optimizer</strong> (<em>Callable</em><em> | </em><em>None</em>) – The numerical optimizer, see docstring of <cite>fit_gpytorch_mll</cite>.</p></li>
<li><p><strong>closure_kwargs</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Additional arguments to pass to the <cite>closure</cite> function.</p></li>
<li><p><strong>optimizer_kwargs</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – A dictionary of keyword arguments for the optimizer.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The marginal likelihood after optimization.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.relevance_pursuit.forward_relevance_pursuit">
<span class="sig-prename descclassname"><span class="pre">botorch.models.relevance_pursuit.</span></span><span class="sig-name descname"><span class="pre">forward_relevance_pursuit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sparse_module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mll</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparsity_levels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reset_parameters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reset_dense_parameters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">record_model_trace</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial_support</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">closure</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">closure_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/relevance_pursuit.html#forward_relevance_pursuit"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.relevance_pursuit.forward_relevance_pursuit" title="Link to this definition"></a></dt>
<dd><p>Forward Relevance Pursuit.</p>
<p>NOTE: For the robust <cite>SparseOutlierNoise</cite> model of <a class="reference internal" href="#ament2024pursuit" id="id23"><span>[Ament2024pursuit]</span></a>, the forward
algorithm is generally faster than the backward algorithm, particularly when the
maximum sparsity level is small, but it leads to less robust results when the number
of outliers is large.</p>
<p>For details, see <a class="reference internal" href="#ament2024pursuit" id="id24"><span>[Ament2024pursuit]</span></a> or <a class="reference external" href="https://arxiv.org/abs/2410.24222">https://arxiv.org/abs/2410.24222</a>.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">base_noise</span> <span class="o">=</span> <span class="n">HomoskedasticNoise</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="n">noise_constraint</span><span class="o">=</span><span class="n">NonTransformedInterval</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>       <span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e-1</span><span class="p">,</span> <span class="n">initial_value</span><span class="o">=</span><span class="mf">1e-3</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">likelihood</span> <span class="o">=</span> <span class="n">SparseOutlierGaussianLikelihood</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="n">base_noise</span><span class="o">=</span><span class="n">base_noise</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="n">dim</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">train_Y</span><span class="o">=</span><span class="n">Y</span><span class="p">,</span> <span class="n">likelihood</span><span class="o">=</span><span class="n">likelihood</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mll</span> <span class="o">=</span> <span class="n">ExactMarginalLogLikelihood</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># NOTE: `likelihood.noise_covar` is the `RelevancePursuitMixin`</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sparse_module</span> <span class="o">=</span> <span class="n">likelihood</span><span class="o">.</span><span class="n">noise_covar</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sparse_module</span><span class="p">,</span> <span class="n">model_trace</span> <span class="o">=</span> <span class="n">forward_relevance_pursuit</span><span class="p">(</span><span class="n">sparse_module</span><span class="p">,</span> <span class="n">mll</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sparse_module</strong> (<a class="reference internal" href="#botorch.models.relevance_pursuit.RelevancePursuitMixin" title="botorch.models.relevance_pursuit.RelevancePursuitMixin"><em>RelevancePursuitMixin</em></a>) – The relevance pursuit module.</p></li>
<li><p><strong>mll</strong> (<em>ExactMarginalLogLikelihood</em>) – The marginal likelihood, containing the model to optimize.</p></li>
<li><p><strong>sparsity_levels</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – The sparsity levels to expand the support to.</p></li>
<li><p><strong>reset_parameters</strong> (<em>bool</em>) – If true, initializes the sparse parameter to the all zeros
after each iteration.</p></li>
<li><p><strong>reset_dense_parameters</strong> (<em>bool</em>) – If true, re-initializes the dense parameters, e.g.
other GP hyper-parameters that are <em>not</em> part of the Relevance Pursuit
module, to the initial values provided by their associated constraints.</p></li>
<li><p><strong>record_model_trace</strong> (<em>bool</em>) – If true, records the model state after every iteration.</p></li>
<li><p><strong>initial_support</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – The support with which to initialize the sparse module. By
default, the support is initialized to the empty set.</p></li>
<li><p><strong>closure</strong> (<em>Callable</em><em>[</em><em>[</em><em>]</em><em>, </em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Sequence</em><em>[</em><em>Tensor</em><em> | </em><em>None</em><em>]</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A closure to use to compute the loss and the gradients, see docstring
of <cite>fit_gpytorch_mll</cite> for details.</p></li>
<li><p><strong>optimizer</strong> (<em>Callable</em><em> | </em><em>None</em>) – The numerical optimizer, see docstring of <cite>fit_gpytorch_mll</cite>.</p></li>
<li><p><strong>closure_kwargs</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Additional arguments to pass to the <cite>closure</cite> function.</p></li>
<li><p><strong>optimizer_kwargs</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – A dictionary of keyword arguments to pass to the optimizer.
By default, initializes the “options” sub-dictionary with <cite>maxiter</cite> and
<cite>ftol</cite>, <cite>gtol</cite> values, unless specified.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The relevance pursuit module after forward relevance pursuit optimization, and
a list of models with different supports that were optimized.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple[<a class="reference internal" href="#botorch.models.relevance_pursuit.RelevancePursuitMixin" title="botorch.models.relevance_pursuit.RelevancePursuitMixin"><em>RelevancePursuitMixin</em></a>, list[<a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>] | None]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.relevance_pursuit.backward_relevance_pursuit">
<span class="sig-prename descclassname"><span class="pre">botorch.models.relevance_pursuit.</span></span><span class="sig-name descname"><span class="pre">backward_relevance_pursuit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sparse_module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mll</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparsity_levels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reset_parameters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reset_dense_parameters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">record_model_trace</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial_support</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">closure</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">closure_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/relevance_pursuit.html#backward_relevance_pursuit"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.relevance_pursuit.backward_relevance_pursuit" title="Link to this definition"></a></dt>
<dd><p>Backward Relevance Pursuit.</p>
<p>NOTE: For the robust <cite>SparseOutlierNoise</cite> model of <a class="reference internal" href="#ament2024pursuit" id="id25"><span>[Ament2024pursuit]</span></a>, the backward
algorithm generally leads to more robust results than the forward algorithm,
especially when the number of outliers is large, but is more expensive unless the
support is contracted by more than one in each iteration.</p>
<p>For details, see <a class="reference internal" href="#ament2024pursuit" id="id26"><span>[Ament2024pursuit]</span></a> or <a class="reference external" href="https://arxiv.org/abs/2410.24222">https://arxiv.org/abs/2410.24222</a>.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">base_noise</span> <span class="o">=</span> <span class="n">HomoskedasticNoise</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="n">noise_constraint</span><span class="o">=</span><span class="n">NonTransformedInterval</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>       <span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e-1</span><span class="p">,</span> <span class="n">initial_value</span><span class="o">=</span><span class="mf">1e-3</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">likelihood</span> <span class="o">=</span> <span class="n">SparseOutlierGaussianLikelihood</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="n">base_noise</span><span class="o">=</span><span class="n">base_noise</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="n">dim</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">train_Y</span><span class="o">=</span><span class="n">Y</span><span class="p">,</span> <span class="n">likelihood</span><span class="o">=</span><span class="n">likelihood</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mll</span> <span class="o">=</span> <span class="n">ExactMarginalLogLikelihood</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># NOTE: `likelihood.noise_covar` is the `RelevancePursuitMixin`</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sparse_module</span> <span class="o">=</span> <span class="n">likelihood</span><span class="o">.</span><span class="n">noise_covar</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sparse_module</span><span class="p">,</span> <span class="n">model_trace</span> <span class="o">=</span> <span class="n">backward_relevance_pursuit</span><span class="p">(</span><span class="n">sparse_module</span><span class="p">,</span> <span class="n">mll</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sparse_module</strong> (<a class="reference internal" href="#botorch.models.relevance_pursuit.RelevancePursuitMixin" title="botorch.models.relevance_pursuit.RelevancePursuitMixin"><em>RelevancePursuitMixin</em></a>) – The relevance pursuit module.</p></li>
<li><p><strong>mll</strong> (<em>ExactMarginalLogLikelihood</em>) – The marginal likelihood, containing the model to optimize.</p></li>
<li><p><strong>sparsity_levels</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – The sparsity levels to expand the support to.</p></li>
<li><p><strong>reset_parameters</strong> (<em>bool</em>) – If true, initializes the sparse parameter to the all zeros
after each iteration.</p></li>
<li><p><strong>reset_dense_parameters</strong> (<em>bool</em>) – If true, re-initializes the dense parameters, e.g.
other GP hyper-parameters that are <em>not</em> part of the Relevance Pursuit
module, to the initial values provided by their associated constraints.</p></li>
<li><p><strong>record_model_trace</strong> (<em>bool</em>) – If true, records the model state after every iteration.</p></li>
<li><p><strong>initial_support</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – The support with which to initialize the sparse module. By
default, the support is initialized to the full set.</p></li>
<li><p><strong>closure</strong> (<em>Callable</em><em>[</em><em>[</em><em>]</em><em>, </em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Sequence</em><em>[</em><em>Tensor</em><em> | </em><em>None</em><em>]</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A closure to use to compute the loss and the gradients, see docstring
of <cite>fit_gpytorch_mll</cite> for details.</p></li>
<li><p><strong>optimizer</strong> (<em>Callable</em><em> | </em><em>None</em>) – The numerical optimizer, see docstring of <cite>fit_gpytorch_mll</cite>.</p></li>
<li><p><strong>closure_kwargs</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Additional arguments to pass to the <cite>closure</cite> function.</p></li>
<li><p><strong>optimizer_kwargs</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – A dictionary of keyword arguments to pass to the optimizer.
By default, initializes the “options” sub-dictionary with <cite>maxiter</cite> and
<cite>ftol</cite>, <cite>gtol</cite> values, unless specified.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The relevance pursuit module after forward relevance pursuit optimization, and
a list of models with different supports that were optimized.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple[<a class="reference internal" href="#botorch.models.relevance_pursuit.RelevancePursuitMixin" title="botorch.models.relevance_pursuit.RelevancePursuitMixin"><em>RelevancePursuitMixin</em></a>, list[<a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>] | None]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.relevance_pursuit.get_posterior_over_support">
<span class="sig-prename descclassname"><span class="pre">botorch.models.relevance_pursuit.</span></span><span class="sig-name descname"><span class="pre">get_posterior_over_support</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">rp_class</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_trace</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_support_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_mean_of_support</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/relevance_pursuit.html#get_posterior_over_support"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.relevance_pursuit.get_posterior_over_support" title="Link to this definition"></a></dt>
<dd><p>Computes the posterior distribution over a list of models.
Assumes we are storing both likelihood and GP model in the model_trace.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">likelihood</span> <span class="o">=</span> <span class="n">SparseOutlierGaussianLikelihood</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="n">base_noise</span><span class="o">=</span><span class="n">base_noise</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="n">dim</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">train_Y</span><span class="o">=</span><span class="n">Y</span><span class="p">,</span> <span class="n">likelihood</span><span class="o">=</span><span class="n">likelihood</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mll</span> <span class="o">=</span> <span class="n">ExactMarginalLogLikelihood</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># NOTE: `likelihood.noise_covar` is the `RelevancePursuitMixin`</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sparse_module</span> <span class="o">=</span> <span class="n">likelihood</span><span class="o">.</span><span class="n">noise_covar</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sparse_module</span><span class="p">,</span> <span class="n">model_trace</span> <span class="o">=</span> <span class="n">backward_relevance_pursuit</span><span class="p">(</span><span class="n">sparse_module</span><span class="p">,</span> <span class="n">mll</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># NOTE: SparseOutlierNoise is the type of `sparse_module`</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">support_size</span><span class="p">,</span> <span class="n">bmc_probabilities</span> <span class="o">=</span> <span class="n">get_posterior_over_support</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="n">SparseOutlierNoise</span><span class="p">,</span> <span class="n">model_trace</span><span class="p">,</span> <span class="n">prior_mean_of_support</span><span class="o">=</span><span class="mf">2.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>rp_class</strong> (<em>type</em><em>[</em><a class="reference internal" href="#botorch.models.relevance_pursuit.RelevancePursuitMixin" title="botorch.models.relevance_pursuit.RelevancePursuitMixin"><em>RelevancePursuitMixin</em></a><em>]</em>) – The relevance pursuit class to use for computing the support size.
This is used to get the RelevancePursuitMixin from the Model via the static
method <cite>_from_model</cite>. We could generalize this and let the user pass this
getter instead.</p></li>
<li><p><strong>model_trace</strong> (<em>list</em><em>[</em><a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a><em>]</em>) – A list of models with different support sizes, usually generated
with relevance_pursuit.</p></li>
<li><p><strong>log_support_prior</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – Callable that computes the log prior probability of a
support size. If None, uses a default exponential prior with a mean
specified by <cite>prior_mean_of_support</cite>.</p></li>
<li><p><strong>prior_mean_of_support</strong> (<em>float</em><em> | </em><em>None</em>) – A mean value for the default exponential prior
distribution over the support size. Ignored if <cite>log_support_prior</cite>
is passed.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor of posterior marginal likelihoods, one for each model in the trace.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple[<em>Tensor</em>, <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.relevance_pursuit.initialize_dense_parameters">
<span class="sig-prename descclassname"><span class="pre">botorch.models.relevance_pursuit.</span></span><span class="sig-name descname"><span class="pre">initialize_dense_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/relevance_pursuit.html#initialize_dense_parameters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.relevance_pursuit.initialize_dense_parameters" title="Link to this definition"></a></dt>
<dd><p>Sets the dense parameters of a model to their initial values. Infers initial
values from the constraints, if no initial values are provided. If a parameter
does not have a constraint, it is initialized to zero.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model</strong> (<a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – The model to initialize.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The re-initialized model, and a dictionary of initial values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple[<a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>, dict[str, <em>Any</em>]]</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-botorch.models.map_saas">
<span id="sparse-axis-aligned-subspaces-saas-gp-models"></span><h3>Sparse Axis-Aligned Subspaces (SAAS) GP Models<a class="headerlink" href="#module-botorch.models.map_saas" title="Link to this heading"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.map_saas.SaasPriorHelper">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.map_saas.</span></span><span class="sig-name descname"><span class="pre">SaasPriorHelper</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tau</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/map_saas.html#SaasPriorHelper"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.map_saas.SaasPriorHelper" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Helper class for specifying parameter and setting closures.</p>
<p>Instantiates a new helper object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>tau</strong> (<em>float</em><em> | </em><em>None</em>) – Value of the global shrinkage parameter. If <cite>None</cite>, the tau will be
a free parameter and inferred from the data.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.map_saas.SaasPriorHelper.tau">
<span class="sig-name descname"><span class="pre">tau</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">m</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/map_saas.html#SaasPriorHelper.tau"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.map_saas.SaasPriorHelper.tau" title="Link to this definition"></a></dt>
<dd><p>The global shrinkage parameter <cite>tau</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>m</strong> (<em>Kernel</em>) – A kernel object equipped with a lengthscale.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The global shrinkage parameter of the SAAS prior.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.map_saas.SaasPriorHelper.inv_lengthscale_prior_param_or_closure">
<span class="sig-name descname"><span class="pre">inv_lengthscale_prior_param_or_closure</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">m</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/map_saas.html#SaasPriorHelper.inv_lengthscale_prior_param_or_closure"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.map_saas.SaasPriorHelper.inv_lengthscale_prior_param_or_closure" title="Link to this definition"></a></dt>
<dd><p>Closure to compute the scaled inverse lengthscale parameter (<cite>tau / l^2</cite>)
to which the SAAS prior is applied.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>m</strong> (<em>Kernel</em>) – A kernel object equipped with a lengthscale.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The scaled inverse lengthscale parameter.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.map_saas.SaasPriorHelper.inv_lengthscale_prior_setting_closure">
<span class="sig-name descname"><span class="pre">inv_lengthscale_prior_setting_closure</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">m</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/map_saas.html#SaasPriorHelper.inv_lengthscale_prior_setting_closure"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.map_saas.SaasPriorHelper.inv_lengthscale_prior_setting_closure" title="Link to this definition"></a></dt>
<dd><p>Closure to set the inverse lengthscale prior parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>m</strong> (<em>Kernel</em>) – A kernel object equipped with a lengthscale.</p></li>
<li><p><strong>value</strong> (<em>Tensor</em>) – The value of the scaled inverse lengthscale parameter, (<cite>tau / l^2</cite>),
used to recover and set the lengthscale of the kernel.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.map_saas.SaasPriorHelper.tau_prior_param_or_closure">
<span class="sig-name descname"><span class="pre">tau_prior_param_or_closure</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">m</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/map_saas.html#SaasPriorHelper.tau_prior_param_or_closure"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.map_saas.SaasPriorHelper.tau_prior_param_or_closure" title="Link to this definition"></a></dt>
<dd><p>Closure to compute the global shrinkage parameter <cite>tau</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>m</strong> (<em>Kernel</em>) – A kernel object equipped with a <cite>raw_tau</cite> parameter.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The transformed global shrinkage parameter <cite>tau</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.map_saas.SaasPriorHelper.tau_prior_setting_closure">
<span class="sig-name descname"><span class="pre">tau_prior_setting_closure</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">m</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/map_saas.html#SaasPriorHelper.tau_prior_setting_closure"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.map_saas.SaasPriorHelper.tau_prior_setting_closure" title="Link to this definition"></a></dt>
<dd><p>Closure to set the global shrinkage parameter <cite>tau</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>m</strong> (<em>Kernel</em>) – A kernel object equipped with a <cite>raw_tau</cite> parameter.</p></li>
<li><p><strong>value</strong> (<em>Tensor</em>) – The value of the global shrinkage parameter.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.map_saas.add_saas_prior">
<span class="sig-prename descclassname"><span class="pre">botorch.models.map_saas.</span></span><span class="sig-name descname"><span class="pre">add_saas_prior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">base_kernel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/map_saas.html#add_saas_prior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.map_saas.add_saas_prior" title="Link to this definition"></a></dt>
<dd><p>Add a SAAS prior to a given base_kernel.</p>
<p>The SAAS prior is given by tau / lengthscale^2 ~ HC(1.0). If tau is None,
we place an additional HC(0.1) prior on tau similar to the original SAAS prior
that relies on inference with NUTS.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">matern_kernel</span> <span class="o">=</span> <span class="n">MaternKernel</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">add_saas_prior</span><span class="p">(</span><span class="n">matern_kernel</span><span class="p">,</span> <span class="n">tau</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>  <span class="c1"># Add a SAAS prior</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>base_kernel</strong> (<em>Kernel</em>) – Base kernel that has a lengthscale and uses ARD.
Note that this function modifies the kernel object in place.</p></li>
<li><p><strong>tau</strong> (<em>float</em><em> | </em><em>None</em>) – Value of the global shrinkage. If <cite>None</cite>, infer the global
shrinkage parameter.</p></li>
<li><p><strong>log_scale</strong> (<em>bool</em>) – Set to <cite>True</cite> if the lengthscale and tau should be optimized on
a log-scale without any domain rescaling. That is, we will learn
<cite>raw_lengthscale := log(lengthscale)</cite> and this hyperparameter needs to
satisfy the corresponding bound constraints. Setting this to <cite>True</cite> will
generally improve the numerical stability, but requires an optimizer that
can handle bound constraints, e.g., L-BFGS-B.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Base kernel with SAAS priors added.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Kernel</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.map_saas.get_map_saas_model">
<span class="sig-prename descclassname"><span class="pre">botorch.models.map_saas.</span></span><span class="sig-name descname"><span class="pre">get_map_saas_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Yvar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outcome_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/map_saas.html#get_map_saas_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.map_saas.get_map_saas_model" title="Link to this definition"></a></dt>
<dd><p>Helper method for creating an unfitted MAP SAAS model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>Tensor</em>) – Tensor of shape <cite>n x d</cite> with training inputs.</p></li>
<li><p><strong>train_Y</strong> (<em>Tensor</em>) – Tensor of shape <cite>n x 1</cite> with training targets.</p></li>
<li><p><strong>train_Yvar</strong> (<em>Tensor</em><em> | </em><em>None</em>) – Optional tensor of shape <cite>n x 1</cite> with observed noise,
inferred if None.</p></li>
<li><p><strong>input_transform</strong> (<a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>InputTransform</em></a><em> | </em><em>None</em>) – An optional input transform.</p></li>
<li><p><strong>outcome_transform</strong> (<a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><em>OutcomeTransform</em></a><em> | </em><em>None</em>) – An optional outcome transforms.</p></li>
<li><p><strong>tau</strong> (<em>float</em><em> | </em><em>None</em>) – Fixed value of the global shrinkage tau. If None, the model
places a HC(0.1) prior on tau and infers it.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A SingleTaskGP with a Matern kernel and a SAAS prior.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.gp_regression.SingleTaskGP" title="botorch.models.gp_regression.SingleTaskGP"><em>SingleTaskGP</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.map_saas.get_mean_module_with_normal_prior">
<span class="sig-prename descclassname"><span class="pre">botorch.models.map_saas.</span></span><span class="sig-name descname"><span class="pre">get_mean_module_with_normal_prior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/map_saas.html#get_mean_module_with_normal_prior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.map_saas.get_mean_module_with_normal_prior" title="Link to this definition"></a></dt>
<dd><p>Return constant mean with a N(0, 1) prior constrained to [-10, 10].</p>
<p>This prior assumes the outputs (targets) have been standardized to have zero mean
and unit variance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch_shape</strong> (<em>Size</em><em> | </em><em>None</em>) – Optional batch shape for the constant-mean module.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>ConstantMean module.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>ConstantMean</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.map_saas.get_gaussian_likelihood_with_gamma_prior">
<span class="sig-prename descclassname"><span class="pre">botorch.models.map_saas.</span></span><span class="sig-name descname"><span class="pre">get_gaussian_likelihood_with_gamma_prior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/map_saas.html#get_gaussian_likelihood_with_gamma_prior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.map_saas.get_gaussian_likelihood_with_gamma_prior" title="Link to this definition"></a></dt>
<dd><p>Return Gaussian likelihood with a Gamma(0.9, 10) prior.</p>
<p>This prior prefers small noise, but also has heavy tails.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch_shape</strong> (<em>Size</em><em> | </em><em>None</em>) – Batch shape for the likelihood.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>GaussianLikelihood with Gamma(0.9, 10) prior constrained to [1e-4, 0.1].</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.map_saas.get_additive_map_saas_covar_module">
<span class="sig-prename descclassname"><span class="pre">botorch.models.map_saas.</span></span><span class="sig-name descname"><span class="pre">get_additive_map_saas_covar_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ard_num_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_taus</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">active_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/map_saas.html#get_additive_map_saas_covar_module"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.map_saas.get_additive_map_saas_covar_module" title="Link to this definition"></a></dt>
<dd><p>Return an additive map SAAS covar module.</p>
<p>The constructed kernel is an additive kernel with <cite>num_taus</cite> terms. Each term is a
scaled Matern kernel with a SAAS prior and a tau sampled from a HalfCauchy(0, 1)
distrbution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ard_num_dims</strong> (<em>int</em>) – The number of inputs dimensions.</p></li>
<li><p><strong>num_taus</strong> (<em>int</em>) – The number of taus to use (4 if omitted).</p></li>
<li><p><strong>active_dims</strong> (<em>tuple</em><em>[</em><em>int</em><em>, </em><em>...</em><em>] </em><em>| </em><em>None</em>) – Active dims for the covar module. The kernel will be evaluated
only using these columns of the input tensor.</p></li>
<li><p><strong>batch_shape</strong> (<em>Size</em><em> | </em><em>None</em>) – Batch shape for the covar module.</p></li>
<li><p><strong>dtype</strong> (<em>dtype</em><em> | </em><em>None</em>)</p></li>
<li><p><strong>device</strong> (<em>device</em><em> | </em><em>None</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An additive MAP SAAS covar module.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.map_saas.AdditiveMapSaasSingleTaskGP">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.map_saas.</span></span><span class="sig-name descname"><span class="pre">AdditiveMapSaasSingleTaskGP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Yvar=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outcome_transform=&lt;class</span> <span class="pre">'botorch.utils.types.DEFAULT'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_transform=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_taus=4</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/map_saas.html#AdditiveMapSaasSingleTaskGP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.map_saas.AdditiveMapSaasSingleTaskGP" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.gp_regression.SingleTaskGP" title="botorch.models.gp_regression.SingleTaskGP"><code class="xref py py-class docutils literal notranslate"><span class="pre">SingleTaskGP</span></code></a></p>
<p>An additive MAP SAAS single-task GP.</p>
<p>This is a maximum-a-posteriori (MAP) version of sparse axis-aligned subspace BO
(SAASBO), see <cite>SaasFullyBayesianSingleTaskGP</cite> for more details. SAASBO is a
high-dimensional Bayesian optimization approach that uses approximate fully
Bayesian inference via NUTS to learn the model hyperparameters. This works very
well, but is very computationally expensive which limits the use of SAASBO to a
small (~100) number of trials. Two of the main benefits with SAASBO are:</p>
<ol class="arabic simple">
<li><p>A sparse prior on the inverse lengthscales that avoid overfitting.</p></li>
<li><p>The ability to sample several (~16) sets of hyperparameters from the
posterior that we can average over when computing the acquisition
function (ensembling).</p></li>
</ol>
<p>The goal of this Additive MAP SAAS model is to retain the main benefits of the SAAS
model while significantly speeding up the time to fit the model. We achieve this by
creating an additive kernel where each kernel in the sum is a Matern-5/2 kernel
with a SAAS prior and a separate outputscale. The sparsity level for each kernel
is sampled from an HC(0.1) distribution leading to a mix of sparsity levels (as is
often the case for the fully Bayesian SAAS model). We learn all the hyperparameters
using MAP inference which is significantly faster than using NUTS.</p>
<p>While we often find that the original SAAS model with NUTS performs better, the
additive MAP SAAS model can be several orders of magnitude faster to fit, which
makes it applicable to problems with potentially thousands of trials.</p>
<p>Instantiates an AdditiveMapSaasSingleTaskGP.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite> tensor of training features.</p></li>
<li><p><strong>train_Y</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x m</cite> tensor of training observations.</p></li>
<li><p><strong>train_Yvar</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x m</cite> tensor of observed noise.</p></li>
<li><p><strong>outcome_transform</strong> (<a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><em>OutcomeTransform</em></a><em> | </em><em>_DefaultType</em><em> | </em><em>None</em>) – An outcome transform that is applied to the
training data during instantiation and to the posterior during
inference (that is, the <cite>Posterior</cite> obtained by calling
<cite>.posterior</cite> on the model will be on the original scale). We use a
<cite>Standardize</cite> transform if no <cite>outcome_transform</cite> is specified.
Pass down <cite>None</cite> to use no outcome transform.</p></li>
<li><p><strong>input_transform</strong> (<a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>InputTransform</em></a><em> | </em><em>None</em>) – An optional input transform.</p></li>
<li><p><strong>num_taus</strong> (<em>int</em>) – The number of taus to use (4 if omitted).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-botorch.models.robust_relevance_pursuit_model">
<span id="variational-gp-models"></span><h3>Variational GP Models<a class="headerlink" href="#module-botorch.models.robust_relevance_pursuit_model" title="Link to this heading"></a></h3>
<p>This file contains a readily usable implementation of the robust Gaussian process
model of <a class="reference internal" href="#ament2024pursuit" id="id27"><span>[Ament2024pursuit]</span></a>, leveraging the Relevance Pursuit algorithm.</p>
<p>In particular, this file contains a <cite>RobustRelevancePursuitMixin</cite> class, and a concrete
implementation of a <cite>SingleTaskGP</cite> model, <cite>RobustRelevancePursuitSingleTaskGP</cite>, which
has the same API as a standard <cite>SingleTaskGP</cite> model, but automatically instantiates the
robust likelihood <cite>SparseOutlierGaussianLikelihood</cite> and dispatches the relevance pursuit
algorithm during model fitting via <cite>fit_gpytorch_mll</cite>.</p>
<p>Even though a standard <cite>SingleTaskGP</cite> model is expressive enough to implement the robust
model by changing the likelihood, its optimization is more complex. So the main reason
for the <cite>RobustRelevancePursuitMixin</cite> class is to hide this complexity by using multiple
dispatch of <cite>fit_gpytorch_mll</cite>, which needs to do two distinct operations in the context
of the robust model:</p>
<ol class="arabic simple">
<li><p>It needs to toggle the relevance pursuit discrete optimization algorithm that
changes the support, and as a sub-task,</p></li>
<li><p>it needs to still carry out the numerical optimization of the hyper-parameters given
a fixed support, but still with a <cite>SparseOutlierGaussianLikelihood</cite>. Since the types
of the marginal likelihood (<cite>MarginalLogLikelihood</cite>) and the likelihood
(<cite>SparseOutlierGaussianLikelihood</cite>) are the same in both calls, the only way we can
leverage the multiple dispatch mechanism is the model type.</p></li>
</ol>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.robust_relevance_pursuit_model.RobustRelevancePursuitMixin">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.robust_relevance_pursuit_model.</span></span><span class="sig-name descname"><span class="pre">RobustRelevancePursuitMixin</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">base_likelihood</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_mean_of_support</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">convex_parameterization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_model_trace</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/robust_relevance_pursuit_model.html#RobustRelevancePursuitMixin"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.robust_relevance_pursuit_model.RobustRelevancePursuitMixin" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>A Mixin class for robust relevance pursuit models, which wraps a base likelihood
with a <cite>SparseOutlierGaussianLikelihood</cite> to detect outliers, and calls the
relevance pursuit algorithm during model fitting via <cite>fit_gpytorch_mll</cite>.</p>
<p>This is distinct from the <cite>RelevancePursuitMixin</cite> class, which is a Mixin class to
equip a specific module (the likelihood, in the case of the robust model) with the
relevance pursuit algorithms.</p>
<p>Initializes a robust relevance pursuit model, which wraps a base likelihood
with a <cite>SparseOutlierGaussianLikelihood</cite> to detect outliers, and calls the
relevance pursuit algorithm during model fitting via <cite>fit_gpytorch_mll</cite>.</p>
<p>For details, see <a class="reference internal" href="#ament2024pursuit" id="id28"><span>[Ament2024pursuit]</span></a> or <a class="reference external" href="https://arxiv.org/abs/2410.24222">https://arxiv.org/abs/2410.24222</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>base_likelihood</strong> (<em>GaussianLikelihood</em><em> | </em><em>FixedNoiseGaussianLikelihood</em>) – The base likelihood that will be wrapped by a
<cite>SparseOutlierGaussianLikelihood</cite> to detect outliers.</p></li>
<li><p><strong>dim</strong> (<em>int</em>) – The number of training data points, i.e. the maximum dimensionality
of the support set of the likelihood.</p></li>
<li><p><strong>prior_mean_of_support</strong> (<em>float</em><em> | </em><em>None</em>) – The mean value for the default exponential prior
distribution over the support size.</p></li>
<li><p><strong>convex_parameterization</strong> (<em>bool</em>) – If True, use a convex parameterization of the
sparse noise model. See <cite>SparseOutlierGaussianLikelihood</cite> for details.</p></li>
<li><p><strong>cache_model_trace</strong> (<em>bool</em>) – If True, cache the model trace during relevance pursuit.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.robust_relevance_pursuit_model.RobustRelevancePursuitMixin.to_standard_model">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">to_standard_model</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/robust_relevance_pursuit_model.html#RobustRelevancePursuitMixin.to_standard_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.robust_relevance_pursuit_model.RobustRelevancePursuitMixin.to_standard_model" title="Link to this definition"></a></dt>
<dd><p>Converts this <cite>RobustRelevancePursuitMixin</cite> to an equivalent standard model
with the same robust likelihood and hyper-parameters. This leaves the model
structure and predictions unchanged, but leads <cite>fit_gpytorch_mll</cite>’s dispatch to
<em>numerically</em> optimize the hyper-parameters of the model with a fixed support
set, as opposed to dispatching to the discrete optimization via the relevance
pursuit algorithm.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A standard model.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.robust_relevance_pursuit_model.RobustRelevancePursuitMixin.load_standard_model">
<span class="sig-name descname"><span class="pre">load_standard_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">standard_model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/robust_relevance_pursuit_model.html#RobustRelevancePursuitMixin.load_standard_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.robust_relevance_pursuit_model.RobustRelevancePursuitMixin.load_standard_model" title="Link to this definition"></a></dt>
<dd><p>Loads the state dict of a model into the <cite>RobustRelevancePursuitMixin</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>standard_model</strong> (<a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A standard model with the same parameter structure and
likelihood as the <cite>RobustRelevancePursuitMixin</cite> model.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The <cite>RobustRelevancePursuitMixin</cite> with the standard model’s state dict.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.robust_relevance_pursuit_model.RobustRelevancePursuitMixin" title="botorch.models.robust_relevance_pursuit_model.RobustRelevancePursuitMixin"><em>RobustRelevancePursuitMixin</em></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.robust_relevance_pursuit_model.RobustRelevancePursuitSingleTaskGP">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.robust_relevance_pursuit_model.</span></span><span class="sig-name descname"><span class="pre">RobustRelevancePursuitSingleTaskGP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Yvar=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">likelihood=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">covar_module=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean_module=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outcome_transform=&lt;class</span> <span class="pre">'botorch.utils.types.DEFAULT'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_transform=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">convex_parameterization=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_mean_of_support=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_model_trace=False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/robust_relevance_pursuit_model.html#RobustRelevancePursuitSingleTaskGP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.robust_relevance_pursuit_model.RobustRelevancePursuitSingleTaskGP" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.gp_regression.SingleTaskGP" title="botorch.models.gp_regression.SingleTaskGP"><code class="xref py py-class docutils literal notranslate"><span class="pre">SingleTaskGP</span></code></a>, <a class="reference internal" href="#botorch.models.robust_relevance_pursuit_model.RobustRelevancePursuitMixin" title="botorch.models.robust_relevance_pursuit_model.RobustRelevancePursuitMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">RobustRelevancePursuitMixin</span></code></a></p>
<dl class="simple">
<dt>A robust single-task GP model that toggles the relevance pursuit algorithm</dt><dd><p>during model fitting via <cite>fit_gpytorch_mll</cite>.</p>
</dd>
</dl>
<p>For details, see <a class="reference internal" href="#ament2024pursuit" id="id29"><span>[Ament2024pursuit]</span></a> or <a class="reference external" href="https://arxiv.org/abs/2410.24222">https://arxiv.org/abs/2410.24222</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite> tensor of training features.</p></li>
<li><p><strong>train_Y</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x m</cite> tensor of training observations.</p></li>
<li><p><strong>train_Yvar</strong> (<em>Tensor</em><em> | </em><em>None</em>) – An optional <cite>batch_shape x n x m</cite> tensor of observed
measurement noise.</p></li>
<li><p><strong>likelihood</strong> (<em>Likelihood</em><em> | </em><em>None</em>) – A base likelihood that will be wrapped by a
<cite>SparseOutlierGaussianLikelihood</cite> to detect outliers. If omitted,
use a standard <cite>GaussianLikelihood</cite> with inferred noise level if
<cite>train_Yvar</cite> is None, and a <cite>FixedNoiseGaussianLikelihood</cite> with the
given noise observations if <cite>train_Yvar</cite> is not None.</p></li>
<li><p><strong>covar_module</strong> (<em>Module</em><em> | </em><em>None</em>) – The module computing the covariance (Kernel) matrix.
If omitted, uses an <cite>RBFKernel</cite>.</p></li>
<li><p><strong>mean_module</strong> (<em>Mean</em><em> | </em><em>None</em>) – The mean function to be used. If omitted, use a
<cite>ConstantMean</cite>.</p></li>
<li><p><strong>outcome_transform</strong> (<a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><em>OutcomeTransform</em></a><em> | </em><em>_DefaultType</em><em> | </em><em>None</em>) – An outcome transform that is applied to the
training data during instantiation and to the posterior during
inference (that is, the <cite>Posterior</cite> obtained by calling
<cite>.posterior</cite> on the model will be on the original scale). We use a
<cite>Standardize</cite> transform if no <cite>outcome_transform</cite> is specified.
Pass down <cite>None</cite> to use no outcome transform.</p></li>
<li><p><strong>input_transform</strong> (<a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>InputTransform</em></a><em> | </em><em>None</em>) – An input transform that is applied in the model’s
forward pass.</p></li>
<li><p><strong>convex_parameterization</strong> (<em>bool</em>) – If True, use a convex parameterization of the
sparse noise model. See <cite>SparseOutlierGaussianLikelihood</cite> for details.</p></li>
<li><p><strong>prior_mean_of_support</strong> (<em>float</em><em> | </em><em>None</em>) – The mean value for the default exponential prior
distribution over the support size.</p></li>
<li><p><strong>cache_model_trace</strong> (<em>bool</em>) – If True, cache the model trace during relevance pursuit.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">RobustRelevancePursuitSingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">train_Y</span><span class="o">=</span><span class="n">Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mll</span> <span class="o">=</span> <span class="n">ExactMarginalLogLikelihood</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">m</span><span class="p">,</span> <span class="n">likelihood</span><span class="o">=</span><span class="n">m</span><span class="o">.</span><span class="n">likelihood</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mll</span> <span class="o">=</span> <span class="n">fit_gpytorch_mll</span><span class="p">(</span><span class="n">mll</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.robust_relevance_pursuit_model.RobustRelevancePursuitSingleTaskGP.to_standard_model">
<span class="sig-name descname"><span class="pre">to_standard_model</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/robust_relevance_pursuit_model.html#RobustRelevancePursuitSingleTaskGP.to_standard_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.robust_relevance_pursuit_model.RobustRelevancePursuitSingleTaskGP.to_standard_model" title="Link to this definition"></a></dt>
<dd><p>Returns a standard SingleTaskGP with the same parameters as this model.
This is used to avoid recursion through the fit_gpytorch_mll dispatch.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<p id="module-botorch.models.approximate_gp">References</p>
<div role="list" class="citation-list">
<div class="citation" id="burt2020svgp" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>burt2020svgp<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id31">1</a>,<a role="doc-backlink" href="#id44">2</a>,<a role="doc-backlink" href="#id46">3</a>,<a role="doc-backlink" href="#id48">4</a>)</span>
<p>David R. Burt and Carl Edward Rasmussen and Mark van der Wilk,
Convergence of Sparse Variational Inference in Gaussian Process Regression,
Journal of Machine Learning Research, 2020,
<a class="reference external" href="http://jmlr.org/papers/v21/19-1015.html">http://jmlr.org/papers/v21/19-1015.html</a>.</p>
</div>
<div class="citation" id="hensman2013svgp" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id30">hensman2013svgp</a><span class="fn-bracket">]</span></span>
<p>James Hensman and Nicolo Fusi and Neil D. Lawrence, Gaussian Processes
for Big Data, Proceedings of the 29th Conference on Uncertainty in
Artificial Intelligence, 2013, <a class="reference external" href="https://arxiv.org/abs/1309.6835">https://arxiv.org/abs/1309.6835</a>.</p>
</div>
<div class="citation" id="moss2023ipa" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>moss2023ipa<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id32">1</a>,<a role="doc-backlink" href="#id45">2</a>,<a role="doc-backlink" href="#id47">3</a>,<a role="doc-backlink" href="#id51">4</a>)</span>
<p>Henry B. Moss and Sebastian W. Ober and Victor Picheny,
Inducing Point Allocation for Sparse Gaussian Processes
in High-Throughput Bayesian Optimization,Proceedings of
the 25th International Conference on Artificial Intelligence
and Statistics, 2023, <a class="reference external" href="https://arxiv.org/pdf/2301.10123.pdf">https://arxiv.org/pdf/2301.10123.pdf</a>.</p>
</div>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.approximate_gp.ApproximateGPyTorchModel">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.approximate_gp.</span></span><span class="sig-name descname"><span class="pre">ApproximateGPyTorchModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">likelihood</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_outputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/approximate_gp.html#ApproximateGPyTorchModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.approximate_gp.ApproximateGPyTorchModel" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.gpytorch.GPyTorchModel" title="botorch.models.gpytorch.GPyTorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">GPyTorchModel</span></code></a></p>
<p>Botorch wrapper class for various (variational) approximate GP models in
GPyTorch.</p>
<p>This can either include stochastic variational GPs (SVGPs) or
variational implementations of weight space approximate GPs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>ApproximateGP</em><em> | </em><em>None</em>) – Instance of gpytorch.approximate GP models. If omitted,
constructs a <cite>_SingleTaskVariationalGP</cite>.</p></li>
<li><p><strong>likelihood</strong> (<em>Likelihood</em><em> | </em><em>None</em>) – Instance of a GPyTorch likelihood. If omitted, uses a
either a <cite>GaussianLikelihood</cite> (if <cite>num_outputs=1</cite>) or a
<cite>MultitaskGaussianLikelihood`(if `num_outputs&gt;1</cite>).</p></li>
<li><p><strong>num_outputs</strong> (<em>int</em>) – Number of outputs expected for the GP model.</p></li>
<li><p><strong>args</strong> – Optional positional arguments passed to the
<cite>_SingleTaskVariationalGP</cite> constructor if no model is provided.</p></li>
<li><p><strong>kwargs</strong> – Optional keyword arguments passed to the
<cite>_SingleTaskVariationalGP</cite> constructor if no model is provided.</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.approximate_gp.ApproximateGPyTorchModel.num_outputs">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">num_outputs</span></span><a class="headerlink" href="#botorch.models.approximate_gp.ApproximateGPyTorchModel.num_outputs" title="Link to this definition"></a></dt>
<dd><p>The number of outputs of the model.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.approximate_gp.ApproximateGPyTorchModel.eval">
<span class="sig-name descname"><span class="pre">eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/approximate_gp.html#ApproximateGPyTorchModel.eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.approximate_gp.ApproximateGPyTorchModel.eval" title="Link to this definition"></a></dt>
<dd><p>Puts the model in <cite>eval</cite> mode.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Self</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.approximate_gp.ApproximateGPyTorchModel.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/approximate_gp.html#ApproximateGPyTorchModel.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.approximate_gp.ApproximateGPyTorchModel.train" title="Link to this definition"></a></dt>
<dd><p>Put the model in <cite>train</cite> mode.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>mode</strong> (<em>bool</em>) – A boolean denoting whether to put in <cite>train</cite> or <cite>eval</cite> mode.
If <cite>False</cite>, model is put in <cite>eval</cite> mode.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Self</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.approximate_gp.ApproximateGPyTorchModel.posterior">
<span class="sig-name descname"><span class="pre">posterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observation_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/approximate_gp.html#ApproximateGPyTorchModel.posterior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.approximate_gp.ApproximateGPyTorchModel.posterior" title="Link to this definition"></a></dt>
<dd><p>Computes the posterior over model outputs at the provided points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> – A <cite>(batch_shape) x q x d</cite>-dim Tensor, where <cite>d</cite> is the dimension
of the feature space and <cite>q</cite> is the number of points considered
jointly.</p></li>
<li><p><strong>observation_noise</strong> (<em>bool</em>) – If True, add the observation noise from the
likelihood to the posterior. If a Tensor, use it directly as the
observation noise (must be of shape <cite>(batch_shape) x q</cite>). It is
assumed to be in the outcome-transformed space if an outcome
transform is used.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="acquisition.html#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – An optional PosteriorTransform.</p></li>
<li><p><strong>output_indices</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>GPyTorchPosterior</cite> object, representing a batch of <cite>b</cite> joint
distributions over <cite>q</cite> points. Includes observation noise if
specified.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.gpytorch.GPyTorchPosterior" title="botorch.posteriors.gpytorch.GPyTorchPosterior"><em>GPyTorchPosterior</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.approximate_gp.ApproximateGPyTorchModel.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/approximate_gp.html#ApproximateGPyTorchModel.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.approximate_gp.ApproximateGPyTorchModel.forward" title="Link to this definition"></a></dt>
<dd><p>Define the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>MultivariateNormal</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.approximate_gp.SingleTaskVariationalGP">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.approximate_gp.</span></span><span class="sig-name descname"><span class="pre">SingleTaskVariationalGP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Y=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">likelihood=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_outputs=1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learn_inducing_points=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">covar_module=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean_module=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">variational_distribution=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">variational_strategy=&lt;class</span> <span class="pre">'gpytorch.variational.variational_strategy.VariationalStrategy'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inducing_points=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inducing_point_allocator=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outcome_transform=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_transform=None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/approximate_gp.html#SingleTaskVariationalGP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.approximate_gp.SingleTaskVariationalGP" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.approximate_gp.ApproximateGPyTorchModel" title="botorch.models.approximate_gp.ApproximateGPyTorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">ApproximateGPyTorchModel</span></code></a></p>
<p>A single-task variational GP model following <a class="reference internal" href="#hensman2013svgp" id="id30"><span>[hensman2013svgp]</span></a>.</p>
<p>By default, the inducing points are initialized though the
<cite>GreedyVarianceReduction</cite> of <a class="reference internal" href="#burt2020svgp" id="id31"><span>[burt2020svgp]</span></a>, which is known to be
effective for building globally accurate models. However, custom
inducing point allocators designed for specific down-stream tasks can also be
provided (see <a class="reference internal" href="#moss2023ipa" id="id32"><span>[moss2023ipa]</span></a> for details), e.g. <cite>GreedyImprovementReduction</cite>
when the goal is to build a model suitable for standard BO.</p>
<p>A single-task variational GP using relatively strong priors on the Kernel
hyperparameters, which work best when covariates are normalized to the unit
cube and outcomes are standardized (zero mean, unit variance).</p>
<p>This model works in batch mode (each batch having its own hyperparameters).
When the training observations include multiple outputs, this model will use
batching to model outputs independently. However, batches of multi-output models
are not supported at this time, if you need to use those, please use a
ModelListGP.</p>
<p>Use this model if you have a lot of data or if your responses are non-Gaussian.</p>
<p>To train this model, you should use gpytorch.mlls.VariationalELBO and not
the exact marginal log likelihood.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">botorch.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">SingleTaskVariationalGP</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.mlls</span><span class="w"> </span><span class="kn">import</span> <span class="n">VariationalELBO</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskVariationalGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mll</span> <span class="o">=</span> <span class="n">VariationalELBO</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">model</span><span class="o">.</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">num_data</span><span class="o">=</span><span class="n">train_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>Tensor</em>) – Training inputs (due to the ability of the SVGP to sub-sample
this does not have to be all of the training inputs).</p></li>
<li><p><strong>train_Y</strong> (<em>Tensor</em><em> | </em><em>None</em>) – Training targets (optional).</p></li>
<li><p><strong>likelihood</strong> (<em>Likelihood</em><em> | </em><em>None</em>) – Instance of a GPyTorch likelihood. If omitted, uses a
either a <cite>GaussianLikelihood</cite> (if <cite>num_outputs=1</cite>) or a
<cite>MultitaskGaussianLikelihood`(if `num_outputs&gt;1</cite>).</p></li>
<li><p><strong>num_outputs</strong> (<em>int</em>) – Number of output responses per input (default: 1).</p></li>
<li><p><strong>learn_inducing_points</strong> (<em>bool</em>) – If True, the inducing point locations are learned
jointly with the other model parameters.</p></li>
<li><p><strong>covar_module</strong> (<em>Kernel</em><em> | </em><em>None</em>) – Kernel function. If omitted, uses an <cite>RBFKernel</cite>.</p></li>
<li><p><strong>mean_module</strong> (<em>Mean</em><em> | </em><em>None</em>) – Mean of GP model. If omitted, uses a <cite>ConstantMean</cite>.</p></li>
<li><p><strong>variational_distribution</strong> (<em>_VariationalDistribution</em><em> | </em><em>None</em>) – Type of variational distribution to use
(default: CholeskyVariationalDistribution), the properties of the
variational distribution will encourage scalability or ease of
optimization.</p></li>
<li><p><strong>variational_strategy</strong> (<em>type</em><em>[</em><em>_VariationalStrategy</em><em>]</em>) – Type of variational strategy to use (default:
VariationalStrategy). The default setting uses “whitening” of the
variational distribution to make training easier.</p></li>
<li><p><strong>inducing_points</strong> (<em>Tensor</em><em> | </em><em>int</em><em> | </em><em>None</em>) – The number or specific locations of the inducing points.</p></li>
<li><p><strong>inducing_point_allocator</strong> (<a class="reference internal" href="#botorch.models.utils.inducing_point_allocators.InducingPointAllocator" title="botorch.models.utils.inducing_point_allocators.InducingPointAllocator"><em>InducingPointAllocator</em></a><em> | </em><em>None</em>) – The <cite>InducingPointAllocator</cite> used to
initialize the inducing point locations. If omitted,
uses <cite>GreedyVarianceReduction</cite>.</p></li>
<li><p><strong>outcome_transform</strong> (<a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><em>OutcomeTransform</em></a><em> | </em><em>None</em>) – An outcome transform that is applied to the training
data during instantiation and to the posterior during inference.
NOTE: If this model is trained in minibatches, an outcome transform
with learnable parameters (such as <cite>Standardize</cite>) would update its
parameters for each minibatch, which is undesirable. If you do intend
to train in minibatches, we recommend you not use an outcome transform
and instead pre-transform your whole data set before fitting the model.</p></li>
<li><p><strong>input_transform</strong> (<a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>InputTransform</em></a><em> | </em><em>None</em>) – An input transform that is applied in the model’s
forward pass.
NOTE: If this model is trained in minibatches, an input transform
with learnable parameters (such as <cite>Normalize</cite>) would update its
parameters for each minibatch, which is undesirable. If you do intend
to train in minibatches, we recommend you not use an input transform
and instead pre-transform your whole data set before fitting the model.</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.approximate_gp.SingleTaskVariationalGP.batch_shape">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">batch_shape</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Size</span></em><a class="headerlink" href="#botorch.models.approximate_gp.SingleTaskVariationalGP.batch_shape" title="Link to this definition"></a></dt>
<dd><p>The batch shape of the model.</p>
<p>This is a batch shape from an I/O perspective. For a model with <cite>m</cite>
outputs, a <cite>test_batch_shape x q x d</cite>-shaped input <cite>X</cite> to the <cite>posterior</cite>
method returns a Posterior object over an output of shape
<cite>broadcast(test_batch_shape, model.batch_shape) x q x m</cite>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.approximate_gp.SingleTaskVariationalGP.init_inducing_points">
<span class="sig-name descname"><span class="pre">init_inducing_points</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/approximate_gp.html#SingleTaskVariationalGP.init_inducing_points"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.approximate_gp.SingleTaskVariationalGP.init_inducing_points" title="Link to this definition"></a></dt>
<dd><p>Reinitialize the inducing point locations in-place with the current kernel
applied to <cite>inputs</cite> through the model’s inducing point allocation strategy.
The variational distribution and variational strategy caches are reset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>inputs</strong> (<em>Tensor</em>) – (*batch_shape, n, d)-dim input data tensor.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>(*batch_shape, m, d)-dim tensor of selected inducing point locations.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="model-components">
<h2>Model Components<a class="headerlink" href="#model-components" title="Link to this heading"></a></h2>
<section id="module-botorch.models.kernels.categorical">
<span id="kernels"></span><h3>Kernels<a class="headerlink" href="#module-botorch.models.kernels.categorical" title="Link to this heading"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.kernels.categorical.CategoricalKernel">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.kernels.categorical.</span></span><span class="sig-name descname"><span class="pre">CategoricalKernel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ard_num_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">active_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lengthscale_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lengthscale_constraint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-06</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/kernels/categorical.html#CategoricalKernel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.kernels.categorical.CategoricalKernel" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Kernel</span></code></p>
<p>A Kernel for categorical features.</p>
<p>Computes <cite>exp(-dist(x1, x2) / lengthscale)</cite>, where
<cite>dist(x1, x2)</cite> is zero if <cite>x1 == x2</cite> and one if <cite>x1 != x2</cite>.
If the last dimension is not a batch dimension, then the
mean is considered.</p>
<p>Note: This kernel is NOT differentiable w.r.t. the inputs.</p>
<p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ard_num_dims</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>)</p></li>
<li><p><strong>batch_shape</strong> (<em>Optional</em><em>[</em><em>torch.Size</em><em>]</em>)</p></li>
<li><p><strong>active_dims</strong> (<em>Optional</em><em>[</em><em>Tuple</em><em>[</em><em>int</em><em>, </em><em>...</em><em>]</em><em>]</em>)</p></li>
<li><p><strong>lengthscale_prior</strong> (<em>Optional</em><em>[</em><em>Prior</em><em>]</em>)</p></li>
<li><p><strong>lengthscale_constraint</strong> (<em>Optional</em><em>[</em><em>Interval</em><em>]</em>)</p></li>
<li><p><strong>eps</strong> (<em>float</em>)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class" id="module-botorch.models.kernels.downsampling">
<dt class="sig sig-object py" id="botorch.models.kernels.downsampling.DownsamplingKernel">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.kernels.downsampling.</span></span><span class="sig-name descname"><span class="pre">DownsamplingKernel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">power_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offset_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">power_constraint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offset_constraint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/kernels/downsampling.html#DownsamplingKernel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.kernels.downsampling.DownsamplingKernel" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Kernel</span></code></p>
<p>GPyTorch Downsampling Kernel.</p>
<p>Computes a covariance matrix based on the down sampling kernel between
inputs <cite>x_1</cite> and <cite>x_2</cite> (we expect <cite>d = 1</cite>):</p>
<blockquote>
<div><dl class="simple">
<dt>K(mathbf{x_1}, mathbf{x_2}) = c + (1 - x_1)^(1 + delta) *</dt><dd><p>(1 - x_2)^(1 + delta).</p>
</dd>
</dl>
</div></blockquote>
<p>where <cite>c</cite> is an offset parameter, and <cite>delta</cite> is a power parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>power_constraint</strong> (<em>Interval</em><em> | </em><em>None</em>) – Constraint to place on power parameter. Default is
<cite>Positive</cite>.</p></li>
<li><p><strong>power_prior</strong> (<em>Prior</em><em> | </em><em>None</em>) – Prior over the power parameter.</p></li>
<li><p><strong>offset_constraint</strong> (<em>Interval</em><em> | </em><em>None</em>) – Constraint to place on offset parameter. Default is
<cite>Positive</cite>.</p></li>
<li><p><strong>active_dims</strong> – List of data dimensions to operate on. <cite>len(active_dims)</cite>
should equal <cite>num_dimensions</cite>.</p></li>
<li><p><strong>offset_prior</strong> (<em>Prior</em><em> | </em><em>None</em>)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class" id="module-botorch.models.kernels.exponential_decay">
<dt class="sig sig-object py" id="botorch.models.kernels.exponential_decay.ExponentialDecayKernel">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.kernels.exponential_decay.</span></span><span class="sig-name descname"><span class="pre">ExponentialDecayKernel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">power_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offset_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">power_constraint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offset_constraint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/kernels/exponential_decay.html#ExponentialDecayKernel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.kernels.exponential_decay.ExponentialDecayKernel" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Kernel</span></code></p>
<p>GPyTorch Exponential Decay Kernel.</p>
<p>Computes a covariance matrix based on the exponential decay kernel
between inputs <cite>x_1</cite> and <cite>x_2</cite> (we expect <cite>d = 1</cite>):</p>
<blockquote>
<div><p>K(x_1, x_2) = w + beta^alpha / (x_1 + x_2 + beta)^alpha.</p>
</div></blockquote>
<p>where <cite>w</cite> is an offset parameter, <cite>beta</cite> is a lenthscale parameter, and
<cite>alpha</cite> is a power parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lengthscale_constraint</strong> – Constraint to place on lengthscale parameter.
Default is <cite>Positive</cite>.</p></li>
<li><p><strong>lengthscale_prior</strong> – Prior over the lengthscale parameter.</p></li>
<li><p><strong>power_constraint</strong> (<em>Interval</em><em> | </em><em>None</em>) – Constraint to place on power parameter. Default is
<cite>Positive</cite>.</p></li>
<li><p><strong>power_prior</strong> (<em>Prior</em><em> | </em><em>None</em>) – Prior over the power parameter.</p></li>
<li><p><strong>offset_constraint</strong> (<em>Interval</em><em> | </em><em>None</em>) – Constraint to place on offset parameter. Default is
<cite>Positive</cite>.</p></li>
<li><p><strong>active_dims</strong> – List of data dimensions to operate on. <cite>len(active_dims)</cite>
should equal <cite>num_dimensions</cite>.</p></li>
<li><p><strong>offset_prior</strong> (<em>Prior</em><em> | </em><em>None</em>)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class" id="module-botorch.models.kernels.infinite_width_bnn">
<dt class="sig sig-object py" id="botorch.models.kernels.infinite_width_bnn.InfiniteWidthBNNKernel">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.kernels.infinite_width_bnn.</span></span><span class="sig-name descname"><span class="pre">InfiniteWidthBNNKernel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">depth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">active_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">acos_eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/kernels/infinite_width_bnn.html#InfiniteWidthBNNKernel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.kernels.infinite_width_bnn.InfiniteWidthBNNKernel" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Kernel</span></code></p>
<p>Infinite-width BNN kernel.</p>
<p>Defines the GP kernel which is equivalent to performing exact Bayesian
inference on a fully-connected deep neural network with ReLU activations
and i.i.d. priors in the infinite-width limit.
See <a class="reference internal" href="#cho2009kernel" id="id33"><span>[Cho2009kernel]</span></a> and <a class="reference internal" href="#lee2018deep" id="id34"><span>[Lee2018deep]</span></a> for details.</p>
<div role="list" class="citation-list">
<div class="citation" id="cho2009kernel" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id33">Cho2009kernel</a><span class="fn-bracket">]</span></span>
<p>Y. Cho, and L. Saul. Kernel methods for deep learning.
Advances in Neural Information Processing Systems 22. 2009.</p>
</div>
<div class="citation" id="lee2018deep" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id34">Lee2018deep</a><span class="fn-bracket">]</span></span>
<p>J. Lee, Y. Bahri, R. Novak, S. Schoenholz, J. Pennington, and J. Dickstein.
Deep Neural Networks as Gaussian Processes.
International Conference on Learning Representations. 2018.</p>
</div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>depth</strong> (<em>int</em>) – Depth of neural network.</p></li>
<li><p><strong>batch_shape</strong> (<em>torch.Size</em><em> | </em><em>None</em>) – This will set a separate weight/bias var for each batch.
It should be <span class="math notranslate nohighlight">\(B_1 \times \ldots \times B_k\)</span> if <span class="math notranslate nohighlight">\(\mathbf\)</span> is
a <span class="math notranslate nohighlight">\(B_1 \times \ldots \times B_k \times N \times D\)</span> tensor.</p></li>
<li><p><strong>active_dims</strong> (<em>param</em>) – Compute the covariance of only a few input dimensions.
The ints corresponds to the indices of the dimensions.</p></li>
<li><p><strong>acos_eps</strong> (<em>param</em>) – A small positive value to restrict acos inputs to
:math`[-1 + epsilon, 1 - epsilon]`</p></li>
<li><p><strong>device</strong> (<em>param</em>) – Device for parameters.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class" id="module-botorch.models.kernels.linear_truncated_fidelity">
<dt class="sig sig-object py" id="botorch.models.kernels.linear_truncated_fidelity.LinearTruncatedFidelityKernel">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.kernels.linear_truncated_fidelity.</span></span><span class="sig-name descname"><span class="pre">LinearTruncatedFidelityKernel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fidelity_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">power_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">power_constraint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nu</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lengthscale_prior_unbiased</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lengthscale_prior_biased</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lengthscale_constraint_unbiased</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lengthscale_constraint_biased</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">covar_module_unbiased</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">covar_module_biased</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/kernels/linear_truncated_fidelity.html#LinearTruncatedFidelityKernel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.kernels.linear_truncated_fidelity.LinearTruncatedFidelityKernel" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Kernel</span></code></p>
<p>GPyTorch Linear Truncated Fidelity Kernel.</p>
<p>Computes a covariance matrix based on the Linear truncated kernel between
inputs <cite>x_1</cite> and <cite>x_2</cite> for up to two fidelity parmeters:</p>
<blockquote>
<div><p>K(x_1, x_2) = k_0 + c_1(x_1, x_2)k_1 + c_2(x_1,x_2)k_2 + c_3(x_1,x_2)k_3</p>
</div></blockquote>
<p>where</p>
<ul class="simple">
<li><dl class="simple">
<dt><cite>k_i(i=0,1,2,3)</cite> are Matern kernels calculated between non-fidelity</dt><dd><p>parameters of <cite>x_1</cite> and <cite>x_2</cite> with different priors.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><cite>c_1=(1 - x_1[f_1])(1 - x_2[f_1]))(1 + x_1[f_1] x_2[f_1])^p</cite> is the kernel</dt><dd><p>of the the bias term, which can be decomposed into a determistic part
and a polynomial kernel. Here <cite>f_1</cite> is the first fidelity dimension and
<cite>p</cite> is the order of the polynomial kernel.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><cite>c_3</cite> is the same as <cite>c_1</cite> but is calculated for the second fidelity</dt><dd><p>dimension <cite>f_2</cite>.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><cite>c_2</cite> is the interaction term with four deterministic terms and the</dt><dd><p>polynomial kernel between <cite>x_1[…, [f_1, f_2]]</cite> and
<cite>x_2[…, [f_1, f_2]]</cite>.</p>
</dd>
</dl>
</li>
</ul>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Non-batch: Simple option</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">covar_module</span> <span class="o">=</span> <span class="n">LinearTruncatedFidelityKernel</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">covar</span> <span class="o">=</span> <span class="n">covar_module</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># Output: LinearOperator of size (10 x 10)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Batch: Simple option</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">covar_module</span> <span class="o">=</span> <span class="n">LinearTruncatedFidelityKernel</span><span class="p">(</span><span class="n">batch_shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">2</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">covar</span> <span class="o">=</span> <span class="n">covar_module</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># Output: LinearOperator of size (2 x 10 x 10)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fidelity_dims</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – A list containing either one or two indices specifying
the fidelity parameters of the input.</p></li>
<li><p><strong>dimension</strong> (<em>int</em><em> | </em><em>None</em>) – The dimension of <cite>x</cite>. Unused if <cite>active_dims</cite> is specified.</p></li>
<li><p><strong>power_prior</strong> (<em>Prior</em><em> | </em><em>None</em>) – Prior for the power parameter of the polynomial kernel.
Default is <cite>None</cite>.</p></li>
<li><p><strong>power_constraint</strong> (<em>Interval</em><em> | </em><em>None</em>) – Constraint on the power parameter of the polynomial
kernel. Default is <cite>Positive</cite>.</p></li>
<li><p><strong>nu</strong> (<em>float</em>) – The smoothness parameter for the Matern kernel: either 1/2, 3/2,
or 5/2. Unused if both <cite>covar_module_unbiased</cite> and
<cite>covar_module_biased</cite> are specified.</p></li>
<li><p><strong>lengthscale_prior_unbiased</strong> (<em>Prior</em><em> | </em><em>None</em>) – Prior on the lengthscale parameter of Matern
kernel <cite>k_0</cite>. Default is <cite>Gamma(1.1, 1/20)</cite>.</p></li>
<li><p><strong>lengthscale_constraint_unbiased</strong> (<em>Interval</em><em> | </em><em>None</em>) – Constraint on the lengthscale parameter
of the Matern kernel <cite>k_0</cite>. Default is <cite>Positive</cite>.</p></li>
<li><p><strong>lengthscale_prior_biased</strong> (<em>Prior</em><em> | </em><em>None</em>) – Prior on the lengthscale parameter of Matern
kernels <cite>k_i(i&gt;0)</cite>. Default is <cite>Gamma(5, 1/20)</cite>.</p></li>
<li><p><strong>lengthscale_constraint_biased</strong> (<em>Interval</em><em> | </em><em>None</em>) – Constraint on the lengthscale parameter
of the Matern kernels <cite>k_i(i&gt;0)</cite>. Default is <cite>Positive</cite>.</p></li>
<li><p><strong>covar_module_unbiased</strong> (<em>Kernel</em><em> | </em><em>None</em>) – Specify a custom kernel for <cite>k_0</cite>. If omitted,
use a <cite>MaternKernel</cite>.</p></li>
<li><p><strong>covar_module_biased</strong> (<em>Kernel</em><em> | </em><em>None</em>) – Specify a custom kernel for the biased parts
<cite>k_i(i&gt;0)</cite>. If omitted, use a <cite>MaternKernel</cite>.</p></li>
<li><p><strong>batch_shape</strong> – If specified, use a separate lengthscale for each batch of
input data. If <cite>x1</cite> is a <cite>batch_shape x n x d</cite> tensor, this should
be <cite>batch_shape</cite>.</p></li>
<li><p><strong>active_dims</strong> – Compute the covariance of a subset of input dimensions. The
numbers correspond to the indices of the dimensions.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class" id="module-botorch.models.kernels.contextual_lcea">
<dt class="sig sig-object py" id="botorch.models.kernels.contextual_lcea.LCEAKernel">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.kernels.contextual_lcea.</span></span><span class="sig-name descname"><span class="pre">LCEAKernel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">decomposition</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_embedding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cat_feature_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embs_feature_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embs_dim_list</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_weight_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/kernels/contextual_lcea.html#LCEAKernel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.kernels.contextual_lcea.LCEAKernel" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Kernel</span></code></p>
<p>The Latent Context Embedding Additive (LCE-A) Kernel.</p>
<p>This kernel is similar to the SACKernel, and is used when context breakdowns are
unbserverable. It assumes the same additive structure and a spatial kernel shared
across contexts. Rather than assuming independence, LCEAKernel models the
correlation in the latent functions for each context through learning context
embeddings.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>decomposition</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>list</em><em>[</em><em>int</em><em>]</em><em>]</em>) – Keys index context names. Values are the indexes of
parameters belong to the context.</p></li>
<li><p><strong>batch_shape</strong> (<em>Size</em>) – Batch shape as usual for gpytorch kernels. Model does not
support batch training. When batch_shape is non-empty, it is used for
loading hyper-parameter values generated from MCMC sampling.</p></li>
<li><p><strong>train_embedding</strong> (<em>bool</em>) – A boolean indictor of whether to learn context embeddings.</p></li>
<li><p><strong>cat_feature_dict</strong> (<em>dict</em><em> | </em><em>None</em>) – Keys are context names and values are list of categorical
features i.e. {“context_name” : [cat_0, …, cat_k]}. k equals the
number of categorical variables. If None, uses context names in the
decomposition as the only categorical feature, i.e., k = 1.</p></li>
<li><p><strong>embs_feature_dict</strong> (<em>dict</em><em> | </em><em>None</em>) – Pre-trained continuous embedding features of each
context.</p></li>
<li><p><strong>embs_dim_list</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – Embedding dimension for each categorical variable. The length
equals to num of categorical features k. If None, the embedding
dimension is set to 1 for each categorical variable.</p></li>
<li><p><strong>context_weight_dict</strong> (<em>dict</em><em> | </em><em>None</em>) – Known population weights of each context.</p></li>
<li><p><strong>device</strong> (<em>device</em><em> | </em><em>None</em>)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class" id="module-botorch.models.kernels.contextual_sac">
<dt class="sig sig-object py" id="botorch.models.kernels.contextual_sac.SACKernel">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.kernels.contextual_sac.</span></span><span class="sig-name descname"><span class="pre">SACKernel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">decomposition</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/kernels/contextual_sac.html#SACKernel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.kernels.contextual_sac.SACKernel" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Kernel</span></code></p>
<p>The structural additive contextual(SAC) kernel.</p>
<p>The kernel is used for contextual BO without oberseving context breakdowns.
There are d parameters and M contexts. In total, the dimension of parameter space
is d*M and input x can be written as
x=[x_11, …, x_1d, x_21, …, x_2d, …,  x_M1, …, x_Md].</p>
<p>The kernel uses the parameter decomposition and assumes an additive structure
across contexts. Each context compponent is assumed to be independent.</p>
<div class="math notranslate nohighlight">
\[\begin{equation*}
   k(\mathbf{x}, \mathbf{x'}) = k_1(\mathbf{x_(1)}, \mathbf{x'_(1)}) + \cdots
   + k_M(\mathbf{x_(M)}, \mathbf{x'_(M)})
\end{equation*}\]</div>
<p>where
* :math: M is the number of partitions of parameter space. Each partition contains
same number of parameters d. Each kernel <cite>k_i</cite> acts only on d parameters of ith
partition i.e. <cite>mathbf{x}_(i)</cite>. Each kernel <cite>k_i</cite> is a scaled RBF kernel
with same lengthscales but different outputscales.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>decomposition</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>list</em><em>[</em><em>int</em><em>]</em><em>]</em>) – Keys are context names. Values are the indexes of parameters
belong to the context. The parameter indexes are in the same order
across contexts.</p></li>
<li><p><strong>batch_shape</strong> (<em>Size</em>) – Batch shape as usual for gpytorch kernels.</p></li>
<li><p><strong>device</strong> (<em>device</em><em> | </em><em>None</em>) – The torch device.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class" id="module-botorch.models.kernels.orthogonal_additive_kernel">
<dt class="sig sig-object py" id="botorch.models.kernels.orthogonal_additive_kernel.OrthogonalAdditiveKernel">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.kernels.orthogonal_additive_kernel.</span></span><span class="sig-name descname"><span class="pre">OrthogonalAdditiveKernel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">base_kernel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">quad_deg</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">second_order</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">coeff_constraint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">Positive()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offset_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">coeffs_1_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">coeffs_2_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/kernels/orthogonal_additive_kernel.html#OrthogonalAdditiveKernel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.kernels.orthogonal_additive_kernel.OrthogonalAdditiveKernel" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Kernel</span></code></p>
<p>Orthogonal Additive Kernels (OAKs) were introduced in <a class="reference internal" href="#lu2022additive" id="id35"><span>[Lu2022additive]</span></a>, though
only for the case of Gaussian base kernels with a Gaussian input data distribution.</p>
<p>The implementation here generalizes OAKs to arbitrary base kernels by using a
Gauss-Legendre quadrature approximation to the required one-dimensional integrals
involving the base kernels.</p>
<div role="list" class="citation-list">
<div class="citation" id="lu2022additive" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id35">Lu2022additive</a><span class="fn-bracket">]</span></span>
<p>X. Lu, A. Boukouvalas, and J. Hensman. Additive Gaussian processes revisited.
Proceedings of the 39th International Conference on Machine Learning. Jul 2022.</p>
</div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>base_kernel</strong> (<em>Kernel</em>) – The kernel which to orthogonalize and evaluate in <cite>forward</cite>.</p></li>
<li><p><strong>dim</strong> (<em>int</em>) – Input dimensionality of the kernel.</p></li>
<li><p><strong>quad_deg</strong> (<em>int</em>) – Number of integration nodes for orthogonalization.</p></li>
<li><p><strong>second_order</strong> (<em>bool</em>) – Toggles second order interactions. If true, both the time and
space complexity of evaluating the kernel are quadratic in <cite>dim</cite>.</p></li>
<li><p><strong>batch_shape</strong> (<em>Size</em><em> | </em><em>None</em>) – Optional batch shape for the kernel and its parameters.</p></li>
<li><p><strong>dtype</strong> (<em>dtype</em><em> | </em><em>None</em>) – Initialization dtype for required Tensors.</p></li>
<li><p><strong>device</strong> (<em>device</em><em> | </em><em>None</em>) – Initialization device for required Tensors.</p></li>
<li><p><strong>coeff_constraint</strong> (<em>Interval</em>) – Constraint on the coefficients of the additive kernel.</p></li>
<li><p><strong>offset_prior</strong> (<em>Prior</em><em> | </em><em>None</em>) – Prior on the offset coefficient. Should be prior with non-
negative support.</p></li>
<li><p><strong>coeffs_1_prior</strong> (<em>Prior</em><em> | </em><em>None</em>) – Prior on the parameter main effects. Should be prior with
non-negative support.</p></li>
<li><p><strong>coeffs_2_prior</strong> (<em>Prior</em><em> | </em><em>None</em>) – coeffs_1_prior: Prior on the parameter interactions. Should
be prior with non-negative support.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-botorch.models.likelihoods.pairwise">
<span id="likelihoods"></span><h3>Likelihoods<a class="headerlink" href="#module-botorch.models.likelihoods.pairwise" title="Link to this heading"></a></h3>
<p>Pairwise likelihood for pairwise preference model (e.g., PairwiseGP).</p>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.likelihoods.pairwise.PairwiseLikelihood">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.likelihoods.pairwise.</span></span><span class="sig-name descname"><span class="pre">PairwiseLikelihood</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">max_plate_nesting</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/likelihoods/pairwise.html#PairwiseLikelihood"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.likelihoods.pairwise.PairwiseLikelihood" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Likelihood</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>Pairwise likelihood base class for pairwise preference GP (e.g., PairwiseGP).</p>
<p>Initialized like a <cite>gpytorch.likelihoods.Likelihood</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>max_plate_nesting</strong> (<em>int</em>) – Defaults to 1.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.likelihoods.pairwise.PairwiseLikelihood.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">utility</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">D</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/likelihoods/pairwise.html#PairwiseLikelihood.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.likelihoods.pairwise.PairwiseLikelihood.forward" title="Link to this definition"></a></dt>
<dd><p>Given the difference in (estimated) utility util_diff = f(v) - f(u),
return a Bernoulli distribution object representing the likelihood of
the user prefer v over u.</p>
<p>Note that this is not used by the <cite>PairwiseGP</cite> model,</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>utility</strong> (<em>Tensor</em>)</p></li>
<li><p><strong>D</strong> (<em>Tensor</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Bernoulli</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.likelihoods.pairwise.PairwiseLikelihood.p">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">p</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">utility</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">D</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/likelihoods/pairwise.html#PairwiseLikelihood.p"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.likelihoods.pairwise.PairwiseLikelihood.p" title="Link to this definition"></a></dt>
<dd><p>Given the difference in (estimated) utility util_diff = f(v) - f(u),
return the probability of the user prefer v over u.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>utility</strong> (<em>Tensor</em>) – A Tensor of shape <cite>(batch_size) x n</cite>, the utility at MAP point</p></li>
<li><p><strong>D</strong> (<em>Tensor</em>) – D is <cite>(batch_size x) m x n</cite> matrix with all elements being zero in last
dimension except at two positions D[…, i] = 1 and D[…, j] = -1
respectively, representing item i is preferred over item j.</p></li>
<li><p><strong>log</strong> – if true, return log probability</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.likelihoods.pairwise.PairwiseLikelihood.log_p">
<span class="sig-name descname"><span class="pre">log_p</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">utility</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">D</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/likelihoods/pairwise.html#PairwiseLikelihood.log_p"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.likelihoods.pairwise.PairwiseLikelihood.log_p" title="Link to this definition"></a></dt>
<dd><p>return the log of p</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>utility</strong> (<em>Tensor</em>)</p></li>
<li><p><strong>D</strong> (<em>Tensor</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.likelihoods.pairwise.PairwiseLikelihood.negative_log_gradient_sum">
<span class="sig-name descname"><span class="pre">negative_log_gradient_sum</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">utility</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">D</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/likelihoods/pairwise.html#PairwiseLikelihood.negative_log_gradient_sum"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.likelihoods.pairwise.PairwiseLikelihood.negative_log_gradient_sum" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Calculate the sum of negative log gradient with respect to each item’s latent</dt><dd><p>utility values. Useful for models using laplace approximation.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>utility</strong> (<em>Tensor</em>) – A Tensor of shape <cite>(batch_size x) n</cite>, the utility at MAP point</p></li>
<li><p><strong>D</strong> (<em>Tensor</em>) – D is <cite>(batch_size x) m x n</cite> matrix with all elements being zero in last
dimension except at two positions D[…, i] = 1 and D[…, j] = -1
respectively, representing item i is preferred over item j.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>(batch_size x) n</cite> Tensor representing the sum of negative log gradient
values of the likelihood over all comparisons (i.e., the m dimension)
with respect to each item.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.likelihoods.pairwise.PairwiseLikelihood.negative_log_hessian_sum">
<span class="sig-name descname"><span class="pre">negative_log_hessian_sum</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">utility</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">D</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/likelihoods/pairwise.html#PairwiseLikelihood.negative_log_hessian_sum"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.likelihoods.pairwise.PairwiseLikelihood.negative_log_hessian_sum" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Calculate the sum of negative log hessian with respect to each item’s latent</dt><dd><p>utility values. Useful for models using laplace approximation.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>utility</strong> (<em>Tensor</em>) – A Tensor of shape <cite>(batch_size) x n</cite>, the utility at MAP point</p></li>
<li><p><strong>D</strong> (<em>Tensor</em>) – D is <cite>(batch_size x) m x n</cite> matrix with all elements being zero in last
dimension except at two positions D[…, i] = 1 and D[…, j] = -1
respectively, representing item i is preferred over item j.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>(batch_size x) n x n</cite> Tensor representing the sum of negative log hessian
values of the likelihood over all comparisons (i.e., the m dimension) with
respect to each item.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.likelihoods.pairwise.PairwiseProbitLikelihood">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.likelihoods.pairwise.</span></span><span class="sig-name descname"><span class="pre">PairwiseProbitLikelihood</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">max_plate_nesting</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/likelihoods/pairwise.html#PairwiseProbitLikelihood"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.likelihoods.pairwise.PairwiseProbitLikelihood" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.likelihoods.pairwise.PairwiseLikelihood" title="botorch.models.likelihoods.pairwise.PairwiseLikelihood"><code class="xref py py-class docutils literal notranslate"><span class="pre">PairwiseLikelihood</span></code></a></p>
<p>Pairwise likelihood using probit function</p>
<p>Given two items v and u with utilities f(v) and f(u), the probability that we
prefer v over u with probability std_normal_cdf((f(v) - f(u))/sqrt(2)). Note
that this formulation implicitly assume the noise term is fixed at 1.</p>
<p>Initialized like a <cite>gpytorch.likelihoods.Likelihood</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>max_plate_nesting</strong> (<em>int</em>) – Defaults to 1.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.likelihoods.pairwise.PairwiseProbitLikelihood.p">
<span class="sig-name descname"><span class="pre">p</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">utility</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">D</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/likelihoods/pairwise.html#PairwiseProbitLikelihood.p"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.likelihoods.pairwise.PairwiseProbitLikelihood.p" title="Link to this definition"></a></dt>
<dd><p>Given the difference in (estimated) utility util_diff = f(v) - f(u),
return the probability of the user prefer v over u.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>utility</strong> (<em>Tensor</em>) – A Tensor of shape <cite>(batch_size) x n</cite>, the utility at MAP point</p></li>
<li><p><strong>D</strong> (<em>Tensor</em>) – D is <cite>(batch_size x) m x n</cite> matrix with all elements being zero in last
dimension except at two positions D[…, i] = 1 and D[…, j] = -1
respectively, representing item i is preferred over item j.</p></li>
<li><p><strong>log</strong> (<em>bool</em>) – if true, return log probability</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.likelihoods.pairwise.PairwiseProbitLikelihood.negative_log_gradient_sum">
<span class="sig-name descname"><span class="pre">negative_log_gradient_sum</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">utility</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">D</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/likelihoods/pairwise.html#PairwiseProbitLikelihood.negative_log_gradient_sum"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.likelihoods.pairwise.PairwiseProbitLikelihood.negative_log_gradient_sum" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Calculate the sum of negative log gradient with respect to each item’s latent</dt><dd><p>utility values. Useful for models using laplace approximation.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>utility</strong> (<em>Tensor</em>) – A Tensor of shape <cite>(batch_size x) n</cite>, the utility at MAP point</p></li>
<li><p><strong>D</strong> (<em>Tensor</em>) – D is <cite>(batch_size x) m x n</cite> matrix with all elements being zero in last
dimension except at two positions D[…, i] = 1 and D[…, j] = -1
respectively, representing item i is preferred over item j.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>(batch_size x) n</cite> Tensor representing the sum of negative log gradient
values of the likelihood over all comparisons (i.e., the m dimension)
with respect to each item.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.likelihoods.pairwise.PairwiseProbitLikelihood.negative_log_hessian_sum">
<span class="sig-name descname"><span class="pre">negative_log_hessian_sum</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">utility</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">D</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/likelihoods/pairwise.html#PairwiseProbitLikelihood.negative_log_hessian_sum"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.likelihoods.pairwise.PairwiseProbitLikelihood.negative_log_hessian_sum" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Calculate the sum of negative log hessian with respect to each item’s latent</dt><dd><p>utility values. Useful for models using laplace approximation.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>utility</strong> (<em>Tensor</em>) – A Tensor of shape <cite>(batch_size) x n</cite>, the utility at MAP point</p></li>
<li><p><strong>D</strong> (<em>Tensor</em>) – D is <cite>(batch_size x) m x n</cite> matrix with all elements being zero in last
dimension except at two positions D[…, i] = 1 and D[…, j] = -1
respectively, representing item i is preferred over item j.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>(batch_size x) n x n</cite> Tensor representing the sum of negative log hessian
values of the likelihood over all comparisons (i.e., the m dimension) with
respect to each item.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.likelihoods.pairwise.PairwiseLogitLikelihood">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.likelihoods.pairwise.</span></span><span class="sig-name descname"><span class="pre">PairwiseLogitLikelihood</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">max_plate_nesting</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/likelihoods/pairwise.html#PairwiseLogitLikelihood"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.likelihoods.pairwise.PairwiseLogitLikelihood" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.likelihoods.pairwise.PairwiseLikelihood" title="botorch.models.likelihoods.pairwise.PairwiseLikelihood"><code class="xref py py-class docutils literal notranslate"><span class="pre">PairwiseLikelihood</span></code></a></p>
<p>Pairwise likelihood using logistic (i.e., sigmoid) function</p>
<p>Given two items v and u with utilities f(v) and f(u), the probability that we
prefer v over u with probability sigmoid(f(v) - f(u)). Note
that this formulation implicitly assume the beta term in logistic function is
fixed at 1.</p>
<p>Initialized like a <cite>gpytorch.likelihoods.Likelihood</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>max_plate_nesting</strong> (<em>int</em>) – Defaults to 1.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.likelihoods.pairwise.PairwiseLogitLikelihood.log_p">
<span class="sig-name descname"><span class="pre">log_p</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">utility</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">D</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/likelihoods/pairwise.html#PairwiseLogitLikelihood.log_p"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.likelihoods.pairwise.PairwiseLogitLikelihood.log_p" title="Link to this definition"></a></dt>
<dd><p>return the log of p</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>utility</strong> (<em>Tensor</em>)</p></li>
<li><p><strong>D</strong> (<em>Tensor</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.likelihoods.pairwise.PairwiseLogitLikelihood.p">
<span class="sig-name descname"><span class="pre">p</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">utility</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">D</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/likelihoods/pairwise.html#PairwiseLogitLikelihood.p"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.likelihoods.pairwise.PairwiseLogitLikelihood.p" title="Link to this definition"></a></dt>
<dd><p>Given the difference in (estimated) utility util_diff = f(v) - f(u),
return the probability of the user prefer v over u.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>utility</strong> (<em>Tensor</em>) – A Tensor of shape <cite>(batch_size) x n</cite>, the utility at MAP point</p></li>
<li><p><strong>D</strong> (<em>Tensor</em>) – D is <cite>(batch_size x) m x n</cite> matrix with all elements being zero in last
dimension except at two positions D[…, i] = 1 and D[…, j] = -1
respectively, representing item i is preferred over item j.</p></li>
<li><p><strong>log</strong> – if true, return log probability</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.likelihoods.pairwise.PairwiseLogitLikelihood.negative_log_gradient_sum">
<span class="sig-name descname"><span class="pre">negative_log_gradient_sum</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">utility</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">D</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/likelihoods/pairwise.html#PairwiseLogitLikelihood.negative_log_gradient_sum"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.likelihoods.pairwise.PairwiseLogitLikelihood.negative_log_gradient_sum" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Calculate the sum of negative log gradient with respect to each item’s latent</dt><dd><p>utility values. Useful for models using laplace approximation.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>utility</strong> (<em>Tensor</em>) – A Tensor of shape <cite>(batch_size x) n</cite>, the utility at MAP point</p></li>
<li><p><strong>D</strong> (<em>Tensor</em>) – D is <cite>(batch_size x) m x n</cite> matrix with all elements being zero in last
dimension except at two positions D[…, i] = 1 and D[…, j] = -1
respectively, representing item i is preferred over item j.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>(batch_size x) n</cite> Tensor representing the sum of negative log gradient
values of the likelihood over all comparisons (i.e., the m dimension)
with respect to each item.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.likelihoods.pairwise.PairwiseLogitLikelihood.negative_log_hessian_sum">
<span class="sig-name descname"><span class="pre">negative_log_hessian_sum</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">utility</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">D</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/likelihoods/pairwise.html#PairwiseLogitLikelihood.negative_log_hessian_sum"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.likelihoods.pairwise.PairwiseLogitLikelihood.negative_log_hessian_sum" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Calculate the sum of negative log hessian with respect to each item’s latent</dt><dd><p>utility values. Useful for models using laplace approximation.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>utility</strong> (<em>Tensor</em>) – A Tensor of shape <cite>(batch_size) x n</cite>, the utility at MAP point</p></li>
<li><p><strong>D</strong> (<em>Tensor</em>) – D is <cite>(batch_size x) m x n</cite> matrix with all elements being zero in last
dimension except at two positions D[…, i] = 1 and D[…, j] = -1
respectively, representing item i is preferred over item j.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>(batch_size x) n x n</cite> Tensor representing the sum of negative log hessian
values of the likelihood over all comparisons (i.e., the m dimension) with
respect to each item.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class" id="module-botorch.models.likelihoods.sparse_outlier_noise">
<dt class="sig sig-object py" id="botorch.models.likelihoods.sparse_outlier_noise.SparseOutlierGaussianLikelihood">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.likelihoods.sparse_outlier_noise.</span></span><span class="sig-name descname"><span class="pre">SparseOutlierGaussianLikelihood</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">base_noise</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outlier_indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rho_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rho_constraint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">convex_parameterization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loo</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/likelihoods/sparse_outlier_noise.html#SparseOutlierGaussianLikelihood"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.likelihoods.sparse_outlier_noise.SparseOutlierGaussianLikelihood" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">_GaussianLikelihoodBase</span></code></p>
<p>A likelihood that models the noise of a GP with SparseOutlierNoise, a noise
model in the Relevance Pursuit family of models, permitting additional “robust”
variance for a small set of outlier data points. Notably, the indices of the
outlier data points are inferred during the optimization of the associated log
marginal likelihood via the Relevance Pursuit algorithm.</p>
<p>For details, see <a class="reference internal" href="#ament2024pursuit" id="id36"><span>[Ament2024pursuit]</span></a> or <a class="reference external" href="https://arxiv.org/abs/2410.24222">https://arxiv.org/abs/2410.24222</a>.</p>
<p>NOTE: Letting base_noise also use the non-transformed constraints, will lead
to more stable optimization, but is orthogonal implementation-wise. If the base
noise is a HomoskedasticNoise, one can pass the non-transformed constraint as
the <cite>noise_constraint</cite>.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">base_noise</span> <span class="o">=</span> <span class="n">HomoskedasticNoise</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="n">noise_constraint</span><span class="o">=</span><span class="n">NonTransformedInterval</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>       <span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e-1</span><span class="p">,</span> <span class="n">initial_value</span><span class="o">=</span><span class="mf">1e-3</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">likelihood</span> <span class="o">=</span> <span class="n">SparseOutlierGaussianLikelihood</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="n">base_noise</span><span class="o">=</span><span class="n">base_noise</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="n">dim</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">train_Y</span><span class="o">=</span><span class="n">Y</span><span class="p">,</span> <span class="n">likelihood</span><span class="o">=</span><span class="n">likelihood</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mll</span> <span class="o">=</span> <span class="n">ExactMarginalLogLikelihood</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># NOTE: `likelihood.noise_covar` is the `RelevancePursuitMixin`</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sparse_module</span> <span class="o">=</span> <span class="n">likelihood</span><span class="o">.</span><span class="n">noise_covar</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">backward_relevance_pursuit</span><span class="p">(</span><span class="n">sparse_module</span><span class="p">,</span> <span class="n">mll</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>base_noise</strong> (<em>Noise</em><em> | </em><em>FixedGaussianNoise</em>) – The base noise model.</p></li>
<li><p><strong>dim</strong> (<em>int</em>) – The number of training observations, which determines the maximum
number of data-point-specific noise variances of the noise model.</p></li>
<li><p><strong>outlier_indices</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – The indices of the outliers.</p></li>
<li><p><strong>rho_prior</strong> (<em>Prior</em><em> | </em><em>None</em>) – Prior for <cite>self.noise_covar</cite>’s rho parameter.</p></li>
<li><p><strong>rho_constraint</strong> (<a class="reference internal" href="utils.html#botorch.utils.constraints.NonTransformedInterval" title="botorch.utils.constraints.NonTransformedInterval"><em>NonTransformedInterval</em></a><em> | </em><em>None</em>) – Constraint for <cite>self.noise_covar</cite>’s rho parameter. Needs to
be a NonTransformedInterval because exact sparsity cannot be represented
using smooth transforms like a softplus or sigmoid.</p></li>
<li><p><strong>batch_shape</strong> (<em>Size</em><em> | </em><em>None</em>) – The batch shape of the learned noise parameter (default: []).</p></li>
<li><p><strong>convex_parameterization</strong> (<em>bool</em>) – Whether to use the convex parameterization of rho,
which generally improves optimization results and is thus recommended.</p></li>
<li><p><strong>loo</strong> (<em>bool</em>) – Whether to use leave-one-out (LOO) update equations that can compute
the optimal values of each individual rho, keeping all else equal.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.likelihoods.sparse_outlier_noise.SparseOutlierGaussianLikelihood.marginal">
<span class="sig-name descname"><span class="pre">marginal</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">function_dist</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/likelihoods/sparse_outlier_noise.html#SparseOutlierGaussianLikelihood.marginal"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.likelihoods.sparse_outlier_noise.SparseOutlierGaussianLikelihood.marginal" title="Link to this definition"></a></dt>
<dd><p>Computes a predictive distribution <span class="math notranslate nohighlight">\(p(y^* | \mathbf x^*)\)</span> given either a posterior
distribution <span class="math notranslate nohighlight">\(p(\mathbf f | \mathcal D, \mathbf x)\)</span> or a
prior distribution <span class="math notranslate nohighlight">\(p(\mathbf f|\mathbf x)\)</span> as input.</p>
<p>With both exact inference and variational inference, the form of
<span class="math notranslate nohighlight">\(p(\mathbf f|\mathcal D, \mathbf x)\)</span> or <span class="math notranslate nohighlight">\(p(\mathbf f|
\mathbf x)\)</span> should usually be Gaussian. As a result, function_dist
should usually be a <code class="xref py py-obj docutils literal notranslate"><span class="pre">MultivariateNormal</span></code> specified by the mean and
(co)variance of <span class="math notranslate nohighlight">\(p(\mathbf f|...)\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>function_dist</strong> (<em>MultivariateNormal</em>) – Distribution for <span class="math notranslate nohighlight">\(f(x)\)</span>.</p></li>
<li><p><strong>args</strong> – Additional args (passed to the forward function).</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – Additional kwargs (passed to the forward function).</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>list</em><em>[</em><em>Tensor</em><em>] </em><em>| </em><em>None</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The marginal distribution, or samples from it.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>MultivariateNormal</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.likelihoods.sparse_outlier_noise.SparseOutlierGaussianLikelihood.expected_log_prob">
<span class="sig-name descname"><span class="pre">expected_log_prob</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/likelihoods/sparse_outlier_noise.html#SparseOutlierGaussianLikelihood.expected_log_prob"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.likelihoods.sparse_outlier_noise.SparseOutlierGaussianLikelihood.expected_log_prob" title="Link to this definition"></a></dt>
<dd><p>(Used by <code class="xref py py-obj docutils literal notranslate"><span class="pre">VariationalELBO</span></code> for variational inference.)</p>
<p>Computes the expected log likelihood, where the expectation is over the GP variational distribution.</p>
<div class="math notranslate nohighlight">
\[\sum_{\mathbf x, y} \mathbb{E}_{q\left( f(\mathbf x) \right)}
\left[ \log p \left( y \mid f(\mathbf x) \right) \right]\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observations</strong> – Values of <span class="math notranslate nohighlight">\(y\)</span>.</p></li>
<li><p><strong>function_dist</strong> – Distribution for <span class="math notranslate nohighlight">\(f(x)\)</span>.</p></li>
<li><p><strong>args</strong> – Additional args (passed to the forward function).</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – Additional kwargs (passed to the forward function).</p></li>
<li><p><strong>target</strong> (<em>Tensor</em>)</p></li>
<li><p><strong>input</strong> (<em>MultivariateNormal</em>)</p></li>
<li><p><strong>params</strong> (<em>Any</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.likelihoods.sparse_outlier_noise.SparseOutlierNoise">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.likelihoods.sparse_outlier_noise.</span></span><span class="sig-name descname"><span class="pre">SparseOutlierNoise</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">base_noise</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outlier_indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rho_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rho_constraint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">convex_parameterization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loo</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/likelihoods/sparse_outlier_noise.html#SparseOutlierNoise"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.likelihoods.sparse_outlier_noise.SparseOutlierNoise" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Noise</span></code>, <a class="reference internal" href="#botorch.models.relevance_pursuit.RelevancePursuitMixin" title="botorch.models.relevance_pursuit.RelevancePursuitMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">RelevancePursuitMixin</span></code></a></p>
<p>A noise model in the Relevance Pursuit family of models, permitting
additional “robust” variance for a small set of outlier data points.
See also <cite>SparseOutlierGaussianLikelihood</cite>, which leverages this noise model.</p>
<p>For details, see <a class="reference internal" href="#ament2024pursuit" id="id37"><span>[Ament2024pursuit]</span></a> or <a class="reference external" href="https://arxiv.org/abs/2410.24222">https://arxiv.org/abs/2410.24222</a>.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">base_noise</span> <span class="o">=</span> <span class="n">HomoskedasticNoise</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="n">noise_constraint</span><span class="o">=</span><span class="n">NonTransformedInterval</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>       <span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e-1</span><span class="p">,</span> <span class="n">initial_value</span><span class="o">=</span><span class="mf">1e-3</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">likelihood</span> <span class="o">=</span> <span class="n">SparseOutlierGaussianLikelihood</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="n">base_noise</span><span class="o">=</span><span class="n">base_noise</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="n">dim</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">train_Y</span><span class="o">=</span><span class="n">Y</span><span class="p">,</span> <span class="n">likelihood</span><span class="o">=</span><span class="n">likelihood</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mll</span> <span class="o">=</span> <span class="n">ExactMarginalLogLikelihood</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># NOTE: `likelihood.noise_covar` is the `SparseOutlierNoise`</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sparse_module</span> <span class="o">=</span> <span class="n">likelihood</span><span class="o">.</span><span class="n">noise_covar</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">backward_relevance_pursuit</span><span class="p">(</span><span class="n">sparse_module</span><span class="p">,</span> <span class="n">mll</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>base_noise</strong> (<em>Noise</em><em> | </em><em>FixedGaussianNoise</em>) – The base noise model.</p></li>
<li><p><strong>dim</strong> (<em>int</em>) – The number of training observations, which determines the maximum
number of data-point-specific noise variances of the noise model.</p></li>
<li><p><strong>outlier_indices</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – The indices of the outliers.</p></li>
<li><p><strong>rho_prior</strong> (<em>Prior</em><em> | </em><em>None</em>) – Prior for the rho parameter.</p></li>
<li><p><strong>rho_constraint</strong> (<a class="reference internal" href="utils.html#botorch.utils.constraints.NonTransformedInterval" title="botorch.utils.constraints.NonTransformedInterval"><em>NonTransformedInterval</em></a><em> | </em><em>None</em>) – Constraint for the rho parameter. Needs to be a
NonTransformedInterval because exact sparsity cannot be represented
using smooth transforms like a softplus or sigmoid.</p></li>
<li><p><strong>batch_shape</strong> (<em>Size</em><em> | </em><em>None</em>) – The batch shape of the learned noise parameter (default: []).</p></li>
<li><p><strong>convex_parameterization</strong> (<em>bool</em>) – Whether to use the convex parameterization of rho,
which generally improves optimization results and is thus recommended.</p></li>
<li><p><strong>loo</strong> (<em>bool</em>) – Whether to use leave-one-out (LOO) update equations that can compute
the optimal values of each individual rho, keeping all else equal.</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.likelihoods.sparse_outlier_noise.SparseOutlierNoise.sparse_parameter">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">sparse_parameter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Parameter</span></em><a class="headerlink" href="#botorch.models.likelihoods.sparse_outlier_noise.SparseOutlierNoise.sparse_parameter" title="Link to this definition"></a></dt>
<dd><p>The sparse parameter, required to have a single indexing dimension.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.likelihoods.sparse_outlier_noise.SparseOutlierNoise.set_sparse_parameter">
<span class="sig-name descname"><span class="pre">set_sparse_parameter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/likelihoods/sparse_outlier_noise.html#SparseOutlierNoise.set_sparse_parameter"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.likelihoods.sparse_outlier_noise.SparseOutlierNoise.set_sparse_parameter" title="Link to this definition"></a></dt>
<dd><p>Sets the sparse parameter.</p>
<p>NOTE: We can’t use the property setter &#64;sparse_parameter.setter because of
the special way PyTorch treats Parameter types, including custom setters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>value</strong> (<em>Parameter</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.likelihoods.sparse_outlier_noise.SparseOutlierNoise.convex_parameterization">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">convex_parameterization</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.likelihoods.sparse_outlier_noise.SparseOutlierNoise.convex_parameterization" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.likelihoods.sparse_outlier_noise.SparseOutlierNoise.rho">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">rho</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tensor</span></em><a class="headerlink" href="#botorch.models.likelihoods.sparse_outlier_noise.SparseOutlierNoise.rho" title="Link to this definition"></a></dt>
<dd><p>Dense representation of the data-point-specific variances, corresponding to
the latent <cite>self.raw_rho</cite> values, which might be represented sparsely or in the
convex parameterization. The last dimension is equal to the number of training
points <cite>self.dim</cite>.</p>
<p>NOTE: <cite>rho</cite> differs from <cite>self.sparse_parameter</cite> in that the latter returns the
the parameter in its sparse representation when <cite>self.is_sparse</cite> is true, and in
its latent convex paramzeterization when <cite>self.convex_parameterization</cite> is true,
while <cite>rho</cite> always returns the data-point-specific variances, embedded in a
dense tensor. The dense representation is used to propagate gradients to the
sparse rhos in the support.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A <cite>batch_shape x self.dim</cite>-dim Tensor of robustness variances.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.likelihoods.sparse_outlier_noise.SparseOutlierNoise.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">diag_K</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/likelihoods/sparse_outlier_noise.html#SparseOutlierNoise.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.likelihoods.sparse_outlier_noise.SparseOutlierNoise.forward" title="Link to this definition"></a></dt>
<dd><p>Computes the covariance matrix of the sparse outlier noise model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>list</em><em>[</em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – The training inputs, used to determine if the model is applied to the
training data, in which case the outlier variances are applied, or not.
NOTE: By default, BoTorch passes the transformed training inputs to
the likelihood during both training and inference.</p></li>
<li><p><strong>shape</strong> (<em>Size</em><em> | </em><em>None</em>) – The shape of the covariance matrix, which is used to broadcast the
rho values to the correct shape.</p></li>
<li><p><strong>diag_K</strong> (<em>Tensor</em><em> | </em><em>None</em>) – The diagonal of the covariance matrix, which is used to scale the
rho values in the convex parameterization.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – Any additional parameters of the base noise model, same as for
GPyTorch’s noise model. Note that this implementation does not support
non-kwarg <cite>params</cite> arguments, which are used in GPyTorch’s noise models.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape x self.dim</cite>-dim Tensor of robustness variances.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>LinearOperator</em> | <em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.likelihoods.sparse_outlier_noise.SparseOutlierNoise.expansion_objective">
<span class="sig-name descname"><span class="pre">expansion_objective</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mll</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/likelihoods/sparse_outlier_noise.html#SparseOutlierNoise.expansion_objective"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.likelihoods.sparse_outlier_noise.SparseOutlierNoise.expansion_objective" title="Link to this definition"></a></dt>
<dd><p>Computes an objective value for all the inactive parameters, i.e.
self.sparse_parameter[~self.is_active] since we can’t add already active
parameters to the support. This value will be used to select the parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>mll</strong> (<em>ExactMarginalLogLikelihood</em>) – The marginal likelihood, containing the model to optimize.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The expansion objective value for all the inactive parameters.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="transforms">
<h2>Transforms<a class="headerlink" href="#transforms" title="Link to this heading"></a></h2>
<section id="module-botorch.models.transforms.outcome">
<span id="outcome-transforms"></span><h3>Outcome Transforms<a class="headerlink" href="#module-botorch.models.transforms.outcome" title="Link to this heading"></a></h3>
<p>Outcome transformations for automatically transforming and un-transforming
model outputs. Outcome transformations are typically part of a Model and
applied (i) within the model constructor to transform the train observations
to the model space, and (ii) in the <cite>Model.posterior</cite> call to untransform
the model posterior back to the original space.</p>
<p>References</p>
<div role="list" class="citation-list">
<div class="citation" id="eriksson2021scalable" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id38">eriksson2021scalable</a><span class="fn-bracket">]</span></span>
<p>D. Eriksson, M. Poloczek. Scalable Constrained Bayesian Optimization.
International Conference on Artificial Intelligence and Statistics. PMLR, 2021,
<a class="reference external" href="http://proceedings.mlr.press/v130/eriksson21a.html">http://proceedings.mlr.press/v130/eriksson21a.html</a></p>
</div>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.OutcomeTransform">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.outcome.</span></span><span class="sig-name descname"><span class="pre">OutcomeTransform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#OutcomeTransform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.OutcomeTransform" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>Abstract base class for outcome transforms.</p>
<p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="field-list simple">
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.OutcomeTransform.forward">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Yvar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#OutcomeTransform.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.OutcomeTransform.forward" title="Link to this definition"></a></dt>
<dd><p>Transform the outcomes in a model’s training targets</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Y</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of training targets.</p></li>
<li><p><strong>Yvar</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of observation noises
associated with the training targets (if applicable).</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of training inputs (if applicable).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The transformed outcome observations.</p></li>
<li><p>The transformed observation noise (if applicable).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>A two-tuple with the transformed outcomes</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.OutcomeTransform.subset_output">
<span class="sig-name descname"><span class="pre">subset_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idcs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#OutcomeTransform.subset_output"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.OutcomeTransform.subset_output" title="Link to this definition"></a></dt>
<dd><p>Subset the transform along the output dimension.</p>
<p>This functionality is used to properly treat outcome transformations
in the <cite>subset_model</cite> functionality.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>idcs</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – The output indices to subset the transform to.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The current outcome transform, subset to the specified output indices.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><em>OutcomeTransform</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.OutcomeTransform.untransform">
<span class="sig-name descname"><span class="pre">untransform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Yvar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#OutcomeTransform.untransform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.OutcomeTransform.untransform" title="Link to this definition"></a></dt>
<dd><p>Un-transform previously transformed outcomes</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Y</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of transfomred training targets.</p></li>
<li><p><strong>Yvar</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of transformed observation
noises associated with the training targets (if applicable).</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of training inputs (if applicable).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The un-transformed outcome observations.</p></li>
<li><p>The un-transformed observation noise (if applicable).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>A two-tuple with the un-transformed outcomes</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.OutcomeTransform.untransform_posterior">
<span class="sig-name descname"><span class="pre">untransform_posterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">posterior</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#OutcomeTransform.untransform_posterior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.OutcomeTransform.untransform_posterior" title="Link to this definition"></a></dt>
<dd><p>Un-transform a posterior.</p>
<p>Posteriors with <cite>_is_linear=True</cite> should return a <cite>GPyTorchPosterior</cite> when
<cite>posterior</cite> is a <cite>GPyTorchPosterior</cite>. Posteriors with <cite>_is_linear=False</cite>
likely return a <cite>TransformedPosterior</cite> instead.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>posterior</strong> (<a class="reference internal" href="posteriors.html#botorch.posteriors.posterior.Posterior" title="botorch.posteriors.posterior.Posterior"><em>Posterior</em></a>) – A posterior in the transformed space.</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of training inputs (if applicable).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The un-transformed posterior.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.posterior.Posterior" title="botorch.posteriors.posterior.Posterior"><em>Posterior</em></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.ChainedOutcomeTransform">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.outcome.</span></span><span class="sig-name descname"><span class="pre">ChainedOutcomeTransform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">transforms</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#ChainedOutcomeTransform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.ChainedOutcomeTransform" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">OutcomeTransform</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ModuleDict</span></code></p>
<p>An outcome transform representing the chaining of individual transforms</p>
<p>Chaining of outcome transforms.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>transforms</strong> (<a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><em>OutcomeTransform</em></a>) – The transforms to chain. Internally, the names of the
kwargs are used as the keys for accessing the individual
transforms on the module.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.ChainedOutcomeTransform.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Yvar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#ChainedOutcomeTransform.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.ChainedOutcomeTransform.forward" title="Link to this definition"></a></dt>
<dd><p>Transform the outcomes in a model’s training targets</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Y</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of training targets.</p></li>
<li><p><strong>Yvar</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of observation noises
associated with the training targets (if applicable).</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of training inputs (if applicable).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The transformed outcome observations.</p></li>
<li><p>The transformed observation noise (if applicable).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>A two-tuple with the transformed outcomes</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.ChainedOutcomeTransform.subset_output">
<span class="sig-name descname"><span class="pre">subset_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idcs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#ChainedOutcomeTransform.subset_output"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.ChainedOutcomeTransform.subset_output" title="Link to this definition"></a></dt>
<dd><p>Subset the transform along the output dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>idcs</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – The output indices to subset the transform to.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The current outcome transform, subset to the specified output indices.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><em>OutcomeTransform</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.ChainedOutcomeTransform.untransform">
<span class="sig-name descname"><span class="pre">untransform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Yvar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#ChainedOutcomeTransform.untransform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.ChainedOutcomeTransform.untransform" title="Link to this definition"></a></dt>
<dd><p>Un-transform previously transformed outcomes</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Y</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of transfomred training targets.</p></li>
<li><p><strong>Yvar</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of transformed observation
noises associated with the training targets (if applicable).</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of training inputs (if applicable).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The un-transformed outcome observations.</p></li>
<li><p>The un-transformed observation noise (if applicable).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>A two-tuple with the un-transformed outcomes</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.ChainedOutcomeTransform.untransform_posterior">
<span class="sig-name descname"><span class="pre">untransform_posterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">posterior</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#ChainedOutcomeTransform.untransform_posterior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.ChainedOutcomeTransform.untransform_posterior" title="Link to this definition"></a></dt>
<dd><p>Un-transform a posterior</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>posterior</strong> (<a class="reference internal" href="posteriors.html#botorch.posteriors.posterior.Posterior" title="botorch.posteriors.posterior.Posterior"><em>Posterior</em></a>) – A posterior in the transformed space.</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of training inputs (if applicable).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The un-transformed posterior.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.posterior.Posterior" title="botorch.posteriors.posterior.Posterior"><em>Posterior</em></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.Standardize">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.outcome.</span></span><span class="sig-name descname"><span class="pre">Standardize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">m</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_stdv</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-08</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#Standardize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.Standardize" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">OutcomeTransform</span></code></a></p>
<p>Standardize outcomes (zero mean, unit variance).</p>
<p>This module is stateful: If in train mode, calling forward updates the
module state (i.e. the mean/std normalizing constants). If in eval mode,
calling forward simply applies the standardization using the current module
state.</p>
<p>Standardize outcomes (zero mean, unit variance).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>m</strong> (<em>int</em>) – The output dimension.</p></li>
<li><p><strong>outputs</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – Which of the outputs to standardize. If omitted, all
outputs will be standardized.</p></li>
<li><p><strong>batch_shape</strong> (<em>torch.Size</em>) – The batch_shape of the training targets.</p></li>
<li><p><strong>min_stddv</strong> – The minimum standard deviation for which to perform
standardization (if lower, only de-mean the data).</p></li>
<li><p><strong>min_stdv</strong> (<em>float</em>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.Standardize.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Yvar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#Standardize.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.Standardize.forward" title="Link to this definition"></a></dt>
<dd><p>Standardize outcomes.</p>
<p>If the module is in train mode, this updates the module state (i.e. the
mean/std normalizing constants). If the module is in eval mode, simply
applies the normalization using the module state.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Y</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of training targets.</p></li>
<li><p><strong>Yvar</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of observation noises
associated with the training targets (if applicable).</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of training inputs (if applicable).
This argument is not used by this transform, but it is used by
its subclass, <cite>StratifiedStandardize</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The transformed outcome observations.</p></li>
<li><p>The transformed observation noise (if applicable).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>A two-tuple with the transformed outcomes</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.Standardize.subset_output">
<span class="sig-name descname"><span class="pre">subset_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idcs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#Standardize.subset_output"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.Standardize.subset_output" title="Link to this definition"></a></dt>
<dd><p>Subset the transform along the output dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>idcs</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – The output indices to subset the transform to.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The current outcome transform, subset to the specified output indices.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><em>OutcomeTransform</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.Standardize.untransform">
<span class="sig-name descname"><span class="pre">untransform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Yvar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#Standardize.untransform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.Standardize.untransform" title="Link to this definition"></a></dt>
<dd><p>Un-standardize outcomes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Y</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of standardized targets.</p></li>
<li><p><strong>Yvar</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of standardized observation
noises associated with the targets (if applicable).</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of inputs (if applicable).
This argument is not used by this transform, but it is used by
its subclass, <cite>StratifiedStandardize</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The un-standardized outcome observations.</p></li>
<li><p>The un-standardized observation noise (if applicable).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>A two-tuple with the un-standardized outcomes</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.Standardize.untransform_posterior">
<span class="sig-name descname"><span class="pre">untransform_posterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">posterior</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#Standardize.untransform_posterior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.Standardize.untransform_posterior" title="Link to this definition"></a></dt>
<dd><p>Un-standardize the posterior.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>posterior</strong> (<a class="reference internal" href="posteriors.html#botorch.posteriors.posterior.Posterior" title="botorch.posteriors.posterior.Posterior"><em>Posterior</em></a>) – A posterior in the standardized space.</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of inputs (if applicable).
This argument is not used by this transform, but it is used by
its subclass, <cite>StratifiedStandardize</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The un-standardized posterior. If the input posterior is a
<cite>GPyTorchPosterior</cite>, return a <cite>GPyTorchPosterior</cite>. Otherwise, return a
<cite>TransformedPosterior</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.gpytorch.GPyTorchPosterior" title="botorch.posteriors.gpytorch.GPyTorchPosterior"><em>GPyTorchPosterior</em></a> | <a class="reference internal" href="posteriors.html#botorch.posteriors.transformed.TransformedPosterior" title="botorch.posteriors.transformed.TransformedPosterior"><em>TransformedPosterior</em></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.StratifiedStandardize">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.outcome.</span></span><span class="sig-name descname"><span class="pre">StratifiedStandardize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task_values</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stratification_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_stdv</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-08</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#StratifiedStandardize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.StratifiedStandardize" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.transforms.outcome.Standardize" title="botorch.models.transforms.outcome.Standardize"><code class="xref py py-class docutils literal notranslate"><span class="pre">Standardize</span></code></a></p>
<p>Standardize outcomes (zero mean, unit variance) along stratification dimension.</p>
<p>This module is stateful: If in train mode, calling forward updates the
module state (i.e. the mean/std normalizing constants). If in eval mode,
calling forward simply applies the standardization using the current module
state.</p>
<p>Standardize outcomes (zero mean, unit variance) along stratification dim.</p>
<p>Note: This currenlty only supports single output models
(including multi-task models that have a single output).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>task_values</strong> (<em>Tensor</em>) – <cite>t</cite>-dim tensor of task values.</p></li>
<li><p><strong>stratification_idx</strong> (<em>int</em>) – The index of the stratification dimension.</p></li>
<li><p><strong>batch_shape</strong> (<em>torch.Size</em>) – The batch_shape of the training targets.</p></li>
<li><p><strong>min_stddv</strong> – The minimum standard deviation for which to perform
standardization (if lower, only de-mean the data).</p></li>
<li><p><strong>min_stdv</strong> (<em>float</em>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.StratifiedStandardize.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Yvar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#StratifiedStandardize.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.StratifiedStandardize.forward" title="Link to this definition"></a></dt>
<dd><p>Standardize outcomes.</p>
<p>If the module is in train mode, this updates the module state (i.e. the
mean/std normalizing constants). If the module is in eval mode, simply
applies the normalization using the module state.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Y</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of training targets.</p></li>
<li><p><strong>Yvar</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of observation noises
associated with the training targets (if applicable).</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of input parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The transformed outcome observations.</p></li>
<li><p>The transformed observation noise (if applicable).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>A two-tuple with the transformed outcomes</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.StratifiedStandardize.subset_output">
<span class="sig-name descname"><span class="pre">subset_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idcs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#StratifiedStandardize.subset_output"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.StratifiedStandardize.subset_output" title="Link to this definition"></a></dt>
<dd><p>Subset the transform along the output dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>idcs</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – The output indices to subset the transform to.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The current outcome transform, subset to the specified output indices.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><em>OutcomeTransform</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.StratifiedStandardize.untransform">
<span class="sig-name descname"><span class="pre">untransform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Yvar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#StratifiedStandardize.untransform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.StratifiedStandardize.untransform" title="Link to this definition"></a></dt>
<dd><p>Un-standardize outcomes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Y</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of standardized targets.</p></li>
<li><p><strong>Yvar</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of standardized observation
noises associated with the targets (if applicable).</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of input parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The un-standardized outcome observations.</p></li>
<li><p>The un-standardized observation noise (if applicable).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>A two-tuple with the un-standardized outcomes</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.StratifiedStandardize.untransform_posterior">
<span class="sig-name descname"><span class="pre">untransform_posterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">posterior</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#StratifiedStandardize.untransform_posterior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.StratifiedStandardize.untransform_posterior" title="Link to this definition"></a></dt>
<dd><p>Un-standardize the posterior.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>posterior</strong> (<a class="reference internal" href="posteriors.html#botorch.posteriors.posterior.Posterior" title="botorch.posteriors.posterior.Posterior"><em>Posterior</em></a>) – A posterior in the standardized space.</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of training inputs (if applicable).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The un-standardized posterior. If the input posterior is a
<cite>GPyTorchPosterior</cite>, return a <cite>GPyTorchPosterior</cite>. Otherwise, return a
<cite>TransformedPosterior</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.gpytorch.GPyTorchPosterior" title="botorch.posteriors.gpytorch.GPyTorchPosterior"><em>GPyTorchPosterior</em></a> | <a class="reference internal" href="posteriors.html#botorch.posteriors.transformed.TransformedPosterior" title="botorch.posteriors.transformed.TransformedPosterior"><em>TransformedPosterior</em></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.Log">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.outcome.</span></span><span class="sig-name descname"><span class="pre">Log</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">outputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#Log"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.Log" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">OutcomeTransform</span></code></a></p>
<p>Log-transform outcomes.</p>
<p>Useful if the targets are modeled using a (multivariate) log-Normal
distribution. This means that we can use a standard GP model on the
log-transformed outcomes and un-transform the model posterior of that GP.</p>
<p>Log-transform outcomes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>outputs</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – Which of the outputs to log-transform. If omitted, all
outputs will be standardized.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.Log.subset_output">
<span class="sig-name descname"><span class="pre">subset_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idcs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#Log.subset_output"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.Log.subset_output" title="Link to this definition"></a></dt>
<dd><p>Subset the transform along the output dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>idcs</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – The output indices to subset the transform to.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The current outcome transform, subset to the specified output indices.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><em>OutcomeTransform</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.Log.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Yvar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#Log.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.Log.forward" title="Link to this definition"></a></dt>
<dd><p>Log-transform outcomes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Y</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of training targets.</p></li>
<li><p><strong>Yvar</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of observation noises
associated with the training targets (if applicable).</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of training inputs (if applicable).
This argument is not used by this transform.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The transformed outcome observations.</p></li>
<li><p>The transformed observation noise (if applicable).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>A two-tuple with the transformed outcomes</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.Log.untransform">
<span class="sig-name descname"><span class="pre">untransform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Yvar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#Log.untransform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.Log.untransform" title="Link to this definition"></a></dt>
<dd><p>Un-transform log-transformed outcomes</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Y</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of log-transfomred targets.</p></li>
<li><p><strong>Yvar</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of log- transformed
observation noises associated with the training targets
(if applicable).</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of inputs (if applicable).
This argument is not used by this transform.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The exponentiated outcome observations.</p></li>
<li><p>The exponentiated observation noise (if applicable).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>A two-tuple with the un-transformed outcomes</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.Log.untransform_posterior">
<span class="sig-name descname"><span class="pre">untransform_posterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">posterior</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#Log.untransform_posterior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.Log.untransform_posterior" title="Link to this definition"></a></dt>
<dd><p>Un-transform the log-transformed posterior.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>posterior</strong> (<a class="reference internal" href="posteriors.html#botorch.posteriors.posterior.Posterior" title="botorch.posteriors.posterior.Posterior"><em>Posterior</em></a>) – A posterior in the log-transformed space.</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of inputs (if applicable).
This argument is not used by this transform.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The un-transformed posterior.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.transformed.TransformedPosterior" title="botorch.posteriors.transformed.TransformedPosterior"><em>TransformedPosterior</em></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.Power">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.outcome.</span></span><span class="sig-name descname"><span class="pre">Power</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">power</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#Power"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.Power" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">OutcomeTransform</span></code></a></p>
<p>Power-transform outcomes.</p>
<p>Useful if the targets are modeled using a (multivariate) power transform of
a Normal distribution. This means that we can use a standard GP model on the
power-transformed outcomes and un-transform the model posterior of that GP.</p>
<p>Power-transform outcomes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>outputs</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – Which of the outputs to power-transform. If omitted, all
outputs will be standardized.</p></li>
<li><p><strong>power</strong> (<em>float</em>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.Power.subset_output">
<span class="sig-name descname"><span class="pre">subset_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idcs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#Power.subset_output"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.Power.subset_output" title="Link to this definition"></a></dt>
<dd><p>Subset the transform along the output dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>idcs</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – The output indices to subset the transform to.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The current outcome transform, subset to the specified output indices.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><em>OutcomeTransform</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.Power.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Yvar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#Power.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.Power.forward" title="Link to this definition"></a></dt>
<dd><p>Power-transform outcomes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Y</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of training targets.</p></li>
<li><p><strong>Yvar</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of observation noises
associated with the training targets (if applicable).</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of training inputs (if applicable).
This argument is not used by this transform.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The transformed outcome observations.</p></li>
<li><p>The transformed observation noise (if applicable).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>A two-tuple with the transformed outcomes</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.Power.untransform">
<span class="sig-name descname"><span class="pre">untransform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Yvar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#Power.untransform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.Power.untransform" title="Link to this definition"></a></dt>
<dd><p>Un-transform power-transformed outcomes</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Y</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of power-transfomred targets.</p></li>
<li><p><strong>Yvar</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of power-transformed
observation noises associated with the training targets
(if applicable).</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of inputs (if applicable).
This argument is not used by this transform.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The un-power transformed outcome observations.</p></li>
<li><p>The un-power transformed observation noise (if applicable).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>A two-tuple with the un-transformed outcomes</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.Power.untransform_posterior">
<span class="sig-name descname"><span class="pre">untransform_posterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">posterior</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#Power.untransform_posterior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.Power.untransform_posterior" title="Link to this definition"></a></dt>
<dd><p>Un-transform the power-transformed posterior.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>posterior</strong> (<a class="reference internal" href="posteriors.html#botorch.posteriors.posterior.Posterior" title="botorch.posteriors.posterior.Posterior"><em>Posterior</em></a>) – A posterior in the power-transformed space.</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of inputs (if applicable).
This argument is not used by this transform.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The un-transformed posterior.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.transformed.TransformedPosterior" title="botorch.posteriors.transformed.TransformedPosterior"><em>TransformedPosterior</em></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.Bilog">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.outcome.</span></span><span class="sig-name descname"><span class="pre">Bilog</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">outputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#Bilog"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.Bilog" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">OutcomeTransform</span></code></a></p>
<p>Bilog-transform outcomes.</p>
<p>The Bilog transform <a class="reference internal" href="#eriksson2021scalable" id="id38"><span>[eriksson2021scalable]</span></a> is useful for modeling outcome
constraints as it magnifies values near zero and flattens extreme values.</p>
<p>Bilog-transform outcomes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>outputs</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – Which of the outputs to Bilog-transform. If omitted, all
outputs will be transformed.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.Bilog.subset_output">
<span class="sig-name descname"><span class="pre">subset_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idcs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#Bilog.subset_output"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.Bilog.subset_output" title="Link to this definition"></a></dt>
<dd><p>Subset the transform along the output dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>idcs</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – The output indices to subset the transform to.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The current outcome transform, subset to the specified output indices.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><em>OutcomeTransform</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.Bilog.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Yvar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#Bilog.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.Bilog.forward" title="Link to this definition"></a></dt>
<dd><p>Bilog-transform outcomes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Y</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of training targets.</p></li>
<li><p><strong>Yvar</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of observation noises
associated with the training targets (if applicable).</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of training inputs (if applicable).
This argument is not used by this transform.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The transformed outcome observations.</p></li>
<li><p>The transformed observation noise (if applicable).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>A two-tuple with the transformed outcomes</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.Bilog.untransform">
<span class="sig-name descname"><span class="pre">untransform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Yvar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#Bilog.untransform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.Bilog.untransform" title="Link to this definition"></a></dt>
<dd><p>Un-transform bilog-transformed outcomes</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Y</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of bilog-transfomred targets.</p></li>
<li><p><strong>Yvar</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of bilog-transformed
observation noises associated with the training targets
(if applicable).</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of inputs (if applicable).
This argument is not used by this transform.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The un-transformed outcome observations.</p></li>
<li><p>The un-transformed observation noise (if applicable).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>A two-tuple with the un-transformed outcomes</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.Bilog.untransform_posterior">
<span class="sig-name descname"><span class="pre">untransform_posterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">posterior</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#Bilog.untransform_posterior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.Bilog.untransform_posterior" title="Link to this definition"></a></dt>
<dd><p>Un-transform the bilog-transformed posterior.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>posterior</strong> (<a class="reference internal" href="posteriors.html#botorch.posteriors.posterior.Posterior" title="botorch.posteriors.posterior.Posterior"><em>Posterior</em></a>) – A posterior in the bilog-transformed space.</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of inputs (if applicable).
This argument is not used by this transform.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The un-transformed posterior.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.transformed.TransformedPosterior" title="botorch.posteriors.transformed.TransformedPosterior"><em>TransformedPosterior</em></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-botorch.models.transforms.input">
<span id="input-transforms"></span><h3>Input Transforms<a class="headerlink" href="#module-botorch.models.transforms.input" title="Link to this heading"></a></h3>
<p>Input Transformations.</p>
<p>These classes implement a variety of transformations for
input parameters including: learned input warping functions,
rounding functions, and log transformations. The input transformation
is typically part of a Model and applied within the model.forward()
method.</p>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.transforms.input.InputTransform">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.input.</span></span><span class="sig-name descname"><span class="pre">InputTransform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#InputTransform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.InputTransform" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>Abstract base class for input transforms.</p>
<dl class="simple">
<dt>Properties:</dt><dd><dl class="simple">
<dt>is_one_to_many: A boolean denoting whether the transform produces</dt><dd><p>multiple values for each input.</p>
</dd>
<dt>transform_on_train: A boolean indicating whether to apply the</dt><dd><p>transform in train() mode.</p>
</dd>
<dt>transform_on_eval: A boolean indicating whether to apply the</dt><dd><p>transform in eval() mode.</p>
</dd>
<dt>transform_on_fantasize: A boolean indicating whether to apply</dt><dd><p>the transform when called from within a <cite>fantasize</cite> call.</p>
</dd>
</dl>
</dd>
</dl>
<p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="field-list simple">
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.transforms.input.InputTransform.is_one_to_many">
<span class="sig-name descname"><span class="pre">is_one_to_many</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#botorch.models.transforms.input.InputTransform.is_one_to_many" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.transforms.input.InputTransform.transform_on_eval">
<span class="sig-name descname"><span class="pre">transform_on_eval</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.transforms.input.InputTransform.transform_on_eval" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.transforms.input.InputTransform.transform_on_train">
<span class="sig-name descname"><span class="pre">transform_on_train</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.transforms.input.InputTransform.transform_on_train" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.transforms.input.InputTransform.transform_on_fantasize">
<span class="sig-name descname"><span class="pre">transform_on_fantasize</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.transforms.input.InputTransform.transform_on_fantasize" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.InputTransform.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#InputTransform.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.InputTransform.forward" title="Link to this definition"></a></dt>
<dd><p>Transform the inputs to a model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of inputs.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape x n’ x d</cite>-dim tensor of transformed inputs.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.InputTransform.transform">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#InputTransform.transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.InputTransform.transform" title="Link to this definition"></a></dt>
<dd><p>Transform the inputs to a model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of inputs.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape x n x d</cite>-dim tensor of transformed inputs.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.InputTransform.untransform">
<span class="sig-name descname"><span class="pre">untransform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#InputTransform.untransform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.InputTransform.untransform" title="Link to this definition"></a></dt>
<dd><p>Un-transform the inputs to a model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of transformed inputs.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape x n x d</cite>-dim tensor of un-transformed inputs.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.InputTransform.equals">
<span class="sig-name descname"><span class="pre">equals</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#InputTransform.equals"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.InputTransform.equals" title="Link to this definition"></a></dt>
<dd><p>Check if another input transform is equivalent.</p>
<p>Note: The reason that a custom equals method is defined rather than
defining an __eq__ method is because defining an __eq__ method sets
the __hash__ method to None. Hashing modules is currently used in
pytorch. See <a class="reference external" href="https://github.com/pytorch/pytorch/issues/7733">https://github.com/pytorch/pytorch/issues/7733</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>other</strong> (<a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>InputTransform</em></a>) – Another input transform.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A boolean indicating if the other transform is equivalent.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.InputTransform.preprocess_transform">
<span class="sig-name descname"><span class="pre">preprocess_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#InputTransform.preprocess_transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.InputTransform.preprocess_transform" title="Link to this definition"></a></dt>
<dd><p>Apply transforms for preprocessing inputs.</p>
<p>The main use cases for this method are 1) to preprocess training data
before calling <cite>set_train_data</cite> and 2) preprocess <cite>X_baseline</cite> for noisy
acquisition functions so that <cite>X_baseline</cite> is “preprocessed” with the
same transformations as the cached training inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of inputs.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape x n x d</cite>-dim tensor of (transformed) inputs.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.transforms.input.BatchBroadcastedInputTransform">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.input.</span></span><span class="sig-name descname"><span class="pre">BatchBroadcastedInputTransform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">transforms</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">broadcast_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-3</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#BatchBroadcastedInputTransform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.BatchBroadcastedInputTransform" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">InputTransform</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ModuleDict</span></code></p>
<p>An input transform representing a list of transforms to be broadcasted.</p>
<p>A transform list that is broadcasted across a batch dimension specified by
<cite>broadcast_index</cite>. This is allows using a batched Gaussian process model when
the input transforms are different for different batch dimensions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>transforms</strong> (<em>list</em><em>[</em><a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>InputTransform</em></a><em>]</em>) – The transforms to broadcast across the first batch dimension.
The transform at position i in the list will be applied to <cite>X[i]</cite> for
a given input tensor <cite>X</cite> in the forward pass.</p></li>
<li><p><strong>broadcast_index</strong> (<em>int</em>) – The tensor index at which the transforms are broadcasted.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tf1</span> <span class="o">=</span> <span class="n">Normalize</span><span class="p">(</span><span class="n">d</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tf2</span> <span class="o">=</span> <span class="n">InputStandardize</span><span class="p">(</span><span class="n">d</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tf</span> <span class="o">=</span> <span class="n">BatchBroadcastedTransformList</span><span class="p">(</span><span class="n">transforms</span><span class="o">=</span><span class="p">[</span><span class="n">tf1</span><span class="p">,</span> <span class="n">tf2</span><span class="p">])</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.BatchBroadcastedInputTransform.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#BatchBroadcastedInputTransform.transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.BatchBroadcastedInputTransform.transform" title="Link to this definition"></a></dt>
<dd><p>Transform the inputs to a model.</p>
<p>Individual transforms are applied in sequence and results are returned as
a batched tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of inputs.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape x n x d</cite>-dim tensor of transformed inputs.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.BatchBroadcastedInputTransform.untransform">
<span class="sig-name descname"><span class="pre">untransform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#BatchBroadcastedInputTransform.untransform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.BatchBroadcastedInputTransform.untransform" title="Link to this definition"></a></dt>
<dd><p>Un-transform the inputs to a model.</p>
<p>Un-transforms of the individual transforms are applied in reverse sequence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of transformed inputs.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape x n x d</cite>-dim tensor of un-transformed inputs.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.BatchBroadcastedInputTransform.equals">
<span class="sig-name descname"><span class="pre">equals</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#BatchBroadcastedInputTransform.equals"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.BatchBroadcastedInputTransform.equals" title="Link to this definition"></a></dt>
<dd><p>Check if another input transform is equivalent.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>other</strong> (<a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>InputTransform</em></a>) – Another input transform.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A boolean indicating if the other transform is equivalent.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.BatchBroadcastedInputTransform.preprocess_transform">
<span class="sig-name descname"><span class="pre">preprocess_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#BatchBroadcastedInputTransform.preprocess_transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.BatchBroadcastedInputTransform.preprocess_transform" title="Link to this definition"></a></dt>
<dd><p>Apply transforms for preprocessing inputs.</p>
<p>The main use cases for this method are 1) to preprocess training data
before calling <cite>set_train_data</cite> and 2) preprocess <cite>X_baseline</cite> for noisy
acquisition functions so that <cite>X_baseline</cite> is “preprocessed” with the
same transformations as the cached training inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of inputs.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape x n x d</cite>-dim tensor of (transformed) inputs.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.transforms.input.ChainedInputTransform">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.input.</span></span><span class="sig-name descname"><span class="pre">ChainedInputTransform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">transforms</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#ChainedInputTransform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.ChainedInputTransform" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">InputTransform</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ModuleDict</span></code></p>
<p>An input transform representing the chaining of individual transforms.</p>
<p>Chaining of input transforms.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>transforms</strong> (<a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>InputTransform</em></a>) – The transforms to chain. Internally, the names of the
kwargs are used as the keys for accessing the individual
transforms on the module.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tf1</span> <span class="o">=</span> <span class="n">Normalize</span><span class="p">(</span><span class="n">d</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tf2</span> <span class="o">=</span> <span class="n">Normalize</span><span class="p">(</span><span class="n">d</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tf</span> <span class="o">=</span> <span class="n">ChainedInputTransform</span><span class="p">(</span><span class="n">tf1</span><span class="o">=</span><span class="n">tf1</span><span class="p">,</span> <span class="n">tf2</span><span class="o">=</span><span class="n">tf2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">list</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="go">[&#39;tf1&#39;, &#39;tf2&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tf</span><span class="p">[</span><span class="s2">&quot;tf1&quot;</span><span class="p">]</span>
<span class="go">Normalize()</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.ChainedInputTransform.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#ChainedInputTransform.transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.ChainedInputTransform.transform" title="Link to this definition"></a></dt>
<dd><p>Transform the inputs to a model.</p>
<p>Individual transforms are applied in sequence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of inputs.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape x n x d</cite>-dim tensor of transformed inputs.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.ChainedInputTransform.untransform">
<span class="sig-name descname"><span class="pre">untransform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#ChainedInputTransform.untransform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.ChainedInputTransform.untransform" title="Link to this definition"></a></dt>
<dd><p>Un-transform the inputs to a model.</p>
<p>Un-transforms of the individual transforms are applied in reverse sequence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of transformed inputs.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape x n x d</cite>-dim tensor of un-transformed inputs.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.ChainedInputTransform.equals">
<span class="sig-name descname"><span class="pre">equals</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#ChainedInputTransform.equals"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.ChainedInputTransform.equals" title="Link to this definition"></a></dt>
<dd><p>Check if another input transform is equivalent.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>other</strong> (<a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>InputTransform</em></a>) – Another input transform.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A boolean indicating if the other transform is equivalent.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.ChainedInputTransform.preprocess_transform">
<span class="sig-name descname"><span class="pre">preprocess_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#ChainedInputTransform.preprocess_transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.ChainedInputTransform.preprocess_transform" title="Link to this definition"></a></dt>
<dd><p>Apply transforms for preprocessing inputs.</p>
<p>The main use cases for this method are 1) to preprocess training data
before calling <cite>set_train_data</cite> and 2) preprocess <cite>X_baseline</cite> for noisy
acquisition functions so that <cite>X_baseline</cite> is “preprocessed” with the
same transformations as the cached training inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of inputs.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape x n x d</cite>-dim tensor of (transformed) inputs.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.transforms.input.ReversibleInputTransform">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.input.</span></span><span class="sig-name descname"><span class="pre">ReversibleInputTransform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#ReversibleInputTransform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.ReversibleInputTransform" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">InputTransform</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>An abstract class for a reversible input transform.</p>
<dl class="simple">
<dt>Properties:</dt><dd><dl class="simple">
<dt>reverse: A boolean indicating if the functionality of transform</dt><dd><p>and untransform methods should be swapped.</p>
</dd>
</dl>
</dd>
</dl>
<p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="field-list simple">
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.transforms.input.ReversibleInputTransform.reverse">
<span class="sig-name descname"><span class="pre">reverse</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.transforms.input.ReversibleInputTransform.reverse" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.ReversibleInputTransform.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#ReversibleInputTransform.transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.ReversibleInputTransform.transform" title="Link to this definition"></a></dt>
<dd><p>Transform the inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of inputs.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape x n x d</cite>-dim tensor of transformed inputs.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.ReversibleInputTransform.untransform">
<span class="sig-name descname"><span class="pre">untransform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#ReversibleInputTransform.untransform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.ReversibleInputTransform.untransform" title="Link to this definition"></a></dt>
<dd><p>Un-transform the inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of inputs.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape x n x d</cite>-dim tensor of un-transformed inputs.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.ReversibleInputTransform.equals">
<span class="sig-name descname"><span class="pre">equals</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#ReversibleInputTransform.equals"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.ReversibleInputTransform.equals" title="Link to this definition"></a></dt>
<dd><p>Check if another input transform is equivalent.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>other</strong> (<a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>InputTransform</em></a>) – Another input transform.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A boolean indicating if the other transform is equivalent.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.transforms.input.AffineInputTransform">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.input.</span></span><span class="sig-name descname"><span class="pre">AffineInputTransform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">d</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">coefficient</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_train</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_eval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_fantasize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reverse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#AffineInputTransform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.AffineInputTransform" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.transforms.input.ReversibleInputTransform" title="botorch.models.transforms.input.ReversibleInputTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">ReversibleInputTransform</span></code></a></p>
<p>Apply affine transformation to input:</p>
<blockquote>
<div><p><cite>output = (input - offset) / coefficient</cite></p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>d</strong> (<em>int</em>) – The dimension of the input space.</p></li>
<li><p><strong>coefficient</strong> (<em>Tensor</em>) – Tensor of linear coefficients, shape must to be
broadcastable with <cite>(batch_shape x n x d)</cite>-dim input tensors.</p></li>
<li><p><strong>offset</strong> (<em>Tensor</em>) – Tensor of offset coefficients, shape must to be
broadcastable with <cite>(batch_shape x n x d)</cite>-dim input tensors.</p></li>
<li><p><strong>indices</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>Tensor</em><em> | </em><em>None</em>) – The indices of the inputs to transform. If omitted,
take all dimensions of the inputs into account. Either a list of ints
or a Tensor of type <cite>torch.long</cite>.</p></li>
<li><p><strong>batch_shape</strong> (<em>torch.Size</em>) – The batch shape of the inputs (assuming input tensors
of shape <cite>batch_shape x n x d</cite>). If provided, perform individual
transformation per batch, otherwise uses a single transformation.</p></li>
<li><p><strong>transform_on_train</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transform in train() mode. Default: True.</p></li>
<li><p><strong>transform_on_eval</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transform in eval() mode. Default: True.</p></li>
<li><p><strong>transform_on_fantasize</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transform when called from within a <cite>fantasize</cite> call. Default: True.</p></li>
<li><p><strong>reverse</strong> (<em>bool</em>) – A boolean indicating whether the forward pass should untransform
the inputs.</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.transforms.input.AffineInputTransform.coefficient">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">coefficient</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tensor</span></em><a class="headerlink" href="#botorch.models.transforms.input.AffineInputTransform.coefficient" title="Link to this definition"></a></dt>
<dd><p>The tensor of linear coefficients.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.transforms.input.AffineInputTransform.offset">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">offset</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tensor</span></em><a class="headerlink" href="#botorch.models.transforms.input.AffineInputTransform.offset" title="Link to this definition"></a></dt>
<dd><p>The tensor of offset coefficients.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.transforms.input.AffineInputTransform.learn_coefficients">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">learn_coefficients</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.transforms.input.AffineInputTransform.learn_coefficients" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.AffineInputTransform.equals">
<span class="sig-name descname"><span class="pre">equals</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#AffineInputTransform.equals"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.AffineInputTransform.equals" title="Link to this definition"></a></dt>
<dd><p>Check if another input transform is equivalent.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>other</strong> (<a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>InputTransform</em></a>) – Another input transform.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A boolean indicating if the other transform is equivalent.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.transforms.input.Normalize">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.input.</span></span><span class="sig-name descname"><span class="pre">Normalize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">d</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_train</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_eval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_fantasize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reverse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-08</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learn_bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">almost_zero</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-12</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">center</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#Normalize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.Normalize" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.transforms.input.AffineInputTransform" title="botorch.models.transforms.input.AffineInputTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">AffineInputTransform</span></code></a></p>
<p>Normalize the inputs have unit range and be centered at 0.5 (by default).</p>
<p>If no explicit bounds are provided this module is stateful: If in train mode,
calling <cite>forward</cite> updates the module state (i.e. the normalizing bounds). If
in eval mode, calling <cite>forward</cite> simply applies the normalization using the
current module state.</p>
<p>Normalize the inputs to the unit cube.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>d</strong> (<em>int</em>) – The dimension of the input space.</p></li>
<li><p><strong>indices</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>Tensor</em><em> | </em><em>None</em>) – The indices of the inputs to normalize. If omitted,
take all dimensions of the inputs into account.</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em><em> | </em><em>None</em>) – If provided, use these bounds to normalize the inputs. If
omitted, learn the bounds in train mode.</p></li>
<li><p><strong>batch_shape</strong> (<em>torch.Size</em>) – The batch shape of the inputs (assuming input tensors
of shape <cite>batch_shape x n x d</cite>). If provided, perform individual
normalization per batch, otherwise uses a single normalization.</p></li>
<li><p><strong>transform_on_train</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transforms in train() mode. Default: True.</p></li>
<li><p><strong>transform_on_eval</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transform in eval() mode. Default: True.</p></li>
<li><p><strong>transform_on_fantasize</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transform when called from within a <cite>fantasize</cite> call. Default: True.</p></li>
<li><p><strong>reverse</strong> (<em>bool</em>) – A boolean indicating whether the forward pass should untransform
the inputs.</p></li>
<li><p><strong>min_range</strong> (<em>float</em>) – If the range of an input dimension is smaller than <cite>min_range</cite>,
that input dimension will not be normalized. This is equivalent to
using bounds of <cite>[0, 1]</cite> for this dimension, and helps avoid division
by zero errors and related numerical issues. See the example below.
NOTE: This only applies if <cite>learn_bounds=True</cite>.</p></li>
<li><p><strong>learn_bounds</strong> (<em>bool</em><em> | </em><em>None</em>) – Whether to learn the bounds in train mode. Defaults
to False if bounds are provided, otherwise defaults to True.</p></li>
<li><p><strong>center</strong> (<em>float</em>) – The center of the range for each parameter. Default: 0.5.</p></li>
<li><p><strong>almost_zero</strong> (<em>float</em>)</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">t</span> <span class="o">=</span> <span class="n">Normalize</span><span class="p">(</span><span class="n">d</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">]]))</span>
<span class="gp">... </span><span class="n">tensor</span><span class="p">([[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">],</span>
<span class="gp">... </span>        <span class="p">[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="gp">... </span><span class="n">Normalize</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">3.5</span><span class="p">,</span> <span class="mf">2.8</span><span class="p">]]))</span>
<span class="gp">... </span><span class="n">tensor</span><span class="p">([[</span><span class="mf">3.5</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span><span class="o">.</span><span class="n">bounds</span>
<span class="gp">... </span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">],</span>
<span class="gp">... </span>        <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span><span class="o">.</span><span class="n">coefficient</span>
<span class="gp">... </span><span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">]])</span>
</pre></div>
</div>
<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.transforms.input.Normalize.ranges">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">ranges</span></span><a class="headerlink" href="#botorch.models.transforms.input.Normalize.ranges" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.transforms.input.Normalize.mins">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">mins</span></span><a class="headerlink" href="#botorch.models.transforms.input.Normalize.mins" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.transforms.input.Normalize.bounds">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">bounds</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tensor</span></em><a class="headerlink" href="#botorch.models.transforms.input.Normalize.bounds" title="Link to this definition"></a></dt>
<dd><p>The bounds used for normalizing the inputs.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.transforms.input.Normalize.learn_bounds">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">learn_bounds</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.transforms.input.Normalize.learn_bounds" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.Normalize.get_init_args">
<span class="sig-name descname"><span class="pre">get_init_args</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#Normalize.get_init_args"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.Normalize.get_init_args" title="Link to this definition"></a></dt>
<dd><p>Get the arguments necessary to construct an exact copy of the transform.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict[str, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.transforms.input.InputStandardize">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.input.</span></span><span class="sig-name descname"><span class="pre">InputStandardize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">d</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_train</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_eval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_fantasize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reverse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_std</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-08</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#InputStandardize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.InputStandardize" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.transforms.input.AffineInputTransform" title="botorch.models.transforms.input.AffineInputTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">AffineInputTransform</span></code></a></p>
<p>Standardize inputs (zero mean, unit variance).</p>
<p>In train mode, calling <cite>forward</cite> updates the module state
(i.e. the mean/std normalizing constants). If in eval mode, calling <cite>forward</cite>
simply applies the standardization using the current module state.</p>
<p>Standardize inputs (zero mean, unit variance).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>d</strong> (<em>int</em>) – The dimension of the input space.</p></li>
<li><p><strong>indices</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>Tensor</em><em> | </em><em>None</em>) – The indices of the inputs to standardize. If omitted,
take all dimensions of the inputs into account.</p></li>
<li><p><strong>batch_shape</strong> (<em>torch.Size</em>) – The batch shape of the inputs (asssuming input tensors
of shape <cite>batch_shape x n x d</cite>). If provided, perform individual
normalization per batch, otherwise uses a single normalization.</p></li>
<li><p><strong>transform_on_train</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transforms in train() mode. Default: True</p></li>
<li><p><strong>transform_on_eval</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transform in eval() mode. Default: True</p></li>
<li><p><strong>reverse</strong> (<em>bool</em>) – A boolean indicating whether the forward pass should untransform
the inputs.</p></li>
<li><p><strong>min_std</strong> (<em>float</em>) – If the standard deviation of an input dimension is smaller than
<cite>min_std</cite>, that input dimension will not be standardized. This is
equivalent to using a standard deviation of 1.0 and a mean of 0.0 for
this dimension, and helps avoid division by zero errors and related
numerical issues.</p></li>
<li><p><strong>transform_on_fantasize</strong> (<em>bool</em>)</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.transforms.input.InputStandardize.stds">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">stds</span></span><a class="headerlink" href="#botorch.models.transforms.input.InputStandardize.stds" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.transforms.input.InputStandardize.means">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">means</span></span><a class="headerlink" href="#botorch.models.transforms.input.InputStandardize.means" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.transforms.input.Round">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.input.</span></span><span class="sig-name descname"><span class="pre">Round</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">integer_indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">categorical_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_train</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_eval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_fantasize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">approximate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#Round"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.Round" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">InputTransform</span></code></a></p>
<p>A discretization transformation for discrete inputs.</p>
<p>If <cite>approximate=False</cite> (the default), uses PyTorch’s <cite>round</cite>.</p>
<p>If <cite>approximate=True</cite>, a differentiable approximate rounding function is
used, with a temperature parameter of <cite>tau</cite>. This method is a piecewise
approximation of a rounding function where each piece is a hyperbolic
tangent function.</p>
<p>For integers, this will typically be used in conjunction
with normalization as follows:</p>
<p>In eval() mode (i.e. after training), the inputs pass
would typically be normalized to the unit cube (e.g. during candidate
optimization). 1. These are unnormalized back to the raw input space.
2. The integers are rounded. 3. All values are normalized to the unit
cube.</p>
<p>In train() mode, the inputs can either (a) be normalized to the unit
cube or (b) provided using their raw values. In the case of (a)
transform_on_train should be set to True, so that the normalized inputs
are unnormalized before rounding. In the case of (b) transform_on_train
should be set to False, so that the raw inputs are rounded and then
normalized to the unit cube.</p>
<p>By default, the straight through estimators are used for the gradients as
proposed in <a class="reference internal" href="utils.html#daulton2022bopr" id="id39"><span>[Daulton2022bopr]</span></a>. This transformation supports differentiable
approximate rounding (currently only for integers). The rounding function
is approximated with a piece-wise function where each piece is a hyperbolic
tangent function.</p>
<p>For categorical parameters, the input must be one-hot encoded.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">bounds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">integer_indices</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">categorical_features</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">:</span> <span class="mi">2</span><span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">unnormalize_tf</span> <span class="o">=</span> <span class="n">Normalize</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">d</span><span class="o">=</span><span class="n">d</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">transform_on_eval</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">transform_on_train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">round_tf</span> <span class="o">=</span> <span class="n">Round</span><span class="p">(</span><span class="n">integer_indices</span><span class="p">,</span> <span class="n">categorical_features</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">normalize_tf</span> <span class="o">=</span> <span class="n">Normalize</span><span class="p">(</span><span class="n">d</span><span class="o">=</span><span class="n">d</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tf</span> <span class="o">=</span> <span class="n">ChainedInputTransform</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">tf1</span><span class="o">=</span><span class="n">unnormalize_tf</span><span class="p">,</span> <span class="n">tf2</span><span class="o">=</span><span class="n">round_tf</span><span class="p">,</span> <span class="n">tf3</span><span class="o">=</span><span class="n">normalize_tf</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
</pre></div>
</div>
<p>Initialize transform.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>integer_indices</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>LongTensor</em><em> | </em><em>None</em>) – The indices of the integer inputs.</p></li>
<li><p><strong>categorical_features</strong> (<em>dict</em><em>[</em><em>int</em><em>, </em><em>int</em><em>] </em><em>| </em><em>None</em>) – A dictionary mapping the starting index of each
categorical feature to its cardinality. This assumes that categoricals
are one-hot encoded.</p></li>
<li><p><strong>transform_on_train</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transforms in train() mode. Default: True.</p></li>
<li><p><strong>transform_on_eval</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transform in eval() mode. Default: True.</p></li>
<li><p><strong>transform_on_fantasize</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transform when called from within a <cite>fantasize</cite> call. Default: True.</p></li>
<li><p><strong>approximate</strong> (<em>bool</em>) – A boolean indicating whether approximate or exact
rounding should be used. Default: False.</p></li>
<li><p><strong>tau</strong> (<em>float</em>) – The temperature parameter for approximate rounding.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.Round.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#Round.transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.Round.transform" title="Link to this definition"></a></dt>
<dd><p>Discretize the inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of inputs.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape x n x d</cite>-dim tensor of discretized inputs.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.Round.equals">
<span class="sig-name descname"><span class="pre">equals</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#Round.equals"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.Round.equals" title="Link to this definition"></a></dt>
<dd><p>Check if another input transform is equivalent.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>other</strong> (<a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>InputTransform</em></a>) – Another input transform.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A boolean indicating if the other transform is equivalent.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.Round.get_init_args">
<span class="sig-name descname"><span class="pre">get_init_args</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#Round.get_init_args"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.Round.get_init_args" title="Link to this definition"></a></dt>
<dd><p>Get the arguments necessary to construct an exact copy of the transform.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict[str, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.transforms.input.Log10">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.input.</span></span><span class="sig-name descname"><span class="pre">Log10</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_train</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_eval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_fantasize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reverse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#Log10"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.Log10" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.transforms.input.ReversibleInputTransform" title="botorch.models.transforms.input.ReversibleInputTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">ReversibleInputTransform</span></code></a></p>
<p>A base-10 log transformation.</p>
<p>Initialize transform.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>indices</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – The indices of the inputs to log transform.</p></li>
<li><p><strong>transform_on_train</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transforms in train() mode. Default: True.</p></li>
<li><p><strong>transform_on_eval</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transform in eval() mode. Default: True.</p></li>
<li><p><strong>transform_on_fantasize</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transform when called from within a <cite>fantasize</cite> call. Default: True.</p></li>
<li><p><strong>reverse</strong> (<em>bool</em>) – A boolean indicating whether the forward pass should untransform
the inputs.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.transforms.input.Warp">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.input.</span></span><span class="sig-name descname"><span class="pre">Warp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">d</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_train</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_eval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_fantasize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reverse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">concentration1_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">concentration0_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#Warp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.Warp" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.transforms.input.ReversibleInputTransform" title="botorch.models.transforms.input.ReversibleInputTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">ReversibleInputTransform</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>A transform that uses learned input warping functions.</p>
<p>Each specified input dimension is warped using the CDF of a
Kumaraswamy distribution. Typically, MAP estimates of the
parameters of the Kumaraswamy distribution, for each input
dimension, are learned jointly with the GP hyperparameters.</p>
<p>TODO: implement support using independent warping functions
for each output in batched multi-output and multi-task models.</p>
<p>For now, ModelListGPs should be used to learn independent warping
functions for each output.</p>
<p>Initialize transform.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>indices</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – The indices of the inputs to warp.</p></li>
<li><p><strong>transform_on_train</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transforms in train() mode. Default: True.</p></li>
<li><p><strong>transform_on_eval</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transform in eval() mode. Default: True.</p></li>
<li><p><strong>transform_on_fantasize</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transform when called from within a <cite>fantasize</cite> call. Default: True.</p></li>
<li><p><strong>reverse</strong> (<em>bool</em>) – A boolean indicating whether the forward pass should untransform
the inputs.</p></li>
<li><p><strong>eps</strong> (<em>float</em>) – A small value used to clip values to be in the interval (0, 1).</p></li>
<li><p><strong>concentration1_prior</strong> (<em>Prior</em><em> | </em><em>None</em>) – A prior distribution on the concentration1 parameter
of the Kumaraswamy distribution.</p></li>
<li><p><strong>concentration0_prior</strong> (<em>Prior</em><em> | </em><em>None</em>) – A prior distribution on the concentration0 parameter
of the Kumaraswamy distribution.</p></li>
<li><p><strong>batch_shape</strong> (<em>torch.Size</em><em> | </em><em>None</em>) – An optional batch shape, for learning independent warping
parameters for each batch of inputs. This should match the input batch
shape of the model (i.e., <cite>train_X.shape[:-2]</cite>).
NOTE: This is only supported for single-output models.</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>2 x d</cite>-dim tensor of lower and upper bounds for the inputs.</p></li>
<li><p><strong>d</strong> (<em>int</em>)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.transforms.input.AppendFeatures">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.input.</span></span><span class="sig-name descname"><span class="pre">AppendFeatures</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">feature_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">f</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fkwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_expand</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_train</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_eval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_fantasize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#AppendFeatures"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.AppendFeatures" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">InputTransform</span></code></a></p>
<p>A transform that appends the input with a given set of features either
provided beforehand or generated on the fly via a callable.</p>
<p>As an example, the predefined set of features can be used with
<cite>RiskMeasureMCObjective</cite> to optimize risk measures as described in
<a class="reference internal" href="acquisition.html#cakmak2020risk" id="id40"><span>[Cakmak2020risk]</span></a>. A tutorial notebook implementing the rhoKG acqusition
function introduced in <a class="reference internal" href="acquisition.html#cakmak2020risk" id="id41"><span>[Cakmak2020risk]</span></a> can be found at
<a class="reference external" href="https://botorch.org/docs/tutorials/risk_averse_bo_with_environmental_variables">https://botorch.org/docs/tutorials/risk_averse_bo_with_environmental_variables</a>.</p>
<p>The steps for using this to obtain samples of a risk measure are as follows:</p>
<ul class="simple">
<li><p>Train a model on <cite>(x, w)</cite> inputs and the corresponding observations;</p></li>
<li><p>Pass in an instance of <cite>AppendFeatures</cite> with the <cite>feature_set</cite> denoting the
samples of <cite>W</cite> as the <cite>input_transform</cite> to the trained model;</p></li>
<li><p>Call <cite>posterior(…).rsample(…)</cite> on the model with <cite>x</cite> inputs only to
get the joint posterior samples over <cite>(x, w)`s, where the `w`s come
from the `feature_set</cite>;</p></li>
<li><p>Pass these posterior samples through the <cite>RiskMeasureMCObjective</cite> of choice to
get the samples of the risk measure.</p></li>
</ul>
<p>Note: The samples of the risk measure obtained this way are in general biased
since the <cite>feature_set</cite> does not fully represent the distribution of the
environmental variable.</p>
<p>Possible examples for using a callable include statistical models that are built on
PyTorch, built-in mathematical operations such as torch.sum, or custom scripted
functions. By this, this input transform allows for advanced feature engineering
and transfer learning models within the optimization loop.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># We consider 1D `x` and 1D `w`, with `W` having a</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># uniform distribution over [0, 1]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">train_X</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">train_Y</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">input_transform</span><span class="o">=</span><span class="n">AppendFeatures</span><span class="p">(</span><span class="n">feature_set</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mll</span> <span class="o">=</span> <span class="n">ExactMarginalLogLikelihood</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fit_gpytorch_mll</span><span class="p">(</span><span class="n">mll</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">test_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># `posterior_samples` is a `10 x 30 x 1`-dim tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">posterior_samples</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">posterior</span><span class="p">(</span><span class="n">test_x</span><span class="p">)</span><span class="o">.</span><span class="n">rsamples</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">size</span><span class="p">([</span><span class="mi">10</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">risk_measure</span> <span class="o">=</span> <span class="n">VaR</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">n_w</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># `risk_measure_samples` is a `10 x 3`-dim tensor of samples of the</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># risk measure VaR</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">risk_measure_samples</span> <span class="o">=</span> <span class="n">risk_measure</span><span class="p">(</span><span class="n">posterior_samples</span><span class="p">)</span>
</pre></div>
</div>
<p>Append <cite>feature_set</cite> to each input or generate a set of features to
append on the fly via a callable.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>feature_set</strong> (<em>Tensor</em><em> | </em><em>None</em>) – An <cite>n_f x d_f</cite>-dim tensor denoting the features to be
appended to the inputs. Default: None.</p></li>
<li><p><strong>f</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – A callable mapping a <cite>batch_shape x q x d</cite>-dim input tensor <cite>X</cite>
to a <cite>batch_shape x q x n_f x d_f</cite>-dimensional output tensor.
Default: None.</p></li>
<li><p><strong>indices</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – List of indices denoting the indices of the features to be
passed into f. Per default all features are passed to <cite>f</cite>.
Default: None.</p></li>
<li><p><strong>fkwargs</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Dictionary of keyword arguments passed to the callable <cite>f</cite>.
Default: None.</p></li>
<li><p><strong>skip_expand</strong> (<em>bool</em>) – A boolean indicating whether to expand the input tensor
before appending features. This is intended for use with an
<cite>InputPerturbation</cite>. If <cite>True</cite>, the input tensor will be expected
to be of shape <cite>batch_shape x (q * n_f) x d</cite>. Not implemented
in combination with a callable.</p></li>
<li><p><strong>transform_on_train</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transforms in train() mode. Default: False.</p></li>
<li><p><strong>transform_on_eval</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transform in eval() mode. Default: True.</p></li>
<li><p><strong>transform_on_fantasize</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transform when called from within a <cite>fantasize</cite> call. Default: False.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.transforms.input.AppendFeatures.is_one_to_many">
<span class="sig-name descname"><span class="pre">is_one_to_many</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#botorch.models.transforms.input.AppendFeatures.is_one_to_many" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.AppendFeatures.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#AppendFeatures.transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.AppendFeatures.transform" title="Link to this definition"></a></dt>
<dd><p>Transform the inputs by appending <cite>feature_set</cite> to each input or
by generating a set of features to be appended on the fly via a callable.</p>
<p>For each <cite>1 x d</cite>-dim element in the input tensor, this will produce
an <cite>n_f x (d + d_f)</cite>-dim tensor with <cite>feature_set</cite> appended as the last <cite>d_f</cite>
dimensions. For a generic <cite>batch_shape x q x d</cite>-dim <cite>X</cite>, this translates to a
<cite>batch_shape x (q * n_f) x (d + d_f)</cite>-dim output, where the values corresponding
to <cite>X[…, i, :]</cite> are found in <cite>output[…, i * n_f: (i + 1) * n_f, :]</cite>.</p>
<p>Note: Adding the <cite>feature_set</cite> on the <cite>q-batch</cite> dimension is necessary to avoid
introducing additional bias by evaluating the inputs on independent GP
sample paths.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x q x d</cite>-dim tensor of inputs. If <cite>self.skip_expand</cite> is
<cite>True</cite>, then <cite>X</cite> should be of shape <cite>batch_shape x (q * n_f) x d</cite>,
typically obtained by passing a <cite>batch_shape x q x d</cite> shape input
through an <cite>InputPerturbation</cite> with <cite>n_f</cite> perturbation values.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape x (q * n_f) x (d + d_f)</cite>-dim tensor of appended inputs.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.transforms.input.InteractionFeatures">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.input.</span></span><span class="sig-name descname"><span class="pre">InteractionFeatures</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#InteractionFeatures"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.InteractionFeatures" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.transforms.input.AppendFeatures" title="botorch.models.transforms.input.AppendFeatures"><code class="xref py py-class docutils literal notranslate"><span class="pre">AppendFeatures</span></code></a></p>
<p>A transform that appends the first-order interaction terms $x_i * x_j, i &lt; j$,
for all or a subset of the input variables.</p>
<p>Initializes the InteractionFeatures transform.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>indices</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – Indices of the subset of dimensions to compute interaction
features on.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.transforms.input.FilterFeatures">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.input.</span></span><span class="sig-name descname"><span class="pre">FilterFeatures</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">feature_indices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_train</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_eval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_fantasize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#FilterFeatures"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.FilterFeatures" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">InputTransform</span></code></a></p>
<p>A transform that filters the input with a given set of features indices.</p>
<p>As an example, this can be used in a multiobjective optimization with <cite>ModelListGP</cite>
in which the specific models only share subsets of features (feature selection).
A reason could be that it is known that specific features do not have any impact on
a specific objective but they need to be included in the model for another one.</p>
<p>Filter features from a model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>feature_set</strong> – An one-dim tensor denoting the indices of the features to be
kept and fed to the model.</p></li>
<li><p><strong>transform_on_train</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transforms in train() mode. Default: True.</p></li>
<li><p><strong>transform_on_eval</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transform in eval() mode. Default: True.</p></li>
<li><p><strong>transform_on_fantasize</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transform when called from within a <cite>fantasize</cite> call. Default: True.</p></li>
<li><p><strong>feature_indices</strong> (<em>Tensor</em>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.FilterFeatures.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#FilterFeatures.transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.FilterFeatures.transform" title="Link to this definition"></a></dt>
<dd><p>Transform the inputs by keeping only the in <cite>feature_indices</cite> specified
feature indices and filtering out the others.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x q x d</cite>-dim tensor of inputs.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>A <cite>batch_shape x q x e</cite>-dim tensor of filtered inputs,</dt><dd><p>where <cite>e</cite> is the length of <cite>feature_indices</cite>.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.FilterFeatures.equals">
<span class="sig-name descname"><span class="pre">equals</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#FilterFeatures.equals"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.FilterFeatures.equals" title="Link to this definition"></a></dt>
<dd><p>Check if another input transform is equivalent.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>other</strong> (<a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>InputTransform</em></a>) – Another input transform</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A boolean indicating if the other transform is equivalent.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.transforms.input.InputPerturbation">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.input.</span></span><span class="sig-name descname"><span class="pre">InputPerturbation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">perturbation_set</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multiplicative</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_train</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_eval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_fantasize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#InputPerturbation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.InputPerturbation" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">InputTransform</span></code></a></p>
<p>A transform that adds the set of perturbations to the given input.</p>
<p>Similar to <cite>AppendFeatures</cite>, this can be used with <cite>RiskMeasureMCObjective</cite>
to optimize risk measures. See <cite>AppendFeatures</cite> for additional discussion
on optimizing risk measures.</p>
<p>A tutorial notebook using this with <cite>qNoisyExpectedImprovement</cite> can be found at
<a class="reference external" href="https://botorch.org/docs/tutorials/risk_averse_bo_with_input_perturbations">https://botorch.org/docs/tutorials/risk_averse_bo_with_input_perturbations</a>.</p>
<p>Add <cite>perturbation_set</cite> to each input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>perturbation_set</strong> (<em>Tensor</em><em> | </em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em>) – An <cite>n_p x d</cite>-dim tensor denoting the perturbations
to be added to the inputs. Alternatively, this can be a callable that
returns <cite>batch x n_p x d</cite>-dim tensor of perturbations for input of
shape <cite>batch x d</cite>. This is useful for heteroscedastic perturbations.</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>2 x d</cite>-dim tensor of lower and upper bounds for each
column of the input. If given, the perturbed inputs will be
clamped to these bounds.</p></li>
<li><p><strong>indices</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – A list of indices specifying a subset of inputs on which to apply
the transform. Note that <cite>len(indices)</cite> should be equal to the second
dimension of <cite>perturbation_set</cite> and <cite>bounds</cite>. The dimensionality of
the input <cite>X.shape[-1]</cite> can be larger if we only transform a subset.</p></li>
<li><p><strong>multiplicative</strong> (<em>bool</em>) – A boolean indicating whether the input perturbations
are additive or multiplicative. If True, inputs will be multiplied
with the perturbations.</p></li>
<li><p><strong>transform_on_train</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transforms in train() mode. Default: False.</p></li>
<li><p><strong>transform_on_eval</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transform in eval() mode. Default: True.</p></li>
<li><p><strong>transform_on_fantasize</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transform when called from within a <cite>fantasize</cite> call. Default: False.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.transforms.input.InputPerturbation.is_one_to_many">
<span class="sig-name descname"><span class="pre">is_one_to_many</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#botorch.models.transforms.input.InputPerturbation.is_one_to_many" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.InputPerturbation.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#InputPerturbation.transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.InputPerturbation.transform" title="Link to this definition"></a></dt>
<dd><p>Transform the inputs by adding <cite>perturbation_set</cite> to each input.</p>
<p>For each <cite>1 x d</cite>-dim element in the input tensor, this will produce
an <cite>n_p x d</cite>-dim tensor with the <cite>perturbation_set</cite> added to the input.
For a generic <cite>batch_shape x q x d</cite>-dim <cite>X</cite>, this translates to a
<cite>batch_shape x (q * n_p) x d</cite>-dim output, where the values corresponding
to <cite>X[…, i, :]</cite> are found in <cite>output[…, i * n_w: (i + 1) * n_w, :]</cite>.</p>
<p>Note: Adding the <cite>perturbation_set</cite> on the <cite>q-batch</cite> dimension is necessary
to avoid introducing additional bias by evaluating the inputs on independent
GP sample paths.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x q x d</cite>-dim tensor of inputs.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape x (q * n_p) x d</cite>-dim tensor of perturbed inputs.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.transforms.input.InputPerturbation.batch_shape">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">batch_shape</span></span><a class="headerlink" href="#botorch.models.transforms.input.InputPerturbation.batch_shape" title="Link to this definition"></a></dt>
<dd><p>Returns a shape tuple such that <cite>subset_transform</cite> pre-allocates
a (b x n_p x n x d) - dim tensor, where <cite>b</cite> is the batch shape of the
input <cite>X</cite> of the transform and <cite>n_p</cite> is the number of perturbations.
NOTE: this function is dependent on calling <cite>_expanded_perturbations(X)</cite>
because <cite>n_p</cite> is inaccessible otherwise if <cite>perturbation_set</cite> is a function.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.transforms.input.OneHotToNumeric">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.input.</span></span><span class="sig-name descname"><span class="pre">OneHotToNumeric</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">categorical_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_train</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_eval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_fantasize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#OneHotToNumeric"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.OneHotToNumeric" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">InputTransform</span></code></a></p>
<p>Transform categorical parameters from a one-hot to a numeric representation.</p>
<p>Initialize.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dim</strong> (<em>int</em>) – The dimension of the one-hot-encoded input.</p></li>
<li><p><strong>categorical_features</strong> (<em>dict</em><em>[</em><em>int</em><em>, </em><em>int</em><em>] </em><em>| </em><em>None</em>) – A dictionary mapping the starting index of each
categorical feature to its cardinality. This assumes that categoricals
are one-hot encoded.</p></li>
<li><p><strong>transform_on_train</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transforms in train() mode. Default: False.</p></li>
<li><p><strong>transform_on_eval</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transform in eval() mode. Default: True.</p></li>
<li><p><strong>transform_on_fantasize</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transform when called from within a <cite>fantasize</cite> call. Default: False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape x n x d’</cite>-dim tensor of where the one-hot encoded
categoricals are transformed to integer representation.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.OneHotToNumeric.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#OneHotToNumeric.transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.OneHotToNumeric.transform" title="Link to this definition"></a></dt>
<dd><p>Transform the categorical inputs into integer representation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of inputs.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape x n x d’</cite>-dim tensor of where the one-hot encoded
categoricals are transformed to integer representation.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.OneHotToNumeric.untransform">
<span class="sig-name descname"><span class="pre">untransform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#OneHotToNumeric.untransform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.OneHotToNumeric.untransform" title="Link to this definition"></a></dt>
<dd><p>Transform the categoricals from integer representation to one-hot.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d’</cite>-dim tensor of transformed inputs, where
the categoricals are represented as integers.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape x n x d</cite>-dim tensor of inputs, where the categoricals
have been transformed to one-hot representation.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.OneHotToNumeric.equals">
<span class="sig-name descname"><span class="pre">equals</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#OneHotToNumeric.equals"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.OneHotToNumeric.equals" title="Link to this definition"></a></dt>
<dd><p>Check if another input transform is equivalent.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>other</strong> (<a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>InputTransform</em></a>) – Another input transform.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A boolean indicating if the other transform is equivalent.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-botorch.models.transforms.factory">
<span id="transform-factory-methods"></span><h3>Transform Factory Methods<a class="headerlink" href="#module-botorch.models.transforms.factory" title="Link to this heading"></a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.transforms.factory.get_rounding_input_transform">
<span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.factory.</span></span><span class="sig-name descname"><span class="pre">get_rounding_input_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">one_hot_bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">integer_indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">categorical_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initialization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_numeric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">approximate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/factory.html#get_rounding_input_transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.factory.get_rounding_input_transform" title="Link to this definition"></a></dt>
<dd><p>Get a rounding input transform.</p>
<p>The rounding function will take inputs from the unit cube,
unnormalize the integers raw search space, round the inputs,
and normalize them back to the unit cube.</p>
<p>Categoricals are assumed to be one-hot encoded. Integers are
currently assumed to be contiguous ranges (e.g. [1,2,3] and not
[1,5,7]).</p>
<p>TODO: support non-contiguous sets of integers by modifying
the rounding function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>one_hot_bounds</strong> (<em>Tensor</em>) – The raw search space bounds where categoricals are
encoded in one-hot representation and the integer parameters
are not normalized.</p></li>
<li><p><strong>integer_indices</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – The indices of the integer parameters.</p></li>
<li><p><strong>categorical_features</strong> (<em>dict</em><em>[</em><em>int</em><em>, </em><em>int</em><em>] </em><em>| </em><em>None</em>) – A dictionary mapping indices to cardinalities
for the categorical features.</p></li>
<li><p><strong>initialization</strong> (<em>bool</em>) – A boolean indicating whether this exact rounding
function is for initialization. For initialization, the bounds
for are expanded such that the end point of a range is selected
with same probability that an interior point is selected, after
rounding.</p></li>
<li><p><strong>return_numeric</strong> (<em>bool</em>) – A boolean indicating whether to return numeric or
one-hot encoded categoricals. Returning a nummeric
representation is helpful if the downstream code (e.g. kernel)
expects a numeric representation of the categoricals.</p></li>
<li><p><strong>approximate</strong> (<em>bool</em>) – A boolean indicating whether to use an approximate
rounding function.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The rounding function ChainedInputTransform.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.transforms.input.ChainedInputTransform" title="botorch.models.transforms.input.ChainedInputTransform"><em>ChainedInputTransform</em></a></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-botorch.models.transforms.utils">
<span id="transform-utilities"></span><h3>Transform Utilities<a class="headerlink" href="#module-botorch.models.transforms.utils" title="Link to this heading"></a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.transforms.utils.lognorm_to_norm">
<span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.utils.</span></span><span class="sig-name descname"><span class="pre">lognorm_to_norm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mu</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Cov</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/utils.html#lognorm_to_norm"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.utils.lognorm_to_norm" title="Link to this definition"></a></dt>
<dd><p>Compute mean and covariance of a MVN from those of the associated log-MVN</p>
<p>If <cite>Y</cite> is log-normal with mean mu_ln and covariance Cov_ln, then
<cite>X ~ N(mu_n, Cov_n)</cite> with</p>
<blockquote>
<div><p>Cov_n_{ij} = log(1 + Cov_ln_{ij} / (mu_ln_{i} * mu_n_{j}))
mu_n_{i} = log(mu_ln_{i}) - 0.5 * log(1 + Cov_ln_{ii} / mu_ln_{i}**2)</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mu</strong> (<em>Tensor</em>) – A <cite>batch_shape x n</cite> mean vector of the log-Normal distribution.</p></li>
<li><p><strong>Cov</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x n</cite> covariance matrix of the log-Normal
distribution.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The <cite>batch_shape x n</cite> mean vector of the Normal distribution</p></li>
<li><p>The <cite>batch_shape x n x n</cite> covariance matrix of the Normal distribution</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>A two-tuple containing</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.transforms.utils.norm_to_lognorm">
<span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.utils.</span></span><span class="sig-name descname"><span class="pre">norm_to_lognorm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mu</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Cov</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/utils.html#norm_to_lognorm"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.utils.norm_to_lognorm" title="Link to this definition"></a></dt>
<dd><p>Compute mean and covariance of a log-MVN from its MVN sufficient statistics</p>
<p>If <cite>X ~ N(mu, Cov)</cite> and <cite>Y = exp(X)</cite>, then <cite>Y</cite> is log-normal with</p>
<blockquote>
<div><p>mu_ln_{i} = exp(mu_{i} + 0.5 * Cov_{ii})
Cov_ln_{ij} = exp(mu_{i} + mu_{j} + 0.5 * (Cov_{ii} + Cov_{jj})) *
(exp(Cov_{ij}) - 1)</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mu</strong> (<em>Tensor</em>) – A <cite>batch_shape x n</cite> mean vector of the Normal distribution.</p></li>
<li><p><strong>Cov</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x n</cite> covariance matrix of the Normal distribution.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The <cite>batch_shape x n</cite> mean vector of the log-Normal distribution.</p></li>
<li><dl class="simple">
<dt>The <cite>batch_shape x n x n</cite> covariance matrix of the log-Normal</dt><dd><p>distribution.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>A two-tuple containing</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.transforms.utils.norm_to_lognorm_mean">
<span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.utils.</span></span><span class="sig-name descname"><span class="pre">norm_to_lognorm_mean</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mu</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">var</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/utils.html#norm_to_lognorm_mean"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.utils.norm_to_lognorm_mean" title="Link to this definition"></a></dt>
<dd><p>Compute mean of a log-MVN from its MVN marginals</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mu</strong> (<em>Tensor</em>) – A <cite>batch_shape x n</cite> mean vector of the Normal distribution.</p></li>
<li><p><strong>var</strong> (<em>Tensor</em>) – A <cite>batch_shape x n</cite> variance vectorof the Normal distribution.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The <cite>batch_shape x n</cite> mean vector of the log-Normal distribution.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.transforms.utils.norm_to_lognorm_variance">
<span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.utils.</span></span><span class="sig-name descname"><span class="pre">norm_to_lognorm_variance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mu</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">var</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/utils.html#norm_to_lognorm_variance"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.utils.norm_to_lognorm_variance" title="Link to this definition"></a></dt>
<dd><p>Compute variance of a log-MVN from its MVN marginals</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mu</strong> (<em>Tensor</em>) – A <cite>batch_shape x n</cite> mean vector of the Normal distribution.</p></li>
<li><p><strong>var</strong> (<em>Tensor</em>) – A <cite>batch_shape x n</cite> variance vectorof the Normal distribution.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The <cite>batch_shape x n</cite> variance vector of the log-Normal distribution.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.transforms.utils.expand_and_copy_tensor">
<span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.utils.</span></span><span class="sig-name descname"><span class="pre">expand_and_copy_tensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_shape</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/utils.html#expand_and_copy_tensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.utils.expand_and_copy_tensor" title="Link to this definition"></a></dt>
<dd><p>Expand and copy X according to batch_shape.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>input_batch_shape x n x d</cite>-dim tensor of inputs.</p></li>
<li><p><strong>batch_shape</strong> (<em>Size</em>) – The new batch shape.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>new_batch_shape x n x d</cite>-dim tensor of inputs, where <cite>new_batch_shape</cite>
is <cite>input_batch_shape</cite> against <cite>batch_shape</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.transforms.utils.subset_transform">
<span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.utils.</span></span><span class="sig-name descname"><span class="pre">subset_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">transform</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/utils.html#subset_transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.utils.subset_transform" title="Link to this definition"></a></dt>
<dd><p>Decorator of an input transform function to separate out indexing logic.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.transforms.utils.interaction_features">
<span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.utils.</span></span><span class="sig-name descname"><span class="pre">interaction_features</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/utils.html#interaction_features"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.utils.interaction_features" title="Link to this definition"></a></dt>
<dd><p>Computes the interaction features between the inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x q x d</cite>-dim tensor of inputs.</p></li>
<li><p><strong>indices</strong> – The input dimensions to generate interaction features for.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>n x q x 1 x (d * (d-1) / 2))</cite>-dim tensor of interaction features.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.transforms.utils.nanstd">
<span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.utils.</span></span><span class="sig-name descname"><span class="pre">nanstd</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/utils.html#nanstd"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.utils.nanstd" title="Link to this definition"></a></dt>
<dd><p>Computes the standard deviation of the input, ignoring NaNs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of inputs.</p></li>
<li><p><strong>dim</strong> (<em>int</em>) – The dimension along which to compute the standard deviation.</p></li>
<li><p><strong>keepdim</strong> (<em>bool</em>) – If True, the dimension along which the standard deviation is
compute is kept.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.transforms.utils.kumaraswamy_warp">
<span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.utils.</span></span><span class="sig-name descname"><span class="pre">kumaraswamy_warp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-08</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/utils.html#kumaraswamy_warp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.utils.kumaraswamy_warp" title="Link to this definition"></a></dt>
<dd><p>Warp inputs through a Kumaraswamy CDF.</p>
<p>This assumes that X is contained within the unit cube. This first
normalizes inputs to [eps, 1-eps]^d (to ensure that no values are 0 or 1)
and then applies passes those inputs through a Kumaraswamy CDF.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of inputs.</p></li>
<li><p><strong>c0</strong> (<em>Tensor</em>) – A <cite>d</cite>-dim tensor of the concentration0 parameter for the
Kumaraswamy distribution.</p></li>
<li><p><strong>c1</strong> (<em>Tensor</em>) – A <cite>d</cite>-dim tensor of the concentration1 parameter for the
Kumaraswamy distribution.</p></li>
<li><p><strong>eps</strong> (<em>float</em>) – A small value that is used to ensure inputs are not 0 or 1.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape x n x d</cite>-dim tensor of warped inputs.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.transforms.utils.inv_kumaraswamy_warp">
<span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.utils.</span></span><span class="sig-name descname"><span class="pre">inv_kumaraswamy_warp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-08</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/utils.html#inv_kumaraswamy_warp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.utils.inv_kumaraswamy_warp" title="Link to this definition"></a></dt>
<dd><p>Map warped inputs through an inverse Kumaraswamy CDF.</p>
<p>This takes warped inputs (X) and transforms those via an inverse
Kumaraswamy CDF. This then unnormalizes the inputs using bounds of
[eps, 1-eps]^d and ensures that the values are within [0, 1]^d.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of inputs.</p></li>
<li><p><strong>c0</strong> (<em>Tensor</em>) – A <cite>d</cite>-dim tensor of the concentration0 parameter for the
Kumaraswamy distribution.</p></li>
<li><p><strong>c1</strong> (<em>Tensor</em>) – A <cite>d</cite>-dim tensor of the concentration1 parameter for the
Kumaraswamy distribution.</p></li>
<li><p><strong>eps</strong> (<em>float</em>) – A small value that is used to ensure inputs are not 0 or 1.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape x n x d</cite>-dim tensor of untransformed inputs.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</section>
</section>
<section id="utilities">
<h2>Utilities<a class="headerlink" href="#utilities" title="Link to this heading"></a></h2>
<section id="module-botorch.models.utils.gpytorch_modules">
<span id="gpytorch-module-constructors"></span><h3>GPyTorch Module Constructors<a class="headerlink" href="#module-botorch.models.utils.gpytorch_modules" title="Link to this heading"></a></h3>
<p>Pre-packaged kernels for bayesian optimization, including a Scale/Matern
kernel that is well-suited to low-dimensional high-noise problems, and
a dimension-agnostic RBF kernel without outputscale.</p>
<p>References:</p>
<div role="list" class="citation-list">
<div class="citation" id="hvarfner2024vanilla" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Hvarfner2024vanilla<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id6">1</a>,<a role="doc-backlink" href="#id42">2</a>,<a role="doc-backlink" href="#id43">3</a>)</span>
<p>C. Hvarfner, E. O. Hellsten, L. Nardi,
Vanilla Bayesian Optimization Performs Great in High Dimensions.
In International Conference on Machine Learning, 2024.</p>
</div>
</div>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.utils.gpytorch_modules.get_matern_kernel_with_gamma_prior">
<span class="sig-prename descclassname"><span class="pre">botorch.models.utils.gpytorch_modules.</span></span><span class="sig-name descname"><span class="pre">get_matern_kernel_with_gamma_prior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ard_num_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/utils/gpytorch_modules.html#get_matern_kernel_with_gamma_prior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.utils.gpytorch_modules.get_matern_kernel_with_gamma_prior" title="Link to this definition"></a></dt>
<dd><p>Constructs the Scale-Matern kernel that is used by default by
several models. This uses a Gamma(3.0, 6.0) prior for the lengthscale
and a Gamma(2.0, 0.15) prior for the output scale.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ard_num_dims</strong> (<em>int</em>)</p></li>
<li><p><strong>batch_shape</strong> (<em>Size</em><em> | </em><em>None</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>ScaleKernel</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.utils.gpytorch_modules.get_gaussian_likelihood_with_gamma_prior">
<span class="sig-prename descclassname"><span class="pre">botorch.models.utils.gpytorch_modules.</span></span><span class="sig-name descname"><span class="pre">get_gaussian_likelihood_with_gamma_prior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/utils/gpytorch_modules.html#get_gaussian_likelihood_with_gamma_prior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.utils.gpytorch_modules.get_gaussian_likelihood_with_gamma_prior" title="Link to this definition"></a></dt>
<dd><p>Constructs the GaussianLikelihood that is used by default by
several models. This uses a Gamma(1.1, 0.05) prior and constrains the
noise level to be greater than MIN_INFERRED_NOISE_LEVEL (=1e-4).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch_shape</strong> (<em>Size</em><em> | </em><em>None</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>GaussianLikelihood</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.utils.gpytorch_modules.get_gaussian_likelihood_with_lognormal_prior">
<span class="sig-prename descclassname"><span class="pre">botorch.models.utils.gpytorch_modules.</span></span><span class="sig-name descname"><span class="pre">get_gaussian_likelihood_with_lognormal_prior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/utils/gpytorch_modules.html#get_gaussian_likelihood_with_lognormal_prior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.utils.gpytorch_modules.get_gaussian_likelihood_with_lognormal_prior" title="Link to this definition"></a></dt>
<dd><p>Return Gaussian likelihood with a LogNormal(-4.0, 1.0) prior.
This prior is based on <a class="reference internal" href="#hvarfner2024vanilla" id="id42"><span>[Hvarfner2024vanilla]</span></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch_shape</strong> (<em>Size</em><em> | </em><em>None</em>) – Batch shape for the likelihood.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>GaussianLikelihood with LogNormal(-4.0, 1.0) prior and constrains the
noise level to be greater than MIN_INFERRED_NOISE_LEVEL (=1e-4).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>GaussianLikelihood</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.utils.gpytorch_modules.get_covar_module_with_dim_scaled_prior">
<span class="sig-prename descclassname"><span class="pre">botorch.models.utils.gpytorch_modules.</span></span><span class="sig-name descname"><span class="pre">get_covar_module_with_dim_scaled_prior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ard_num_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_rbf_kernel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">active_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/utils/gpytorch_modules.html#get_covar_module_with_dim_scaled_prior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.utils.gpytorch_modules.get_covar_module_with_dim_scaled_prior" title="Link to this definition"></a></dt>
<dd><p>Returns an RBF or Matern kernel with priors
from  <a class="reference internal" href="#hvarfner2024vanilla" id="id43"><span>[Hvarfner2024vanilla]</span></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ard_num_dims</strong> (<em>int</em>) – Number of feature dimensions for ARD.</p></li>
<li><p><strong>batch_shape</strong> (<em>Size</em><em> | </em><em>None</em>) – Batch shape for the covariance module.</p></li>
<li><p><strong>use_rbf_kernel</strong> (<em>bool</em>) – Whether to use an RBF kernel. If False, uses a Matern kernel.</p></li>
<li><p><strong>active_dims</strong> (<em>Sequence</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – The set of input dimensions to compute the covariances on.
By default, the covariance is computed using the full input tensor.
Set this if you’d like to ignore certain dimensions.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A Kernel constructed according to the given arguments. The prior is constrained
to have lengthscales larger than 0.025 for numerical stability.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>MaternKernel</em> | <em>RBFKernel</em></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-botorch.models.converter">
<span id="model-conversion"></span><h3>Model Conversion<a class="headerlink" href="#module-botorch.models.converter" title="Link to this heading"></a></h3>
<p>Utilities for converting between different models.</p>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.converter.model_list_to_batched">
<span class="sig-prename descclassname"><span class="pre">botorch.models.converter.</span></span><span class="sig-name descname"><span class="pre">model_list_to_batched</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_list</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/converter.html#model_list_to_batched"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.converter.model_list_to_batched" title="Link to this definition"></a></dt>
<dd><p>Convert a ModelListGP to a BatchedMultiOutputGPyTorchModel.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model_list</strong> (<a class="reference internal" href="#botorch.models.model_list_gp_regression.ModelListGP" title="botorch.models.model_list_gp_regression.ModelListGP"><em>ModelListGP</em></a>) – The <cite>ModelListGP</cite> to be converted to the appropriate
<cite>BatchedMultiOutputGPyTorchModel</cite>. All sub-models must be of the same
type and have the shape (batch shape and number of training inputs).</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The model converted into a <cite>BatchedMultiOutputGPyTorchModel</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel" title="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel"><em>BatchedMultiOutputGPyTorchModel</em></a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">list_gp</span> <span class="o">=</span> <span class="n">ModelListGP</span><span class="p">(</span><span class="n">gp1</span><span class="p">,</span> <span class="n">gp2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch_gp</span> <span class="o">=</span> <span class="n">model_list_to_batched</span><span class="p">(</span><span class="n">list_gp</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.converter.set_attribute">
<span class="sig-prename descclassname"><span class="pre">botorch.models.converter.</span></span><span class="sig-name descname"><span class="pre">set_attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obj</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">val</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/converter.html#set_attribute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.converter.set_attribute" title="Link to this definition"></a></dt>
<dd><p>Like <cite>setattr</cite> but works with hierarchical attribute specification.
E.g. if obj=Zoo(), and attr=”tiger.age”, set_attribute(obj, attr, 3),
would set the Zoo’s tiger’s age to three.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>attr</strong> (<em>str</em>)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.converter.get_attribute">
<span class="sig-prename descclassname"><span class="pre">botorch.models.converter.</span></span><span class="sig-name descname"><span class="pre">get_attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obj</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attr</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/converter.html#get_attribute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.converter.get_attribute" title="Link to this definition"></a></dt>
<dd><p>Like <cite>getattr</cite> but works with hierarchical attribute specification.
E.g. if obj=Zoo(), and attr=”tiger.age”, get_attribute(obj, attr),
would return the Zoo’s tiger’s age.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>attr</strong> (<em>str</em>)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.converter.batched_to_model_list">
<span class="sig-prename descclassname"><span class="pre">botorch.models.converter.</span></span><span class="sig-name descname"><span class="pre">batched_to_model_list</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/converter.html#batched_to_model_list"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.converter.batched_to_model_list" title="Link to this definition"></a></dt>
<dd><p>Convert a BatchedMultiOutputGPyTorchModel to a ModelListGP.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch_model</strong> (<a class="reference internal" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel" title="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel"><em>BatchedMultiOutputGPyTorchModel</em></a>) – The <cite>BatchedMultiOutputGPyTorchModel</cite> to be converted to a
<cite>ModelListGP</cite>.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The model converted into a <cite>ModelListGP</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.model_list_gp_regression.ModelListGP" title="botorch.models.model_list_gp_regression.ModelListGP"><em>ModelListGP</em></a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch_gp</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">list_gp</span> <span class="o">=</span> <span class="n">batched_to_model_list</span><span class="p">(</span><span class="n">batch_gp</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.converter.batched_multi_output_to_single_output">
<span class="sig-prename descclassname"><span class="pre">botorch.models.converter.</span></span><span class="sig-name descname"><span class="pre">batched_multi_output_to_single_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_mo_model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/converter.html#batched_multi_output_to_single_output"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.converter.batched_multi_output_to_single_output" title="Link to this definition"></a></dt>
<dd><p>Convert a model from batched multi-output to a batched single-output.</p>
<p>Note: the underlying GPyTorch GP does not change. The GPyTorch GP’s batch_shape
(referred to as <cite>_aug_batch_shape</cite>) is still <cite>_input_batch_shape x num_outputs</cite>.
The only things that change are the attributes of the
BatchedMultiOutputGPyTorchModel that are responsible the internal accounting of
the number of outputs: namely, num_outputs, _input_batch_shape, and
_aug_batch_shape.
Initially for the batched MO models these are: <cite>num_outputs = m</cite>,
<cite>_input_batch_shape = train_X.batch_shape</cite>, and
<cite>_aug_batch_shape = train_X.batch_shape + torch.Size([num_outputs])</cite>.
In the new SO model, these are: <cite>num_outputs = 1</cite>,
<cite>_input_batch_shape = train_X.batch_shape + torch.Size([num_outputs])</cite>,
and <cite>_aug_batch_shape = train_X.batch_shape + torch.Size([num_outputs])</cite>.</p>
<p>This is a (hopefully) temporary measure until multi-output MVNs with
independent outputs have better support in GPyTorch (see
<a class="reference external" href="https://github.com/cornellius-gp/gpytorch/pull/1083">https://github.com/cornellius-gp/gpytorch/pull/1083</a>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batched_mo_model</strong> – The BatchedMultiOutputGPyTorchModel</p></li>
<li><p><strong>batch_mo_model</strong> (<a class="reference internal" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel" title="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel"><em>BatchedMultiOutputGPyTorchModel</em></a>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The model converted into a batch single-output model.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel" title="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel"><em>BatchedMultiOutputGPyTorchModel</em></a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch_mo_gp</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">,</span> <span class="n">outcome_transform</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch_so_gp</span> <span class="o">=</span> <span class="n">batched_multi_output_to_single_output</span><span class="p">(</span><span class="n">batch_mo_gp</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="module-botorch.models.utils.inducing_point_allocators">
<span id="inducing-point-allocators"></span><h3>Inducing Point Allocators<a class="headerlink" href="#module-botorch.models.utils.inducing_point_allocators" title="Link to this heading"></a></h3>
<p>Functionality for allocating the inducing points of sparse Gaussian
process models.</p>
<p>References</p>
<div role="list" class="citation-list">
<div class="citation" id="chen2018dpp" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>chen2018dpp<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id49">1</a>,<a role="doc-backlink" href="#id50">2</a>)</span>
<p>Laming Chen and Guoxin Zhang and Hanning Zhou, Fast greedy MAP inference
for determinantal point process to improve recommendation diversity,
Proceedings of the 32nd International Conference on Neural Information
Processing Systems, 2018, <a class="reference external" href="https://arxiv.org/abs/1709.05135">https://arxiv.org/abs/1709.05135</a>.</p>
</div>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.utils.inducing_point_allocators.InducingPointAllocator">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.utils.inducing_point_allocators.</span></span><span class="sig-name descname"><span class="pre">InducingPointAllocator</span></span><a class="reference internal" href="_modules/botorch/models/utils/inducing_point_allocators.html#InducingPointAllocator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.utils.inducing_point_allocators.InducingPointAllocator" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>This class provides functionality to initialize the inducing point locations
of an inducing point-based model, e.g. a <cite>SingleTaskVariationalGP</cite>.</p>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.utils.inducing_point_allocators.InducingPointAllocator.allocate_inducing_points">
<span class="sig-name descname"><span class="pre">allocate_inducing_points</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">covar_module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_inducing</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_batch_shape</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/utils/inducing_point_allocators.html#InducingPointAllocator.allocate_inducing_points"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.utils.inducing_point_allocators.InducingPointAllocator.allocate_inducing_points" title="Link to this definition"></a></dt>
<dd><p>Initialize the <cite>num_inducing</cite> inducing point locations according to a
specific initialization strategy. todo say something about quality</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>Tensor</em>) – A (*batch_shape, n, d)-dim input data tensor.</p></li>
<li><p><strong>covar_module</strong> (<em>Module</em>) – GPyTorch Module returning a LinearOperator kernel matrix.</p></li>
<li><p><strong>num_inducing</strong> (<em>int</em>) – The maximun number (m) of inducing points (m &lt;= n).</p></li>
<li><p><strong>input_batch_shape</strong> (<em>Size</em>) – The non-task-related batch shape.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A (*batch_shape, m, d)-dim tensor of inducing point locations.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.utils.inducing_point_allocators.QualityFunction">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.utils.inducing_point_allocators.</span></span><span class="sig-name descname"><span class="pre">QualityFunction</span></span><a class="reference internal" href="_modules/botorch/models/utils/inducing_point_allocators.html#QualityFunction"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.utils.inducing_point_allocators.QualityFunction" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>A function that scores inputs with respect
to a specific criterion.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.utils.inducing_point_allocators.UnitQualityFunction">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.utils.inducing_point_allocators.</span></span><span class="sig-name descname"><span class="pre">UnitQualityFunction</span></span><a class="reference internal" href="_modules/botorch/models/utils/inducing_point_allocators.html#UnitQualityFunction"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.utils.inducing_point_allocators.UnitQualityFunction" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.utils.inducing_point_allocators.QualityFunction" title="botorch.models.utils.inducing_point_allocators.QualityFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">QualityFunction</span></code></a></p>
<p>A function returning ones for each element. Using this quality function
for inducing point allocation corresponds to allocating inducing points
with the sole aim of minimizing predictive variance, i.e. the approach
of <a class="reference internal" href="#burt2020svgp" id="id44"><span>[burt2020svgp]</span></a>.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.utils.inducing_point_allocators.ExpectedImprovementQualityFunction">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.utils.inducing_point_allocators.</span></span><span class="sig-name descname"><span class="pre">ExpectedImprovementQualityFunction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximize</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/utils/inducing_point_allocators.html#ExpectedImprovementQualityFunction"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.utils.inducing_point_allocators.ExpectedImprovementQualityFunction" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.utils.inducing_point_allocators.QualityFunction" title="botorch.models.utils.inducing_point_allocators.QualityFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">QualityFunction</span></code></a></p>
<p>A function measuring the quality of input points as their expected
improvement with respect to a conservative baseline. Expectations
are according to the model from the previous BO step. See <a class="reference internal" href="#moss2023ipa" id="id45"><span>[moss2023ipa]</span></a>
for details and justification.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – The model fitted during the previous BO step. For now, this
must be a single task model (i.e. num_outputs=1).</p></li>
<li><p><strong>maximize</strong> (<em>bool</em>) – Set True if we are performing function maximization, else
set False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.utils.inducing_point_allocators.GreedyVarianceReduction">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.utils.inducing_point_allocators.</span></span><span class="sig-name descname"><span class="pre">GreedyVarianceReduction</span></span><a class="reference internal" href="_modules/botorch/models/utils/inducing_point_allocators.html#GreedyVarianceReduction"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.utils.inducing_point_allocators.GreedyVarianceReduction" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.utils.inducing_point_allocators.InducingPointAllocator" title="botorch.models.utils.inducing_point_allocators.InducingPointAllocator"><code class="xref py py-class docutils literal notranslate"><span class="pre">InducingPointAllocator</span></code></a></p>
<p>The inducing point allocator proposed by <a class="reference internal" href="#burt2020svgp" id="id46"><span>[burt2020svgp]</span></a>, that
greedily chooses inducing point locations with maximal (conditional)
predictive variance.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.utils.inducing_point_allocators.GreedyImprovementReduction">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.utils.inducing_point_allocators.</span></span><span class="sig-name descname"><span class="pre">GreedyImprovementReduction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximize</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/utils/inducing_point_allocators.html#GreedyImprovementReduction"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.utils.inducing_point_allocators.GreedyImprovementReduction" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.utils.inducing_point_allocators.InducingPointAllocator" title="botorch.models.utils.inducing_point_allocators.InducingPointAllocator"><code class="xref py py-class docutils literal notranslate"><span class="pre">InducingPointAllocator</span></code></a></p>
<p>An inducing point allocator that greedily chooses inducing points with large
predictive variance and that are in promising regions of the search
space (according to the model form the previous BO step), see <a class="reference internal" href="#moss2023ipa" id="id47"><span>[moss2023ipa]</span></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – The model fitted during the previous BO step.</p></li>
<li><p><strong>maximize</strong> (<em>bool</em>) – Set True if we are performing function maximization, else
set False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.utils.inducing_point_allocators._pivoted_cholesky_init">
<span class="sig-prename descclassname"><span class="pre">botorch.models.utils.inducing_point_allocators.</span></span><span class="sig-name descname"><span class="pre">_pivoted_cholesky_init</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_matrix</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">quality_scores</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-06</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/utils/inducing_point_allocators.html#_pivoted_cholesky_init"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.utils.inducing_point_allocators._pivoted_cholesky_init" title="Link to this definition"></a></dt>
<dd><p>A pivoted Cholesky initialization method for the inducing points,
originally proposed in <a class="reference internal" href="#burt2020svgp" id="id48"><span>[burt2020svgp]</span></a> with the algorithm itself coming from
<a class="reference internal" href="#chen2018dpp" id="id49"><span>[chen2018dpp]</span></a>. Code is a PyTorch version from <a class="reference internal" href="#chen2018dpp" id="id50"><span>[chen2018dpp]</span></a>, based on
<a class="reference external" href="https://github.com/laming-chen/fast-map-dpp/blob/master/dpp.py">https://github.com/laming-chen/fast-map-dpp/blob/master/dpp.py</a> but with a small
modification to allow the underlying DPP to be defined through its diversity-quality
decomposition,as discussed by <a class="reference internal" href="#moss2023ipa" id="id51"><span>[moss2023ipa]</span></a>. This method returns a greedy
approximation of the MAP estimate of the specified DPP, i.e. its returns a
set of points that are highly diverse (according to the provided kernel_matrix)
and have high quality (according to the provided quality_scores).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_inputs</strong> (<em>Tensor</em>) – training inputs (of shape n x d)</p></li>
<li><p><strong>kernel_matrix</strong> (<em>Tensor</em><em> | </em><em>LinearOperator</em>) – kernel matrix on the training inputs</p></li>
<li><p><strong>max_length</strong> (<em>int</em>) – number of inducing points to initialize</p></li>
<li><p><strong>quality_scores</strong> (<em>Tensor</em>) – scores representing the quality of each candidate
input (of shape [n])</p></li>
<li><p><strong>epsilon</strong> (<em>float</em>) – numerical jitter for stability.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>max_length x d tensor of the training inputs corresponding to the top
max_length pivots of the training kernel matrix</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-botorch.models.utils.assorted">
<span id="other-utilties"></span><h3>Other Utilties<a class="headerlink" href="#module-botorch.models.utils.assorted" title="Link to this heading"></a></h3>
<p>Assorted helper methods and objects for working with BoTorch models.</p>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.utils.assorted.multioutput_to_batch_mode_transform">
<span class="sig-prename descclassname"><span class="pre">botorch.models.utils.assorted.</span></span><span class="sig-name descname"><span class="pre">multioutput_to_batch_mode_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Yvar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/utils/assorted.html#multioutput_to_batch_mode_transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.utils.assorted.multioutput_to_batch_mode_transform" title="Link to this definition"></a></dt>
<dd><p>Transforms training inputs for a multi-output model.</p>
<p>Used for multi-output models that internally are represented by a
batched single output model, where each output is modeled as an
independent batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>Tensor</em>) – A <cite>n x d</cite> or <cite>input_batch_shape x n x d</cite> (batch mode) tensor of
training features.</p></li>
<li><p><strong>train_Y</strong> (<em>Tensor</em>) – A <cite>n x m</cite> or <cite>target_batch_shape x n x m</cite> (batch mode) tensor of
training observations.</p></li>
<li><p><strong>num_outputs</strong> (<em>int</em>) – number of outputs</p></li>
<li><p><strong>train_Yvar</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>n x m</cite> or <cite>target_batch_shape x n x m</cite> tensor of observed
measurement noise.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>3-element tuple containing</p>
<ul class="simple">
<li><p>A <cite>input_batch_shape x m x n x d</cite> tensor of training features.</p></li>
<li><p>A <cite>target_batch_shape x m x n</cite> tensor of training observations.</p></li>
<li><p>A <cite>target_batch_shape x m x n</cite> tensor observed measurement noise.</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple[<em>Tensor</em>, <em>Tensor</em>, <em>Tensor</em> | None]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.utils.assorted.add_output_dim">
<span class="sig-prename descclassname"><span class="pre">botorch.models.utils.assorted.</span></span><span class="sig-name descname"><span class="pre">add_output_dim</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">original_batch_shape</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/utils/assorted.html#add_output_dim"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.utils.assorted.add_output_dim" title="Link to this definition"></a></dt>
<dd><p>Insert the output dimension at the correct location.</p>
<p>The trailing batch dimensions of X must match the original batch dimensions
of the training inputs, but can also include extra batch dimensions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>(new_batch_shape) x (original_batch_shape) x n x d</cite> tensor of
features.</p></li>
<li><p><strong>original_batch_shape</strong> (<em>Size</em>) – the batch shape of the model’s training inputs.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>2-element tuple containing</p>
<ul class="simple">
<li><dl class="simple">
<dt>A <cite>(new_batch_shape) x (original_batch_shape) x m x n x d</cite> tensor of</dt><dd><p>features.</p>
</dd>
</dl>
</li>
<li><p>The index corresponding to the output dimension.</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple[<em>Tensor</em>, int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.utils.assorted.check_no_nans">
<span class="sig-prename descclassname"><span class="pre">botorch.models.utils.assorted.</span></span><span class="sig-name descname"><span class="pre">check_no_nans</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Z</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/utils/assorted.html#check_no_nans"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.utils.assorted.check_no_nans" title="Link to this definition"></a></dt>
<dd><p>Check that tensor does not contain NaN values.</p>
<p>Raises an InputDataError if <cite>Z</cite> contains NaN values.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>Z</strong> (<em>Tensor</em>) – The input tensor.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.utils.assorted.check_min_max_scaling">
<span class="sig-prename descclassname"><span class="pre">botorch.models.utils.assorted.</span></span><span class="sig-name descname"><span class="pre">check_min_max_scaling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">atol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raise_on_fail</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/utils/assorted.html#check_min_max_scaling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.utils.assorted.check_min_max_scaling" title="Link to this definition"></a></dt>
<dd><p>Check that tensor is normalized to the unit cube.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite> input tensor. Typically the training inputs
of a model.</p></li>
<li><p><strong>strict</strong> (<em>bool</em>) – If True, require <cite>X</cite> to be scaled to the unit cube (rather than
just to be contained within the unit cube).</p></li>
<li><p><strong>atol</strong> (<em>float</em>) – The tolerance for the boundary check. Only used if <cite>strict=True</cite>.</p></li>
<li><p><strong>raise_on_fail</strong> (<em>bool</em>) – If True, raise an exception instead of a warning.</p></li>
<li><p><strong>ignore_dims</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – Subset of dimensions where the min-max scaling check is omitted.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.utils.assorted.check_standardization">
<span class="sig-prename descclassname"><span class="pre">botorch.models.utils.assorted.</span></span><span class="sig-name descname"><span class="pre">check_standardization</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">atol_mean</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">atol_std</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raise_on_fail</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/utils/assorted.html#check_standardization"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.utils.assorted.check_standardization" title="Link to this definition"></a></dt>
<dd><p>Check that tensor is standardized (zero mean, unit variance).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Y</strong> (<em>Tensor</em>) – The input tensor of shape <cite>batch_shape x n x m</cite>. Typically the
train targets of a model. Standardization is checked across the
<cite>n</cite>-dimension.</p></li>
<li><p><strong>atol_mean</strong> (<em>float</em>) – The tolerance for the mean check.</p></li>
<li><p><strong>atol_std</strong> (<em>float</em>) – The tolerance for the std check.</p></li>
<li><p><strong>raise_on_fail</strong> (<em>bool</em>) – If True, raise an exception instead of a warning.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.utils.assorted.validate_input_scaling">
<span class="sig-prename descclassname"><span class="pre">botorch.models.utils.assorted.</span></span><span class="sig-name descname"><span class="pre">validate_input_scaling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Yvar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raise_on_fail</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_X_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">check_nans_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/utils/assorted.html#validate_input_scaling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.utils.assorted.validate_input_scaling" title="Link to this definition"></a></dt>
<dd><p>Helper function to validate input data to models.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>Tensor</em>) – A <cite>n x d</cite> or <cite>batch_shape x n x d</cite> (batch mode) tensor of
training features.</p></li>
<li><p><strong>train_Y</strong> (<em>Tensor</em>) – A <cite>n x m</cite> or <cite>batch_shape x n x m</cite> (batch mode) tensor of
training observations.</p></li>
<li><p><strong>train_Yvar</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x n x m</cite> or <cite>batch_shape x n x m</cite> (batch mode)
tensor of observed measurement noise.</p></li>
<li><p><strong>raise_on_fail</strong> (<em>bool</em>) – If True, raise an error instead of emitting a warning
(only for normalization/standardization checks, an error is always
raised if NaN values are present).</p></li>
<li><p><strong>ignore_X_dims</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – For this subset of dimensions from <cite>{1, …, d}</cite>, ignore the
min-max scaling check.</p></li>
<li><p><strong>check_nans_only</strong> (<em>bool</em>) – If True, only check for NaN values. Skips min-max scaling
and standardization checks. This is used when the model is provided
with a custom covariance module, to avoid potentially irrelevant
warnings.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>This function is typically called inside the constructor of standard BoTorch
models. It validates the following:
(i) none of the inputs contain NaN values
(ii) the training data (<cite>train_X</cite>) is normalized to the unit cube for all
dimensions except those in <cite>ignore_X_dims</cite>.
(iii) the training targets (<cite>train_Y</cite>) are standardized (zero mean, unit var)
No checks (other than the NaN check) are performed for observed variances
(<cite>train_Yvar</cite>) at this point.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.utils.assorted.mod_batch_shape">
<span class="sig-prename descclassname"><span class="pre">botorch.models.utils.assorted.</span></span><span class="sig-name descname"><span class="pre">mod_batch_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">names</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/utils/assorted.html#mod_batch_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.utils.assorted.mod_batch_shape" title="Link to this definition"></a></dt>
<dd><p>Recursive helper to modify gpytorch modules’ batch shape attribute.</p>
<p>Modifies the module in-place.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> (<em>Module</em>) – The module to be modified.</p></li>
<li><p><strong>names</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – The list of names to access the attribute. If the full name of
the module is <cite>“module.sub_module.leaf_module”</cite>, this will be
<cite>[“sub_module”, “leaf_module”]</cite>.</p></li>
<li><p><strong>b</strong> (<em>int</em>) – The new size of the last element of the module’s <cite>batch_shape</cite>
attribute.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.utils.assorted.gpt_posterior_settings">
<span class="sig-prename descclassname"><span class="pre">botorch.models.utils.assorted.</span></span><span class="sig-name descname"><span class="pre">gpt_posterior_settings</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/utils/assorted.html#gpt_posterior_settings"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.utils.assorted.gpt_posterior_settings" title="Link to this definition"></a></dt>
<dd><p>Context manager for settings used for computing model posteriors.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.utils.assorted.detect_duplicates">
<span class="sig-prename descclassname"><span class="pre">botorch.models.utils.assorted.</span></span><span class="sig-name descname"><span class="pre">detect_duplicates</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rtol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">atol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-08</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/utils/assorted.html#detect_duplicates"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.utils.assorted.detect_duplicates" title="Link to this definition"></a></dt>
<dd><p>Returns an iterator over index pairs <cite>(duplicate index, original index)</cite> for all
duplicate entries of <cite>X</cite>. Supporting 2-d Tensor only.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – the datapoints tensor with potential duplicated entries</p></li>
<li><p><strong>rtol</strong> (<em>float</em>) – relative tolerance</p></li>
<li><p><strong>atol</strong> (<em>float</em>) – absolute tolerance</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Iterator</em>[tuple[int, int]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.utils.assorted.consolidate_duplicates">
<span class="sig-prename descclassname"><span class="pre">botorch.models.utils.assorted.</span></span><span class="sig-name descname"><span class="pre">consolidate_duplicates</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rtol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">atol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-08</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/utils/assorted.html#consolidate_duplicates"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.utils.assorted.consolidate_duplicates" title="Link to this definition"></a></dt>
<dd><p>Drop duplicated Xs and update the indices tensor Y accordingly.
Supporting 2d Tensor only as in batch mode block design is not guaranteed.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – the datapoints tensor</p></li>
<li><p><strong>Y</strong> (<em>Tensor</em>) – the index tensor to be updated (e.g., pairwise comparisons)</p></li>
<li><p><strong>rtol</strong> (<em>float</em>) – relative tolerance</p></li>
<li><p><strong>atol</strong> (<em>float</em>) – absolute tolerance</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>the consolidated X
consolidated_Y: the consolidated Y (e.g., pairwise comparisons indices)
new_indices: new index of each original item in X, a tensor of size X.shape[-2]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>consolidated_X</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.utils.assorted.fantasize">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.models.utils.assorted.</span></span><span class="sig-name descname"><span class="pre">fantasize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/utils/assorted.html#fantasize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.utils.assorted.fantasize" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">_Flag</span></code></p>
<p>A flag denoting whether we are currently in a <cite>fantasize</cite> context.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>state</strong> (<em>bool</em>)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.utils.assorted.get_task_value_remapping">
<span class="sig-prename descclassname"><span class="pre">botorch.models.utils.assorted.</span></span><span class="sig-name descname"><span class="pre">get_task_value_remapping</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task_values</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/utils/assorted.html#get_task_value_remapping"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.utils.assorted.get_task_value_remapping" title="Link to this definition"></a></dt>
<dd><p>Construct an mapping of discrete task values to contiguous int-valued floats.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>task_values</strong> (<em>Tensor</em>) – A sorted long-valued tensor of task values.</p></li>
<li><p><strong>dtype</strong> (<em>dtype</em>) – The dtype of the model inputs (e.g. <cite>X</cite>), which the new
task values should have mapped to (e.g. float, double).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor of shape <cite>task_values.max() + 1</cite> that maps task values
to new task values. The indexing operation <cite>mapper[task_value]</cite>
will produce a tensor of new task values, of the same shape as
the original. The elements of the <cite>mapper</cite> tensor that do not
appear in the original <cite>task_values</cite> are mapped to <cite>nan</cite>. The
return value will be <cite>None</cite>, when the task values are contiguous
integers starting from zero.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em> | None</p>
</dd>
</dl>
</dd></dl>

</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="acquisition.html" class="btn btn-neutral float-left" title="botorch.acquisition" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="generation.html" class="btn btn-neutral float-right" title="botorch.generation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p></p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>