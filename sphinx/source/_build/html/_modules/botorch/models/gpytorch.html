

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>botorch.models.gpytorch &mdash; BoTorch  documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=03e43079" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../../_static/custom.css?v=ca3e82f4" />

  
      <script src="../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../_static/documentation_options.js?v=5929fcd5"></script>
      <script src="../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            BoTorch
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../acquisition.html">botorch.acquisition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models.html">botorch.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generation.html">botorch.generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../posteriors.html">botorch.posteriors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../optim.html">botorch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../fit.html">botorch.fit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../sampling.html">botorch.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cross_validation.html">botorch.cross_validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../settings.html">botorch.settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../logging.html">botorch.logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../test_functions.html">botorch.test_functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../test_utils.html">botorch.test_utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../exceptions.html">botorch.exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../utils.html">botorch.utils</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">BoTorch</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">botorch.models.gpytorch</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for botorch.models.gpytorch</h1><div class="highlight"><pre>
<span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="c1"># Copyright (c) Meta Platforms, Inc. and affiliates.</span>
<span class="c1">#</span>
<span class="c1"># This source code is licensed under the MIT license found in the</span>
<span class="c1"># LICENSE file in the root directory of this source tree.</span>

<span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Abstract model class for all GPyTorch-based botorch models.</span>

<span class="sd">To implement your own, simply inherit from both the provided classes and a</span>
<span class="sd">GPyTorch Model class such as an ExactGP.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">__future__</span><span class="w"> </span><span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">itertools</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">ABC</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">copy</span><span class="w"> </span><span class="kn">import</span> <span class="n">deepcopy</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">TYPE_CHECKING</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.acquisition.objective</span><span class="w"> </span><span class="kn">import</span> <span class="n">PosteriorTransform</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.exceptions.errors</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">BotorchTensorDimensionError</span><span class="p">,</span>
    <span class="n">InputDataError</span><span class="p">,</span>
    <span class="n">UnsupportedError</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.exceptions.warnings</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">_get_single_precision_warning</span><span class="p">,</span>
    <span class="n">BotorchTensorDimensionWarning</span><span class="p">,</span>
    <span class="n">InputDataWarning</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.models.model</span><span class="w"> </span><span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">ModelList</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.models.utils</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">_make_X_full</span><span class="p">,</span>
    <span class="n">add_output_dim</span><span class="p">,</span>
    <span class="n">gpt_posterior_settings</span><span class="p">,</span>
    <span class="n">mod_batch_shape</span><span class="p">,</span>
    <span class="n">multioutput_to_batch_mode_transform</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.models.utils.assorted</span><span class="w"> </span><span class="kn">import</span> <span class="n">fantasize</span> <span class="k">as</span> <span class="n">fantasize_flag</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.posteriors.fully_bayesian</span><span class="w"> </span><span class="kn">import</span> <span class="n">GaussianMixturePosterior</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.posteriors.gpytorch</span><span class="w"> </span><span class="kn">import</span> <span class="n">GPyTorchPosterior</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.utils.multitask</span><span class="w"> </span><span class="kn">import</span> <span class="n">separate_mtmvn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.utils.transforms</span><span class="w"> </span><span class="kn">import</span> <span class="n">is_ensemble</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.distributions</span><span class="w"> </span><span class="kn">import</span> <span class="n">MultitaskMultivariateNormal</span><span class="p">,</span> <span class="n">MultivariateNormal</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.likelihoods.gaussian_likelihood</span><span class="w"> </span><span class="kn">import</span> <span class="n">FixedNoiseGaussianLikelihood</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">linear_operator.operators</span><span class="w"> </span><span class="kn">import</span> <span class="n">BlockDiagLinearOperator</span><span class="p">,</span> <span class="n">CatLinearOperator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">Tensor</span>

<span class="k">if</span> <span class="n">TYPE_CHECKING</span><span class="p">:</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">botorch.posteriors.posterior_list</span><span class="w"> </span><span class="kn">import</span> <span class="n">PosteriorList</span>  <span class="c1"># pragma: no cover</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">botorch.posteriors.transformed</span><span class="w"> </span><span class="kn">import</span> <span class="n">TransformedPosterior</span>  <span class="c1"># pragma: no cover</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.likelihoods</span><span class="w"> </span><span class="kn">import</span> <span class="n">Likelihood</span>  <span class="c1"># pragma: no cover</span>


<div class="viewcode-block" id="GPyTorchModel">
<a class="viewcode-back" href="../../../models.html#botorch.models.gpytorch.GPyTorchModel">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">GPyTorchModel</span><span class="p">(</span><span class="n">Model</span><span class="p">,</span> <span class="n">ABC</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Abstract base class for models based on GPyTorch models.</span>

<span class="sd">    The easiest way to use this is to subclass a model from a GPyTorch model</span>
<span class="sd">    class (e.g. an `ExactGP`) and this `GPyTorchModel`. See e.g. `SingleTaskGP`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">likelihood</span><span class="p">:</span> <span class="n">Likelihood</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_validate_tensor_args</span><span class="p">(</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Yvar</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">strict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Checks that `Y` and `Yvar` have an explicit output dimension if strict.</span>
<span class="sd">        Checks that the dtypes of the inputs match, and warns if using float.</span>

<span class="sd">        This also checks that `Yvar` has the same trailing dimensions as `Y`. Note</span>
<span class="sd">        we only infer that an explicit output dimension exists when `X` and `Y` have</span>
<span class="sd">        the same `batch_shape`.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: A `batch_shape x n x d`-dim Tensor, where `d` is the dimension of</span>
<span class="sd">                the feature space, `n` is the number of points per batch, and</span>
<span class="sd">                `batch_shape` is the batch shape (potentially empty).</span>
<span class="sd">            Y: A `batch_shape&#39; x n x m`-dim Tensor, where `m` is the number of</span>
<span class="sd">                model outputs, `n&#39;` is the number of points per batch, and</span>
<span class="sd">                `batch_shape&#39;` is the batch shape of the observations.</span>
<span class="sd">            Yvar: A `batch_shape&#39; x n x m` tensor of observed measurement noise.</span>
<span class="sd">                Note: this will be None when using a model that infers the noise</span>
<span class="sd">                level (e.g. a `SingleTaskGP`).</span>
<span class="sd">            strict: A boolean indicating whether to check that `Y` and `Yvar`</span>
<span class="sd">                have an explicit output dimension.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">!=</span> <span class="n">Y</span><span class="o">.</span><span class="n">dim</span><span class="p">():</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">-</span> <span class="n">Y</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">):</span>
                <span class="n">message</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="s2">&quot;An explicit output dimension is required for targets.&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot; Expected Y with dimension </span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span><span class="si">}</span><span class="s2"> (got </span><span class="si">{</span><span class="n">Y</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span><span class="si">=}</span><span class="s2">).&quot;</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">message</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="s2">&quot;Expected X and Y to have the same number of dimensions&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot; (got X with dimension </span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span><span class="si">}</span><span class="s2"> and Y with dimension&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="n">Y</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span><span class="si">}</span><span class="s2">).&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">strict</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">BotorchTensorDimensionError</span><span class="p">(</span><span class="n">message</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="s2">&quot;Non-strict enforcement of botorch tensor conventions. The &quot;</span>
                    <span class="s2">&quot;following error would have been raised with strict enforcement: &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">message</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="n">BotorchTensorDimensionWarning</span><span class="p">,</span>
                    <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                <span class="p">)</span>
        <span class="c1"># Yvar may not have the same batch dimensions, but the trailing dimensions</span>
        <span class="c1"># of Yvar should be the same as the trailing dimensions of Y.</span>
        <span class="k">if</span> <span class="n">Yvar</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="p">(</span><span class="n">Yvar</span><span class="o">.</span><span class="n">dim</span><span class="p">())</span> <span class="p">:]</span> <span class="o">!=</span> <span class="n">Yvar</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">BotorchTensorDimensionError</span><span class="p">(</span>
                <span class="s2">&quot;An explicit output dimension is required for observation noise.&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; Expected Yvar with shape: </span><span class="si">{</span><span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="n">Yvar</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span><span class="w"> </span><span class="p">:]</span><span class="si">}</span><span class="s2"> (got&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="n">Yvar</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">).&quot;</span>
            <span class="p">)</span>
        <span class="c1"># Check the dtypes.</span>
        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">Y</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">or</span> <span class="p">(</span><span class="n">Yvar</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">Y</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">Yvar</span><span class="o">.</span><span class="n">dtype</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">InputDataError</span><span class="p">(</span>
                <span class="s2">&quot;Expected all inputs to share the same dtype. Got &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2"> for X, </span><span class="si">{</span><span class="n">Y</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2"> for Y, and &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">Yvar</span><span class="o">.</span><span class="n">dtype</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">Yvar</span><span class="w"> </span><span class="ow">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="kc">None</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="kc">None</span><span class="si">}</span><span class="s2"> for Yvar.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="n">_get_single_precision_warning</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)),</span>
                <span class="n">InputDataWarning</span><span class="p">,</span>
                <span class="n">stacklevel</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>  <span class="c1"># Warn at model constructor call.</span>
            <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">batch_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;The batch shape of the model.</span>

<span class="sd">        This is a batch shape from an I/O perspective, independent of the internal</span>
<span class="sd">        representation of the model (as e.g. in BatchedMultiOutputGPyTorchModel).</span>
<span class="sd">        For a model with `m` outputs, a `test_batch_shape x q x d`-shaped input `X`</span>
<span class="sd">        to the `posterior` method returns a Posterior object over an output of</span>
<span class="sd">        shape `broadcast(test_batch_shape, model.batch_shape) x q x m`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">num_outputs</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;The number of outputs of the model.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_outputs</span>

    <span class="c1"># pyre-fixme[14]: Inconsistent override.</span>
    <span class="c1"># `botorch.models.gpytorch.GPyTorchModel.posterior` overrides method defined</span>
    <span class="c1"># in `Model` inconsistently. Could not find parameter `output_indices` in</span>
    <span class="c1"># overriding signature.</span>
<div class="viewcode-block" id="GPyTorchModel.posterior">
<a class="viewcode-back" href="../../../models.html#botorch.models.gpytorch.GPyTorchModel.posterior">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">posterior</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">observation_noise</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">PosteriorTransform</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">GPyTorchPosterior</span> <span class="o">|</span> <span class="n">TransformedPosterior</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the posterior over model outputs at the provided points.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: A `(batch_shape) x q x d`-dim Tensor, where `d` is the dimension</span>
<span class="sd">                of the feature space and `q` is the number of points considered</span>
<span class="sd">                jointly.</span>
<span class="sd">            observation_noise: If True, add the observation noise from the</span>
<span class="sd">                likelihood to the posterior. If a Tensor, use it directly as the</span>
<span class="sd">                observation noise (must be of shape `(batch_shape) x q`). It is</span>
<span class="sd">                assumed to be in the outcome-transformed space if an outcome</span>
<span class="sd">                transform is used.</span>
<span class="sd">            posterior_transform: An optional PosteriorTransform.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `GPyTorchPosterior` object, representing a batch of `b` joint</span>
<span class="sd">            distributions over `q` points. Includes observation noise if</span>
<span class="sd">            specified.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># make sure model is in eval mode</span>
        <span class="c1"># input transforms are applied at `posterior` in `eval` mode, and at</span>
        <span class="c1"># `model.forward()` at the training time</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_inputs</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">gpt_posterior_settings</span><span class="p">():</span>
            <span class="c1"># NOTE: BoTorch&#39;s GPyTorchModels also inherit from GPyTorch&#39;s ExactGP, thus</span>
            <span class="c1"># self(X) calls GPyTorch&#39;s ExactGP&#39;s __call__, which computes the posterior,</span>
            <span class="c1"># rather than e.g. SingleTaskGP&#39;s forward, which computes the prior.</span>
            <span class="n">mvn</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">observation_noise</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">False</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">observation_noise</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                    <span class="c1"># TODO: Make sure observation noise is transformed correctly</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_validate_tensor_args</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="n">observation_noise</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">observation_noise</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                        <span class="n">observation_noise</span> <span class="o">=</span> <span class="n">observation_noise</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                    <span class="n">mvn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span><span class="p">(</span><span class="n">mvn</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="n">observation_noise</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">mvn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span><span class="p">(</span><span class="n">mvn</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
        <span class="n">posterior</span> <span class="o">=</span> <span class="n">GPyTorchPosterior</span><span class="p">(</span><span class="n">distribution</span><span class="o">=</span><span class="n">mvn</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;outcome_transform&quot;</span><span class="p">):</span>
            <span class="n">posterior</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">outcome_transform</span><span class="o">.</span><span class="n">untransform_posterior</span><span class="p">(</span><span class="n">posterior</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">posterior_transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">posterior_transform</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">posterior</span></div>


<div class="viewcode-block" id="GPyTorchModel.condition_on_observations">
<a class="viewcode-back" href="../../../models.html#botorch.models.gpytorch.GPyTorchModel.condition_on_observations">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">condition_on_observations</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">noise</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Model</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Condition the model on new observations.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: A `batch_shape x n&#39; x d`-dim Tensor, where `d` is the dimension of</span>
<span class="sd">                the feature space, `n&#39;` is the number of points per batch, and</span>
<span class="sd">                `batch_shape` is the batch shape (must be compatible with the</span>
<span class="sd">                batch shape of the model).</span>
<span class="sd">            Y: A `batch_shape&#39; x n x m`-dim Tensor, where `m` is the number of</span>
<span class="sd">                model outputs, `n&#39;` is the number of points per batch, and</span>
<span class="sd">                `batch_shape&#39;` is the batch shape of the observations.</span>
<span class="sd">                `batch_shape&#39;` must be broadcastable to `batch_shape` using</span>
<span class="sd">                standard broadcasting semantics. If `Y` has fewer batch dimensions</span>
<span class="sd">                than `X`, its is assumed that the missing batch dimensions are</span>
<span class="sd">                the same for all `Y`.</span>
<span class="sd">            noise: If not `None`, a tensor of the same shape as `Y` representing</span>
<span class="sd">                the associated noise variance.</span>
<span class="sd">            kwargs: Passed to `self.get_fantasy_model`.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `Model` object of the same type, representing the original model</span>
<span class="sd">            conditioned on the new observations `(X, Y)` (and possibly noise</span>
<span class="sd">            observations passed in via kwargs).</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; train_X = torch.rand(20, 2)</span>
<span class="sd">            &gt;&gt;&gt; train_Y = torch.sin(train_X[:, 0]) + torch.cos(train_X[:, 1])</span>
<span class="sd">            &gt;&gt;&gt; model = SingleTaskGP(train_X, train_Y)</span>
<span class="sd">            &gt;&gt;&gt; new_X = torch.rand(5, 2)</span>
<span class="sd">            &gt;&gt;&gt; new_Y = torch.sin(new_X[:, 0]) + torch.cos(new_X[:, 1])</span>
<span class="sd">            &gt;&gt;&gt; model = model.condition_on_observations(X=new_X, Y=new_Y)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">Yvar</span> <span class="o">=</span> <span class="n">noise</span>

        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;outcome_transform&quot;</span><span class="p">):</span>
            <span class="c1"># pass the transformed data to get_fantasy_model below</span>
            <span class="c1"># (unless we&#39;ve already trasnformed if BatchedMultiOutputGPyTorchModel)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">BatchedMultiOutputGPyTorchModel</span><span class="p">):</span>
                <span class="c1"># `noise` is assumed to already be outcome-transformed.</span>
                <span class="n">Y</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">outcome_transform</span><span class="p">(</span><span class="n">Y</span><span class="o">=</span><span class="n">Y</span><span class="p">,</span> <span class="n">Yvar</span><span class="o">=</span><span class="n">Yvar</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>
        <span class="c1"># Validate using strict=False, since we cannot tell if Y has an explicit</span>
        <span class="c1"># output dimension. Do not check shapes when fantasizing as they are</span>
        <span class="c1"># not expected to match.</span>
        <span class="k">if</span> <span class="n">fantasize_flag</span><span class="o">.</span><span class="n">off</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_validate_tensor_args</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="n">Y</span><span class="p">,</span> <span class="n">Yvar</span><span class="o">=</span><span class="n">Yvar</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">Y</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">Y</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">Yvar</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">kwargs</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;noise&quot;</span><span class="p">:</span> <span class="n">Yvar</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)})</span>
        <span class="c1"># get_fantasy_model will properly copy any existing outcome transforms</span>
        <span class="c1"># (since it deepcopies the original model)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_fantasy_model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">targets</span><span class="o">=</span><span class="n">Y</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>
</div>



<span class="c1"># pyre-fixme[13]: uninitialized attributes _num_outputs, _input_batch_shape,</span>
<span class="c1"># _aug_batch_shape</span>
<div class="viewcode-block" id="BatchedMultiOutputGPyTorchModel">
<a class="viewcode-back" href="../../../models.html#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">BatchedMultiOutputGPyTorchModel</span><span class="p">(</span><span class="n">GPyTorchModel</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Base class for batched multi-output GPyTorch models with independent outputs.</span>

<span class="sd">    This model should be used when the same training data is used for all outputs.</span>
<span class="sd">    Outputs are modeled independently by using a different batch for each output.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_num_outputs</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">_input_batch_shape</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span>
    <span class="n">_aug_batch_shape</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span>

<div class="viewcode-block" id="BatchedMultiOutputGPyTorchModel.get_batch_dimensions">
<a class="viewcode-back" href="../../../models.html#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel.get_batch_dimensions">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_batch_dimensions</span><span class="p">(</span>
        <span class="n">train_X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">:</span> <span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Get the raw batch shape and output-augmented batch shape of the inputs.</span>

<span class="sd">        Args:</span>
<span class="sd">            train_X: A `n x d` or `batch_shape x n x d` (batch mode) tensor of training</span>
<span class="sd">                features.</span>
<span class="sd">            train_Y: A `n x m` or `batch_shape x n x m` (batch mode) tensor of</span>
<span class="sd">                training observations.</span>

<span class="sd">        Returns:</span>
<span class="sd">            2-element tuple containing</span>

<span class="sd">            - The `input_batch_shape`</span>
<span class="sd">            - The output-augmented batch shape: `input_batch_shape x (m)`</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">input_batch_shape</span> <span class="o">=</span> <span class="n">train_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">aug_batch_shape</span> <span class="o">=</span> <span class="n">input_batch_shape</span>
        <span class="n">num_outputs</span> <span class="o">=</span> <span class="n">train_Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">num_outputs</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">aug_batch_shape</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">num_outputs</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">input_batch_shape</span><span class="p">,</span> <span class="n">aug_batch_shape</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_set_dimensions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Store the number of outputs and the batch shape.</span>

<span class="sd">        Args:</span>
<span class="sd">            train_X: A `n x d` or `batch_shape x n x d` (batch mode) tensor of training</span>
<span class="sd">                features.</span>
<span class="sd">            train_Y: A `n x m` or `batch_shape x n x m` (batch mode) tensor of</span>
<span class="sd">                training observations.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_num_outputs</span> <span class="o">=</span> <span class="n">train_Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_input_batch_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_aug_batch_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_batch_dimensions</span><span class="p">(</span>
            <span class="n">train_X</span><span class="o">=</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="o">=</span><span class="n">train_Y</span>
        <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">batch_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;The batch shape of the model.</span>

<span class="sd">        This is a batch shape from an I/O perspective, independent of the internal</span>
<span class="sd">        representation of the model (as e.g. in BatchedMultiOutputGPyTorchModel).</span>
<span class="sd">        For a model with `m` outputs, a `test_batch_shape x q x d`-shaped input `X`</span>
<span class="sd">        to the `posterior` method returns a Posterior object over an output of</span>
<span class="sd">        shape `broadcast(test_batch_shape, model.batch_shape) x q x m`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_batch_shape</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_transform_tensor_args</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Yvar</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Transforms tensor arguments: for single output models, the output</span>
<span class="sd">        dimension is squeezed and for multi-output models, the output dimension is</span>
<span class="sd">        transformed into the left-most batch dimension.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: A `n x d` or `batch_shape x n x d` (batch mode) tensor of training</span>
<span class="sd">                features.</span>
<span class="sd">            Y: A `n x m` or `batch_shape x n x m` (batch mode) tensor of</span>
<span class="sd">                training observations.</span>
<span class="sd">            Yvar: A `n x m` or `batch_shape x n x m` (batch mode) tensor of</span>
<span class="sd">                observed measurement noise. Note: this will be None when using a model</span>
<span class="sd">                that infers the noise level (e.g. a `SingleTaskGP`).</span>

<span class="sd">        Returns:</span>
<span class="sd">            3-element tuple containing</span>

<span class="sd">            - A `input_batch_shape x (m) x n x d` tensor of training features.</span>
<span class="sd">            - A `target_batch_shape x (m) x n` tensor of training observations.</span>
<span class="sd">            - A `target_batch_shape x (m) x n` tensor observed measurement noise</span>
<span class="sd">                (or None).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_outputs</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">multioutput_to_batch_mode_transform</span><span class="p">(</span>
                <span class="n">train_X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">train_Y</span><span class="o">=</span><span class="n">Y</span><span class="p">,</span> <span class="n">train_Yvar</span><span class="o">=</span><span class="n">Yvar</span><span class="p">,</span> <span class="n">num_outputs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_outputs</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="kc">None</span> <span class="k">if</span> <span class="n">Yvar</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">Yvar</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_apply_noise</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">mvn</span><span class="p">:</span> <span class="n">MultivariateNormal</span><span class="p">,</span>
        <span class="n">observation_noise</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MultivariateNormal</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Adds the observation noise to the posterior.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: A tensor of shape `batch_shape x q x d`.</span>
<span class="sd">            mvn: A `MultivariateNormal` object representing the posterior over the true</span>
<span class="sd">                latent function.</span>
<span class="sd">            num_outputs: The number of outputs of the model.</span>
<span class="sd">            observation_noise: If True, add the observation noise from the</span>
<span class="sd">                likelihood to the posterior. If a Tensor, use it directly as the</span>
<span class="sd">                observation noise (must be of shape `(batch_shape) x q x m`).</span>

<span class="sd">        Returns:</span>
<span class="sd">            The posterior predictive.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">observation_noise</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">mvn</span>
        <span class="c1"># noise_shape is `broadcast(test_batch_shape, model.batch_shape) x m x q`</span>
        <span class="n">noise_shape</span> <span class="o">=</span> <span class="n">mvn</span><span class="o">.</span><span class="n">batch_shape</span> <span class="o">+</span> <span class="n">mvn</span><span class="o">.</span><span class="n">event_shape</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">observation_noise</span><span class="p">):</span>
            <span class="c1"># TODO: Validate noise shape</span>
            <span class="c1"># make observation_noise&#39;s shape match noise_shape</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_outputs</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">obs_noise</span> <span class="o">=</span> <span class="n">observation_noise</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">obs_noise</span> <span class="o">=</span> <span class="n">observation_noise</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">mvn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span><span class="p">(</span>
                <span class="n">mvn</span><span class="p">,</span>
                <span class="n">X</span><span class="p">,</span>
                <span class="n">noise</span><span class="o">=</span><span class="n">obs_noise</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">noise_shape</span><span class="p">),</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">FixedNoiseGaussianLikelihood</span><span class="p">):</span>
            <span class="c1"># Use the mean of the previous noise values (TODO: be smarter here).</span>
            <span class="n">observation_noise</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span><span class="o">.</span><span class="n">noise</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">mvn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span><span class="p">(</span>
                <span class="n">mvn</span><span class="p">,</span>
                <span class="n">X</span><span class="p">,</span>
                <span class="n">noise</span><span class="o">=</span><span class="n">observation_noise</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">noise_shape</span><span class="p">),</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">mvn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span><span class="p">(</span><span class="n">mvn</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mvn</span>

    <span class="c1"># pyre-ignore[14]: Inconsistent override. Could not find parameter</span>
    <span class="c1"># `Keywords(typing.Any)` in overriding signature.</span>
<div class="viewcode-block" id="BatchedMultiOutputGPyTorchModel.posterior">
<a class="viewcode-back" href="../../../models.html#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel.posterior">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">posterior</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">output_indices</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">observation_noise</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">PosteriorTransform</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">GPyTorchPosterior</span> <span class="o">|</span> <span class="n">TransformedPosterior</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the posterior over model outputs at the provided points.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: A `(batch_shape) x q x d`-dim Tensor, where `d` is the dimension</span>
<span class="sd">                of the feature space and `q` is the number of points considered</span>
<span class="sd">                jointly.</span>
<span class="sd">            output_indices: A list of indices, corresponding to the outputs over</span>
<span class="sd">                which to compute the posterior (if the model is multi-output).</span>
<span class="sd">                Can be used to speed up computation if only a subset of the</span>
<span class="sd">                model&#39;s outputs are required for optimization. If omitted,</span>
<span class="sd">                computes the posterior over all model outputs.</span>
<span class="sd">            observation_noise: If True, add the observation noise from the</span>
<span class="sd">                likelihood to the posterior. If a Tensor, use it directly as the</span>
<span class="sd">                observation noise (must be of shape `(batch_shape) x q x m`).</span>
<span class="sd">            posterior_transform: An optional PosteriorTransform.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `GPyTorchPosterior` object, representing `batch_shape` joint</span>
<span class="sd">            distributions over `q` points and the outputs selected by</span>
<span class="sd">            `output_indices` each. Includes observation noise if specified.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># make sure model is in eval mode</span>
        <span class="c1"># input transforms are applied at `posterior` in `eval` mode, and at</span>
        <span class="c1"># `model.forward()` at the training time</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_inputs</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">gpt_posterior_settings</span><span class="p">():</span>
            <span class="c1"># insert a dimension for the output dimension</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_outputs</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">X</span><span class="p">,</span> <span class="n">output_dim_idx</span> <span class="o">=</span> <span class="n">add_output_dim</span><span class="p">(</span>
                    <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">original_batch_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_input_batch_shape</span>
                <span class="p">)</span>
            <span class="c1"># NOTE: BoTorch&#39;s GPyTorchModels also inherit from GPyTorch&#39;s ExactGP, thus</span>
            <span class="c1"># self(X) calls GPyTorch&#39;s ExactGP&#39;s __call__, which computes the posterior,</span>
            <span class="c1"># rather than e.g. SingleTaskGP&#39;s forward, which computes the prior.</span>
            <span class="n">mvn</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="n">mvn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_noise</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">mvn</span><span class="o">=</span><span class="n">mvn</span><span class="p">,</span> <span class="n">observation_noise</span><span class="o">=</span><span class="n">observation_noise</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_outputs</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">is_tracing</span><span class="p">():</span>
                    <span class="n">mvn</span> <span class="o">=</span> <span class="n">MultitaskMultivariateNormal</span><span class="o">.</span><span class="n">from_batch_mvn</span><span class="p">(</span>
                        <span class="n">mvn</span><span class="p">,</span> <span class="n">task_dim</span><span class="o">=</span><span class="n">output_dim_idx</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">mean_x</span> <span class="o">=</span> <span class="n">mvn</span><span class="o">.</span><span class="n">mean</span>
                    <span class="n">covar_x</span> <span class="o">=</span> <span class="n">mvn</span><span class="o">.</span><span class="n">lazy_covariance_matrix</span>
                    <span class="n">output_indices</span> <span class="o">=</span> <span class="n">output_indices</span> <span class="ow">or</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_outputs</span><span class="p">)</span>
                    <span class="n">mvns</span> <span class="o">=</span> <span class="p">[</span>
                        <span class="n">MultivariateNormal</span><span class="p">(</span>
                            <span class="n">mean_x</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="n">output_dim_idx</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">t</span><span class="p">),</span>
                            <span class="n">covar_x</span><span class="p">[(</span><span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">),)</span> <span class="o">*</span> <span class="n">output_dim_idx</span> <span class="o">+</span> <span class="p">(</span><span class="n">t</span><span class="p">,)],</span>
                        <span class="p">)</span>
                        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">output_indices</span>
                    <span class="p">]</span>
                    <span class="n">mvn</span> <span class="o">=</span> <span class="n">MultitaskMultivariateNormal</span><span class="o">.</span><span class="n">from_independent_mvns</span><span class="p">(</span><span class="n">mvns</span><span class="o">=</span><span class="n">mvns</span><span class="p">)</span>

        <span class="n">posterior</span> <span class="o">=</span> <span class="n">GPyTorchPosterior</span><span class="p">(</span><span class="n">distribution</span><span class="o">=</span><span class="n">mvn</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;outcome_transform&quot;</span><span class="p">):</span>
            <span class="n">posterior</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">outcome_transform</span><span class="o">.</span><span class="n">untransform_posterior</span><span class="p">(</span><span class="n">posterior</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">posterior_transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">posterior_transform</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">posterior</span></div>


    <span class="c1"># pyre-ignore[14]: Inconsistent override. Could not find parameter `noise`.</span>
<div class="viewcode-block" id="BatchedMultiOutputGPyTorchModel.condition_on_observations">
<a class="viewcode-back" href="../../../models.html#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel.condition_on_observations">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">condition_on_observations</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">BatchedMultiOutputGPyTorchModel</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Condition the model on new observations.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: A `batch_shape x n&#39; x d`-dim Tensor, where `d` is the dimension of</span>
<span class="sd">                the feature space, `m` is the number of points per batch, and</span>
<span class="sd">                `batch_shape` is the batch shape (must be compatible with the</span>
<span class="sd">                batch shape of the model).</span>
<span class="sd">            Y: A `batch_shape&#39; x n&#39; x m`-dim Tensor, where `m` is the number of</span>
<span class="sd">                model outputs, `n&#39;` is the number of points per batch, and</span>
<span class="sd">                `batch_shape&#39;` is the batch shape of the observations.</span>
<span class="sd">                `batch_shape&#39;` must be broadcastable to `batch_shape` using</span>
<span class="sd">                standard broadcasting semantics. If `Y` has fewer batch dimensions</span>
<span class="sd">                than `X`, its is assumed that the missing batch dimensions are</span>
<span class="sd">                the same for all `Y`.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `BatchedMultiOutputGPyTorchModel` object of the same type with</span>
<span class="sd">            `n + n&#39;` training examples, representing the original model</span>
<span class="sd">            conditioned on the new observations `(X, Y)` (and possibly noise</span>
<span class="sd">            observations passed in via kwargs).</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; train_X = torch.rand(20, 2)</span>
<span class="sd">            &gt;&gt;&gt; train_Y = torch.cat(</span>
<span class="sd">            &gt;&gt;&gt;     [torch.sin(train_X[:, 0]), torch.cos(train_X[:, 1])], -1</span>
<span class="sd">            &gt;&gt;&gt; )</span>
<span class="sd">            &gt;&gt;&gt; model = SingleTaskGP(train_X, train_Y)</span>
<span class="sd">            &gt;&gt;&gt; new_X = torch.rand(5, 2)</span>
<span class="sd">            &gt;&gt;&gt; new_Y = torch.cat([torch.sin(new_X[:, 0]), torch.cos(new_X[:, 1])], -1)</span>
<span class="sd">            &gt;&gt;&gt; model = model.condition_on_observations(X=new_X, Y=new_Y)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">noise</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;noise&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;outcome_transform&quot;</span><span class="p">):</span>
            <span class="c1"># We need to apply transforms before shifting batch indices around.</span>
            <span class="c1"># `noise` is assumed to already be outcome-transformed.</span>
            <span class="n">Y</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">outcome_transform</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>
        <span class="c1"># Do not check shapes when fantasizing as they are not expected to match.</span>
        <span class="k">if</span> <span class="n">fantasize_flag</span><span class="o">.</span><span class="n">off</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_validate_tensor_args</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="n">Y</span><span class="p">,</span> <span class="n">Yvar</span><span class="o">=</span><span class="n">noise</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">X</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_outputs</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">noise</span> <span class="o">=</span> <span class="n">multioutput_to_batch_mode_transform</span><span class="p">(</span>
                <span class="n">train_X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">train_Y</span><span class="o">=</span><span class="n">Y</span><span class="p">,</span> <span class="n">num_outputs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_outputs</span><span class="p">,</span> <span class="n">train_Yvar</span><span class="o">=</span><span class="n">noise</span>
            <span class="p">)</span>
            <span class="c1"># `multioutput_to_batch_mode_transform` removes the output dimension,</span>
            <span class="c1"># which is necessary for `condition_on_observations`</span>
            <span class="n">targets</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">noise</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">noise</span> <span class="o">=</span> <span class="n">noise</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="n">X</span>
            <span class="n">targets</span> <span class="o">=</span> <span class="n">Y</span>
        <span class="k">if</span> <span class="n">noise</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;noise&quot;</span><span class="p">:</span> <span class="n">noise</span><span class="p">})</span>
        <span class="n">fantasy_model</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">condition_on_observations</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="n">targets</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">fantasy_model</span><span class="o">.</span><span class="n">_input_batch_shape</span> <span class="o">=</span> <span class="n">fantasy_model</span><span class="o">.</span><span class="n">train_targets</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span>
            <span class="p">:</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_outputs</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_fully_bayesian</span><span class="p">:</span>
            <span class="n">fantasy_model</span><span class="o">.</span><span class="n">_aug_batch_shape</span> <span class="o">=</span> <span class="n">fantasy_model</span><span class="o">.</span><span class="n">train_targets</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">fantasy_model</span></div>


<div class="viewcode-block" id="BatchedMultiOutputGPyTorchModel.subset_output">
<a class="viewcode-back" href="../../../models.html#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel.subset_output">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">subset_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idcs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">BatchedMultiOutputGPyTorchModel</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Subset the model along the output dimension.</span>

<span class="sd">        Args:</span>
<span class="sd">            idcs: The output indices to subset the model to.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The current model, subset to the specified output indices.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">subset_batch_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_subset_batch_dict</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="s2">&quot;`subset_output` requires the model to define a `_subset_batch_dict` &quot;</span>
                <span class="s2">&quot;attribute that lists the indices of the output dimensions in each &quot;</span>
                <span class="s2">&quot;model parameter that needs to be subset.&quot;</span>
            <span class="p">)</span>

        <span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">idcs</span><span class="p">)</span>
        <span class="n">new_model</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="n">subset_everything</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_outputs</span> <span class="o">==</span> <span class="n">m</span> <span class="ow">and</span> <span class="n">idcs</span> <span class="o">==</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">subset_everything</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">new_model</span>

        <span class="n">tidxr</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">idcs</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">new_model</span><span class="o">.</span><span class="n">train_targets</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">idxr</span> <span class="o">=</span> <span class="n">tidxr</span> <span class="k">if</span> <span class="n">m</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">idcs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">new_tail_bs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">m</span><span class="p">])</span> <span class="k">if</span> <span class="n">m</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">()</span>

        <span class="n">new_model</span><span class="o">.</span><span class="n">_num_outputs</span> <span class="o">=</span> <span class="n">m</span>
        <span class="n">new_model</span><span class="o">.</span><span class="n">_aug_batch_shape</span> <span class="o">=</span> <span class="n">new_model</span><span class="o">.</span><span class="n">_aug_batch_shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">new_tail_bs</span>
        <span class="n">new_model</span><span class="o">.</span><span class="n">train_inputs</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span>
            <span class="n">ti</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">idxr</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="k">for</span> <span class="n">ti</span> <span class="ow">in</span> <span class="n">new_model</span><span class="o">.</span><span class="n">train_inputs</span>
        <span class="p">)</span>
        <span class="n">new_model</span><span class="o">.</span><span class="n">train_targets</span> <span class="o">=</span> <span class="n">new_model</span><span class="o">.</span><span class="n">train_targets</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">idxr</span><span class="p">,</span> <span class="p">:]</span>

        <span class="c1"># adjust batch shapes of parameters/buffers if necessary</span>
        <span class="k">for</span> <span class="n">full_name</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span>
            <span class="n">new_model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">(),</span> <span class="n">new_model</span><span class="o">.</span><span class="n">named_buffers</span><span class="p">()</span>
        <span class="p">):</span>
            <span class="k">if</span> <span class="n">full_name</span> <span class="ow">in</span> <span class="n">subset_batch_dict</span><span class="p">:</span>
                <span class="n">idx</span> <span class="o">=</span> <span class="n">subset_batch_dict</span><span class="p">[</span><span class="n">full_name</span><span class="p">]</span>
                <span class="n">new_data</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="n">idx</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">tidxr</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">m</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">new_data</span> <span class="o">=</span> <span class="n">new_data</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
                <span class="n">p</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">new_data</span>
            <span class="n">mod_name</span> <span class="o">=</span> <span class="n">full_name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">mod_batch_shape</span><span class="p">(</span><span class="n">new_model</span><span class="p">,</span> <span class="n">mod_name</span><span class="p">,</span> <span class="n">m</span> <span class="k">if</span> <span class="n">m</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>

        <span class="c1"># subset outcome transform if present</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">subset_octf</span> <span class="o">=</span> <span class="n">new_model</span><span class="o">.</span><span class="n">outcome_transform</span><span class="o">.</span><span class="n">subset_output</span><span class="p">(</span><span class="n">idcs</span><span class="o">=</span><span class="n">idcs</span><span class="p">)</span>
            <span class="n">new_model</span><span class="o">.</span><span class="n">outcome_transform</span> <span class="o">=</span> <span class="n">subset_octf</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="k">pass</span>

        <span class="c1"># Subset fixed noise likelihood if present.</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">FixedNoiseGaussianLikelihood</span><span class="p">):</span>
            <span class="n">full_noise</span> <span class="o">=</span> <span class="n">new_model</span><span class="o">.</span><span class="n">likelihood</span><span class="o">.</span><span class="n">noise_covar</span><span class="o">.</span><span class="n">noise</span>
            <span class="n">new_noise</span> <span class="o">=</span> <span class="n">full_noise</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">idcs</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">idcs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">idcs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">:]</span>
            <span class="n">new_model</span><span class="o">.</span><span class="n">likelihood</span><span class="o">.</span><span class="n">noise_covar</span><span class="o">.</span><span class="n">noise</span> <span class="o">=</span> <span class="n">new_noise</span>

        <span class="k">return</span> <span class="n">new_model</span></div>
</div>



<div class="viewcode-block" id="ModelListGPyTorchModel">
<a class="viewcode-back" href="../../../models.html#botorch.models.gpytorch.ModelListGPyTorchModel">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">ModelListGPyTorchModel</span><span class="p">(</span><span class="n">ModelList</span><span class="p">,</span> <span class="n">GPyTorchModel</span><span class="p">,</span> <span class="n">ABC</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Abstract base class for models based on multi-output GPyTorch models.</span>

<span class="sd">    This is meant to be used with a gpytorch ModelList wrapper for independent</span>
<span class="sd">    evaluation of submodels. Those submodels can themselves be multi-output</span>
<span class="sd">    models, in which case the task covariances will be ignored.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">batch_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;The batch shape of the model.</span>

<span class="sd">        This is a batch shape from an I/O perspective, independent of the internal</span>
<span class="sd">        representation of the model (as e.g. in BatchedMultiOutputGPyTorchModel).</span>
<span class="sd">        For a model with `m` outputs, a `test_batch_shape x q x d`-shaped input `X`</span>
<span class="sd">        to the `posterior` method returns a Posterior object over an output of</span>
<span class="sd">        shape `broadcast(test_batch_shape, model.batch_shape) x q x m`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">batch_shapes</span> <span class="o">=</span> <span class="p">{</span><span class="n">m</span><span class="o">.</span><span class="n">batch_shape</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">}</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_shapes</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Component models of </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> have different &quot;</span>
                <span class="s2">&quot;batch shapes&quot;</span>
            <span class="p">)</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">broadcast_shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">broadcast_shapes</span><span class="p">(</span><span class="o">*</span><span class="n">batch_shapes</span><span class="p">)</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="n">msg</span> <span class="o">+</span> <span class="s2">&quot;. Broadcasting batch shapes.&quot;</span><span class="p">,</span> <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">broadcast_shape</span>
            <span class="k">except</span> <span class="ne">RuntimeError</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="n">msg</span> <span class="o">+</span> <span class="s2">&quot; that are not broadcastble.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">batch_shapes</span><span class="p">))</span>

    <span class="c1"># pyre-fixme[14]: Inconsistent override in return types</span>
<div class="viewcode-block" id="ModelListGPyTorchModel.posterior">
<a class="viewcode-back" href="../../../models.html#botorch.models.gpytorch.ModelListGPyTorchModel.posterior">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">posterior</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">output_indices</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">observation_noise</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">PosteriorTransform</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">GPyTorchPosterior</span> <span class="o">|</span> <span class="n">PosteriorList</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the posterior over model outputs at the provided points.</span>
<span class="sd">        If any model returns a MultitaskMultivariateNormal posterior, then that</span>
<span class="sd">        will be split into individual MVNs per task, with inter-task covariance</span>
<span class="sd">        ignored.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: A `b x q x d`-dim Tensor, where `d` is the dimension of the</span>
<span class="sd">                feature space, `q` is the number of points considered jointly,</span>
<span class="sd">                and `b` is the batch dimension.</span>
<span class="sd">            output_indices: A list of indices, corresponding to the outputs over</span>
<span class="sd">                which to compute the posterior (if the model is multi-output).</span>
<span class="sd">                Can be used to speed up computation if only a subset of the</span>
<span class="sd">                model&#39;s outputs are required for optimization. If omitted,</span>
<span class="sd">                computes the posterior over all model outputs.</span>
<span class="sd">            observation_noise: If True, add the observation noise from the</span>
<span class="sd">                respective likelihoods to the posterior. If a Tensor of shape</span>
<span class="sd">                `(batch_shape) x q x m`, use it directly as the observation</span>
<span class="sd">                noise (with `observation_noise[...,i]` added to the posterior</span>
<span class="sd">                of the `i`-th model).</span>
<span class="sd">            posterior_transform: An optional PosteriorTransform.</span>

<span class="sd">        Returns:</span>
<span class="sd">            - If no `posterior_transform` is provided and the component models have no</span>
<span class="sd">                `outcome_transform`, or if the component models only use linear outcome</span>
<span class="sd">                transforms like `Standardize` (i.e. not `Log`), returns a</span>
<span class="sd">                `GPyTorchPosterior` or `GaussianMixturePosterior` object,</span>
<span class="sd">                representing `batch_shape` joint distributions over `q` points</span>
<span class="sd">                and the outputs selected by `output_indices` each. Includes</span>
<span class="sd">                measurement noise if `observation_noise` is specified.</span>
<span class="sd">            - If no `posterior_transform` is provided and component models have</span>
<span class="sd">                nonlinear transforms like `Log`, returns a `PosteriorList` with</span>
<span class="sd">                sub-posteriors of type `TransformedPosterior`</span>
<span class="sd">            - If `posterior_transform` is provided, that posterior transform will be</span>
<span class="sd">               applied and will determine the return type. This could potentially be</span>
<span class="sd">               any subclass of `Posterior`, but common choices give a</span>
<span class="sd">               `GPyTorchPosterior`.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Nonlinear transforms untransform to a `TransformedPosterior`,</span>
        <span class="c1"># which can&#39;t be made into a `GPyTorchPosterior`</span>
        <span class="n">returns_untransformed</span> <span class="o">=</span> <span class="nb">any</span><span class="p">(</span>
            <span class="nb">hasattr</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="s2">&quot;outcome_transform&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="ow">not</span> <span class="n">mod</span><span class="o">.</span><span class="n">outcome_transform</span><span class="o">.</span><span class="n">_is_linear</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">mod</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span>
        <span class="p">)</span>
        <span class="c1"># NOTE: We&#39;re not passing in the posterior transform here. We&#39;ll apply it later.</span>
        <span class="n">posterior</span> <span class="o">=</span> <span class="n">ModelList</span><span class="o">.</span><span class="n">posterior</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
            <span class="n">output_indices</span><span class="o">=</span><span class="n">output_indices</span><span class="p">,</span>
            <span class="n">observation_noise</span><span class="o">=</span><span class="n">observation_noise</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">returns_untransformed</span><span class="p">:</span>
            <span class="n">mvns</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">distribution</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">posterior</span><span class="o">.</span><span class="n">posteriors</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">MultitaskMultivariateNormal</span><span class="p">)</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">mvns</span><span class="p">):</span>
                <span class="n">mvn_list</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">mvn</span> <span class="ow">in</span> <span class="n">mvns</span><span class="p">:</span>
                    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">mvn</span><span class="o">.</span><span class="n">event_shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                        <span class="c1"># We separate MTMVNs into independent-across-task MVNs for</span>
                        <span class="c1"># the convenience of using BlockDiagLinearOperator below.</span>
                        <span class="c1"># (b x q x m x m) -&gt; list of m (b x q x 1 x 1)</span>
                        <span class="n">mvn_list</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">separate_mtmvn</span><span class="p">(</span><span class="n">mvn</span><span class="p">))</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">mvn_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mvn</span><span class="p">)</span>
                <span class="n">mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">mvn</span><span class="o">.</span><span class="n">mean</span> <span class="k">for</span> <span class="n">mvn</span> <span class="ow">in</span> <span class="n">mvn_list</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">covars</span> <span class="o">=</span> <span class="n">CatLinearOperator</span><span class="p">(</span>
                    <span class="o">*</span><span class="p">[</span><span class="n">mvn</span><span class="o">.</span><span class="n">lazy_covariance_matrix</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">)</span> <span class="k">for</span> <span class="n">mvn</span> <span class="ow">in</span> <span class="n">mvn_list</span><span class="p">],</span>
                    <span class="n">dim</span><span class="o">=-</span><span class="mi">3</span><span class="p">,</span>
                <span class="p">)</span>  <span class="c1"># List of m (b x q x 1 x 1) -&gt; (b x q x m x 1 x 1)</span>
                <span class="n">mvn</span> <span class="o">=</span> <span class="n">MultitaskMultivariateNormal</span><span class="p">(</span>
                    <span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span>
                    <span class="n">covariance_matrix</span><span class="o">=</span><span class="n">BlockDiagLinearOperator</span><span class="p">(</span><span class="n">covars</span><span class="p">,</span> <span class="n">block_dim</span><span class="o">=-</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                        <span class="n">X</span>
                    <span class="p">),</span>  <span class="c1"># (b x q x m x 1 x 1) -&gt; (b x q x m x m)</span>
                    <span class="n">interleaved</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">mvns</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_broadcast_mvns</span><span class="p">(</span><span class="n">mvns</span><span class="o">=</span><span class="n">mvns</span><span class="p">)</span>
                <span class="n">mvn</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">mvns</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">mvns</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
                    <span class="k">else</span> <span class="n">MultitaskMultivariateNormal</span><span class="o">.</span><span class="n">from_independent_mvns</span><span class="p">(</span><span class="n">mvns</span><span class="o">=</span><span class="n">mvns</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="c1"># Return the result as a GPyTorchPosterior/GaussianMixturePosterior.</span>
            <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">is_ensemble</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">):</span>
                <span class="c1"># Mixing fully Bayesian and other GP models is currently</span>
                <span class="c1"># not supported.</span>
                <span class="n">posterior</span> <span class="o">=</span> <span class="n">GaussianMixturePosterior</span><span class="p">(</span><span class="n">distribution</span><span class="o">=</span><span class="n">mvn</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">posterior</span> <span class="o">=</span> <span class="n">GPyTorchPosterior</span><span class="p">(</span><span class="n">distribution</span><span class="o">=</span><span class="n">mvn</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">posterior_transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">posterior_transform</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">posterior</span></div>


<div class="viewcode-block" id="ModelListGPyTorchModel.condition_on_observations">
<a class="viewcode-back" href="../../../models.html#botorch.models.gpytorch.ModelListGPyTorchModel.condition_on_observations">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">condition_on_observations</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Model</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_broadcast_mvns</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mvns</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">MultivariateNormal</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">MultivariateNormal</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Broadcasts the batch shapes of the given MultivariateNormals.</span>

<span class="sd">        The MVNs will have a batch shape of `input_batch_shape x model_batch_shape`.</span>
<span class="sd">        If the model batch shapes are broadcastable, we will broadcast the mvns to</span>
<span class="sd">        a batch shape of `input_batch_shape x self.batch_shape`.</span>

<span class="sd">        Args:</span>
<span class="sd">            mvns: A list of MultivariateNormals.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list of MultivariateNormals with broadcasted batch shapes.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">mvn_batch_shapes</span> <span class="o">=</span> <span class="p">{</span><span class="n">mvn</span><span class="o">.</span><span class="n">batch_shape</span> <span class="k">for</span> <span class="n">mvn</span> <span class="ow">in</span> <span class="n">mvns</span><span class="p">}</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">mvn_batch_shapes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># All MVNs have the same batch shape. We can return as is.</span>
            <span class="k">return</span> <span class="n">mvns</span>
        <span class="c1"># This call will error out if they&#39;re not broadcastable.</span>
        <span class="c1"># If they&#39;re broadcastable, it&#39;ll log a warning.</span>
        <span class="n">target_model_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_shape</span>
        <span class="n">max_batch</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">mvn_batch_shapes</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="nb">len</span><span class="p">)</span>
        <span class="n">max_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">max_batch</span><span class="p">)</span>
        <span class="n">input_batch_len</span> <span class="o">=</span> <span class="n">max_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">target_model_shape</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">mvns</span><span class="p">)):</span>  <span class="c1"># Loop over index since we modify contents.</span>
            <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">mvns</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">batch_shape</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">max_len</span><span class="p">:</span>
                <span class="c1"># MVN is missing batch dimensions. Unsqueeze as needed.</span>
                <span class="n">mvns</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">mvns</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">input_batch_len</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">mvns</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">batch_shape</span> <span class="o">!=</span> <span class="n">max_batch</span><span class="p">:</span>
                <span class="c1"># Expand to match the batch shapes.</span>
                <span class="n">mvns</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">mvns</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">max_batch</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mvns</span></div>



<div class="viewcode-block" id="MultiTaskGPyTorchModel">
<a class="viewcode-back" href="../../../models.html#botorch.models.gpytorch.MultiTaskGPyTorchModel">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">MultiTaskGPyTorchModel</span><span class="p">(</span><span class="n">GPyTorchModel</span><span class="p">,</span> <span class="n">ABC</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Abstract base class for multi-task models based on GPyTorch models.</span>

<span class="sd">    This class provides the `posterior` method to models that implement a</span>
<span class="sd">    &quot;long-format&quot; multi-task GP in the style of `MultiTaskGP`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_map_tasks</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">task_values</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Map raw task values to the task indices used by the model.</span>

<span class="sd">        Args:</span>
<span class="sd">            task_values: A tensor of task values.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A tensor of task indices with the same shape as the input</span>
<span class="sd">                tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_task_mapper</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">task_values</span><span class="p">)</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">task_values</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_tasks</span><span class="p">)</span>
            <span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Expected all task features in `X` to be between 0 and &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;self.num_tasks - 1. Got </span><span class="si">{</span><span class="n">task_values</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">task_values</span> <span class="o">=</span> <span class="n">task_values</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>

            <span class="n">unexpected_task_values</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">task_values</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_expected_task_values</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">unexpected_task_values</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Received invalid raw task values. Expected raw value to be in&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_expected_task_values</span><span class="si">}</span><span class="s2">, but got unexpected task values:&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="n">unexpected_task_values</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>
            <span class="n">task_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_task_mapper</span><span class="p">[</span><span class="n">task_values</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">task_values</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_apply_noise</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">mvn</span><span class="p">:</span> <span class="n">MultivariateNormal</span><span class="p">,</span>
        <span class="n">num_outputs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">observation_noise</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MultivariateNormal</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Adds the observation noise to the posterior.</span>

<span class="sd">        If the likelihood is a `FixedNoiseGaussianLikelihood`, then</span>
<span class="sd">        the average noise per task is computed, and a diagonal noise</span>
<span class="sd">        matrix is added to the posterior covariance matrix, where</span>
<span class="sd">        the noise per input is the average noise for its respective</span>
<span class="sd">        task. If the likelihood is a Gaussian likelihood, then</span>
<span class="sd">        currently there is a shared inferred noise level for all</span>
<span class="sd">        tasks.</span>

<span class="sd">        TODO: implement support for task-specific inferred noise levels.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: A tensor of shape `batch_shape x q x d + 1`,</span>
<span class="sd">                where `d` is the dimension of the feature space and the `+ 1`</span>
<span class="sd">                dimension is the task feature / index.</span>
<span class="sd">            mvn: A `MultivariateNormal` object representing the posterior over the true</span>
<span class="sd">                latent function.</span>
<span class="sd">            num_outputs: The number of outputs of the model.</span>
<span class="sd">            observation_noise: If True, add observation noise from the respective</span>
<span class="sd">                likelihood. Tensor input is currently not supported.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The posterior predictive.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">observation_noise</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="s2">&quot;Passing a tensor of observations is not supported by MultiTaskGP.&quot;</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">observation_noise</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">mvn</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">FixedNoiseGaussianLikelihood</span><span class="p">):</span>
            <span class="c1"># get task features for test points</span>
            <span class="n">test_task_features</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_task_feature</span><span class="p">]</span>
            <span class="n">test_task_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_map_tasks</span><span class="p">(</span><span class="n">test_task_features</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
            <span class="n">unique_test_task_features</span> <span class="o">=</span> <span class="n">test_task_features</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
            <span class="c1"># get task features for training points</span>
            <span class="n">train_task_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="o">...</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_task_feature</span><span class="p">]</span>
            <span class="n">train_task_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_map_tasks</span><span class="p">(</span><span class="n">train_task_features</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
            <span class="n">noise_by_task</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_tasks</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">task_feature</span> <span class="ow">in</span> <span class="n">unique_test_task_features</span><span class="p">:</span>
                <span class="n">mask</span> <span class="o">=</span> <span class="n">train_task_features</span> <span class="o">==</span> <span class="n">task_feature</span>
                <span class="n">noise_by_task</span><span class="p">[</span><span class="n">task_feature</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span><span class="o">.</span><span class="n">noise</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span>
                    <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span>
                <span class="p">)</span>
            <span class="c1"># noise_shape is `broadcast(test_batch_shape, model.batch_shape) x q`</span>
            <span class="n">noise_shape</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">observation_noise</span> <span class="o">=</span> <span class="n">noise_by_task</span><span class="p">[</span><span class="n">test_task_features</span><span class="p">]</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">noise_shape</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span><span class="p">(</span>
                <span class="n">mvn</span><span class="p">,</span>
                <span class="n">X</span><span class="p">,</span>
                <span class="n">noise</span><span class="o">=</span><span class="n">observation_noise</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span><span class="p">(</span><span class="n">mvn</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>

    <span class="c1"># pyre-ignore[14]: Inconsistent override. Could not find parameter</span>
    <span class="c1"># `Keywords(typing.Any)` in overriding signature.</span>
<div class="viewcode-block" id="MultiTaskGPyTorchModel.posterior">
<a class="viewcode-back" href="../../../models.html#botorch.models.gpytorch.MultiTaskGPyTorchModel.posterior">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">posterior</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">output_indices</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">observation_noise</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">PosteriorTransform</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">GPyTorchPosterior</span> <span class="o">|</span> <span class="n">TransformedPosterior</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the posterior over model outputs at the provided points.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: A tensor of shape `batch_shape x q x d` or `batch_shape x q x (d + 1)`,</span>
<span class="sd">                where `d` is the dimension of the feature space (not including task</span>
<span class="sd">                indices) and `q` is the number of points considered jointly. The `+ 1`</span>
<span class="sd">                dimension is the optional task feature / index. If given, the model</span>
<span class="sd">                produces the outputs for the given task indices. If omitted, the</span>
<span class="sd">                model produces outputs for tasks in in `self._output_tasks` (specified</span>
<span class="sd">                as `output_tasks` while constructing the model), which can overwritten</span>
<span class="sd">                using `output_indices`.</span>
<span class="sd">            output_indices: A list of task values over which to compute the posterior.</span>
<span class="sd">                Only used if `X` does not include the task feature. If omitted,</span>
<span class="sd">                defaults to `self._output_tasks`.</span>
<span class="sd">            observation_noise: If True, add observation noise from the respective</span>
<span class="sd">                likelihoods. If a Tensor, specifies the observation noise levels</span>
<span class="sd">                to add.</span>
<span class="sd">            posterior_transform: An optional PosteriorTransform.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `GPyTorchPosterior` object, representing `batch_shape` joint</span>
<span class="sd">            distributions over `q` points. If the task features are included in `X`,</span>
<span class="sd">            the posterior will be single output. Otherwise, the posterior will be</span>
<span class="sd">            single or multi output corresponding to the tasks included in</span>
<span class="sd">            either the `output_indices` or `self._output_tasks`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">includes_task_feature</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_non_task_features</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">includes_task_feature</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">output_indices</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;`output_indices` must be None when `X` includes task features.&quot;</span>
                <span class="p">)</span>
            <span class="n">task_features</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_task_feature</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
            <span class="n">num_outputs</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="n">X_full</span> <span class="o">=</span> <span class="n">X</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Add the task features to construct the full X for evaluation.</span>
            <span class="n">task_features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_output_tasks</span> <span class="k">if</span> <span class="n">output_indices</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">output_indices</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">num_outputs</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">task_features</span><span class="p">)</span>
            <span class="n">X_full</span> <span class="o">=</span> <span class="n">_make_X_full</span><span class="p">(</span>
                <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">output_indices</span><span class="o">=</span><span class="n">task_features</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="n">tf</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_task_feature</span>
            <span class="p">)</span>
        <span class="c1"># Make sure all task feature values are valid.</span>
        <span class="n">task_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_map_tasks</span><span class="p">(</span><span class="n">task_values</span><span class="o">=</span><span class="n">task_features</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># make sure model is in eval mode</span>
        <span class="c1"># input transforms are applied at `posterior` in `eval` mode, and at</span>
        <span class="c1"># `model.forward()` at the training time</span>
        <span class="n">X_full</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_inputs</span><span class="p">(</span><span class="n">X_full</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">gpt_posterior_settings</span><span class="p">():</span>
            <span class="n">mvn</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">X_full</span><span class="p">)</span>
            <span class="n">mvn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_noise</span><span class="p">(</span>
                <span class="n">X</span><span class="o">=</span><span class="n">X_full</span><span class="p">,</span>
                <span class="n">mvn</span><span class="o">=</span><span class="n">mvn</span><span class="p">,</span>
                <span class="n">num_outputs</span><span class="o">=</span><span class="n">num_outputs</span><span class="p">,</span>
                <span class="n">observation_noise</span><span class="o">=</span><span class="n">observation_noise</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="c1"># If single-output, return the posterior of a single-output model</span>
        <span class="k">if</span> <span class="n">num_outputs</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">posterior</span> <span class="o">=</span> <span class="n">GPyTorchPosterior</span><span class="p">(</span><span class="n">distribution</span><span class="o">=</span><span class="n">mvn</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Otherwise, make a MultitaskMultivariateNormal out of this</span>
            <span class="n">mtmvn</span> <span class="o">=</span> <span class="n">MultitaskMultivariateNormal</span><span class="p">(</span>
                <span class="n">mean</span><span class="o">=</span><span class="n">mvn</span><span class="o">.</span><span class="n">mean</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">mvn</span><span class="o">.</span><span class="n">mean</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">num_outputs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span>
                    <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span>
                <span class="p">),</span>
                <span class="n">covariance_matrix</span><span class="o">=</span><span class="n">mvn</span><span class="o">.</span><span class="n">lazy_covariance_matrix</span><span class="p">,</span>
                <span class="n">interleaved</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">posterior</span> <span class="o">=</span> <span class="n">GPyTorchPosterior</span><span class="p">(</span><span class="n">distribution</span><span class="o">=</span><span class="n">mtmvn</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;outcome_transform&quot;</span><span class="p">):</span>
            <span class="n">posterior</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">outcome_transform</span><span class="o">.</span><span class="n">untransform_posterior</span><span class="p">(</span><span class="n">posterior</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">posterior_transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">posterior_transform</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">posterior</span></div>


<div class="viewcode-block" id="MultiTaskGPyTorchModel.subset_output">
<a class="viewcode-back" href="../../../models.html#botorch.models.gpytorch.MultiTaskGPyTorchModel.subset_output">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">subset_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idcs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">MultiTaskGPyTorchModel</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns a new model that only outputs a subset of the outputs.</span>

<span class="sd">        Args:</span>
<span class="sd">            idcs: A list of output indices, corresponding to the outputs to keep.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A new model that only outputs the requested outputs.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="n">UnsupportedError</span><span class="p">(</span>
            <span class="s2">&quot;Subsetting outputs is not supported by `MultiTaskGPyTorchModel`.&quot;</span>
        <span class="p">)</span></div>
</div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p></p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>