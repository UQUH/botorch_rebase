

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>botorch.models.fully_bayesian &mdash; BoTorch  documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=03e43079" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../../_static/custom.css?v=ca3e82f4" />

  
      <script src="../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../_static/documentation_options.js?v=5929fcd5"></script>
      <script src="../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            BoTorch
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../acquisition.html">botorch.acquisition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models.html">botorch.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generation.html">botorch.generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../posteriors.html">botorch.posteriors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../optim.html">botorch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../fit.html">botorch.fit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../sampling.html">botorch.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cross_validation.html">botorch.cross_validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../settings.html">botorch.settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../logging.html">botorch.logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../test_functions.html">botorch.test_functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../test_utils.html">botorch.test_utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../exceptions.html">botorch.exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../utils.html">botorch.utils</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">BoTorch</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">botorch.models.fully_bayesian</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for botorch.models.fully_bayesian</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright (c) Meta Platforms, Inc. and affiliates.</span>
<span class="c1">#</span>
<span class="c1"># This source code is licensed under the MIT license found in the</span>
<span class="c1"># LICENSE file in the root directory of this source tree.</span>


<span class="sa">r</span><span class="sd">&quot;&quot;&quot;Gaussian Process Regression models with fully Bayesian inference.</span>

<span class="sd">Fully Bayesian models use Bayesian inference over model hyperparameters, such</span>
<span class="sd">as lengthscales and noise variance, learning a posterior distribution for the</span>
<span class="sd">hyperparameters using the No-U-Turn-Sampler (NUTS). This is followed by</span>
<span class="sd">sampling a small set of hyperparameters (often ~16) from the posterior</span>
<span class="sd">that we will use for model predictions and for computing acquisition function</span>
<span class="sd">values. By contrast, our “standard” models (e.g.</span>
<span class="sd">`SingleTaskGP`) learn only a single best value for each hyperparameter using</span>
<span class="sd">MAP. The fully Bayesian method generally results in a better and more</span>
<span class="sd">well-calibrated model, but is more computationally intensive. For a full</span>
<span class="sd">description, see [Eriksson2021saasbo].</span>

<span class="sd">We use a lightweight PyTorch implementation of a Matern-5/2 kernel as there are</span>
<span class="sd">some performance issues with running NUTS on top of standard GPyTorch models.</span>
<span class="sd">The resulting hyperparameter samples are loaded into a batched GPyTorch model</span>
<span class="sd">after fitting.</span>

<span class="sd">References:</span>

<span class="sd">.. [Eriksson2021saasbo]</span>
<span class="sd">    D. Eriksson, M. Jankowiak. High-Dimensional Bayesian Optimization</span>
<span class="sd">    with Sparse Axis-Aligned Subspaces. Proceedings of the Thirty-</span>
<span class="sd">    Seventh Conference on Uncertainty in Artificial Intelligence, 2021.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">ABC</span><span class="p">,</span> <span class="n">abstractmethod</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections.abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">Mapping</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">TypeVar</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">pyro</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.acquisition.objective</span><span class="w"> </span><span class="kn">import</span> <span class="n">PosteriorTransform</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.models.gpytorch</span><span class="w"> </span><span class="kn">import</span> <span class="n">BatchedMultiOutputGPyTorchModel</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.models.transforms.input</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">ChainedInputTransform</span><span class="p">,</span>
    <span class="n">InputTransform</span><span class="p">,</span>
    <span class="n">Normalize</span><span class="p">,</span>
    <span class="n">Warp</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.models.transforms.outcome</span><span class="w"> </span><span class="kn">import</span> <span class="n">OutcomeTransform</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.models.transforms.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">kumaraswamy_warp</span><span class="p">,</span> <span class="n">subset_transform</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.models.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">validate_input_scaling</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.models.utils.gpytorch_modules</span><span class="w"> </span><span class="kn">import</span> <span class="n">MIN_INFERRED_NOISE_LEVEL</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.posteriors.fully_bayesian</span><span class="w"> </span><span class="kn">import</span> <span class="n">GaussianMixturePosterior</span><span class="p">,</span> <span class="n">MCMC_DIM</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.utils.containers</span><span class="w"> </span><span class="kn">import</span> <span class="n">BotorchContainer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.utils.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">SupervisedDataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.constraints</span><span class="w"> </span><span class="kn">import</span> <span class="n">GreaterThan</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.distributions.multivariate_normal</span><span class="w"> </span><span class="kn">import</span> <span class="n">MultivariateNormal</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.kernels</span><span class="w"> </span><span class="kn">import</span> <span class="n">LinearKernel</span><span class="p">,</span> <span class="n">MaternKernel</span><span class="p">,</span> <span class="n">ScaleKernel</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.kernels.kernel</span><span class="w"> </span><span class="kn">import</span> <span class="n">dist</span><span class="p">,</span> <span class="n">Kernel</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.likelihoods.gaussian_likelihood</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">FixedNoiseGaussianLikelihood</span><span class="p">,</span>
    <span class="n">GaussianLikelihood</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.likelihoods.likelihood</span><span class="w"> </span><span class="kn">import</span> <span class="n">Likelihood</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.means.constant_mean</span><span class="w"> </span><span class="kn">import</span> <span class="n">ConstantMean</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.means.mean</span><span class="w"> </span><span class="kn">import</span> <span class="n">Mean</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.models.exact_gp</span><span class="w"> </span><span class="kn">import</span> <span class="n">ExactGP</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyro.ops.integrator</span><span class="w"> </span><span class="kn">import</span> <span class="n">register_exception_handler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">Tensor</span>

<span class="c1"># Can replace with Self type once 3.11 is the minimum version</span>
<span class="n">TFullyBayesianSingleTaskGP</span> <span class="o">=</span> <span class="n">TypeVar</span><span class="p">(</span>
    <span class="s2">&quot;TFullyBayesianSingleTaskGP&quot;</span><span class="p">,</span> <span class="n">bound</span><span class="o">=</span><span class="s2">&quot;FullyBayesianSingleTaskGP&quot;</span>
<span class="p">)</span>

<span class="n">_sqrt5</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_handle_torch_linalg</span><span class="p">(</span><span class="n">exception</span><span class="p">:</span> <span class="ne">Exception</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="k">return</span> <span class="nb">type</span><span class="p">(</span><span class="n">exception</span><span class="p">)</span> <span class="ow">is</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinAlgError</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_handle_valerr_in_dist_init</span><span class="p">(</span><span class="n">exception</span><span class="p">:</span> <span class="ne">Exception</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">exception</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="ne">ValueError</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="k">return</span> <span class="s2">&quot;satisfy the constraint PositiveDefinite()&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">exception</span><span class="p">)</span>


<span class="n">register_exception_handler</span><span class="p">(</span><span class="s2">&quot;torch_linalg&quot;</span><span class="p">,</span> <span class="n">_handle_torch_linalg</span><span class="p">)</span>
<span class="n">register_exception_handler</span><span class="p">(</span><span class="s2">&quot;valerr_in_dist_init&quot;</span><span class="p">,</span> <span class="n">_handle_valerr_in_dist_init</span><span class="p">)</span>


<div class="viewcode-block" id="matern52_kernel">
<a class="viewcode-back" href="../../../models.html#botorch.models.fully_bayesian.matern52_kernel">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">matern52_kernel</span><span class="p">(</span><span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">lengthscale</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Matern-5/2 kernel.&quot;&quot;&quot;</span>
    <span class="n">dist</span> <span class="o">=</span> <span class="n">compute_dists</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">lengthscale</span><span class="o">=</span><span class="n">lengthscale</span><span class="p">)</span>
    <span class="n">sqrt5_dist</span> <span class="o">=</span> <span class="n">_sqrt5</span> <span class="o">*</span> <span class="n">dist</span>
    <span class="k">return</span> <span class="n">sqrt5_dist</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">5</span> <span class="o">/</span> <span class="mi">3</span> <span class="o">*</span> <span class="p">(</span><span class="n">dist</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">sqrt5_dist</span><span class="p">)</span></div>



<div class="viewcode-block" id="linear_kernel">
<a class="viewcode-back" href="../../../models.html#botorch.models.fully_bayesian.linear_kernel">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">linear_kernel</span><span class="p">(</span><span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">weight_variance</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Linear kernel.&quot;&quot;&quot;</span>
    <span class="n">Xw</span> <span class="o">=</span> <span class="n">X</span> <span class="o">*</span> <span class="n">weight_variance</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">Xw</span> <span class="o">@</span> <span class="n">Xw</span><span class="o">.</span><span class="n">t</span><span class="p">()</span></div>



<div class="viewcode-block" id="compute_dists">
<a class="viewcode-back" href="../../../models.html#botorch.models.fully_bayesian.compute_dists">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">compute_dists</span><span class="p">(</span><span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">lengthscale</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute kernel distances.&quot;&quot;&quot;</span>
    <span class="n">scaled_X</span> <span class="o">=</span> <span class="n">X</span> <span class="o">/</span> <span class="n">lengthscale</span>
    <span class="k">return</span> <span class="n">dist</span><span class="p">(</span><span class="n">scaled_X</span><span class="p">,</span> <span class="n">scaled_X</span><span class="p">,</span> <span class="n">x1_eq_x2</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></div>



<div class="viewcode-block" id="reshape_and_detach">
<a class="viewcode-back" href="../../../models.html#botorch.models.fully_bayesian.reshape_and_detach">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">reshape_and_detach</span><span class="p">(</span><span class="n">target</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">new_value</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Detach and reshape `new_value` to match `target`.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">new_value</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">target</span><span class="p">)</span></div>



<div class="viewcode-block" id="PyroModel">
<a class="viewcode-back" href="../../../models.html#botorch.models.fully_bayesian.PyroModel">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">PyroModel</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Base class for a Pyro model; used to assist in learning hyperparameters.</span>

<span class="sd">    This class and its subclasses are not a standard BoTorch models; instead</span>
<span class="sd">    the subclasses are used as inputs to a `SaasFullyBayesianSingleTaskGP`,</span>
<span class="sd">    which should then have its hyperparameters fit with</span>
<span class="sd">    `fit_fully_bayesian_model_nuts`. (By default, its subclass `SaasPyroModel`</span>
<span class="sd">    is used).  A `PyroModel`’s `sample` method should specify lightweight</span>
<span class="sd">    PyTorch functionality, which will be used for fast model fitting with NUTS.</span>
<span class="sd">    The utility of `PyroModel` is in enabling fast fitting with NUTS, since we</span>
<span class="sd">    would otherwise need to use GPyTorch, which is computationally infeasible</span>
<span class="sd">    in combination with Pyro.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="PyroModel.set_inputs">
<a class="viewcode-back" href="../../../models.html#botorch.models.fully_bayesian.PyroModel.set_inputs">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">set_inputs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">train_X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">train_Yvar</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set the training data.</span>

<span class="sd">        Args:</span>
<span class="sd">            train_X: Training inputs (n x d)</span>
<span class="sd">            train_Y: Training targets (n x 1)</span>
<span class="sd">            train_Yvar: Observed noise variance (n x 1). Inferred if None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_X</span> <span class="o">=</span> <span class="n">train_X</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">train_Y</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_Yvar</span> <span class="o">=</span> <span class="n">train_Yvar</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ard_num_dims</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span></div>


<div class="viewcode-block" id="PyroModel.sample">
<a class="viewcode-back" href="../../../models.html#botorch.models.fully_bayesian.PyroModel.sample">[docs]</a>
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Sample from the model.&quot;&quot;&quot;</span>
        <span class="k">pass</span>  <span class="c1"># pragma: no cover</span></div>


<div class="viewcode-block" id="PyroModel.postprocess_mcmc_samples">
<a class="viewcode-back" href="../../../models.html#botorch.models.fully_bayesian.PyroModel.postprocess_mcmc_samples">[docs]</a>
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">postprocess_mcmc_samples</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">mcmc_samples</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Post-process the final MCMC samples.&quot;&quot;&quot;</span>
        <span class="k">pass</span>  <span class="c1"># pragma: no cover</span></div>


<div class="viewcode-block" id="PyroModel.load_mcmc_samples">
<a class="viewcode-back" href="../../../models.html#botorch.models.fully_bayesian.PyroModel.load_mcmc_samples">[docs]</a>
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">load_mcmc_samples</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">mcmc_samples</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Mean</span><span class="p">,</span> <span class="n">Kernel</span><span class="p">,</span> <span class="n">Likelihood</span><span class="p">]:</span>
        <span class="k">pass</span>  <span class="c1"># pragma: no cover</span></div>


<div class="viewcode-block" id="PyroModel.sample_noise">
<a class="viewcode-back" href="../../../models.html#botorch.models.fully_bayesian.PyroModel.sample_noise">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">sample_noise</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Sample the noise variance.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_Yvar</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">MIN_INFERRED_NOISE_LEVEL</span> <span class="o">+</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
                <span class="s2">&quot;noise&quot;</span><span class="p">,</span>
                <span class="n">pyro</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Gamma</span><span class="p">(</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">),</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">10.0</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">),</span>
                <span class="p">),</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_Yvar</span></div>


<div class="viewcode-block" id="PyroModel.sample_mean">
<a class="viewcode-back" href="../../../models.html#botorch.models.fully_bayesian.PyroModel.sample_mean">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">sample_mean</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Sample the mean constant.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
            <span class="s2">&quot;mean&quot;</span><span class="p">,</span>
            <span class="n">pyro</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">),</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">),</span>
            <span class="p">),</span>
        <span class="p">)</span></div>
</div>



<div class="viewcode-block" id="SaasPyroModel">
<a class="viewcode-back" href="../../../models.html#botorch.models.fully_bayesian.SaasPyroModel">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">SaasPyroModel</span><span class="p">(</span><span class="n">PyroModel</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Implementation of the sparse axis-aligned subspace priors (SAAS) model.</span>

<span class="sd">    The SAAS model uses sparsity-inducing priors to identify the most important</span>
<span class="sd">    parameters. This model is suitable for high-dimensional BO with potentially</span>
<span class="sd">    hundreds of tunable parameters. See [Eriksson2021saasbo]_ for more details.</span>

<span class="sd">    `SaasPyroModel` is not a standard BoTorch model; instead, it is used as</span>
<span class="sd">    an input to `SaasFullyBayesianSingleTaskGP`. It is used as a default keyword</span>
<span class="sd">    argument, and end users are not likely to need to instantiate or modify a</span>
<span class="sd">    `SaasPyroModel` unless they want to customize its attributes (such as</span>
<span class="sd">    `covar_module`).</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="SaasPyroModel.sample">
<a class="viewcode-back" href="../../../models.html#botorch.models.fully_bayesian.SaasPyroModel.sample">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Sample from the SAAS model.</span>

<span class="sd">        This samples the mean, noise variance, outputscale, and lengthscales according</span>
<span class="sd">        to the SAAS prior.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">tkwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;dtype&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_X</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="s2">&quot;device&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_X</span><span class="o">.</span><span class="n">device</span><span class="p">}</span>
        <span class="n">outputscale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_outputscale</span><span class="p">(</span><span class="n">concentration</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">)</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_mean</span><span class="p">(</span><span class="o">**</span><span class="n">tkwargs</span><span class="p">)</span>
        <span class="n">noise</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_noise</span><span class="p">(</span><span class="o">**</span><span class="n">tkwargs</span><span class="p">)</span>
        <span class="n">lengthscale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_lengthscale</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ard_num_dims</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Do not attempt to sample Y if the data is empty.</span>
            <span class="c1"># This leads to errors with empty data.</span>
            <span class="n">K</span> <span class="o">=</span> <span class="n">matern52_kernel</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_X</span><span class="p">,</span> <span class="n">lengthscale</span><span class="o">=</span><span class="n">lengthscale</span><span class="p">)</span>
            <span class="n">K</span> <span class="o">=</span> <span class="n">outputscale</span> <span class="o">*</span> <span class="n">K</span> <span class="o">+</span> <span class="n">noise</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">)</span>
            <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
                <span class="s2">&quot;Y&quot;</span><span class="p">,</span>
                <span class="n">pyro</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">MultivariateNormal</span><span class="p">(</span>
                    <span class="n">loc</span><span class="o">=</span><span class="n">mean</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
                    <span class="n">covariance_matrix</span><span class="o">=</span><span class="n">K</span><span class="p">,</span>
                <span class="p">),</span>
                <span class="n">obs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_Y</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
            <span class="p">)</span></div>


<div class="viewcode-block" id="SaasPyroModel.sample_outputscale">
<a class="viewcode-back" href="../../../models.html#botorch.models.fully_bayesian.SaasPyroModel.sample_outputscale">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">sample_outputscale</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">concentration</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">2.0</span><span class="p">,</span> <span class="n">rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.15</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">:</span> <span class="n">Any</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Sample the outputscale.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
            <span class="s2">&quot;outputscale&quot;</span><span class="p">,</span>
            <span class="n">pyro</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Gamma</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">concentration</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">),</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">rate</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">),</span>
            <span class="p">),</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="SaasPyroModel.sample_lengthscale">
<a class="viewcode-back" href="../../../models.html#botorch.models.fully_bayesian.SaasPyroModel.sample_lengthscale">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">sample_lengthscale</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">:</span> <span class="n">Any</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Sample the lengthscale.&quot;&quot;&quot;</span>
        <span class="n">tausq</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
            <span class="s2">&quot;kernel_tausq&quot;</span><span class="p">,</span>
            <span class="n">pyro</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">HalfCauchy</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">)),</span>
        <span class="p">)</span>
        <span class="n">inv_length_sq</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
            <span class="s2">&quot;_kernel_inv_length_sq&quot;</span><span class="p">,</span>
            <span class="n">pyro</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">HalfCauchy</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">)),</span>
        <span class="p">)</span>
        <span class="n">inv_length_sq</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">deterministic</span><span class="p">(</span>
            <span class="s2">&quot;kernel_inv_length_sq&quot;</span><span class="p">,</span> <span class="n">tausq</span> <span class="o">*</span> <span class="n">inv_length_sq</span>
        <span class="p">)</span>
        <span class="n">lengthscale</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">deterministic</span><span class="p">(</span>
            <span class="s2">&quot;lengthscale&quot;</span><span class="p">,</span>
            <span class="n">inv_length_sq</span><span class="o">.</span><span class="n">rsqrt</span><span class="p">(),</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">lengthscale</span></div>


<div class="viewcode-block" id="SaasPyroModel.postprocess_mcmc_samples">
<a class="viewcode-back" href="../../../models.html#botorch.models.fully_bayesian.SaasPyroModel.postprocess_mcmc_samples">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">postprocess_mcmc_samples</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">mcmc_samples</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Post-process the MCMC samples.</span>

<span class="sd">        This computes the true lengthscales and removes the inverse lengthscales and</span>
<span class="sd">        tausq (global shrinkage).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">inv_length_sq</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">mcmc_samples</span><span class="p">[</span><span class="s2">&quot;kernel_tausq&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="o">*</span> <span class="n">mcmc_samples</span><span class="p">[</span><span class="s2">&quot;_kernel_inv_length_sq&quot;</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="n">mcmc_samples</span><span class="p">[</span><span class="s2">&quot;lengthscale&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">inv_length_sq</span><span class="o">.</span><span class="n">rsqrt</span><span class="p">()</span>
        <span class="c1"># Delete `kernel_tausq` and `_kernel_inv_length_sq` since they aren&#39;t loaded</span>
        <span class="c1"># into the final model.</span>
        <span class="k">del</span> <span class="n">mcmc_samples</span><span class="p">[</span><span class="s2">&quot;kernel_tausq&quot;</span><span class="p">],</span> <span class="n">mcmc_samples</span><span class="p">[</span><span class="s2">&quot;_kernel_inv_length_sq&quot;</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">mcmc_samples</span></div>


<div class="viewcode-block" id="SaasPyroModel.load_mcmc_samples">
<a class="viewcode-back" href="../../../models.html#botorch.models.fully_bayesian.SaasPyroModel.load_mcmc_samples">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">load_mcmc_samples</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">mcmc_samples</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Mean</span><span class="p">,</span> <span class="n">Kernel</span><span class="p">,</span> <span class="n">Likelihood</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Load the MCMC samples into the mean_module, covar_module, and likelihood.&quot;&quot;&quot;</span>
        <span class="n">tkwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;device&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_X</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_X</span><span class="o">.</span><span class="n">dtype</span><span class="p">}</span>
        <span class="n">num_mcmc_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">mcmc_samples</span><span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">])</span>
        <span class="n">batch_shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">num_mcmc_samples</span><span class="p">])</span>

        <span class="n">mean_module</span> <span class="o">=</span> <span class="n">ConstantMean</span><span class="p">(</span><span class="n">batch_shape</span><span class="o">=</span><span class="n">batch_shape</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="o">**</span><span class="n">tkwargs</span><span class="p">)</span>
        <span class="n">covar_module</span> <span class="o">=</span> <span class="n">ScaleKernel</span><span class="p">(</span>
            <span class="n">base_kernel</span><span class="o">=</span><span class="n">MaternKernel</span><span class="p">(</span>
                <span class="n">ard_num_dims</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ard_num_dims</span><span class="p">,</span>
                <span class="n">batch_shape</span><span class="o">=</span><span class="n">batch_shape</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="n">batch_shape</span><span class="o">=</span><span class="n">batch_shape</span><span class="p">,</span>
        <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="o">**</span><span class="n">tkwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_Yvar</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">likelihood</span> <span class="o">=</span> <span class="n">FixedNoiseGaussianLikelihood</span><span class="p">(</span>
                <span class="c1"># Reshape to shape `num_mcmc_samples x N`</span>
                <span class="n">noise</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_Yvar</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span>
                    <span class="n">num_mcmc_samples</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_Yvar</span><span class="p">)</span>
                <span class="p">),</span>
                <span class="n">batch_shape</span><span class="o">=</span><span class="n">batch_shape</span><span class="p">,</span>
            <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="o">**</span><span class="n">tkwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">likelihood</span> <span class="o">=</span> <span class="n">GaussianLikelihood</span><span class="p">(</span>
                <span class="n">batch_shape</span><span class="o">=</span><span class="n">batch_shape</span><span class="p">,</span>
                <span class="n">noise_constraint</span><span class="o">=</span><span class="n">GreaterThan</span><span class="p">(</span><span class="n">MIN_INFERRED_NOISE_LEVEL</span><span class="p">),</span>
            <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="o">**</span><span class="n">tkwargs</span><span class="p">)</span>
            <span class="n">likelihood</span><span class="o">.</span><span class="n">noise_covar</span><span class="o">.</span><span class="n">noise</span> <span class="o">=</span> <span class="n">reshape_and_detach</span><span class="p">(</span>
                <span class="n">target</span><span class="o">=</span><span class="n">likelihood</span><span class="o">.</span><span class="n">noise_covar</span><span class="o">.</span><span class="n">noise</span><span class="p">,</span>
                <span class="n">new_value</span><span class="o">=</span><span class="n">mcmc_samples</span><span class="p">[</span><span class="s2">&quot;noise&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">clamp_min</span><span class="p">(</span><span class="n">MIN_INFERRED_NOISE_LEVEL</span><span class="p">),</span>
            <span class="p">)</span>
        <span class="n">covar_module</span><span class="o">.</span><span class="n">base_kernel</span><span class="o">.</span><span class="n">lengthscale</span> <span class="o">=</span> <span class="n">reshape_and_detach</span><span class="p">(</span>
            <span class="n">target</span><span class="o">=</span><span class="n">covar_module</span><span class="o">.</span><span class="n">base_kernel</span><span class="o">.</span><span class="n">lengthscale</span><span class="p">,</span>
            <span class="n">new_value</span><span class="o">=</span><span class="n">mcmc_samples</span><span class="p">[</span><span class="s2">&quot;lengthscale&quot;</span><span class="p">],</span>
        <span class="p">)</span>
        <span class="n">covar_module</span><span class="o">.</span><span class="n">outputscale</span> <span class="o">=</span> <span class="n">reshape_and_detach</span><span class="p">(</span>
            <span class="n">target</span><span class="o">=</span><span class="n">covar_module</span><span class="o">.</span><span class="n">outputscale</span><span class="p">,</span>
            <span class="n">new_value</span><span class="o">=</span><span class="n">mcmc_samples</span><span class="p">[</span><span class="s2">&quot;outputscale&quot;</span><span class="p">],</span>
        <span class="p">)</span>
        <span class="n">mean_module</span><span class="o">.</span><span class="n">constant</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">reshape_and_detach</span><span class="p">(</span>
            <span class="n">target</span><span class="o">=</span><span class="n">mean_module</span><span class="o">.</span><span class="n">constant</span><span class="o">.</span><span class="n">data</span><span class="p">,</span>
            <span class="n">new_value</span><span class="o">=</span><span class="n">mcmc_samples</span><span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">],</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">mean_module</span><span class="p">,</span> <span class="n">covar_module</span><span class="p">,</span> <span class="n">likelihood</span></div>
</div>



<div class="viewcode-block" id="LinearPyroModel">
<a class="viewcode-back" href="../../../models.html#botorch.models.fully_bayesian.LinearPyroModel">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">LinearPyroModel</span><span class="p">(</span><span class="n">PyroModel</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Implementation of a Bayesian Linear pyro model.</span>

<span class="sd">    `LinearPyroModel` is not a standard BoTorch model; instead, it is used as</span>
<span class="sd">    an input to `FullyBayesianLinearSingleTaskGP`. It is used as a default keyword</span>
<span class="sd">    argument, and end users are not likely to need to instantiate or modify a</span>
<span class="sd">    `LinearPyroModel` unless they want to customize its attributes (such as</span>
<span class="sd">    `covar_module`).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">use_input_warping</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">indices_to_warp</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-7</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Initialize the LinearPyroModel.</span>

<span class="sd">        Args:</span>
<span class="sd">            use_input_warping: If True, use input warping.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_input_warping</span> <span class="o">=</span> <span class="n">use_input_warping</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">indices</span> <span class="o">=</span> <span class="n">indices_to_warp</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_eps</span> <span class="o">=</span> <span class="n">eps</span>

<div class="viewcode-block" id="LinearPyroModel.warp">
<a class="viewcode-back" href="../../../models.html#botorch.models.fully_bayesian.LinearPyroModel.warp">[docs]</a>
    <span class="nd">@subset_transform</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">warp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">c0</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">c1</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Warp the input.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">kumaraswamy_warp</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">c0</span><span class="o">=</span><span class="n">c0</span><span class="p">,</span> <span class="n">c1</span><span class="o">=</span><span class="n">c1</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_eps</span><span class="p">)</span></div>


<div class="viewcode-block" id="LinearPyroModel.sample">
<a class="viewcode-back" href="../../../models.html#botorch.models.fully_bayesian.LinearPyroModel.sample">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Sample from the model.&quot;&quot;&quot;</span>
        <span class="n">tkwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;dtype&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_X</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="s2">&quot;device&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_X</span><span class="o">.</span><span class="n">device</span><span class="p">}</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_mean</span><span class="p">(</span><span class="o">**</span><span class="n">tkwargs</span><span class="p">)</span>
        <span class="n">weight_variance</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_weight_variance</span><span class="p">(</span><span class="o">**</span><span class="n">tkwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_input_warping</span><span class="p">:</span>
            <span class="n">c0</span><span class="p">,</span> <span class="n">c1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_concentrations</span><span class="p">(</span><span class="o">**</span><span class="n">tkwargs</span><span class="p">)</span>
            <span class="c1"># unnormalize X from [0, 1] to [eps, 1-eps]</span>
            <span class="n">X_tf</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">warp</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_X</span><span class="p">,</span> <span class="n">c0</span><span class="o">=</span><span class="n">c0</span><span class="p">,</span> <span class="n">c1</span><span class="o">=</span><span class="n">c1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">X_tf</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_X</span>
        <span class="n">X_tf</span> <span class="o">=</span> <span class="n">X_tf</span> <span class="o">-</span> <span class="mf">0.5</span>  <span class="c1"># center transformed data at 0 (for linear model)</span>
        <span class="n">K</span> <span class="o">=</span> <span class="n">linear_kernel</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X_tf</span><span class="p">,</span> <span class="n">weight_variance</span><span class="o">=</span><span class="n">weight_variance</span><span class="p">)</span>
        <span class="n">noise</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_noise</span><span class="p">(</span><span class="o">**</span><span class="n">tkwargs</span><span class="p">)</span>
        <span class="n">K</span> <span class="o">=</span> <span class="n">K</span> <span class="o">+</span> <span class="n">noise</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">)</span>
        <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
            <span class="s2">&quot;Y&quot;</span><span class="p">,</span>
            <span class="n">pyro</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">MultivariateNormal</span><span class="p">(</span>
                <span class="n">loc</span><span class="o">=</span><span class="n">mean</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
                <span class="n">covariance_matrix</span><span class="o">=</span><span class="n">K</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="n">obs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_Y</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="LinearPyroModel.sample_weight_variance">
<a class="viewcode-back" href="../../../models.html#botorch.models.fully_bayesian.LinearPyroModel.sample_weight_variance">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">sample_weight_variance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Sample the weight variance.</span>

<span class="sd">        This is a hierarchical prior is a half-Cauchy prior on the prior weight</span>
<span class="sd">        covariance, which is diagonal with different values for each input</span>
<span class="sd">        dimension. The prior samples a global level of sparsity (tau) and which</span>
<span class="sd">        scales the HalfCauchy prior on the weight variance. Since the weight prior</span>
<span class="sd">        is centered at zero, a prior variance of 0, would correspond to the</span>
<span class="sd">        dimension being irrelevant. This choice of prior is motivated by Saas</span>
<span class="sd">        priors.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">tau_sq</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
            <span class="s2">&quot;tau_sq&quot;</span><span class="p">,</span>
            <span class="n">pyro</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">HalfCauchy</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">)),</span>
        <span class="p">)</span>
        <span class="n">weight_variance_sq</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
            <span class="s2">&quot;_weight_variance_sq&quot;</span><span class="p">,</span>
            <span class="n">pyro</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">HalfCauchy</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ard_num_dims</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">)),</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">pyro</span><span class="o">.</span><span class="n">deterministic</span><span class="p">(</span>
            <span class="s2">&quot;weight_variance&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">tau_sq</span> <span class="o">*</span> <span class="n">weight_variance_sq</span><span class="p">)</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="LinearPyroModel.postprocess_mcmc_samples">
<a class="viewcode-back" href="../../../models.html#botorch.models.fully_bayesian.LinearPyroModel.postprocess_mcmc_samples">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">postprocess_mcmc_samples</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">mcmc_samples</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Post-process the MCMC samples.</span>

<span class="sd">        This computes the true weight variance and removes tausq (global shrinkage).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">mcmc_samples</span><span class="p">[</span><span class="s2">&quot;weight_variance&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">mcmc_samples</span><span class="p">[</span><span class="s2">&quot;tau_sq&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">mcmc_samples</span><span class="p">[</span><span class="s2">&quot;_weight_variance_sq&quot;</span><span class="p">]</span>
        <span class="p">)</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
        <span class="k">del</span> <span class="n">mcmc_samples</span><span class="p">[</span><span class="s2">&quot;tau_sq&quot;</span><span class="p">],</span> <span class="n">mcmc_samples</span><span class="p">[</span><span class="s2">&quot;_weight_variance_sq&quot;</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">mcmc_samples</span></div>


<div class="viewcode-block" id="LinearPyroModel.sample_concentrations">
<a class="viewcode-back" href="../../../models.html#botorch.models.fully_bayesian.LinearPyroModel.sample_concentrations">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">sample_concentrations</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Sample concentrations for input warping.</span>

<span class="sd">        The prior has a mean value of 1 for each concentration and is very</span>
<span class="sd">        concentrated around the mean.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">c0</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
            <span class="s2">&quot;c0&quot;</span><span class="p">,</span>
            <span class="n">pyro</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">LogNormal</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">ard_num_dims</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">),</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.1</span><span class="o">**</span><span class="mf">0.5</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">ard_num_dims</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">),</span>
            <span class="p">),</span>
        <span class="p">)</span>
        <span class="n">c1</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
            <span class="s2">&quot;c1&quot;</span><span class="p">,</span>
            <span class="n">pyro</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">LogNormal</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">ard_num_dims</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">),</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.1</span><span class="o">**</span><span class="mf">0.5</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">ard_num_dims</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">),</span>
            <span class="p">),</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">c0</span><span class="p">,</span> <span class="n">c1</span></div>


<div class="viewcode-block" id="LinearPyroModel.load_mcmc_samples">
<a class="viewcode-back" href="../../../models.html#botorch.models.fully_bayesian.LinearPyroModel.load_mcmc_samples">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">load_mcmc_samples</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">mcmc_samples</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Mean</span><span class="p">,</span> <span class="n">Kernel</span><span class="p">,</span> <span class="n">Likelihood</span><span class="p">,</span> <span class="n">InputTransform</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Load the MCMC samples into their corresponding modules.&quot;&quot;&quot;</span>
        <span class="n">tkwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;device&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_X</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_X</span><span class="o">.</span><span class="n">dtype</span><span class="p">}</span>
        <span class="n">num_mcmc_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">mcmc_samples</span><span class="p">[</span><span class="s2">&quot;weight_variance&quot;</span><span class="p">])</span>
        <span class="n">batch_shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">num_mcmc_samples</span><span class="p">])</span>

        <span class="n">mean_module</span> <span class="o">=</span> <span class="n">ConstantMean</span><span class="p">(</span><span class="n">batch_shape</span><span class="o">=</span><span class="n">batch_shape</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="o">**</span><span class="n">tkwargs</span><span class="p">)</span>
        <span class="n">covar_module</span> <span class="o">=</span> <span class="n">LinearKernel</span><span class="p">(</span>
            <span class="n">batch_shape</span><span class="o">=</span><span class="n">batch_shape</span><span class="p">,</span>
            <span class="n">ard_num_dims</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ard_num_dims</span><span class="p">,</span>
        <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="o">**</span><span class="n">tkwargs</span><span class="p">)</span>

        <span class="n">bounds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ard_num_dims</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">)</span>
        <span class="n">bounds</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">input_tf</span> <span class="o">=</span> <span class="n">Normalize</span><span class="p">(</span>
            <span class="n">d</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ard_num_dims</span><span class="p">,</span>
            <span class="n">bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">,</span>
            <span class="n">center</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
            <span class="c1"># batch shape passed here when using input warping</span>
            <span class="c1"># which is applied first and adds a batch dimension</span>
            <span class="n">batch_shape</span><span class="o">=</span><span class="n">batch_shape</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_input_warping</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([]),</span>
        <span class="p">)</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ard_num_dims</span><span class="p">))</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">indices</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">indices</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_input_warping</span><span class="p">:</span>
            <span class="n">warping_function</span> <span class="o">=</span> <span class="n">Warp</span><span class="p">(</span>
                <span class="n">d</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ard_num_dims</span><span class="p">,</span>
                <span class="n">batch_shape</span><span class="o">=</span><span class="n">batch_shape</span><span class="p">,</span>
                <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span>
                <span class="n">bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">,</span>
            <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="o">**</span><span class="n">tkwargs</span><span class="p">)</span>
            <span class="n">warping_function</span><span class="o">.</span><span class="n">concentration0</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">reshape_and_detach</span><span class="p">(</span>
                <span class="n">target</span><span class="o">=</span><span class="n">warping_function</span><span class="o">.</span><span class="n">concentration0</span><span class="p">,</span>
                <span class="n">new_value</span><span class="o">=</span><span class="n">mcmc_samples</span><span class="p">[</span><span class="s2">&quot;c0&quot;</span><span class="p">],</span>
            <span class="p">)</span>
            <span class="n">warping_function</span><span class="o">.</span><span class="n">concentration1</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">reshape_and_detach</span><span class="p">(</span>
                <span class="n">target</span><span class="o">=</span><span class="n">warping_function</span><span class="o">.</span><span class="n">concentration1</span><span class="p">,</span>
                <span class="n">new_value</span><span class="o">=</span><span class="n">mcmc_samples</span><span class="p">[</span><span class="s2">&quot;c1&quot;</span><span class="p">],</span>
            <span class="p">)</span>
            <span class="n">input_tf</span> <span class="o">=</span> <span class="n">ChainedInputTransform</span><span class="p">(</span><span class="n">warp</span><span class="o">=</span><span class="n">warping_function</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="n">input_tf</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_Yvar</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">likelihood</span> <span class="o">=</span> <span class="n">FixedNoiseGaussianLikelihood</span><span class="p">(</span>
                <span class="c1"># Reshape to shape `num_mcmc_samples x N`</span>
                <span class="n">noise</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_Yvar</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span>
                    <span class="n">num_mcmc_samples</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_Yvar</span><span class="p">)</span>
                <span class="p">),</span>
                <span class="n">batch_shape</span><span class="o">=</span><span class="n">batch_shape</span><span class="p">,</span>
            <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="o">**</span><span class="n">tkwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">likelihood</span> <span class="o">=</span> <span class="n">GaussianLikelihood</span><span class="p">(</span>
                <span class="n">batch_shape</span><span class="o">=</span><span class="n">batch_shape</span><span class="p">,</span>
                <span class="n">noise_constraint</span><span class="o">=</span><span class="n">GreaterThan</span><span class="p">(</span><span class="n">MIN_INFERRED_NOISE_LEVEL</span><span class="p">),</span>
            <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="o">**</span><span class="n">tkwargs</span><span class="p">)</span>
            <span class="n">likelihood</span><span class="o">.</span><span class="n">noise_covar</span><span class="o">.</span><span class="n">noise</span> <span class="o">=</span> <span class="n">reshape_and_detach</span><span class="p">(</span>
                <span class="n">target</span><span class="o">=</span><span class="n">likelihood</span><span class="o">.</span><span class="n">noise_covar</span><span class="o">.</span><span class="n">noise</span><span class="p">,</span>
                <span class="n">new_value</span><span class="o">=</span><span class="n">mcmc_samples</span><span class="p">[</span><span class="s2">&quot;noise&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">clamp_min</span><span class="p">(</span><span class="n">MIN_INFERRED_NOISE_LEVEL</span><span class="p">),</span>
            <span class="p">)</span>
        <span class="n">covar_module</span><span class="o">.</span><span class="n">variance</span> <span class="o">=</span> <span class="n">reshape_and_detach</span><span class="p">(</span>
            <span class="n">target</span><span class="o">=</span><span class="n">covar_module</span><span class="o">.</span><span class="n">variance</span><span class="p">,</span>
            <span class="n">new_value</span><span class="o">=</span><span class="n">mcmc_samples</span><span class="p">[</span><span class="s2">&quot;weight_variance&quot;</span><span class="p">],</span>
        <span class="p">)</span>
        <span class="n">mean_module</span><span class="o">.</span><span class="n">constant</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">reshape_and_detach</span><span class="p">(</span>
            <span class="n">target</span><span class="o">=</span><span class="n">mean_module</span><span class="o">.</span><span class="n">constant</span><span class="o">.</span><span class="n">data</span><span class="p">,</span>
            <span class="n">new_value</span><span class="o">=</span><span class="n">mcmc_samples</span><span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">],</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">mean_module</span><span class="p">,</span> <span class="n">covar_module</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">,</span> <span class="n">input_tf</span></div>
</div>



<div class="viewcode-block" id="FullyBayesianSingleTaskGP">
<a class="viewcode-back" href="../../../models.html#botorch.models.fully_bayesian.FullyBayesianSingleTaskGP">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">FullyBayesianSingleTaskGP</span><span class="p">(</span><span class="n">ExactGP</span><span class="p">,</span> <span class="n">BatchedMultiOutputGPyTorchModel</span><span class="p">,</span> <span class="n">ABC</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;An abstract fully Bayesian single-task GP model.</span>

<span class="sd">    This model assumes that the inputs have been normalized to [0, 1]^d and that</span>
<span class="sd">    the output has been standardized to have zero mean and unit variance. You can</span>
<span class="sd">    either normalize and standardize the data before constructing the model or use</span>
<span class="sd">    an `input_transform` and `outcome_transform`.</span>

<span class="sd">    You are expected to use `fit_fully_bayesian_model_nuts` to fit this model as it</span>
<span class="sd">    isn&#39;t compatible with `fit_gpytorch_mll`.</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; saas_gp = SaasFullyBayesianSingleTaskGP(train_X, train_Y)</span>
<span class="sd">        &gt;&gt;&gt; fit_fully_bayesian_model_nuts(saas_gp)</span>
<span class="sd">        &gt;&gt;&gt; posterior = saas_gp.posterior(test_X)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_is_fully_bayesian</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">_is_ensemble</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">train_X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">train_Y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">train_Yvar</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">outcome_transform</span><span class="p">:</span> <span class="n">OutcomeTransform</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">input_transform</span><span class="p">:</span> <span class="n">InputTransform</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">pyro_model</span><span class="p">:</span> <span class="n">PyroModel</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Initialize the fully Bayesian single-task GP model.</span>

<span class="sd">        Args:</span>
<span class="sd">            train_X: Training inputs (n x d)</span>
<span class="sd">            train_Y: Training targets (n x 1)</span>
<span class="sd">            train_Yvar: Observed noise variance (n x 1). Inferred if None.</span>
<span class="sd">            outcome_transform: An outcome transform that is applied to the</span>
<span class="sd">                training data during instantiation and to the posterior during</span>
<span class="sd">                inference (that is, the `Posterior` obtained by calling</span>
<span class="sd">                `.posterior` on the model will be on the original scale).</span>
<span class="sd">            input_transform: An input transform that is applied in the model&#39;s</span>
<span class="sd">                forward pass.</span>
<span class="sd">            pyro_model: The pyro model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span>
            <span class="n">train_X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="n">train_Y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span>
            <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_X</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_Y</span><span class="p">)</span>
            <span class="ow">and</span> <span class="n">train_Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Expected train_X to have shape n x d and train_Y to have shape n x 1&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">train_Yvar</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">train_Y</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">train_Yvar</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Expected train_Yvar to be None or have the same shape as train_Y&quot;</span>
                <span class="p">)</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">transformed_X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_inputs</span><span class="p">(</span>
                <span class="n">X</span><span class="o">=</span><span class="n">train_X</span><span class="p">,</span> <span class="n">input_transform</span><span class="o">=</span><span class="n">input_transform</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">outcome_transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">train_Y</span><span class="p">,</span> <span class="n">train_Yvar</span> <span class="o">=</span> <span class="n">outcome_transform</span><span class="p">(</span>
                <span class="n">Y</span><span class="o">=</span><span class="n">train_Y</span><span class="p">,</span> <span class="n">Yvar</span><span class="o">=</span><span class="n">train_Yvar</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">transformed_X</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_tensor_args</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">transformed_X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="n">train_Y</span><span class="p">)</span>
        <span class="n">validate_input_scaling</span><span class="p">(</span>
            <span class="n">train_X</span><span class="o">=</span><span class="n">transformed_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="o">=</span><span class="n">train_Y</span><span class="p">,</span> <span class="n">train_Yvar</span><span class="o">=</span><span class="n">train_Yvar</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_num_outputs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">train_Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_input_batch_shape</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span> <span class="o">=</span> <span class="n">train_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">train_Yvar</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># Clamp after transforming</span>
            <span class="n">train_Yvar</span> <span class="o">=</span> <span class="n">train_Yvar</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">MIN_INFERRED_NOISE_LEVEL</span><span class="p">)</span>

        <span class="n">X_tf</span><span class="p">,</span> <span class="n">Y_tf</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform_tensor_args</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">train_X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="n">train_Y</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">train_inputs</span><span class="o">=</span><span class="n">X_tf</span><span class="p">,</span> <span class="n">train_targets</span><span class="o">=</span><span class="n">Y_tf</span><span class="p">,</span> <span class="n">likelihood</span><span class="o">=</span><span class="n">GaussianLikelihood</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean_module</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">covar_module</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">pyro_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">pyro_model</span> <span class="o">=</span> <span class="n">SaasPyroModel</span><span class="p">()</span>
        <span class="n">pyro_model</span><span class="o">.</span><span class="n">set_inputs</span><span class="p">(</span>
            <span class="n">train_X</span><span class="o">=</span><span class="n">transformed_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="o">=</span><span class="n">train_Y</span><span class="p">,</span> <span class="n">train_Yvar</span><span class="o">=</span><span class="n">train_Yvar</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pyro_model</span><span class="p">:</span> <span class="n">PyroModel</span> <span class="o">=</span> <span class="n">pyro_model</span>
        <span class="k">if</span> <span class="n">outcome_transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">outcome_transform</span><span class="p">:</span> <span class="n">OutcomeTransform</span> <span class="o">=</span> <span class="n">outcome_transform</span>
        <span class="k">if</span> <span class="n">input_transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">input_transform</span><span class="p">:</span> <span class="n">InputTransform</span> <span class="o">=</span> <span class="n">input_transform</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_check_if_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Raise an exception if the model hasn&#39;t been fitted.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">covar_module</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Model has not been fitted. You need to call &quot;</span>
                <span class="s2">&quot;`fit_fully_bayesian_model_nuts` to fit the model.&quot;</span>
            <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">num_mcmc_samples</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Number of MCMC samples in the model.&quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">batch_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Batch shape of the model, equal to the number of MCMC samples.</span>
<span class="sd">        Note that `SaasFullyBayesianSingleTaskGP` does not support batching</span>
<span class="sd">        over input data at this point.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">num_mcmc_samples</span><span class="p">])</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_aug_batch_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;The batch shape of the model, augmented to include the output dim.&quot;&quot;&quot;</span>
        <span class="n">aug_batch_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_shape</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_outputs</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">aug_batch_shape</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">num_outputs</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">aug_batch_shape</span>

<div class="viewcode-block" id="FullyBayesianSingleTaskGP.train">
<a class="viewcode-back" href="../../../models.html#botorch.models.fully_bayesian.FullyBayesianSingleTaskGP.train">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">:</span> <span class="n">TFullyBayesianSingleTaskGP</span><span class="p">,</span> <span class="n">mode</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">reset</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TFullyBayesianSingleTaskGP</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Puts the model in `train` mode.</span>

<span class="sd">        Args:</span>
<span class="sd">            mode: A boolean indicating whether to put the model in training mode.</span>
<span class="sd">            reset: A boolean indicating whether to reset the model to its initial</span>
<span class="sd">                state if mode is True. If `mode` is False, this argument is ignored.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The model itself.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="ow">and</span> <span class="n">reset</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mean_module</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">covar_module</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="bp">self</span></div>


<div class="viewcode-block" id="FullyBayesianSingleTaskGP.load_mcmc_samples">
<a class="viewcode-back" href="../../../models.html#botorch.models.fully_bayesian.FullyBayesianSingleTaskGP.load_mcmc_samples">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">load_mcmc_samples</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mcmc_samples</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Load the MCMC hyperparameter samples into the model.</span>

<span class="sd">        This method will be called by `fit_fully_bayesian_model_nuts` when the model</span>
<span class="sd">        has been fitted in order to create a batched SingleTaskGP model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mean_module</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">covar_module</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pyro_model</span><span class="o">.</span><span class="n">load_mcmc_samples</span><span class="p">(</span><span class="n">mcmc_samples</span><span class="o">=</span><span class="n">mcmc_samples</span><span class="p">)</span></div>


<div class="viewcode-block" id="FullyBayesianSingleTaskGP.forward">
<a class="viewcode-back" href="../../../models.html#botorch.models.fully_bayesian.FullyBayesianSingleTaskGP.forward">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MultivariateNormal</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Unlike in other classes&#39; `forward` methods, there is no `if self.training`</span>
<span class="sd">        block, because it ought to be unreachable: If `self.train()` has been called,</span>
<span class="sd">        then `self.covar_module` will be None, `check_if_fitted()` will fail, and the</span>
<span class="sd">        rest of this method will not run.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_if_fitted</span><span class="p">()</span>
        <span class="n">mean_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_module</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">covar_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">covar_module</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">MultivariateNormal</span><span class="p">(</span><span class="n">mean_x</span><span class="p">,</span> <span class="n">covar_x</span><span class="p">)</span></div>


    <span class="c1"># pyre-ignore[14]: Inconsistent override</span>
<div class="viewcode-block" id="FullyBayesianSingleTaskGP.posterior">
<a class="viewcode-back" href="../../../models.html#botorch.models.fully_bayesian.FullyBayesianSingleTaskGP.posterior">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">posterior</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">output_indices</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">observation_noise</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">PosteriorTransform</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">GaussianMixturePosterior</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the posterior over model outputs at the provided points.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: A `(batch_shape) x q x d`-dim Tensor, where `d` is the dimension</span>
<span class="sd">                of the feature space and `q` is the number of points considered</span>
<span class="sd">                jointly.</span>
<span class="sd">            output_indices: A list of indices, corresponding to the outputs over</span>
<span class="sd">                which to compute the posterior (if the model is multi-output).</span>
<span class="sd">                Can be used to speed up computation if only a subset of the</span>
<span class="sd">                model&#39;s outputs are required for optimization. If omitted,</span>
<span class="sd">                computes the posterior over all model outputs.</span>
<span class="sd">            observation_noise: If True, add the observation noise from the</span>
<span class="sd">                likelihood to the posterior. If a Tensor, use it directly as the</span>
<span class="sd">                observation noise (must be of shape `(batch_shape) x q x m`).</span>
<span class="sd">            posterior_transform: An optional PosteriorTransform.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `GaussianMixturePosterior` object. Includes observation noise</span>
<span class="sd">                if specified.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_if_fitted</span><span class="p">()</span>
        <span class="n">posterior</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">posterior</span><span class="p">(</span>
            <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">MCMC_DIM</span><span class="p">),</span>
            <span class="n">output_indices</span><span class="o">=</span><span class="n">output_indices</span><span class="p">,</span>
            <span class="n">observation_noise</span><span class="o">=</span><span class="n">observation_noise</span><span class="p">,</span>
            <span class="n">posterior_transform</span><span class="o">=</span><span class="n">posterior_transform</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">posterior</span> <span class="o">=</span> <span class="n">GaussianMixturePosterior</span><span class="p">(</span><span class="n">distribution</span><span class="o">=</span><span class="n">posterior</span><span class="o">.</span><span class="n">distribution</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">posterior</span></div>


<div class="viewcode-block" id="FullyBayesianSingleTaskGP.condition_on_observations">
<a class="viewcode-back" href="../../../models.html#botorch.models.fully_bayesian.FullyBayesianSingleTaskGP.condition_on_observations">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">condition_on_observations</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">BatchedMultiOutputGPyTorchModel</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Conditions on additional observations for a Fully Bayesian model (either</span>
<span class="sd">        identical across models or unique per-model).</span>

<span class="sd">        Args:</span>
<span class="sd">            X: A `batch_shape x num_samples x d`-dim Tensor, where `d` is</span>
<span class="sd">                the dimension of the feature space and `batch_shape` is the number of</span>
<span class="sd">                sampled models.</span>
<span class="sd">            Y: A `batch_shape x num_samples x 1`-dim Tensor, where `d` is</span>
<span class="sd">                the dimension of the feature space and `batch_shape` is the number of</span>
<span class="sd">                sampled models.</span>

<span class="sd">        Returns:</span>
<span class="sd">            BatchedMultiOutputGPyTorchModel: A fully bayesian model conditioned on</span>
<span class="sd">              given observations. The returned model has `batch_shape` copies of the</span>
<span class="sd">              training data in case of identical observations (and `batch_shape`</span>
<span class="sd">              training datasets otherwise).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">Y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="c1"># To avoid an error in GPyTorch when inferring the batch dimension, we add</span>
            <span class="c1"># the explicit batch shape here. The result is that the conditioned model</span>
            <span class="c1"># will have &#39;batch_shape&#39; copies of the training data.</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_shape</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
            <span class="n">Y</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_shape</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

        <span class="k">elif</span> <span class="n">X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&lt;</span> <span class="n">Y</span><span class="o">.</span><span class="n">ndim</span><span class="p">:</span>
            <span class="c1"># We need to duplicate the training data to enable correct batch</span>
            <span class="c1"># size inference in gpytorch.</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="o">*</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>

        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">condition_on_observations</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>
</div>



<div class="viewcode-block" id="SaasFullyBayesianSingleTaskGP">
<a class="viewcode-back" href="../../../models.html#botorch.models.fully_bayesian.SaasFullyBayesianSingleTaskGP">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">SaasFullyBayesianSingleTaskGP</span><span class="p">(</span><span class="n">FullyBayesianSingleTaskGP</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;A fully Bayesian single-task GP model with the SAAS prior.</span>

<span class="sd">    This model assumes that the inputs have been normalized to [0, 1]^d and that</span>
<span class="sd">    the output has been standardized to have zero mean and unit variance. You can</span>
<span class="sd">    either normalize and standardize the data before constructing the model or use</span>
<span class="sd">    an `input_transform` and `outcome_transform`. The SAAS model [Eriksson2021saasbo]_</span>
<span class="sd">    with a Matern-5/2 kernel is used by default.</span>

<span class="sd">    You are expected to use `fit_fully_bayesian_model_nuts` to fit this model as it</span>
<span class="sd">    isn&#39;t compatible with `fit_gpytorch_mll`.</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; saas_gp = SaasFullyBayesianSingleTaskGP(train_X, train_Y)</span>
<span class="sd">        &gt;&gt;&gt; fit_fully_bayesian_model_nuts(saas_gp)</span>
<span class="sd">        &gt;&gt;&gt; posterior = saas_gp.posterior(test_X)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">num_mcmc_samples</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Number of MCMC samples in the model.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_if_fitted</span><span class="p">()</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">covar_module</span><span class="o">.</span><span class="n">outputscale</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">median_lengthscale</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Median lengthscales across the MCMC samples.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_if_fitted</span><span class="p">()</span>
        <span class="n">lengthscale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">covar_module</span><span class="o">.</span><span class="n">base_kernel</span><span class="o">.</span><span class="n">lengthscale</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">lengthscale</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<div class="viewcode-block" id="SaasFullyBayesianSingleTaskGP.load_state_dict">
<a class="viewcode-back" href="../../../models.html#botorch.models.fully_bayesian.SaasFullyBayesianSingleTaskGP.load_state_dict">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">load_state_dict</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">strict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Custom logic for loading the state dict.</span>

<span class="sd">        The standard approach of calling `load_state_dict` currently doesn&#39;t play well</span>
<span class="sd">        with the `SaasFullyBayesianSingleTaskGP` since the `mean_module`, `covar_module`</span>
<span class="sd">        and `likelihood` aren&#39;t initialized until the model has been fitted. The reason</span>
<span class="sd">        for this is that we don&#39;t know the number of MCMC samples until NUTS is called.</span>
<span class="sd">        Given the state dict, we can initialize a new model with some dummy samples and</span>
<span class="sd">        then load the state dict into this model. This currently only works for a</span>
<span class="sd">        `SaasPyroModel` and supporting more Pyro models likely requires moving the model</span>
<span class="sd">        construction logic into the Pyro model itself.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pyro_model</span><span class="p">,</span> <span class="n">SaasPyroModel</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;load_state_dict only works for SaasPyroModel&quot;</span><span class="p">)</span>
        <span class="n">raw_mean</span> <span class="o">=</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;mean_module.raw_constant&quot;</span><span class="p">]</span>
        <span class="n">num_mcmc_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">raw_mean</span><span class="p">)</span>
        <span class="n">dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pyro_model</span><span class="o">.</span><span class="n">train_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">tkwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;device&quot;</span><span class="p">:</span> <span class="n">raw_mean</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">:</span> <span class="n">raw_mean</span><span class="o">.</span><span class="n">dtype</span><span class="p">}</span>
        <span class="c1"># Load some dummy samples</span>
        <span class="n">mcmc_samples</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;mean&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_mcmc_samples</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">),</span>
            <span class="s2">&quot;lengthscale&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_mcmc_samples</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">),</span>
            <span class="s2">&quot;outputscale&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_mcmc_samples</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">),</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pyro_model</span><span class="o">.</span><span class="n">train_Yvar</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">mcmc_samples</span><span class="p">[</span><span class="s2">&quot;noise&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_mcmc_samples</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">)</span>
        <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mean_module</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">covar_module</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pyro_model</span><span class="o">.</span><span class="n">load_mcmc_samples</span><span class="p">(</span><span class="n">mcmc_samples</span><span class="o">=</span><span class="n">mcmc_samples</span><span class="p">)</span>
        <span class="c1"># Load the actual samples from the state dict</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="o">=</span><span class="n">state_dict</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="n">strict</span><span class="p">)</span></div>
</div>



<div class="viewcode-block" id="FullyBayesianLinearSingleTaskGP">
<a class="viewcode-back" href="../../../models.html#botorch.models.fully_bayesian.FullyBayesianLinearSingleTaskGP">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">FullyBayesianLinearSingleTaskGP</span><span class="p">(</span><span class="n">FullyBayesianSingleTaskGP</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;A fully Bayesian single-task GP model with a linear kernel.</span>

<span class="sd">    This model assumes that the inputs have been normalized to [0, 1]^d and that</span>
<span class="sd">    the output has been standardized to have zero mean and unit variance. You can</span>
<span class="sd">    either normalize and standardize the data before constructing the model or use</span>
<span class="sd">    an `input_transform` and `outcome_transform`.</span>

<span class="sd">    You are expected to use `fit_fully_bayesian_model_nuts` to fit this model as it</span>
<span class="sd">    isn&#39;t compatible with `fit_gpytorch_mll`.</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; gp = FullyBayesianLinearSingleTaskGP(train_X, train_Y)</span>
<span class="sd">        &gt;&gt;&gt; fit_fully_bayesian_model_nuts(gp)</span>
<span class="sd">        &gt;&gt;&gt; posterior = gp.posterior(test_X)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">train_X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">train_Y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">train_Yvar</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">outcome_transform</span><span class="p">:</span> <span class="n">OutcomeTransform</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">input_transform</span><span class="p">:</span> <span class="n">InputTransform</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">use_input_warping</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">indices_to_warp</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Initialize the fully Bayesian single-task GP model.</span>

<span class="sd">        Args:</span>
<span class="sd">            train_X: Training inputs (n x d)</span>
<span class="sd">            train_Y: Training targets (n x 1)</span>
<span class="sd">            train_Yvar: Observed noise variance (n x 1). Inferred if None.</span>
<span class="sd">            outcome_transform: An outcome transform that is applied to the</span>
<span class="sd">                training data during instantiation and to the posterior during</span>
<span class="sd">                inference (that is, the `Posterior` obtained by calling</span>
<span class="sd">                `.posterior` on the model will be on the original scale).</span>
<span class="sd">            input_transform: An input transform that is applied in the model&#39;s</span>
<span class="sd">                forward pass.</span>
<span class="sd">            use_input_warping: A boolean indicating whether to use input warping.</span>
<span class="sd">            indices_to_warp: An optional list of indices to warp. The default</span>
<span class="sd">                is to warp all inputs.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">pyro_model</span> <span class="o">=</span> <span class="n">LinearPyroModel</span><span class="p">(</span>
            <span class="n">use_input_warping</span><span class="o">=</span><span class="n">use_input_warping</span><span class="p">,</span> <span class="n">indices_to_warp</span><span class="o">=</span><span class="n">indices_to_warp</span>
        <span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">train_X</span><span class="o">=</span><span class="n">train_X</span><span class="p">,</span>
            <span class="n">train_Y</span><span class="o">=</span><span class="n">train_Y</span><span class="p">,</span>
            <span class="n">train_Yvar</span><span class="o">=</span><span class="n">train_Yvar</span><span class="p">,</span>
            <span class="n">input_transform</span><span class="o">=</span><span class="n">input_transform</span><span class="p">,</span>
            <span class="n">outcome_transform</span><span class="o">=</span><span class="n">outcome_transform</span><span class="p">,</span>
            <span class="n">pyro_model</span><span class="o">=</span><span class="n">pyro_model</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">num_mcmc_samples</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Number of MCMC samples in the model.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_if_fitted</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">covar_module</span><span class="o">.</span><span class="n">batch_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">median_weight_variance</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Median weight variance across the MCMC samples.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_if_fitted</span><span class="p">()</span>
        <span class="n">weight_variance</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">covar_module</span><span class="o">.</span><span class="n">variance</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">weight_variance</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<div class="viewcode-block" id="FullyBayesianLinearSingleTaskGP.load_mcmc_samples">
<a class="viewcode-back" href="../../../models.html#botorch.models.fully_bayesian.FullyBayesianLinearSingleTaskGP.load_mcmc_samples">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">load_mcmc_samples</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mcmc_samples</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Load the MCMC hyperparameter samples into the model.</span>

<span class="sd">        This method will be called by `fit_fully_bayesian_model_nuts` when the model</span>
<span class="sd">        has been fitted in order to create a batched SingleTaskGP model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mean_module</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">covar_module</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">input_transform</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pyro_model</span><span class="o">.</span><span class="n">load_mcmc_samples</span><span class="p">(</span><span class="n">mcmc_samples</span><span class="o">=</span><span class="n">mcmc_samples</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;input_transform&quot;</span><span class="p">):</span>
            <span class="n">tfs</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">input_transform</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_transform</span><span class="p">,</span> <span class="n">ChainedInputTransform</span><span class="p">):</span>
                <span class="n">tfs</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">input_transform</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">tfs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">input_transform</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">input_transform</span> <span class="o">=</span> <span class="n">ChainedInputTransform</span><span class="p">(</span>
                <span class="o">**</span><span class="p">{</span><span class="sa">f</span><span class="s2">&quot;tf</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="n">tf</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">tf</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tfs</span><span class="p">)}</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">input_transform</span> <span class="o">=</span> <span class="n">input_transform</span></div>


<div class="viewcode-block" id="FullyBayesianLinearSingleTaskGP.load_state_dict">
<a class="viewcode-back" href="../../../models.html#botorch.models.fully_bayesian.FullyBayesianLinearSingleTaskGP.load_state_dict">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">load_state_dict</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">strict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Custom logic for loading the state dict.</span>

<span class="sd">        The standard approach of calling `load_state_dict` currently doesn&#39;t play well</span>
<span class="sd">        with the `FullyBayesianLinearSingleTaskGP` since the `mean_module`,</span>
<span class="sd">        `covar_module` and `likelihood` aren&#39;t initialized until the model has been</span>
<span class="sd">        fitted. The reason for this is that we don&#39;t know the number of MCMC samples</span>
<span class="sd">        until NUTS is called. Given the state dict, we can initialize a new model with</span>
<span class="sd">        some dummy samples andthen load the state dict into this model. This currently</span>
<span class="sd">        only works for a `LinearPyroModel` and supporting more Pyro models likely</span>
<span class="sd">        requires moving the model construction logic into the Pyro model itself.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">weight_variance</span> <span class="o">=</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;covar_module.raw_variance&quot;</span><span class="p">]</span>
        <span class="n">num_mcmc_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">weight_variance</span><span class="p">)</span>
        <span class="n">dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pyro_model</span><span class="o">.</span><span class="n">train_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">tkwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;device&quot;</span><span class="p">:</span> <span class="n">weight_variance</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">:</span> <span class="n">weight_variance</span><span class="o">.</span><span class="n">dtype</span><span class="p">}</span>
        <span class="c1"># Load some dummy samples</span>
        <span class="c1"># deal with c0 c1</span>
        <span class="n">mcmc_samples</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;mean&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_mcmc_samples</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">),</span>
            <span class="s2">&quot;weight_variance&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_mcmc_samples</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">),</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pyro_model</span><span class="o">.</span><span class="n">use_input_warping</span><span class="p">:</span>
            <span class="n">mcmc_samples</span><span class="p">[</span><span class="s2">&quot;c0&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_mcmc_samples</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">)</span>
            <span class="n">mcmc_samples</span><span class="p">[</span><span class="s2">&quot;c1&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_mcmc_samples</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pyro_model</span><span class="o">.</span><span class="n">train_Yvar</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">mcmc_samples</span><span class="p">[</span><span class="s2">&quot;noise&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_mcmc_samples</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">load_mcmc_samples</span><span class="p">(</span><span class="n">mcmc_samples</span><span class="o">=</span><span class="n">mcmc_samples</span><span class="p">)</span>
        <span class="c1"># Load the actual samples from the state dict</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="o">=</span><span class="n">state_dict</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="n">strict</span><span class="p">)</span></div>


<div class="viewcode-block" id="FullyBayesianLinearSingleTaskGP.construct_inputs">
<a class="viewcode-back" href="../../../models.html#botorch.models.fully_bayesian.FullyBayesianLinearSingleTaskGP.construct_inputs">[docs]</a>
    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">construct_inputs</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">training_data</span><span class="p">:</span> <span class="n">SupervisedDataset</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">use_input_warping</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">indices_to_warp</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">BotorchContainer</span> <span class="o">|</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Construct `SingleTaskGP` keyword arguments from a `SupervisedDataset`.</span>

<span class="sd">        Args:</span>
<span class="sd">            training_data: A `SupervisedDataset`, with attributes `train_X`,</span>
<span class="sd">                `train_Y`, and, optionally, `train_Yvar`.</span>
<span class="sd">            use_input_warping: A boolean indicating whether to use input warping.</span>
<span class="sd">            indices_to_warp: An optional list of indices to warp. The default</span>
<span class="sd">                is to warp all inputs.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A dict of keyword arguments that can be used to initialize a</span>
<span class="sd">            `FullyBayesianLinearSingleTaskGP`, with keys `train_X`, `train_Y`,</span>
<span class="sd">            `use_input_warping`, `indices_to_warp`, and, optionally, `train_Yvar`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="o">**</span><span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">construct_inputs</span><span class="p">(</span><span class="n">training_data</span><span class="o">=</span><span class="n">training_data</span><span class="p">),</span>
            <span class="s2">&quot;use_input_warping&quot;</span><span class="p">:</span> <span class="n">use_input_warping</span><span class="p">,</span>
            <span class="s2">&quot;indices_to_warp&quot;</span><span class="p">:</span> <span class="n">indices_to_warp</span><span class="p">,</span>
        <span class="p">}</span></div>
</div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p></p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>