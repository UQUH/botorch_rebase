

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>botorch.models.gp_regression &mdash; BoTorch  documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=03e43079" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../../_static/custom.css?v=ca3e82f4" />

  
      <script src="../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../_static/documentation_options.js?v=5929fcd5"></script>
      <script src="../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            BoTorch
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../acquisition.html">botorch.acquisition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models.html">botorch.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generation.html">botorch.generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../posteriors.html">botorch.posteriors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../optim.html">botorch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../fit.html">botorch.fit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../sampling.html">botorch.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cross_validation.html">botorch.cross_validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../settings.html">botorch.settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../logging.html">botorch.logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../test_functions.html">botorch.test_functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../test_utils.html">botorch.test_utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../exceptions.html">botorch.exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../utils.html">botorch.utils</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">BoTorch</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">botorch.models.gp_regression</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for botorch.models.gp_regression</h1><div class="highlight"><pre>
<span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="c1"># Copyright (c) Meta Platforms, Inc. and affiliates.</span>
<span class="c1">#</span>
<span class="c1"># This source code is licensed under the MIT license found in the</span>
<span class="c1"># LICENSE file in the root directory of this source tree.</span>

<span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Gaussian Process Regression models based on GPyTorch models.</span>

<span class="sd">These models are often a good starting point and are further documented in the</span>
<span class="sd">tutorials.</span>

<span class="sd">`SingleTaskGP` is a single-task exact GP model that uses relatively strong priors on</span>
<span class="sd">the Kernel hyperparameters, which work best when covariates are normalized to the unit</span>
<span class="sd">cube and outcomes are standardized (zero mean, unit variance). By default, this model</span>
<span class="sd">uses a `Standardize` outcome transform, which applies this standardization. However,</span>
<span class="sd">it does not (yet) use an input transform by default.</span>

<span class="sd">`SingleTaskGP` model works in batch mode (each batch having its own hyperparameters).</span>
<span class="sd">When the training observations include multiple outputs, `SingleTaskGP` uses</span>
<span class="sd">batching to model outputs independently.</span>

<span class="sd">`SingleTaskGP` supports multiple outputs. However, as a single-task model,</span>
<span class="sd">`SingleTaskGP` should be used only when the outputs are independent and all</span>
<span class="sd">use the same training inputs. If outputs are independent but they have different</span>
<span class="sd">training inputs, use the `ModelListGP`. When modeling correlations between outputs,</span>
<span class="sd">use a multi-task model like `MultiTaskGP`.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">__future__</span><span class="w"> </span><span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.models.gpytorch</span><span class="w"> </span><span class="kn">import</span> <span class="n">BatchedMultiOutputGPyTorchModel</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.models.model</span><span class="w"> </span><span class="kn">import</span> <span class="n">FantasizeMixin</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.models.transforms.input</span><span class="w"> </span><span class="kn">import</span> <span class="n">InputTransform</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.models.transforms.outcome</span><span class="w"> </span><span class="kn">import</span> <span class="n">OutcomeTransform</span><span class="p">,</span> <span class="n">Standardize</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.models.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">validate_input_scaling</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.models.utils.gpytorch_modules</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">get_covar_module_with_dim_scaled_prior</span><span class="p">,</span>
    <span class="n">get_gaussian_likelihood_with_lognormal_prior</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.utils.containers</span><span class="w"> </span><span class="kn">import</span> <span class="n">BotorchContainer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.utils.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">SupervisedDataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.utils.types</span><span class="w"> </span><span class="kn">import</span> <span class="n">_DefaultType</span><span class="p">,</span> <span class="n">DEFAULT</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.distributions.multivariate_normal</span><span class="w"> </span><span class="kn">import</span> <span class="n">MultivariateNormal</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.likelihoods.gaussian_likelihood</span><span class="w"> </span><span class="kn">import</span> <span class="n">FixedNoiseGaussianLikelihood</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.likelihoods.likelihood</span><span class="w"> </span><span class="kn">import</span> <span class="n">Likelihood</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.means.constant_mean</span><span class="w"> </span><span class="kn">import</span> <span class="n">ConstantMean</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.means.mean</span><span class="w"> </span><span class="kn">import</span> <span class="n">Mean</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.models.exact_gp</span><span class="w"> </span><span class="kn">import</span> <span class="n">ExactGP</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.module</span><span class="w"> </span><span class="kn">import</span> <span class="n">Module</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">Tensor</span>


<div class="viewcode-block" id="SingleTaskGP">
<a class="viewcode-back" href="../../../models.html#botorch.models.gp_regression.SingleTaskGP">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">SingleTaskGP</span><span class="p">(</span><span class="n">BatchedMultiOutputGPyTorchModel</span><span class="p">,</span> <span class="n">ExactGP</span><span class="p">,</span> <span class="n">FantasizeMixin</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;A single-task exact GP model, supporting both known and inferred noise levels.</span>

<span class="sd">    A single-task exact GP which, by default, utilizes hyperparameter priors</span>
<span class="sd">    from [Hvarfner2024vanilla]_. These priors designed to perform well independently of</span>
<span class="sd">    the dimensionality of the problem. Moreover, they suggest a moderately low level of</span>
<span class="sd">    noise. Importantly, The model works best when covariates are normalized to the unit</span>
<span class="sd">    cube and outcomes are standardized (zero mean, unit variance). For a detailed</span>
<span class="sd">    discussion on the hyperparameter priors, see</span>
<span class="sd">    https://github.com/pytorch/botorch/discussions/2451.</span>

<span class="sd">    This model works in batch mode (each batch having its own hyperparameters).</span>
<span class="sd">    When the training observations include multiple outputs, this model will use</span>
<span class="sd">    batching to model outputs independently.</span>

<span class="sd">    Use this model when you have independent output(s) and all outputs use the</span>
<span class="sd">    same training data. If outputs are independent and outputs have different</span>
<span class="sd">    training data, use the ModelListGP. When modeling correlations between</span>
<span class="sd">    outputs, use the MultiTaskGP.</span>

<span class="sd">    An example of a case in which noise levels are known is online</span>
<span class="sd">    experimentation, where noise can be measured using the variability of</span>
<span class="sd">    different observations from the same arm, or provided by outside software.</span>
<span class="sd">    Another use case is simulation optimization, where the evaluation can</span>
<span class="sd">    provide variance estimates, perhaps from bootstrapping. In any case, these</span>
<span class="sd">    noise levels can be provided to `SingleTaskGP` as `train_Yvar`.</span>

<span class="sd">    `SingleTaskGP` can also be used when the observations are known to be</span>
<span class="sd">    noise-free. Noise-free observations can be modeled using arbitrarily small</span>
<span class="sd">    noise values, such as `train_Yvar=torch.full_like(train_Y, 1e-6)`.</span>

<span class="sd">    Example:</span>
<span class="sd">        Model with inferred noise levels:</span>

<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; from botorch.models.gp_regression import SingleTaskGP</span>
<span class="sd">        &gt;&gt;&gt; from botorch.models.transforms.outcome import Standardize</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; train_X = torch.rand(20, 2, dtype=torch.float64)</span>
<span class="sd">        &gt;&gt;&gt; train_Y = torch.sin(train_X).sum(dim=1, keepdim=True)</span>
<span class="sd">        &gt;&gt;&gt; outcome_transform = Standardize(m=1)</span>
<span class="sd">        &gt;&gt;&gt; inferred_noise_model = SingleTaskGP(</span>
<span class="sd">        ...     train_X, train_Y, outcome_transform=outcome_transform,</span>
<span class="sd">        ... )</span>

<span class="sd">        Model with a known observation variance of 0.2:</span>

<span class="sd">        &gt;&gt;&gt; train_Yvar = torch.full_like(train_Y, 0.2)</span>
<span class="sd">        &gt;&gt;&gt; observed_noise_model = SingleTaskGP(</span>
<span class="sd">        ...     train_X, train_Y, train_Yvar,</span>
<span class="sd">        ...     outcome_transform=outcome_transform,</span>
<span class="sd">        ... )</span>

<span class="sd">        With noise-free observations:</span>

<span class="sd">        &gt;&gt;&gt; train_Yvar = torch.full_like(train_Y, 1e-6)</span>
<span class="sd">        &gt;&gt;&gt; noise_free_model = SingleTaskGP(</span>
<span class="sd">        ...     train_X, train_Y, train_Yvar,</span>
<span class="sd">        ...     outcome_transform=outcome_transform,</span>
<span class="sd">        ... )</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">train_X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">train_Y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">train_Yvar</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">likelihood</span><span class="p">:</span> <span class="n">Likelihood</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">covar_module</span><span class="p">:</span> <span class="n">Module</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">mean_module</span><span class="p">:</span> <span class="n">Mean</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">outcome_transform</span><span class="p">:</span> <span class="n">OutcomeTransform</span> <span class="o">|</span> <span class="n">_DefaultType</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="n">DEFAULT</span><span class="p">,</span>
        <span class="n">input_transform</span><span class="p">:</span> <span class="n">InputTransform</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            train_X: A `batch_shape x n x d` tensor of training features.</span>
<span class="sd">            train_Y: A `batch_shape x n x m` tensor of training observations.</span>
<span class="sd">            train_Yvar: An optional `batch_shape x n x m` tensor of observed</span>
<span class="sd">                measurement noise.</span>
<span class="sd">            likelihood: A likelihood. If omitted, use a standard</span>
<span class="sd">                `GaussianLikelihood` with inferred noise level if `train_Yvar`</span>
<span class="sd">                is None, and a `FixedNoiseGaussianLikelihood` with the given</span>
<span class="sd">                noise observations if `train_Yvar` is not None.</span>
<span class="sd">            covar_module: The module computing the covariance (Kernel) matrix.</span>
<span class="sd">                If omitted, uses an `RBFKernel`.</span>
<span class="sd">            mean_module: The mean function to be used. If omitted, use a</span>
<span class="sd">                `ConstantMean`.</span>
<span class="sd">            outcome_transform: An outcome transform that is applied to the</span>
<span class="sd">                training data during instantiation and to the posterior during</span>
<span class="sd">                inference (that is, the `Posterior` obtained by calling</span>
<span class="sd">                `.posterior` on the model will be on the original scale). We use a</span>
<span class="sd">                `Standardize` transform if no `outcome_transform` is specified.</span>
<span class="sd">                Pass down `None` to use no outcome transform.</span>
<span class="sd">            input_transform: An input transform that is applied in the model&#39;s</span>
<span class="sd">                forward pass.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_tensor_args</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">train_X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="n">train_Y</span><span class="p">,</span> <span class="n">Yvar</span><span class="o">=</span><span class="n">train_Yvar</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">outcome_transform</span> <span class="o">==</span> <span class="n">DEFAULT</span><span class="p">:</span>
            <span class="n">outcome_transform</span> <span class="o">=</span> <span class="n">Standardize</span><span class="p">(</span>
                <span class="n">m</span><span class="o">=</span><span class="n">train_Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">batch_shape</span><span class="o">=</span><span class="n">train_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">transformed_X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_inputs</span><span class="p">(</span>
                <span class="n">X</span><span class="o">=</span><span class="n">train_X</span><span class="p">,</span> <span class="n">input_transform</span><span class="o">=</span><span class="n">input_transform</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">outcome_transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">train_Y</span><span class="p">,</span> <span class="n">train_Yvar</span> <span class="o">=</span> <span class="n">outcome_transform</span><span class="p">(</span>
                <span class="n">Y</span><span class="o">=</span><span class="n">train_Y</span><span class="p">,</span> <span class="n">Yvar</span><span class="o">=</span><span class="n">train_Yvar</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">transformed_X</span>
            <span class="p">)</span>
        <span class="c1"># Validate again after applying the transforms</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_tensor_args</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">transformed_X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="n">train_Y</span><span class="p">,</span> <span class="n">Yvar</span><span class="o">=</span><span class="n">train_Yvar</span><span class="p">)</span>
        <span class="n">ignore_X_dims</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_ignore_X_dims_scaling_check&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">validate_input_scaling</span><span class="p">(</span>
            <span class="n">train_X</span><span class="o">=</span><span class="n">transformed_X</span><span class="p">,</span>
            <span class="n">train_Y</span><span class="o">=</span><span class="n">train_Y</span><span class="p">,</span>
            <span class="n">train_Yvar</span><span class="o">=</span><span class="n">train_Yvar</span><span class="p">,</span>
            <span class="n">ignore_X_dims</span><span class="o">=</span><span class="n">ignore_X_dims</span><span class="p">,</span>
            <span class="n">check_nans_only</span><span class="o">=</span><span class="n">covar_module</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set_dimensions</span><span class="p">(</span><span class="n">train_X</span><span class="o">=</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="o">=</span><span class="n">train_Y</span><span class="p">)</span>
        <span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">,</span> <span class="n">train_Yvar</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform_tensor_args</span><span class="p">(</span>
            <span class="n">X</span><span class="o">=</span><span class="n">train_X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="n">train_Y</span><span class="p">,</span> <span class="n">Yvar</span><span class="o">=</span><span class="n">train_Yvar</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">likelihood</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">train_Yvar</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">likelihood</span> <span class="o">=</span> <span class="n">get_gaussian_likelihood_with_lognormal_prior</span><span class="p">(</span>
                    <span class="n">batch_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_aug_batch_shape</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">likelihood</span> <span class="o">=</span> <span class="n">FixedNoiseGaussianLikelihood</span><span class="p">(</span>
                    <span class="n">noise</span><span class="o">=</span><span class="n">train_Yvar</span><span class="p">,</span> <span class="n">batch_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_aug_batch_shape</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># This is used to check if the `model_list_to_batched` can be used</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_is_custom_likelihood</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">ExactGP</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="n">train_inputs</span><span class="o">=</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_targets</span><span class="o">=</span><span class="n">train_Y</span><span class="p">,</span> <span class="n">likelihood</span><span class="o">=</span><span class="n">likelihood</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">mean_module</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">mean_module</span> <span class="o">=</span> <span class="n">ConstantMean</span><span class="p">(</span><span class="n">batch_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_aug_batch_shape</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean_module</span> <span class="o">=</span> <span class="n">mean_module</span>
        <span class="k">if</span> <span class="n">covar_module</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">covar_module</span> <span class="o">=</span> <span class="n">get_covar_module_with_dim_scaled_prior</span><span class="p">(</span>
                <span class="n">ard_num_dims</span><span class="o">=</span><span class="n">transformed_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                <span class="n">batch_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_aug_batch_shape</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="c1"># Used for subsetting along the output dimension. See Model.subset_output.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_subset_batch_dict</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;mean_module.raw_constant&quot;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                <span class="s2">&quot;covar_module.raw_lengthscale&quot;</span><span class="p">:</span> <span class="o">-</span><span class="mi">3</span><span class="p">,</span>
            <span class="p">}</span>
            <span class="k">if</span> <span class="n">train_Yvar</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_subset_batch_dict</span><span class="p">[</span><span class="s2">&quot;likelihood.noise_covar.raw_noise&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">covar_module</span><span class="p">:</span> <span class="n">Module</span> <span class="o">=</span> <span class="n">covar_module</span>
        <span class="c1"># TODO: Allow subsetting of other covar modules</span>
        <span class="k">if</span> <span class="n">outcome_transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">outcome_transform</span> <span class="o">=</span> <span class="n">outcome_transform</span>
        <span class="k">if</span> <span class="n">input_transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">input_transform</span> <span class="o">=</span> <span class="n">input_transform</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">train_X</span><span class="p">)</span>

<div class="viewcode-block" id="SingleTaskGP.construct_inputs">
<a class="viewcode-back" href="../../../models.html#botorch.models.gp_regression.SingleTaskGP.construct_inputs">[docs]</a>
    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">construct_inputs</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span> <span class="n">training_data</span><span class="p">:</span> <span class="n">SupervisedDataset</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">task_feature</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">BotorchContainer</span> <span class="o">|</span> <span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Construct `SingleTaskGP` keyword arguments from a `SupervisedDataset`.</span>

<span class="sd">        Args:</span>
<span class="sd">            training_data: A `SupervisedDataset`, with attributes `train_X`,</span>
<span class="sd">                `train_Y`, and, optionally, `train_Yvar`.</span>
<span class="sd">            task_feature: Deprecated and allowed only for backward</span>
<span class="sd">                compatibility; ignored.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A dict of keyword arguments that can be used to initialize a `SingleTaskGP`,</span>
<span class="sd">            with keys `train_X`, `train_Y`, and, optionally, `train_Yvar`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">task_feature</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;`task_feature` is deprecated and will be ignored. In the &quot;</span>
                <span class="s2">&quot;future, this will be an error.&quot;</span><span class="p">,</span>
                <span class="ne">DeprecationWarning</span><span class="p">,</span>
                <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">construct_inputs</span><span class="p">(</span><span class="n">training_data</span><span class="o">=</span><span class="n">training_data</span><span class="p">)</span></div>


<div class="viewcode-block" id="SingleTaskGP.forward">
<a class="viewcode-back" href="../../../models.html#botorch.models.gp_regression.SingleTaskGP.forward">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MultivariateNormal</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_inputs</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">mean_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_module</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">covar_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">covar_module</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">MultivariateNormal</span><span class="p">(</span><span class="n">mean_x</span><span class="p">,</span> <span class="n">covar_x</span><span class="p">)</span></div>
</div>



<span class="c1"># Note: There used to be `HeteroskedasticSingleTaskGP` here,</span>
<span class="c1"># but due to persistent bugs, it was removed in #2616.</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p></p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>