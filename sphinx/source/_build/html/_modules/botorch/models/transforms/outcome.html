

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>botorch.models.transforms.outcome &mdash; BoTorch  documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=03e43079" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/custom.css?v=ca3e82f4" />

  
      <script src="../../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../../_static/documentation_options.js?v=5929fcd5"></script>
      <script src="../../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../index.html" class="icon icon-home">
            BoTorch
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../acquisition.html">botorch.acquisition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../models.html">botorch.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../generation.html">botorch.generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../posteriors.html">botorch.posteriors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../optim.html">botorch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../fit.html">botorch.fit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../sampling.html">botorch.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../cross_validation.html">botorch.cross_validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../settings.html">botorch.settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../logging.html">botorch.logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../test_functions.html">botorch.test_functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../test_utils.html">botorch.test_utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../exceptions.html">botorch.exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../utils.html">botorch.utils</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">BoTorch</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">botorch.models.transforms.outcome</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for botorch.models.transforms.outcome</h1><div class="highlight"><pre>
<span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="c1"># Copyright (c) Meta Platforms, Inc. and affiliates.</span>
<span class="c1">#</span>
<span class="c1"># This source code is licensed under the MIT license found in the</span>
<span class="c1"># LICENSE file in the root directory of this source tree.</span>

<span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Outcome transformations for automatically transforming and un-transforming</span>
<span class="sd">model outputs. Outcome transformations are typically part of a Model and</span>
<span class="sd">applied (i) within the model constructor to transform the train observations</span>
<span class="sd">to the model space, and (ii) in the `Model.posterior` call to untransform</span>
<span class="sd">the model posterior back to the original space.</span>

<span class="sd">References</span>

<span class="sd">.. [eriksson2021scalable]</span>
<span class="sd">    D. Eriksson, M. Poloczek. Scalable Constrained Bayesian Optimization.</span>
<span class="sd">    International Conference on Artificial Intelligence and Statistics. PMLR, 2021,</span>
<span class="sd">    http://proceedings.mlr.press/v130/eriksson21a.html</span>

<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">__future__</span><span class="w"> </span><span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">ABC</span><span class="p">,</span> <span class="n">abstractmethod</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">OrderedDict</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.models.transforms.utils</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">nanstd</span><span class="p">,</span>
    <span class="n">norm_to_lognorm_mean</span><span class="p">,</span>
    <span class="n">norm_to_lognorm_variance</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.models.utils.assorted</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_task_value_remapping</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.posteriors</span><span class="w"> </span><span class="kn">import</span> <span class="n">GPyTorchPosterior</span><span class="p">,</span> <span class="n">Posterior</span><span class="p">,</span> <span class="n">TransformedPosterior</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.utils.transforms</span><span class="w"> </span><span class="kn">import</span> <span class="n">normalize_indices</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">linear_operator.operators</span><span class="w"> </span><span class="kn">import</span> <span class="n">CholLinearOperator</span><span class="p">,</span> <span class="n">DiagLinearOperator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">Module</span><span class="p">,</span> <span class="n">ModuleDict</span>


<div class="viewcode-block" id="OutcomeTransform">
<a class="viewcode-back" href="../../../../models.html#botorch.models.transforms.outcome.OutcomeTransform">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">OutcomeTransform</span><span class="p">(</span><span class="n">Module</span><span class="p">,</span> <span class="n">ABC</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Abstract base class for outcome transforms.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="OutcomeTransform.forward">
<a class="viewcode-back" href="../../../../models.html#botorch.models.transforms.outcome.OutcomeTransform.forward">[docs]</a>
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Yvar</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Transform the outcomes in a model&#39;s training targets</span>

<span class="sd">        Args:</span>
<span class="sd">            Y: A `batch_shape x n x m`-dim tensor of training targets.</span>
<span class="sd">            Yvar: A `batch_shape x n x m`-dim tensor of observation noises</span>
<span class="sd">                associated with the training targets (if applicable).</span>
<span class="sd">            X: A `batch_shape x n x d`-dim tensor of training inputs (if applicable).</span>

<span class="sd">        Returns:</span>
<span class="sd">            A two-tuple with the transformed outcomes:</span>

<span class="sd">            - The transformed outcome observations.</span>
<span class="sd">            - The transformed observation noise (if applicable).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span>  <span class="c1"># pragma: no cover</span></div>


<div class="viewcode-block" id="OutcomeTransform.subset_output">
<a class="viewcode-back" href="../../../../models.html#botorch.models.transforms.outcome.OutcomeTransform.subset_output">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">subset_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idcs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">OutcomeTransform</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Subset the transform along the output dimension.</span>

<span class="sd">        This functionality is used to properly treat outcome transformations</span>
<span class="sd">        in the `subset_model` functionality.</span>

<span class="sd">        Args:</span>
<span class="sd">            idcs: The output indices to subset the transform to.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The current outcome transform, subset to the specified output indices.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> does not implement the &quot;</span>
            <span class="s2">&quot;`subset_output` method&quot;</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="OutcomeTransform.untransform">
<a class="viewcode-back" href="../../../../models.html#botorch.models.transforms.outcome.OutcomeTransform.untransform">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">untransform</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Yvar</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Un-transform previously transformed outcomes</span>

<span class="sd">        Args:</span>
<span class="sd">            Y: A `batch_shape x n x m`-dim tensor of transfomred training targets.</span>
<span class="sd">            Yvar: A `batch_shape x n x m`-dim tensor of transformed observation</span>
<span class="sd">                noises associated with the training targets (if applicable).</span>
<span class="sd">            X: A `batch_shape x n x d`-dim tensor of training inputs (if applicable).</span>

<span class="sd">        Returns:</span>
<span class="sd">            A two-tuple with the un-transformed outcomes:</span>

<span class="sd">            - The un-transformed outcome observations.</span>
<span class="sd">            - The un-transformed observation noise (if applicable).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> does not implement the `untransform` method&quot;</span>
        <span class="p">)</span></div>


    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_is_linear</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        True for transformations such as `Standardize`; these should be able to apply</span>
<span class="sd">        `untransform_posterior` to a GPyTorchPosterior and return a GPyTorchPosterior,</span>
<span class="sd">        because a multivariate normal distribution should remain multivariate normal</span>
<span class="sd">        after applying the transform.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="kc">False</span>

<div class="viewcode-block" id="OutcomeTransform.untransform_posterior">
<a class="viewcode-back" href="../../../../models.html#botorch.models.transforms.outcome.OutcomeTransform.untransform_posterior">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">untransform_posterior</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">posterior</span><span class="p">:</span> <span class="n">Posterior</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Posterior</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Un-transform a posterior.</span>

<span class="sd">        Posteriors with `_is_linear=True` should return a `GPyTorchPosterior` when</span>
<span class="sd">        `posterior` is a `GPyTorchPosterior`. Posteriors with `_is_linear=False`</span>
<span class="sd">        likely return a `TransformedPosterior` instead.</span>

<span class="sd">        Args:</span>
<span class="sd">            posterior: A posterior in the transformed space.</span>
<span class="sd">            X: A `batch_shape x n x d`-dim tensor of training inputs (if applicable).</span>

<span class="sd">        Returns:</span>
<span class="sd">            The un-transformed posterior.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> does not implement the &quot;</span>
            <span class="s2">&quot;`untransform_posterior` method&quot;</span>
        <span class="p">)</span></div>
</div>



<div class="viewcode-block" id="ChainedOutcomeTransform">
<a class="viewcode-back" href="../../../../models.html#botorch.models.transforms.outcome.ChainedOutcomeTransform">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">ChainedOutcomeTransform</span><span class="p">(</span><span class="n">OutcomeTransform</span><span class="p">,</span> <span class="n">ModuleDict</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;An outcome transform representing the chaining of individual transforms&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">transforms</span><span class="p">:</span> <span class="n">OutcomeTransform</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Chaining of outcome transforms.</span>

<span class="sd">        Args:</span>
<span class="sd">            transforms: The transforms to chain. Internally, the names of the</span>
<span class="sd">                kwargs are used as the keys for accessing the individual</span>
<span class="sd">                transforms on the module.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">OrderedDict</span><span class="p">(</span><span class="n">transforms</span><span class="p">))</span>

<div class="viewcode-block" id="ChainedOutcomeTransform.forward">
<a class="viewcode-back" href="../../../../models.html#botorch.models.transforms.outcome.ChainedOutcomeTransform.forward">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Yvar</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Transform the outcomes in a model&#39;s training targets</span>

<span class="sd">        Args:</span>
<span class="sd">            Y: A `batch_shape x n x m`-dim tensor of training targets.</span>
<span class="sd">            Yvar: A `batch_shape x n x m`-dim tensor of observation noises</span>
<span class="sd">                associated with the training targets (if applicable).</span>
<span class="sd">            X: A `batch_shape x n x d`-dim tensor of training inputs (if applicable).</span>

<span class="sd">        Returns:</span>
<span class="sd">            A two-tuple with the transformed outcomes:</span>

<span class="sd">            - The transformed outcome observations.</span>
<span class="sd">            - The transformed observation noise (if applicable).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">tf</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="n">Y</span><span class="p">,</span> <span class="n">Yvar</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">Y</span><span class="o">=</span><span class="n">Y</span><span class="p">,</span> <span class="n">Yvar</span><span class="o">=</span><span class="n">Yvar</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Yvar</span></div>


<div class="viewcode-block" id="ChainedOutcomeTransform.subset_output">
<a class="viewcode-back" href="../../../../models.html#botorch.models.transforms.outcome.ChainedOutcomeTransform.subset_output">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">subset_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idcs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">OutcomeTransform</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Subset the transform along the output dimension.</span>

<span class="sd">        Args:</span>
<span class="sd">            idcs: The output indices to subset the transform to.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The current outcome transform, subset to the specified output indices.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="p">(</span>
            <span class="o">**</span><span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">subset_output</span><span class="p">(</span><span class="n">idcs</span><span class="o">=</span><span class="n">idcs</span><span class="p">)</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">tf</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="ChainedOutcomeTransform.untransform">
<a class="viewcode-back" href="../../../../models.html#botorch.models.transforms.outcome.ChainedOutcomeTransform.untransform">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">untransform</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Yvar</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Un-transform previously transformed outcomes</span>

<span class="sd">        Args:</span>
<span class="sd">            Y: A `batch_shape x n x m`-dim tensor of transfomred training targets.</span>
<span class="sd">            Yvar: A `batch_shape x n x m`-dim tensor of transformed observation</span>
<span class="sd">                noises associated with the training targets (if applicable).</span>
<span class="sd">            X: A `batch_shape x n x d`-dim tensor of training inputs (if applicable).</span>

<span class="sd">        Returns:</span>
<span class="sd">            A two-tuple with the un-transformed outcomes:</span>

<span class="sd">            - The un-transformed outcome observations.</span>
<span class="sd">            - The un-transformed observation noise (if applicable).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">tf</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">values</span><span class="p">()):</span>
            <span class="n">Y</span><span class="p">,</span> <span class="n">Yvar</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">untransform</span><span class="p">(</span><span class="n">Y</span><span class="o">=</span><span class="n">Y</span><span class="p">,</span> <span class="n">Yvar</span><span class="o">=</span><span class="n">Yvar</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Yvar</span></div>


    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_is_linear</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A `ChainedOutcomeTransform` is linear only if all of the component transforms</span>
<span class="sd">        are linear.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">all</span><span class="p">(</span><span class="n">octf</span><span class="o">.</span><span class="n">_is_linear</span> <span class="k">for</span> <span class="n">octf</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

<div class="viewcode-block" id="ChainedOutcomeTransform.untransform_posterior">
<a class="viewcode-back" href="../../../../models.html#botorch.models.transforms.outcome.ChainedOutcomeTransform.untransform_posterior">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">untransform_posterior</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">posterior</span><span class="p">:</span> <span class="n">Posterior</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Posterior</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Un-transform a posterior</span>

<span class="sd">        Args:</span>
<span class="sd">            posterior: A posterior in the transformed space.</span>
<span class="sd">            X: A `batch_shape x n x d`-dim tensor of training inputs (if applicable).</span>

<span class="sd">        Returns:</span>
<span class="sd">            The un-transformed posterior.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">tf</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">values</span><span class="p">()):</span>
            <span class="n">posterior</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">untransform_posterior</span><span class="p">(</span><span class="n">posterior</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">posterior</span></div>
</div>



<div class="viewcode-block" id="Standardize">
<a class="viewcode-back" href="../../../../models.html#botorch.models.transforms.outcome.Standardize">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">Standardize</span><span class="p">(</span><span class="n">OutcomeTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Standardize outcomes (zero mean, unit variance).</span>

<span class="sd">    This module is stateful: If in train mode, calling forward updates the</span>
<span class="sd">    module state (i.e. the mean/std normalizing constants). If in eval mode,</span>
<span class="sd">    calling forward simply applies the standardization using the current module</span>
<span class="sd">    state.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">m</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">batch_shape</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(),</span>  <span class="c1"># noqa: B008</span>
        <span class="n">min_stdv</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-8</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Standardize outcomes (zero mean, unit variance).</span>

<span class="sd">        Args:</span>
<span class="sd">            m: The output dimension.</span>
<span class="sd">            outputs: Which of the outputs to standardize. If omitted, all</span>
<span class="sd">                outputs will be standardized.</span>
<span class="sd">            batch_shape: The batch_shape of the training targets.</span>
<span class="sd">            min_stddv: The minimum standard deviation for which to perform</span>
<span class="sd">                standardization (if lower, only de-mean the data).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;means&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="o">*</span><span class="n">batch_shape</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">m</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;stdvs&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="o">*</span><span class="n">batch_shape</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">m</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;_stdvs_sq&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="o">*</span><span class="n">batch_shape</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">m</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;_is_trained&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="kc">False</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_outputs</span> <span class="o">=</span> <span class="n">normalize_indices</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="n">m</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_m</span> <span class="o">=</span> <span class="n">m</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_shape</span> <span class="o">=</span> <span class="n">batch_shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_min_stdv</span> <span class="o">=</span> <span class="n">min_stdv</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_per_input_means_stdvs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">include_stdvs_sq</span><span class="p">:</span> <span class="nb">bool</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Get per-input means and stdvs.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: A `batch_shape x n x d`-dim tensor of input parameters.</span>
<span class="sd">            include_stdvs_sq: Whether to include the stdvs squared.</span>
<span class="sd">                This parameter is not used by this method</span>

<span class="sd">        Returns:</span>
<span class="sd">            A three-tuple with the  means and stdvs:</span>

<span class="sd">            - The per-input means.</span>
<span class="sd">            - The per-input stdvs.</span>
<span class="sd">            - The per-input stdvs squared.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">means</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stdvs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stdvs_sq</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_validate_training_inputs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Yvar</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Validate training inputs.</span>

<span class="sd">        Args:</span>
<span class="sd">            Y: A `batch_shape x n x m`-dim tensor of training targets.</span>
<span class="sd">            Yvar: A `batch_shape x n x m`-dim tensor of observation noises.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_shape</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Expected Y.shape[:-2] to be </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_batch_shape</span><span class="si">}</span><span class="s2">, matching &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;the `batch_shape` argument to `</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">`, but got &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Y.shape[:-2]=</span><span class="si">{</span><span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Can&#39;t standardize with no observations. </span><span class="si">{</span><span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="si">=}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">Y</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_m</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Wrong output dimension. Y.size(-1) is </span><span class="si">{</span><span class="n">Y</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">; expected &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_m</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>

<div class="viewcode-block" id="Standardize.forward">
<a class="viewcode-back" href="../../../../models.html#botorch.models.transforms.outcome.Standardize.forward">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Yvar</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Standardize outcomes.</span>

<span class="sd">        If the module is in train mode, this updates the module state (i.e. the</span>
<span class="sd">        mean/std normalizing constants). If the module is in eval mode, simply</span>
<span class="sd">        applies the normalization using the module state.</span>

<span class="sd">        Args:</span>
<span class="sd">            Y: A `batch_shape x n x m`-dim tensor of training targets.</span>
<span class="sd">            Yvar: A `batch_shape x n x m`-dim tensor of observation noises</span>
<span class="sd">                associated with the training targets (if applicable).</span>
<span class="sd">            X: A `batch_shape x n x d`-dim tensor of training inputs (if applicable).</span>
<span class="sd">                This argument is not used by this transform, but it is used by</span>
<span class="sd">                its subclass, `StratifiedStandardize`.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A two-tuple with the transformed outcomes:</span>

<span class="sd">            - The transformed outcome observations.</span>
<span class="sd">            - The transformed observation noise (if applicable).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_validate_training_inputs</span><span class="p">(</span><span class="n">Y</span><span class="o">=</span><span class="n">Y</span><span class="p">,</span> <span class="n">Yvar</span><span class="o">=</span><span class="n">Yvar</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">stdvs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
                    <span class="p">(</span><span class="o">*</span><span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">Y</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">Y</span><span class="o">.</span><span class="n">device</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">stdvs</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">stdvs</span> <span class="o">=</span> <span class="n">stdvs</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">stdvs</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_min_stdv</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">stdvs</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>
            <span class="n">means</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_outputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">unused</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_m</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_outputs</span><span class="p">]</span>
                <span class="n">means</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">unused</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
                <span class="n">stdvs</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">unused</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">means</span> <span class="o">=</span> <span class="n">means</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">stdvs</span> <span class="o">=</span> <span class="n">stdvs</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_stdvs_sq</span> <span class="o">=</span> <span class="n">stdvs</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_is_trained</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">include_stdvs_sq</span> <span class="o">=</span> <span class="n">Yvar</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="n">means</span><span class="p">,</span> <span class="n">stdvs</span><span class="p">,</span> <span class="n">stdvs_sq</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_per_input_means_stdvs</span><span class="p">(</span>
            <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">include_stdvs_sq</span><span class="o">=</span><span class="n">include_stdvs_sq</span>
        <span class="p">)</span>
        <span class="n">Y_tf</span> <span class="o">=</span> <span class="p">(</span><span class="n">Y</span> <span class="o">-</span> <span class="n">means</span><span class="p">)</span> <span class="o">/</span> <span class="n">stdvs</span>
        <span class="n">Yvar_tf</span> <span class="o">=</span> <span class="n">Yvar</span> <span class="o">/</span> <span class="n">stdvs_sq</span> <span class="k">if</span> <span class="n">include_stdvs_sq</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="n">Y_tf</span><span class="p">,</span> <span class="n">Yvar_tf</span></div>


<div class="viewcode-block" id="Standardize.subset_output">
<a class="viewcode-back" href="../../../../models.html#botorch.models.transforms.outcome.Standardize.subset_output">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">subset_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idcs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">OutcomeTransform</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Subset the transform along the output dimension.</span>

<span class="sd">        Args:</span>
<span class="sd">            idcs: The output indices to subset the transform to.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The current outcome transform, subset to the specified output indices.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">new_m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">idcs</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">new_m</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_m</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Trying to subset a transform have more outputs than &quot;</span>
                <span class="s2">&quot; the original transform.&quot;</span>
            <span class="p">)</span>
        <span class="n">nlzd_idcs</span> <span class="o">=</span> <span class="n">normalize_indices</span><span class="p">(</span><span class="n">idcs</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_m</span><span class="p">)</span>
        <span class="n">new_outputs</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_outputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">new_outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_outputs</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">nlzd_idcs</span><span class="p">]</span>
        <span class="n">new_tf</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="p">(</span>
            <span class="n">m</span><span class="o">=</span><span class="n">new_m</span><span class="p">,</span>
            <span class="n">outputs</span><span class="o">=</span><span class="n">new_outputs</span><span class="p">,</span>
            <span class="n">batch_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_batch_shape</span><span class="p">,</span>
            <span class="n">min_stdv</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_min_stdv</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">new_tf</span><span class="o">.</span><span class="n">means</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">means</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">nlzd_idcs</span><span class="p">]</span>
        <span class="n">new_tf</span><span class="o">.</span><span class="n">stdvs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stdvs</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">nlzd_idcs</span><span class="p">]</span>
        <span class="n">new_tf</span><span class="o">.</span><span class="n">_stdvs_sq</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stdvs_sq</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">nlzd_idcs</span><span class="p">]</span>
        <span class="n">new_tf</span><span class="o">.</span><span class="n">_is_trained</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_trained</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="n">new_tf</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">new_tf</span></div>


<div class="viewcode-block" id="Standardize.untransform">
<a class="viewcode-back" href="../../../../models.html#botorch.models.transforms.outcome.Standardize.untransform">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">untransform</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Yvar</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Un-standardize outcomes.</span>

<span class="sd">        Args:</span>
<span class="sd">            Y: A `batch_shape x n x m`-dim tensor of standardized targets.</span>
<span class="sd">            Yvar: A `batch_shape x n x m`-dim tensor of standardized observation</span>
<span class="sd">                noises associated with the targets (if applicable).</span>
<span class="sd">            X: A `batch_shape x n x d`-dim tensor of inputs (if applicable).</span>
<span class="sd">                This argument is not used by this transform, but it is used by</span>
<span class="sd">                its subclass, `StratifiedStandardize`.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A two-tuple with the un-standardized outcomes:</span>

<span class="sd">            - The un-standardized outcome observations.</span>
<span class="sd">            - The un-standardized observation noise (if applicable).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_trained</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;`Standardize` transforms must be called on outcome data &quot;</span>
                <span class="s2">&quot;(e.g. `transform(Y)`) before calling `untransform`, since &quot;</span>
                <span class="s2">&quot;means and standard deviations need to be computed.&quot;</span>
            <span class="p">)</span>
        <span class="n">include_stdvs_sq</span> <span class="o">=</span> <span class="n">Yvar</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="n">means</span><span class="p">,</span> <span class="n">stdvs</span><span class="p">,</span> <span class="n">stdvs_sq</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_per_input_means_stdvs</span><span class="p">(</span>
            <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">include_stdvs_sq</span><span class="o">=</span><span class="n">include_stdvs_sq</span>
        <span class="p">)</span>
        <span class="n">Y_utf</span> <span class="o">=</span> <span class="n">means</span> <span class="o">+</span> <span class="n">stdvs</span> <span class="o">*</span> <span class="n">Y</span>
        <span class="n">Yvar_utf</span> <span class="o">=</span> <span class="n">stdvs_sq</span> <span class="o">*</span> <span class="n">Yvar</span> <span class="k">if</span> <span class="n">include_stdvs_sq</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="n">Y_utf</span><span class="p">,</span> <span class="n">Yvar_utf</span></div>


    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_is_linear</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">True</span>

<div class="viewcode-block" id="Standardize.untransform_posterior">
<a class="viewcode-back" href="../../../../models.html#botorch.models.transforms.outcome.Standardize.untransform_posterior">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">untransform_posterior</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">posterior</span><span class="p">:</span> <span class="n">Posterior</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">GPyTorchPosterior</span> <span class="o">|</span> <span class="n">TransformedPosterior</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Un-standardize the posterior.</span>

<span class="sd">        Args:</span>
<span class="sd">            posterior: A posterior in the standardized space.</span>
<span class="sd">            X: A `batch_shape x n x d`-dim tensor of inputs (if applicable).</span>
<span class="sd">                This argument is not used by this transform, but it is used by</span>
<span class="sd">                its subclass, `StratifiedStandardize`.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The un-standardized posterior. If the input posterior is a</span>
<span class="sd">            `GPyTorchPosterior`, return a `GPyTorchPosterior`. Otherwise, return a</span>
<span class="sd">            `TransformedPosterior`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_outputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="s2">&quot;Standardize does not yet support output selection for &quot;</span>
                <span class="s2">&quot;untransform_posterior&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_trained</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;`Standardize` transforms must be called on outcome data &quot;</span>
                <span class="s2">&quot;(e.g. `transform(Y)`) before calling `untransform_posterior`, since &quot;</span>
                <span class="s2">&quot;means and standard deviations need to be computed.&quot;</span>
            <span class="p">)</span>
        <span class="n">is_mtgp_posterior</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span> <span class="ow">is</span> <span class="n">GPyTorchPosterior</span><span class="p">:</span>
            <span class="n">is_mtgp_posterior</span> <span class="o">=</span> <span class="n">posterior</span><span class="o">.</span><span class="n">_is_mt</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_m</span> <span class="o">==</span> <span class="n">posterior</span><span class="o">.</span><span class="n">_extended_shape</span><span class="p">()[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">is_mtgp_posterior</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Incompatible output dimensions encountered. Transform has output &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;dimension </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_m</span><span class="si">}</span><span class="s2"> and posterior has &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">posterior</span><span class="o">.</span><span class="n">_extended_shape</span><span class="p">()[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">GPyTorchPosterior</span><span class="p">:</span>
            <span class="c1"># fall back to TransformedPosterior</span>
            <span class="c1"># this applies to subclasses of GPyTorchPosterior like MultitaskGPPosterior</span>
            <span class="k">return</span> <span class="n">TransformedPosterior</span><span class="p">(</span>
                <span class="n">posterior</span><span class="o">=</span><span class="n">posterior</span><span class="p">,</span>
                <span class="n">sample_transform</span><span class="o">=</span><span class="k">lambda</span> <span class="n">s</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">means</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">stdvs</span> <span class="o">*</span> <span class="n">s</span><span class="p">,</span>
                <span class="n">mean_transform</span><span class="o">=</span><span class="k">lambda</span> <span class="n">m</span><span class="p">,</span> <span class="n">v</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">means</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">stdvs</span> <span class="o">*</span> <span class="n">m</span><span class="p">,</span>
                <span class="n">variance_transform</span><span class="o">=</span><span class="k">lambda</span> <span class="n">m</span><span class="p">,</span> <span class="n">v</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stdvs_sq</span> <span class="o">*</span> <span class="n">v</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="c1"># GPyTorchPosterior (TODO: Should we Lazy-evaluate the mean here as well?)</span>
        <span class="n">mvn</span> <span class="o">=</span> <span class="n">posterior</span><span class="o">.</span><span class="n">distribution</span>
        <span class="n">offset</span><span class="p">,</span> <span class="n">scale_fac</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_per_input_means_stdvs</span><span class="p">(</span>
            <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">include_stdvs_sq</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">posterior</span><span class="o">.</span><span class="n">_is_mt</span><span class="p">:</span>
            <span class="n">mean_tf</span> <span class="o">=</span> <span class="n">offset</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">scale_fac</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">mvn</span><span class="o">.</span><span class="n">mean</span>
            <span class="n">scale_fac</span> <span class="o">=</span> <span class="n">scale_fac</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">mean_tf</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">mean_tf</span> <span class="o">=</span> <span class="n">offset</span> <span class="o">+</span> <span class="n">scale_fac</span> <span class="o">*</span> <span class="n">mvn</span><span class="o">.</span><span class="n">mean</span>
            <span class="n">reps</span> <span class="o">=</span> <span class="n">mean_tf</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">//</span> <span class="n">scale_fac</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">scale_fac</span> <span class="o">=</span> <span class="n">scale_fac</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">mvn</span><span class="o">.</span><span class="n">_interleaved</span><span class="p">:</span>
                <span class="n">scale_fac</span> <span class="o">=</span> <span class="n">scale_fac</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="mi">1</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">scale_fac</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="n">reps</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">scale_fac</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">scale_fac</span><span class="p">,</span> <span class="n">reps</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="n">mvn</span><span class="o">.</span><span class="n">islazy</span>
            <span class="ow">or</span> <span class="n">mvn</span><span class="o">.</span><span class="n">_MultivariateNormal__unbroadcasted_scale_tril</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="p">):</span>
            <span class="c1"># if already computed, we can save a lot of time using scale_tril</span>
            <span class="n">covar_tf</span> <span class="o">=</span> <span class="n">CholLinearOperator</span><span class="p">(</span><span class="n">mvn</span><span class="o">.</span><span class="n">scale_tril</span> <span class="o">*</span> <span class="n">scale_fac</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">lcv</span> <span class="o">=</span> <span class="n">mvn</span><span class="o">.</span><span class="n">lazy_covariance_matrix</span>
            <span class="n">scale_fac</span> <span class="o">=</span> <span class="n">scale_fac</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">lcv</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">scale_mat</span> <span class="o">=</span> <span class="n">DiagLinearOperator</span><span class="p">(</span><span class="n">scale_fac</span><span class="p">)</span>
            <span class="n">covar_tf</span> <span class="o">=</span> <span class="n">scale_mat</span> <span class="o">@</span> <span class="n">lcv</span> <span class="o">@</span> <span class="n">scale_mat</span>

        <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;interleaved&quot;</span><span class="p">:</span> <span class="n">mvn</span><span class="o">.</span><span class="n">_interleaved</span><span class="p">}</span> <span class="k">if</span> <span class="n">posterior</span><span class="o">.</span><span class="n">_is_mt</span> <span class="k">else</span> <span class="p">{}</span>
        <span class="n">mvn_tf</span> <span class="o">=</span> <span class="n">mvn</span><span class="o">.</span><span class="vm">__class__</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">mean_tf</span><span class="p">,</span> <span class="n">covariance_matrix</span><span class="o">=</span><span class="n">covar_tf</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">GPyTorchPosterior</span><span class="p">(</span><span class="n">mvn_tf</span><span class="p">)</span></div>
</div>



<div class="viewcode-block" id="StratifiedStandardize">
<a class="viewcode-back" href="../../../../models.html#botorch.models.transforms.outcome.StratifiedStandardize">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">StratifiedStandardize</span><span class="p">(</span><span class="n">Standardize</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Standardize outcomes (zero mean, unit variance) along stratification dimension.</span>

<span class="sd">    This module is stateful: If in train mode, calling forward updates the</span>
<span class="sd">    module state (i.e. the mean/std normalizing constants). If in eval mode,</span>
<span class="sd">    calling forward simply applies the standardization using the current module</span>
<span class="sd">    state.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">task_values</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">stratification_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">batch_shape</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(),</span>  <span class="c1"># noqa: B008</span>
        <span class="n">min_stdv</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-8</span><span class="p">,</span>
        <span class="c1"># dtype: torch.dtype = torch.double,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Standardize outcomes (zero mean, unit variance) along stratification dim.</span>

<span class="sd">        Note: This currenlty only supports single output models</span>
<span class="sd">        (including multi-task models that have a single output).</span>

<span class="sd">        Args:</span>
<span class="sd">            task_values: `t`-dim tensor of task values.</span>
<span class="sd">            stratification_idx: The index of the stratification dimension.</span>
<span class="sd">            batch_shape: The batch_shape of the training targets.</span>
<span class="sd">            min_stddv: The minimum standard deviation for which to perform</span>
<span class="sd">                standardization (if lower, only de-mean the data).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">OutcomeTransform</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stratification_idx</span> <span class="o">=</span> <span class="n">stratification_idx</span>
        <span class="n">task_values</span> <span class="o">=</span> <span class="n">task_values</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="nb">sorted</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">strata_mapping</span> <span class="o">=</span> <span class="n">get_task_value_remapping</span><span class="p">(</span><span class="n">task_values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">double</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">strata_mapping</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">strata_mapping</span> <span class="o">=</span> <span class="n">task_values</span>
        <span class="n">n_strata</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">strata_mapping</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_min_stdv</span> <span class="o">=</span> <span class="n">min_stdv</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;means&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="o">*</span><span class="n">batch_shape</span><span class="p">,</span> <span class="n">n_strata</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;stdvs&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="o">*</span><span class="n">batch_shape</span><span class="p">,</span> <span class="n">n_strata</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;_stdvs_sq&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="o">*</span><span class="n">batch_shape</span><span class="p">,</span> <span class="n">n_strata</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;_is_trained&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="kc">False</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_shape</span> <span class="o">=</span> <span class="n">batch_shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_m</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># TODO: support multiple outputs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_outputs</span> <span class="o">=</span> <span class="kc">None</span>

<div class="viewcode-block" id="StratifiedStandardize.forward">
<a class="viewcode-back" href="../../../../models.html#botorch.models.transforms.outcome.StratifiedStandardize.forward">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Yvar</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Standardize outcomes.</span>

<span class="sd">        If the module is in train mode, this updates the module state (i.e. the</span>
<span class="sd">        mean/std normalizing constants). If the module is in eval mode, simply</span>
<span class="sd">        applies the normalization using the module state.</span>

<span class="sd">        Args:</span>
<span class="sd">            Y: A `batch_shape x n x m`-dim tensor of training targets.</span>
<span class="sd">            Yvar: A `batch_shape x n x m`-dim tensor of observation noises</span>
<span class="sd">                associated with the training targets (if applicable).</span>
<span class="sd">            X: A `batch_shape x n x d`-dim tensor of input parameters.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A two-tuple with the transformed outcomes:</span>

<span class="sd">            - The transformed outcome observations.</span>
<span class="sd">            - The transformed observation noise (if applicable).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">X</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;X is required for StratifiedStandardize.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_validate_training_inputs</span><span class="p">(</span><span class="n">Y</span><span class="o">=</span><span class="n">Y</span><span class="p">,</span> <span class="n">Yvar</span><span class="o">=</span><span class="n">Yvar</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">means</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">means</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">stdvs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stdvs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_stdvs_sq</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stdvs_sq</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">strata</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stratification_idx</span><span class="p">]</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
            <span class="n">unique_strata</span> <span class="o">=</span> <span class="n">strata</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">unique_strata</span><span class="p">:</span>
                <span class="n">mapped_strata</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">strata_mapping</span><span class="p">[</span><span class="n">s</span><span class="p">]</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
                <span class="n">mask</span> <span class="o">=</span> <span class="n">strata</span> <span class="o">!=</span> <span class="n">s</span>
                <span class="n">Y_strata</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                <span class="n">Y_strata</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;nan&quot;</span><span class="p">)</span>
                <span class="n">stdvs</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">Y_strata</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
                    <span class="k">else</span> <span class="n">nanstd</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">Y_strata</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="n">stdvs</span> <span class="o">=</span> <span class="n">stdvs</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
                    <span class="n">stdvs</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_min_stdv</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">stdvs</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="n">means</span> <span class="o">=</span> <span class="n">Y_strata</span><span class="o">.</span><span class="n">nanmean</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">means</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">mapped_strata</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">means</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">stdvs</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">mapped_strata</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">stdvs</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_stdvs_sq</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">mapped_strata</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">stdvs</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_is_trained</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">training</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">tf_Y</span><span class="p">,</span> <span class="n">tf_Yvar</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">Y</span><span class="o">=</span><span class="n">Y</span><span class="p">,</span> <span class="n">Yvar</span><span class="o">=</span><span class="n">Yvar</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="o">=</span> <span class="n">training</span>
        <span class="k">return</span> <span class="n">tf_Y</span><span class="p">,</span> <span class="n">tf_Yvar</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_get_per_input_means_stdvs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">include_stdvs_sq</span><span class="p">:</span> <span class="nb">bool</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Get per-input means and stdvs.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: A `batch_shape x n x d`-dim tensor of input parameters.</span>
<span class="sd">            include_stdvs_sq: Whether to include the stdvs squared.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A three-tuple with the per-input means and stdvs:</span>

<span class="sd">            - The per-input means.</span>
<span class="sd">            - The per-input stdvs.</span>
<span class="sd">            - The per-input stdvs squared.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">strata</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stratification_idx</span><span class="p">]</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
        <span class="n">mapped_strata</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">strata_mapping</span><span class="p">[</span><span class="n">strata</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
        <span class="c1"># get means and stdvs for each strata</span>
        <span class="n">n_extra_batch_dims</span> <span class="o">=</span> <span class="n">mapped_strata</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_batch_shape</span><span class="p">)</span>
        <span class="n">expand_shape</span> <span class="o">=</span> <span class="n">mapped_strata</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="n">n_extra_batch_dims</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">means</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">means</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span>
            <span class="nb">input</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">means</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">expand_shape</span><span class="p">),</span>
            <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">index</span><span class="o">=</span><span class="n">mapped_strata</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">stdvs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span>
            <span class="nb">input</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stdvs</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">expand_shape</span><span class="p">),</span>
            <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">index</span><span class="o">=</span><span class="n">mapped_strata</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">include_stdvs_sq</span><span class="p">:</span>
            <span class="n">stdvs_sq</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span>
                <span class="nb">input</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_stdvs_sq</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">expand_shape</span><span class="p">),</span>
                <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span>
                <span class="n">index</span><span class="o">=</span><span class="n">mapped_strata</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">stdvs_sq</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="n">means</span><span class="p">,</span> <span class="n">stdvs</span><span class="p">,</span> <span class="n">stdvs_sq</span>

<div class="viewcode-block" id="StratifiedStandardize.subset_output">
<a class="viewcode-back" href="../../../../models.html#botorch.models.transforms.outcome.StratifiedStandardize.subset_output">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">subset_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idcs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">OutcomeTransform</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Subset the transform along the output dimension.</span>

<span class="sd">        Args:</span>
<span class="sd">            idcs: The output indices to subset the transform to.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The current outcome transform, subset to the specified output indices.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>


<div class="viewcode-block" id="StratifiedStandardize.untransform">
<a class="viewcode-back" href="../../../../models.html#botorch.models.transforms.outcome.StratifiedStandardize.untransform">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">untransform</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Yvar</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Un-standardize outcomes.</span>

<span class="sd">        Args:</span>
<span class="sd">            Y: A `batch_shape x n x m`-dim tensor of standardized targets.</span>
<span class="sd">            Yvar: A `batch_shape x n x m`-dim tensor of standardized observation</span>
<span class="sd">                noises associated with the targets (if applicable).</span>
<span class="sd">            X: A `batch_shape x n x d`-dim tensor of input parameters.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A two-tuple with the un-standardized outcomes:</span>

<span class="sd">            - The un-standardized outcome observations.</span>
<span class="sd">            - The un-standardized observation noise (if applicable).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">X</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;X is required for StratifiedStandardize.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">untransform</span><span class="p">(</span><span class="n">Y</span><span class="o">=</span><span class="n">Y</span><span class="p">,</span> <span class="n">Yvar</span><span class="o">=</span><span class="n">Yvar</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">)</span></div>


<div class="viewcode-block" id="StratifiedStandardize.untransform_posterior">
<a class="viewcode-back" href="../../../../models.html#botorch.models.transforms.outcome.StratifiedStandardize.untransform_posterior">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">untransform_posterior</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">posterior</span><span class="p">:</span> <span class="n">Posterior</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">GPyTorchPosterior</span> <span class="o">|</span> <span class="n">TransformedPosterior</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Un-standardize the posterior.</span>

<span class="sd">        Args:</span>
<span class="sd">            posterior: A posterior in the standardized space.</span>
<span class="sd">            X: A `batch_shape x n x d`-dim tensor of training inputs (if applicable).</span>

<span class="sd">        Returns:</span>
<span class="sd">            The un-standardized posterior. If the input posterior is a</span>
<span class="sd">            `GPyTorchPosterior`, return a `GPyTorchPosterior`. Otherwise, return a</span>
<span class="sd">            `TransformedPosterior`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">X</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;X is required for StratifiedStandardize.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">untransform_posterior</span><span class="p">(</span><span class="n">posterior</span><span class="o">=</span><span class="n">posterior</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">)</span></div>
</div>



<div class="viewcode-block" id="Log">
<a class="viewcode-back" href="../../../../models.html#botorch.models.transforms.outcome.Log">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">Log</span><span class="p">(</span><span class="n">OutcomeTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Log-transform outcomes.</span>

<span class="sd">    Useful if the targets are modeled using a (multivariate) log-Normal</span>
<span class="sd">    distribution. This means that we can use a standard GP model on the</span>
<span class="sd">    log-transformed outcomes and un-transform the model posterior of that GP.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Log-transform outcomes.</span>

<span class="sd">        Args:</span>
<span class="sd">            outputs: Which of the outputs to log-transform. If omitted, all</span>
<span class="sd">                outputs will be standardized.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_outputs</span> <span class="o">=</span> <span class="n">outputs</span>

<div class="viewcode-block" id="Log.subset_output">
<a class="viewcode-back" href="../../../../models.html#botorch.models.transforms.outcome.Log.subset_output">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">subset_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idcs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">OutcomeTransform</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Subset the transform along the output dimension.</span>

<span class="sd">        Args:</span>
<span class="sd">            idcs: The output indices to subset the transform to.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The current outcome transform, subset to the specified output indices.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">new_outputs</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_outputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_outputs</span> <span class="o">+</span> <span class="n">idcs</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Negative indexing not supported for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> &quot;</span>
                    <span class="s2">&quot;when subsetting outputs and only transforming some outputs.&quot;</span>
                <span class="p">)</span>
            <span class="n">new_outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_outputs</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">idcs</span><span class="p">]</span>
        <span class="n">new_tf</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="p">(</span><span class="n">outputs</span><span class="o">=</span><span class="n">new_outputs</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="n">new_tf</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">new_tf</span></div>


<div class="viewcode-block" id="Log.forward">
<a class="viewcode-back" href="../../../../models.html#botorch.models.transforms.outcome.Log.forward">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Yvar</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Log-transform outcomes.</span>

<span class="sd">        Args:</span>
<span class="sd">            Y: A `batch_shape x n x m`-dim tensor of training targets.</span>
<span class="sd">            Yvar: A `batch_shape x n x m`-dim tensor of observation noises</span>
<span class="sd">                associated with the training targets (if applicable).</span>
<span class="sd">            X: A `batch_shape x n x d`-dim tensor of training inputs (if applicable).</span>
<span class="sd">                This argument is not used by this transform.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A two-tuple with the transformed outcomes:</span>

<span class="sd">            - The transformed outcome observations.</span>
<span class="sd">            - The transformed observation noise (if applicable).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">Y_tf</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">normalize_indices</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_outputs</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="n">Y</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">outputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">Y_tf</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="n">Y_tf</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">outputs</span> <span class="k">else</span> <span class="n">Y</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
                <span class="p">],</span>
                <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">Yvar</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># TODO: Delta method, possibly issue warning</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="s2">&quot;Log does not yet support transforming observation noise&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">Y_tf</span><span class="p">,</span> <span class="n">Yvar</span></div>


<div class="viewcode-block" id="Log.untransform">
<a class="viewcode-back" href="../../../../models.html#botorch.models.transforms.outcome.Log.untransform">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">untransform</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Yvar</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Un-transform log-transformed outcomes</span>

<span class="sd">        Args:</span>
<span class="sd">            Y: A `batch_shape x n x m`-dim tensor of log-transfomred targets.</span>
<span class="sd">            Yvar: A `batch_shape x n x m`-dim tensor of log- transformed</span>
<span class="sd">                observation noises associated with the training targets</span>
<span class="sd">                (if applicable).</span>
<span class="sd">            X: A `batch_shape x n x d`-dim tensor of inputs (if applicable).</span>
<span class="sd">                This argument is not used by this transform.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A two-tuple with the un-transformed outcomes:</span>

<span class="sd">            - The exponentiated outcome observations.</span>
<span class="sd">            - The exponentiated observation noise (if applicable).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">Y_utf</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">normalize_indices</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_outputs</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="n">Y</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">outputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">Y_utf</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="n">Y_utf</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">outputs</span> <span class="k">else</span> <span class="n">Y</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
                <span class="p">],</span>
                <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">Yvar</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># TODO: Delta method, possibly issue warning</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="s2">&quot;Log does not yet support transforming observation noise&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">Y_utf</span><span class="p">,</span> <span class="n">Yvar</span></div>


<div class="viewcode-block" id="Log.untransform_posterior">
<a class="viewcode-back" href="../../../../models.html#botorch.models.transforms.outcome.Log.untransform_posterior">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">untransform_posterior</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">posterior</span><span class="p">:</span> <span class="n">Posterior</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TransformedPosterior</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Un-transform the log-transformed posterior.</span>

<span class="sd">        Args:</span>
<span class="sd">            posterior: A posterior in the log-transformed space.</span>
<span class="sd">            X: A `batch_shape x n x d`-dim tensor of inputs (if applicable).</span>
<span class="sd">                This argument is not used by this transform.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The un-transformed posterior.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_outputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="s2">&quot;Log does not yet support output selection for untransform_posterior&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">TransformedPosterior</span><span class="p">(</span>
            <span class="n">posterior</span><span class="o">=</span><span class="n">posterior</span><span class="p">,</span>
            <span class="n">sample_transform</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">,</span>
            <span class="n">mean_transform</span><span class="o">=</span><span class="n">norm_to_lognorm_mean</span><span class="p">,</span>
            <span class="n">variance_transform</span><span class="o">=</span><span class="n">norm_to_lognorm_variance</span><span class="p">,</span>
        <span class="p">)</span></div>
</div>



<div class="viewcode-block" id="Power">
<a class="viewcode-back" href="../../../../models.html#botorch.models.transforms.outcome.Power">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">Power</span><span class="p">(</span><span class="n">OutcomeTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Power-transform outcomes.</span>

<span class="sd">    Useful if the targets are modeled using a (multivariate) power transform of</span>
<span class="sd">    a Normal distribution. This means that we can use a standard GP model on the</span>
<span class="sd">    power-transformed outcomes and un-transform the model posterior of that GP.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">power</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Power-transform outcomes.</span>

<span class="sd">        Args:</span>
<span class="sd">            outputs: Which of the outputs to power-transform. If omitted, all</span>
<span class="sd">                outputs will be standardized.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_outputs</span> <span class="o">=</span> <span class="n">outputs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">power</span> <span class="o">=</span> <span class="n">power</span>

<div class="viewcode-block" id="Power.subset_output">
<a class="viewcode-back" href="../../../../models.html#botorch.models.transforms.outcome.Power.subset_output">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">subset_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idcs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">OutcomeTransform</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Subset the transform along the output dimension.</span>

<span class="sd">        Args:</span>
<span class="sd">            idcs: The output indices to subset the transform to.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The current outcome transform, subset to the specified output indices.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">new_outputs</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_outputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_outputs</span> <span class="o">+</span> <span class="n">idcs</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Negative indexing not supported for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> &quot;</span>
                    <span class="s2">&quot;when subsetting outputs and only transforming some outputs.&quot;</span>
                <span class="p">)</span>
            <span class="n">new_outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_outputs</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">idcs</span><span class="p">]</span>
        <span class="n">new_tf</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="p">(</span><span class="n">power</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">power</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">new_outputs</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="n">new_tf</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">new_tf</span></div>


<div class="viewcode-block" id="Power.forward">
<a class="viewcode-back" href="../../../../models.html#botorch.models.transforms.outcome.Power.forward">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Yvar</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Power-transform outcomes.</span>

<span class="sd">        Args:</span>
<span class="sd">            Y: A `batch_shape x n x m`-dim tensor of training targets.</span>
<span class="sd">            Yvar: A `batch_shape x n x m`-dim tensor of observation noises</span>
<span class="sd">                associated with the training targets (if applicable).</span>
<span class="sd">            X: A `batch_shape x n x d`-dim tensor of training inputs (if applicable).</span>
<span class="sd">                This argument is not used by this transform.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A two-tuple with the transformed outcomes:</span>

<span class="sd">            - The transformed outcome observations.</span>
<span class="sd">            - The transformed observation noise (if applicable).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">Y_tf</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">power</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">normalize_indices</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_outputs</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="n">Y</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">outputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">Y_tf</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="n">Y_tf</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">outputs</span> <span class="k">else</span> <span class="n">Y</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
                <span class="p">],</span>
                <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">Yvar</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># TODO: Delta method, possibly issue warning</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="s2">&quot;Power does not yet support transforming observation noise&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">Y_tf</span><span class="p">,</span> <span class="n">Yvar</span></div>


<div class="viewcode-block" id="Power.untransform">
<a class="viewcode-back" href="../../../../models.html#botorch.models.transforms.outcome.Power.untransform">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">untransform</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Yvar</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Un-transform power-transformed outcomes</span>

<span class="sd">        Args:</span>
<span class="sd">            Y: A `batch_shape x n x m`-dim tensor of power-transfomred targets.</span>
<span class="sd">            Yvar: A `batch_shape x n x m`-dim tensor of power-transformed</span>
<span class="sd">                observation noises associated with the training targets</span>
<span class="sd">                (if applicable).</span>
<span class="sd">            X: A `batch_shape x n x d`-dim tensor of inputs (if applicable).</span>
<span class="sd">                This argument is not used by this transform.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A two-tuple with the un-transformed outcomes:</span>

<span class="sd">            - The un-power transformed outcome observations.</span>
<span class="sd">            - The un-power transformed observation noise (if applicable).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">Y_utf</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">power</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">normalize_indices</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_outputs</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="n">Y</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">outputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">Y_utf</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="n">Y_utf</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">outputs</span> <span class="k">else</span> <span class="n">Y</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
                <span class="p">],</span>
                <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">Yvar</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># TODO: Delta method, possibly issue warning</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="s2">&quot;Power does not yet support transforming observation noise&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">Y_utf</span><span class="p">,</span> <span class="n">Yvar</span></div>


<div class="viewcode-block" id="Power.untransform_posterior">
<a class="viewcode-back" href="../../../../models.html#botorch.models.transforms.outcome.Power.untransform_posterior">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">untransform_posterior</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">posterior</span><span class="p">:</span> <span class="n">Posterior</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TransformedPosterior</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Un-transform the power-transformed posterior.</span>

<span class="sd">        Args:</span>
<span class="sd">            posterior: A posterior in the power-transformed space.</span>
<span class="sd">            X: A `batch_shape x n x d`-dim tensor of inputs (if applicable).</span>
<span class="sd">                This argument is not used by this transform.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The un-transformed posterior.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_outputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="s2">&quot;Power does not yet support output selection for untransform_posterior&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">TransformedPosterior</span><span class="p">(</span>
            <span class="n">posterior</span><span class="o">=</span><span class="n">posterior</span><span class="p">,</span>
            <span class="n">sample_transform</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">power</span><span class="p">),</span>
        <span class="p">)</span></div>
</div>



<div class="viewcode-block" id="Bilog">
<a class="viewcode-back" href="../../../../models.html#botorch.models.transforms.outcome.Bilog">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">Bilog</span><span class="p">(</span><span class="n">OutcomeTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Bilog-transform outcomes.</span>

<span class="sd">    The Bilog transform [eriksson2021scalable]_ is useful for modeling outcome</span>
<span class="sd">    constraints as it magnifies values near zero and flattens extreme values.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Bilog-transform outcomes.</span>

<span class="sd">        Args:</span>
<span class="sd">            outputs: Which of the outputs to Bilog-transform. If omitted, all</span>
<span class="sd">                outputs will be transformed.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_outputs</span> <span class="o">=</span> <span class="n">outputs</span>

<div class="viewcode-block" id="Bilog.subset_output">
<a class="viewcode-back" href="../../../../models.html#botorch.models.transforms.outcome.Bilog.subset_output">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">subset_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idcs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">OutcomeTransform</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Subset the transform along the output dimension.</span>

<span class="sd">        Args:</span>
<span class="sd">            idcs: The output indices to subset the transform to.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The current outcome transform, subset to the specified output indices.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">new_outputs</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_outputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_outputs</span> <span class="o">+</span> <span class="n">idcs</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Negative indexing not supported for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> &quot;</span>
                    <span class="s2">&quot;when subsetting outputs and only transforming some outputs.&quot;</span>
                <span class="p">)</span>
            <span class="n">new_outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_outputs</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">idcs</span><span class="p">]</span>
        <span class="n">new_tf</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="p">(</span><span class="n">outputs</span><span class="o">=</span><span class="n">new_outputs</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="n">new_tf</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">new_tf</span></div>


<div class="viewcode-block" id="Bilog.forward">
<a class="viewcode-back" href="../../../../models.html#botorch.models.transforms.outcome.Bilog.forward">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Yvar</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Bilog-transform outcomes.</span>

<span class="sd">        Args:</span>
<span class="sd">            Y: A `batch_shape x n x m`-dim tensor of training targets.</span>
<span class="sd">            Yvar: A `batch_shape x n x m`-dim tensor of observation noises</span>
<span class="sd">                associated with the training targets (if applicable).</span>
<span class="sd">            X: A `batch_shape x n x d`-dim tensor of training inputs (if applicable).</span>
<span class="sd">                This argument is not used by this transform.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A two-tuple with the transformed outcomes:</span>

<span class="sd">            - The transformed outcome observations.</span>
<span class="sd">            - The transformed observation noise (if applicable).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">Y_tf</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">sign</span><span class="p">()</span> <span class="o">*</span> <span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span> <span class="o">+</span> <span class="mf">1.0</span><span class="p">)</span><span class="o">.</span><span class="n">log</span><span class="p">()</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">normalize_indices</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_outputs</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="n">Y</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">outputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">Y_tf</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="n">Y_tf</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">outputs</span> <span class="k">else</span> <span class="n">Y</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
                <span class="p">],</span>
                <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">Yvar</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="s2">&quot;Bilog does not yet support transforming observation noise&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">Y_tf</span><span class="p">,</span> <span class="n">Yvar</span></div>


<div class="viewcode-block" id="Bilog.untransform">
<a class="viewcode-back" href="../../../../models.html#botorch.models.transforms.outcome.Bilog.untransform">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">untransform</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Yvar</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Un-transform bilog-transformed outcomes</span>

<span class="sd">        Args:</span>
<span class="sd">            Y: A `batch_shape x n x m`-dim tensor of bilog-transfomred targets.</span>
<span class="sd">            Yvar: A `batch_shape x n x m`-dim tensor of bilog-transformed</span>
<span class="sd">                observation noises associated with the training targets</span>
<span class="sd">                (if applicable).</span>
<span class="sd">            X: A `batch_shape x n x d`-dim tensor of inputs (if applicable).</span>
<span class="sd">                This argument is not used by this transform.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A two-tuple with the un-transformed outcomes:</span>

<span class="sd">            - The un-transformed outcome observations.</span>
<span class="sd">            - The un-transformed observation noise (if applicable).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">Y_utf</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">sign</span><span class="p">()</span> <span class="o">*</span> <span class="n">Y</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">expm1</span><span class="p">()</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">normalize_indices</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_outputs</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="n">Y</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">outputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">Y_utf</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="n">Y_utf</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">outputs</span> <span class="k">else</span> <span class="n">Y</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
                <span class="p">],</span>
                <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">Yvar</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># TODO: Delta method, possibly issue warning</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="s2">&quot;Bilog does not yet support transforming observation noise&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">Y_utf</span><span class="p">,</span> <span class="n">Yvar</span></div>


<div class="viewcode-block" id="Bilog.untransform_posterior">
<a class="viewcode-back" href="../../../../models.html#botorch.models.transforms.outcome.Bilog.untransform_posterior">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">untransform_posterior</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">posterior</span><span class="p">:</span> <span class="n">Posterior</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TransformedPosterior</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Un-transform the bilog-transformed posterior.</span>

<span class="sd">        Args:</span>
<span class="sd">            posterior: A posterior in the bilog-transformed space.</span>
<span class="sd">            X: A `batch_shape x n x d`-dim tensor of inputs (if applicable).</span>
<span class="sd">                This argument is not used by this transform.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The un-transformed posterior.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_outputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="s2">&quot;Bilog does not yet support output selection for untransform_posterior&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">TransformedPosterior</span><span class="p">(</span>
            <span class="n">posterior</span><span class="o">=</span><span class="n">posterior</span><span class="p">,</span>
            <span class="n">sample_transform</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">sign</span><span class="p">()</span> <span class="o">*</span> <span class="n">x</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">expm1</span><span class="p">(),</span>
        <span class="p">)</span></div>
</div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p></p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>