

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>botorch.models.multitask &mdash; BoTorch  documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=03e43079" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../../_static/custom.css?v=ca3e82f4" />

  
      <script src="../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../_static/documentation_options.js?v=5929fcd5"></script>
      <script src="../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            BoTorch
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../acquisition.html">botorch.acquisition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models.html">botorch.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generation.html">botorch.generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../posteriors.html">botorch.posteriors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../optim.html">botorch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../fit.html">botorch.fit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../sampling.html">botorch.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cross_validation.html">botorch.cross_validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../settings.html">botorch.settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../logging.html">botorch.logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../test_functions.html">botorch.test_functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../test_utils.html">botorch.test_utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../exceptions.html">botorch.exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../utils.html">botorch.utils</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">BoTorch</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">botorch.models.multitask</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for botorch.models.multitask</h1><div class="highlight"><pre>
<span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="c1"># Copyright (c) Meta Platforms, Inc. and affiliates.</span>
<span class="c1">#</span>
<span class="c1"># This source code is licensed under the MIT license found in the</span>
<span class="c1"># LICENSE file in the root directory of this source tree.</span>

<span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Multi-Task GP models.</span>

<span class="sd">References</span>

<span class="sd">.. [Bonilla2007MTGP]</span>
<span class="sd">    E. Bonilla, K. Chai and C. Williams. Multi-task Gaussian Process Prediction.</span>
<span class="sd">    Advances in Neural Information Processing Systems 20, NeurIPS 2007.</span>

<span class="sd">.. [Swersky2013MTBO]</span>
<span class="sd">    K. Swersky, J. Snoek and R. Adams. Multi-Task Bayesian Optimization.</span>
<span class="sd">    Advances in Neural Information Processing Systems 26, NeurIPS 2013.</span>

<span class="sd">.. [Doucet2010sampl]</span>
<span class="sd">    A. Doucet. A Note on Efficient Conditional Simulation of Gaussian Distributions.</span>
<span class="sd">    http://www.stats.ox.ac.uk/~doucet/doucet_simulationconditionalgaussian.pdf,</span>
<span class="sd">    Apr 2010.</span>

<span class="sd">.. [Maddox2021bohdo]</span>
<span class="sd">    W. Maddox, M. Balandat, A. Wilson, and E. Bakshy. Bayesian Optimization with</span>
<span class="sd">    High-Dimensional Outputs. https://arxiv.org/abs/2106.12997, Jun 2021.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">__future__</span><span class="w"> </span><span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.acquisition.objective</span><span class="w"> </span><span class="kn">import</span> <span class="n">PosteriorTransform</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.exceptions.errors</span><span class="w"> </span><span class="kn">import</span> <span class="n">UnsupportedError</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.models.gpytorch</span><span class="w"> </span><span class="kn">import</span> <span class="n">GPyTorchModel</span><span class="p">,</span> <span class="n">MultiTaskGPyTorchModel</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.models.model</span><span class="w"> </span><span class="kn">import</span> <span class="n">FantasizeMixin</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.models.transforms.input</span><span class="w"> </span><span class="kn">import</span> <span class="n">InputTransform</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.models.transforms.outcome</span><span class="w"> </span><span class="kn">import</span> <span class="n">OutcomeTransform</span><span class="p">,</span> <span class="n">Standardize</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.models.utils.assorted</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_task_value_remapping</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.models.utils.gpytorch_modules</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">get_covar_module_with_dim_scaled_prior</span><span class="p">,</span>
    <span class="n">get_gaussian_likelihood_with_lognormal_prior</span><span class="p">,</span>
    <span class="n">MIN_INFERRED_NOISE_LEVEL</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.posteriors.multitask</span><span class="w"> </span><span class="kn">import</span> <span class="n">MultitaskGPPosterior</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.utils.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">MultiTaskDataset</span><span class="p">,</span> <span class="n">SupervisedDataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.utils.types</span><span class="w"> </span><span class="kn">import</span> <span class="n">_DefaultType</span><span class="p">,</span> <span class="n">DEFAULT</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.constraints</span><span class="w"> </span><span class="kn">import</span> <span class="n">GreaterThan</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.distributions.multitask_multivariate_normal</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">MultitaskMultivariateNormal</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.distributions.multivariate_normal</span><span class="w"> </span><span class="kn">import</span> <span class="n">MultivariateNormal</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.kernels.index_kernel</span><span class="w"> </span><span class="kn">import</span> <span class="n">IndexKernel</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.kernels.multitask_kernel</span><span class="w"> </span><span class="kn">import</span> <span class="n">MultitaskKernel</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.likelihoods.gaussian_likelihood</span><span class="w"> </span><span class="kn">import</span> <span class="n">FixedNoiseGaussianLikelihood</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.likelihoods.likelihood</span><span class="w"> </span><span class="kn">import</span> <span class="n">Likelihood</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.likelihoods.multitask_gaussian_likelihood</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">MultitaskGaussianLikelihood</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.means</span><span class="w"> </span><span class="kn">import</span> <span class="n">MultitaskMean</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.means.constant_mean</span><span class="w"> </span><span class="kn">import</span> <span class="n">ConstantMean</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.models.exact_gp</span><span class="w"> </span><span class="kn">import</span> <span class="n">ExactGP</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.module</span><span class="w"> </span><span class="kn">import</span> <span class="n">Module</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.priors.lkj_prior</span><span class="w"> </span><span class="kn">import</span> <span class="n">LKJCovariancePrior</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.priors.prior</span><span class="w"> </span><span class="kn">import</span> <span class="n">Prior</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.priors.smoothed_box_prior</span><span class="w"> </span><span class="kn">import</span> <span class="n">SmoothedBoxPrior</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.priors.torch_priors</span><span class="w"> </span><span class="kn">import</span> <span class="n">GammaPrior</span><span class="p">,</span> <span class="n">LogNormalPrior</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.settings</span><span class="w"> </span><span class="kn">import</span> <span class="n">detach_test_caches</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.utils.errors</span><span class="w"> </span><span class="kn">import</span> <span class="n">CachingError</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.utils.memoize</span><span class="w"> </span><span class="kn">import</span> <span class="n">cached</span><span class="p">,</span> <span class="n">pop_from_cache</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">linear_operator.operators</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">BatchRepeatLinearOperator</span><span class="p">,</span>
    <span class="n">CatLinearOperator</span><span class="p">,</span>
    <span class="n">DiagLinearOperator</span><span class="p">,</span>
    <span class="n">KroneckerProductDiagLinearOperator</span><span class="p">,</span>
    <span class="n">KroneckerProductLinearOperator</span><span class="p">,</span>
    <span class="n">RootLinearOperator</span><span class="p">,</span>
    <span class="n">to_linear_operator</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">Tensor</span>


<div class="viewcode-block" id="MultiTaskGP">
<a class="viewcode-back" href="../../../models.html#botorch.models.multitask.MultiTaskGP">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">MultiTaskGP</span><span class="p">(</span><span class="n">ExactGP</span><span class="p">,</span> <span class="n">MultiTaskGPyTorchModel</span><span class="p">,</span> <span class="n">FantasizeMixin</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Multi-Task exact GP model using an ICM (intrinsic co-regionalization model)</span>
<span class="sd">    kernel. See [Bonilla2007MTGP]_ and [Swersky2013MTBO]_ for a reference on the</span>
<span class="sd">    model and its use in Bayesian optimization.</span>

<span class="sd">    The model can be single-output or multi-output, determined by the `output_tasks`.</span>
<span class="sd">    This model uses relatively strong priors on the base Kernel hyperparameters, which</span>
<span class="sd">    work best when covariates are normalized to the unit cube and outcomes are</span>
<span class="sd">    standardized (zero mean, unit variance) - this standardization should be applied in</span>
<span class="sd">    a stratified fashion at the level of the tasks, rather than across all data points.</span>

<span class="sd">    If the `train_Yvar` is None, this model infers the noise level. If you have</span>
<span class="sd">    known observation noise, you can set `train_Yvar` to a tensor containing</span>
<span class="sd">    the noise variance measurements. WARNING: This currently does not support</span>
<span class="sd">    different noise levels for the different tasks.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">train_X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">train_Y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">task_feature</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">train_Yvar</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">mean_module</span><span class="p">:</span> <span class="n">Module</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">covar_module</span><span class="p">:</span> <span class="n">Module</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">likelihood</span><span class="p">:</span> <span class="n">Likelihood</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">task_covar_prior</span><span class="p">:</span> <span class="n">Prior</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_tasks</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">rank</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">all_tasks</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">outcome_transform</span><span class="p">:</span> <span class="n">OutcomeTransform</span> <span class="o">|</span> <span class="n">_DefaultType</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="n">DEFAULT</span><span class="p">,</span>
        <span class="n">input_transform</span><span class="p">:</span> <span class="n">InputTransform</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Multi-Task GP model using an ICM kernel.</span>

<span class="sd">        Args:</span>
<span class="sd">            train_X: A `n x (d + 1)` or `b x n x (d + 1)` (batch mode) tensor</span>
<span class="sd">                of training data. One of the columns should contain the task</span>
<span class="sd">                features (see `task_feature` argument).</span>
<span class="sd">            train_Y: A `n x 1` or `b x n x 1` (batch mode) tensor of training</span>
<span class="sd">                observations.</span>
<span class="sd">            task_feature: The index of the task feature (`-d &lt;= task_feature &lt;= d`).</span>
<span class="sd">            train_Yvar: An optional `n` or `b x n` (batch mode) tensor of observed</span>
<span class="sd">                measurement noise. If None, we infer the noise.</span>
<span class="sd">                Note that the inferred noise is common across all tasks.</span>
<span class="sd">            mean_module: The mean function to be used. Defaults to `ConstantMean`.</span>
<span class="sd">            covar_module: The module for computing the covariance matrix between</span>
<span class="sd">                the non-task features. Defaults to `RBFKernel`.</span>
<span class="sd">            likelihood: A likelihood. The default is selected based on `train_Yvar`.</span>
<span class="sd">                If `train_Yvar` is None, a standard `GaussianLikelihood` with inferred</span>
<span class="sd">                noise level is used. Otherwise, a FixedNoiseGaussianLikelihood is used.</span>
<span class="sd">            output_tasks: A list of task indices for which to compute model</span>
<span class="sd">                outputs for. If omitted, return outputs for all task indices.</span>
<span class="sd">            rank: The rank to be used for the index kernel. If omitted, use a</span>
<span class="sd">                full rank (i.e. number of tasks) kernel.</span>
<span class="sd">            task_covar_prior : A Prior on the task covariance matrix. Must operate</span>
<span class="sd">                on p.s.d. matrices. A common prior for this is the `LKJ` prior.</span>
<span class="sd">            all_tasks: By default, multi-task GPs infer the list of all tasks from</span>
<span class="sd">                the task features in `train_X`. This is an experimental feature that</span>
<span class="sd">                enables creation of multi-task GPs with tasks that don&#39;t appear in the</span>
<span class="sd">                training data. Note that when a task is not observed, the corresponding</span>
<span class="sd">                task covariance will heavily depend on random initialization and may</span>
<span class="sd">                behave unexpectedly.</span>
<span class="sd">            outcome_transform: An outcome transform that is applied to the</span>
<span class="sd">                training data during instantiation and to the posterior during</span>
<span class="sd">                inference (that is, the `Posterior` obtained by calling</span>
<span class="sd">                `.posterior` on the model will be on the original scale). We use a</span>
<span class="sd">                `Standardize` transform if no `outcome_transform` is specified.</span>
<span class="sd">                Pass down `None` to use no outcome transform. NOTE: Standardization</span>
<span class="sd">                should be applied in a stratified fashion, separately for each task.</span>
<span class="sd">            input_transform: An input transform that is applied in the model&#39;s</span>
<span class="sd">                forward pass.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; X1, X2 = torch.rand(10, 2), torch.rand(20, 2)</span>
<span class="sd">            &gt;&gt;&gt; i1, i2 = torch.zeros(10, 1), torch.ones(20, 1)</span>
<span class="sd">            &gt;&gt;&gt; train_X = torch.cat([</span>
<span class="sd">            &gt;&gt;&gt;     torch.cat([X1, i1], -1), torch.cat([X2, i2], -1),</span>
<span class="sd">            &gt;&gt;&gt; ])</span>
<span class="sd">            &gt;&gt;&gt; train_Y = torch.cat([f1(X1), f2(X2)]).unsqueeze(-1)</span>
<span class="sd">            &gt;&gt;&gt; model = MultiTaskGP(train_X, train_Y, task_feature=-1)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">transformed_X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_inputs</span><span class="p">(</span>
                <span class="n">X</span><span class="o">=</span><span class="n">train_X</span><span class="p">,</span> <span class="n">input_transform</span><span class="o">=</span><span class="n">input_transform</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_tensor_args</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">transformed_X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="n">train_Y</span><span class="p">,</span> <span class="n">Yvar</span><span class="o">=</span><span class="n">train_Yvar</span><span class="p">)</span>
        <span class="p">(</span>
            <span class="n">all_tasks_inferred</span><span class="p">,</span>
            <span class="n">task_feature</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_non_task_features</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_all_tasks</span><span class="p">(</span><span class="n">transformed_X</span><span class="p">,</span> <span class="n">task_feature</span><span class="p">,</span> <span class="n">output_tasks</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">all_tasks</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">set</span><span class="p">(</span><span class="n">all_tasks_inferred</span><span class="p">)</span><span class="o">.</span><span class="n">issubset</span><span class="p">(</span><span class="n">all_tasks</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">UnsupportedError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The provided </span><span class="si">{</span><span class="n">all_tasks</span><span class="si">=}</span><span class="s2"> does not contain all the task features &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;inferred from the training data </span><span class="si">{</span><span class="n">all_tasks_inferred</span><span class="si">=}</span><span class="s2">. &quot;</span>
                <span class="s2">&quot;This is not allowed as it will lead to errors during model training.&quot;</span>
            <span class="p">)</span>
        <span class="n">all_tasks</span> <span class="o">=</span> <span class="n">all_tasks</span> <span class="ow">or</span> <span class="n">all_tasks_inferred</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_tasks</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_tasks</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">outcome_transform</span> <span class="o">==</span> <span class="n">DEFAULT</span><span class="p">:</span>
            <span class="n">outcome_transform</span> <span class="o">=</span> <span class="n">Standardize</span><span class="p">(</span><span class="n">m</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_shape</span><span class="o">=</span><span class="n">train_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">outcome_transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">train_Y</span><span class="p">,</span> <span class="n">train_Yvar</span> <span class="o">=</span> <span class="n">outcome_transform</span><span class="p">(</span>
                <span class="n">Y</span><span class="o">=</span><span class="n">train_Y</span><span class="p">,</span> <span class="n">Yvar</span><span class="o">=</span><span class="n">train_Yvar</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">transformed_X</span>
            <span class="p">)</span>

        <span class="c1"># squeeze output dim</span>
        <span class="n">train_Y</span> <span class="o">=</span> <span class="n">train_Y</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">output_tasks</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">output_tasks</span> <span class="o">=</span> <span class="n">all_tasks</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">set</span><span class="p">(</span><span class="n">output_tasks</span><span class="p">)</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="n">all_tasks</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;All output tasks must be present in input data.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_output_tasks</span> <span class="o">=</span> <span class="n">output_tasks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_num_outputs</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_tasks</span><span class="p">)</span>

        <span class="c1"># TODO (T41270962): Support task-specific noise levels in likelihood</span>
        <span class="k">if</span> <span class="n">likelihood</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">train_Yvar</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">likelihood</span> <span class="o">=</span> <span class="n">get_gaussian_likelihood_with_lognormal_prior</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">likelihood</span> <span class="o">=</span> <span class="n">FixedNoiseGaussianLikelihood</span><span class="p">(</span><span class="n">noise</span><span class="o">=</span><span class="n">train_Yvar</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="c1"># construct indexer to be used in forward</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_task_feature</span> <span class="o">=</span> <span class="n">task_feature</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_base_idxr</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_non_task_features</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_base_idxr</span><span class="p">[</span><span class="n">task_feature</span><span class="p">:]</span> <span class="o">+=</span> <span class="mi">1</span>  <span class="c1"># exclude task feature</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">train_inputs</span><span class="o">=</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_targets</span><span class="o">=</span><span class="n">train_Y</span><span class="p">,</span> <span class="n">likelihood</span><span class="o">=</span><span class="n">likelihood</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean_module</span> <span class="o">=</span> <span class="n">mean_module</span> <span class="ow">or</span> <span class="n">ConstantMean</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">covar_module</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">covar_module</span> <span class="o">=</span> <span class="n">get_covar_module_with_dim_scaled_prior</span><span class="p">(</span>
                <span class="n">ard_num_dims</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_non_task_features</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">covar_module</span> <span class="o">=</span> <span class="n">covar_module</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_rank</span> <span class="o">=</span> <span class="n">rank</span> <span class="k">if</span> <span class="n">rank</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_tasks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">task_covar_module</span> <span class="o">=</span> <span class="n">IndexKernel</span><span class="p">(</span>
            <span class="n">num_tasks</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_tasks</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_rank</span><span class="p">,</span> <span class="n">prior</span><span class="o">=</span><span class="n">task_covar_prior</span>
        <span class="p">)</span>
        <span class="n">task_mapper</span> <span class="o">=</span> <span class="n">get_task_value_remapping</span><span class="p">(</span>
            <span class="n">task_values</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
                <span class="n">all_tasks</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">train_X</span><span class="o">.</span><span class="n">device</span>
            <span class="p">),</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">train_X</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;_task_mapper&quot;</span><span class="p">,</span> <span class="n">task_mapper</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_expected_task_values</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">all_tasks</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">input_transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">input_transform</span> <span class="o">=</span> <span class="n">input_transform</span>
        <span class="k">if</span> <span class="n">outcome_transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">outcome_transform</span> <span class="o">=</span> <span class="n">outcome_transform</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">train_X</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_split_inputs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Extracts base features and task indices from input data.</span>

<span class="sd">        Args:</span>
<span class="sd">            x: The full input tensor with trailing dimension of size `d + 1`.</span>
<span class="sd">                Should be of float/double data type.</span>

<span class="sd">        Returns:</span>
<span class="sd">            2-element tuple containing</span>

<span class="sd">            - A `q x d` or `b x q x d` (batch mode) tensor with trailing</span>
<span class="sd">            dimension made up of the `d` non-task-index columns of `x`, arranged</span>
<span class="sd">            in the order as specified by the indexer generated during model</span>
<span class="sd">            instantiation.</span>
<span class="sd">            - A `q` or `b x q` (batch mode) tensor of long data type containing</span>
<span class="sd">            the task indices.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">batch_shape</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">x_basic</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_base_idxr</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_shape</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">d</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]))</span>
        <span class="n">task_idcs</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">x</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_task_feature</span><span class="p">]</span>
            <span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_shape</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span>
            <span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">task_idcs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_map_tasks</span><span class="p">(</span><span class="n">task_values</span><span class="o">=</span><span class="n">task_idcs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x_basic</span><span class="p">,</span> <span class="n">task_idcs</span>

<div class="viewcode-block" id="MultiTaskGP.forward">
<a class="viewcode-back" href="../../../models.html#botorch.models.multitask.MultiTaskGP.forward">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MultivariateNormal</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_inputs</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x_basic</span><span class="p">,</span> <span class="n">task_idcs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_split_inputs</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># Compute base mean and covariance</span>
        <span class="n">mean_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_module</span><span class="p">(</span><span class="n">x_basic</span><span class="p">)</span>
        <span class="n">covar_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">covar_module</span><span class="p">(</span><span class="n">x_basic</span><span class="p">)</span>
        <span class="c1"># Compute task covariances</span>
        <span class="n">covar_i</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_covar_module</span><span class="p">(</span><span class="n">task_idcs</span><span class="p">)</span>
        <span class="c1"># Combine the two in an ICM fashion</span>
        <span class="n">covar</span> <span class="o">=</span> <span class="n">covar_x</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">covar_i</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">MultivariateNormal</span><span class="p">(</span><span class="n">mean_x</span><span class="p">,</span> <span class="n">covar</span><span class="p">)</span></div>


<div class="viewcode-block" id="MultiTaskGP.get_all_tasks">
<a class="viewcode-back" href="../../../models.html#botorch.models.multitask.MultiTaskGP.get_all_tasks">[docs]</a>
    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_all_tasks</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">train_X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">task_feature</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">output_tasks</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
        <span class="k">if</span> <span class="n">train_X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
            <span class="c1"># Currently, batch mode MTGPs are blocked upstream in GPyTorch</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported shape </span><span class="si">{</span><span class="n">train_X</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> for train_X.&quot;</span><span class="p">)</span>

        <span class="n">d</span> <span class="o">=</span> <span class="n">train_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="o">-</span><span class="n">d</span> <span class="o">&lt;=</span> <span class="n">task_feature</span> <span class="o">&lt;=</span> <span class="n">d</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Must have that -</span><span class="si">{</span><span class="n">d</span><span class="si">}</span><span class="s2"> &lt;= task_feature &lt;= </span><span class="si">{</span><span class="n">d</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">task_feature</span> <span class="o">=</span> <span class="n">task_feature</span> <span class="o">%</span> <span class="p">(</span><span class="n">d</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">all_tasks</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">train_X</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">task_feature</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="nb">sorted</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">all_tasks</span><span class="p">,</span> <span class="n">task_feature</span><span class="p">,</span> <span class="n">d</span></div>


<div class="viewcode-block" id="MultiTaskGP.construct_inputs">
<a class="viewcode-back" href="../../../models.html#botorch.models.multitask.MultiTaskGP.construct_inputs">[docs]</a>
    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">construct_inputs</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">training_data</span><span class="p">:</span> <span class="n">SupervisedDataset</span> <span class="o">|</span> <span class="n">MultiTaskDataset</span><span class="p">,</span>
        <span class="n">task_feature</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">output_tasks</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">task_covar_prior</span><span class="p">:</span> <span class="n">Prior</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">prior_config</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">rank</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Construct `Model` keyword arguments from a dataset and other args.</span>

<span class="sd">        Args:</span>
<span class="sd">            training_data: A `SupervisedDataset` or a `MultiTaskDataset`.</span>
<span class="sd">            task_feature: Column index of embedded task indicator features.</span>
<span class="sd">            output_tasks: A list of task indices for which to compute model</span>
<span class="sd">                outputs for. If omitted, return outputs for all task indices.</span>
<span class="sd">            task_covar_prior: A GPyTorch `Prior` object to use as prior on</span>
<span class="sd">                the cross-task covariance matrix,</span>
<span class="sd">            prior_config: Configuration for inter-task covariance prior.</span>
<span class="sd">                Should only be used if `task_covar_prior` is not passed directly. Must</span>
<span class="sd">                contain `use_LKJ_prior` indicator and should contain float value `eta`.</span>
<span class="sd">            rank: The rank of the cross-task covariance matrix.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">task_covar_prior</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">prior_config</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Only one of `task_covar_prior` and `prior_config` arguments expected.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">prior_config</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">prior_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;use_LKJ_prior&quot;</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Currently only config for LKJ prior is supported.&quot;</span><span class="p">)</span>

            <span class="n">num_tasks</span> <span class="o">=</span> <span class="n">training_data</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">task_feature</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
            <span class="n">sd_prior</span> <span class="o">=</span> <span class="n">GammaPrior</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">)</span>
            <span class="n">sd_prior</span><span class="o">.</span><span class="n">_event_shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">num_tasks</span><span class="p">])</span>
            <span class="n">eta</span> <span class="o">=</span> <span class="n">prior_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;eta&quot;</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">eta</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">eta</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;eta must be a real number, your eta was </span><span class="si">{</span><span class="n">eta</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
            <span class="n">task_covar_prior</span> <span class="o">=</span> <span class="n">LKJCovariancePrior</span><span class="p">(</span><span class="n">num_tasks</span><span class="p">,</span> <span class="n">eta</span><span class="p">,</span> <span class="n">sd_prior</span><span class="p">)</span>

        <span class="c1"># Call Model.construct_inputs to parse training data</span>
        <span class="n">base_inputs</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">construct_inputs</span><span class="p">(</span><span class="n">training_data</span><span class="o">=</span><span class="n">training_data</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="n">MultiTaskDataset</span><span class="p">)</span>
            <span class="c1"># If task features are included in the data, all tasks will have</span>
            <span class="c1"># some observations and they may have different task features.</span>
            <span class="ow">and</span> <span class="n">training_data</span><span class="o">.</span><span class="n">task_feature_index</span> <span class="ow">is</span> <span class="kc">None</span>
        <span class="p">):</span>
            <span class="n">all_tasks</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">training_data</span><span class="o">.</span><span class="n">datasets</span><span class="p">)))</span>
            <span class="n">base_inputs</span><span class="p">[</span><span class="s2">&quot;all_tasks&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">all_tasks</span>
        <span class="k">if</span> <span class="n">task_covar_prior</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">base_inputs</span><span class="p">[</span><span class="s2">&quot;task_covar_prior&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">task_covar_prior</span>
        <span class="k">if</span> <span class="n">rank</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">base_inputs</span><span class="p">[</span><span class="s2">&quot;rank&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">rank</span>
        <span class="n">base_inputs</span><span class="p">[</span><span class="s2">&quot;task_feature&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">task_feature</span>
        <span class="n">base_inputs</span><span class="p">[</span><span class="s2">&quot;output_tasks&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">output_tasks</span>
        <span class="k">return</span> <span class="n">base_inputs</span></div>
</div>



<div class="viewcode-block" id="KroneckerMultiTaskGP">
<a class="viewcode-back" href="../../../models.html#botorch.models.multitask.KroneckerMultiTaskGP">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">KroneckerMultiTaskGP</span><span class="p">(</span><span class="n">ExactGP</span><span class="p">,</span> <span class="n">GPyTorchModel</span><span class="p">,</span> <span class="n">FantasizeMixin</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Multi-task GP with Kronecker structure, using an ICM kernel.</span>

<span class="sd">    This model assumes the &quot;block design&quot; case, i.e., it requires that all tasks</span>
<span class="sd">    are observed at all data points.</span>

<span class="sd">    For posterior sampling, this model uses Matheron&#39;s rule [Doucet2010sampl] to compute</span>
<span class="sd">    the posterior over all tasks as in [Maddox2021bohdo] by exploiting Kronecker</span>
<span class="sd">    structure.</span>

<span class="sd">    When a multi-fidelity model has Kronecker structure, this means there is one</span>
<span class="sd">    covariance kernel over the fidelity features (call it `K_f`) and another over</span>
<span class="sd">    the rest of the input parameters (call it `K_i`), and the resulting covariance</span>
<span class="sd">    across inputs and fidelities is given by the Kronecker product of the two</span>
<span class="sd">    covariance matrices. This is equivalent to saying the covariance between</span>
<span class="sd">    two input and feature pairs is given by</span>

<span class="sd">    K((parameter_1, fidelity_1), (parameter_2, fidelity_2))</span>
<span class="sd">        = K_f(fidelity_1, fidelity_2) * K_i(parameter_1, parameter_2).</span>

<span class="sd">    Then the covariance matrix of `n_i` parameters and `n_f` fidelities can be</span>
<span class="sd">    codified as a Kronecker product of an `n_i x n_i` matrix and an</span>
<span class="sd">    `n_f x n_f` matrix, which is far more parsimonious than specifying the</span>
<span class="sd">    whole `(n_i * n_f) x (n_i * n_f)` covariance matrix.</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; train_X = torch.rand(10, 2)</span>
<span class="sd">        &gt;&gt;&gt; train_Y = torch.cat([f_1(X), f_2(X)], dim=-1)</span>
<span class="sd">        &gt;&gt;&gt; model = KroneckerMultiTaskGP(train_X, train_Y)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">train_X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">train_Y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">likelihood</span><span class="p">:</span> <span class="n">MultitaskGaussianLikelihood</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">data_covar_module</span><span class="p">:</span> <span class="n">Module</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">task_covar_prior</span><span class="p">:</span> <span class="n">Prior</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">rank</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">input_transform</span><span class="p">:</span> <span class="n">InputTransform</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">outcome_transform</span><span class="p">:</span> <span class="n">OutcomeTransform</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            train_X: A `batch_shape x n x d` tensor of training features.</span>
<span class="sd">            train_Y: A `batch_shape x n x m` tensor of training observations.</span>
<span class="sd">            likelihood: A `MultitaskGaussianLikelihood`. If omitted, uses a</span>
<span class="sd">                `MultitaskGaussianLikelihood` with a `GammaPrior(1.1, 0.05)`</span>
<span class="sd">                noise prior.</span>
<span class="sd">            data_covar_module: The module computing the covariance (Kernel) matrix</span>
<span class="sd">                in data space. If omitted, uses an `RBFKernel`.</span>
<span class="sd">            task_covar_prior : A Prior on the task covariance matrix. Must operate</span>
<span class="sd">                on p.s.d. matrices. A common prior for this is the `LKJ` prior. If</span>
<span class="sd">                omitted, uses `LKJCovariancePrior` with `eta` parameter as specified</span>
<span class="sd">                in the keyword arguments (if not specified, use `eta=1.5`).</span>
<span class="sd">            rank: The rank of the ICM kernel. If omitted, use a full rank kernel.</span>
<span class="sd">            kwargs: Additional arguments to override default settings of priors,</span>
<span class="sd">                including:</span>
<span class="sd">                - eta: The eta parameter on the default LKJ task_covar_prior.</span>
<span class="sd">                A value of 1.0 is uninformative, values &lt;1.0 favor stronger</span>
<span class="sd">                correlations (in magnitude), correlations vanish as eta -&gt; inf.</span>
<span class="sd">                - sd_prior: A scalar prior over nonnegative numbers, which is used</span>
<span class="sd">                for the default LKJCovariancePrior task_covar_prior.</span>
<span class="sd">                - likelihood_rank: The rank of the task covariance matrix to fit.</span>
<span class="sd">                Defaults to 0 (which corresponds to a diagonal covariance matrix).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">transformed_X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_inputs</span><span class="p">(</span>
                <span class="n">X</span><span class="o">=</span><span class="n">train_X</span><span class="p">,</span> <span class="n">input_transform</span><span class="o">=</span><span class="n">input_transform</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">outcome_transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">train_Y</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">outcome_transform</span><span class="p">(</span><span class="n">train_Y</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">transformed_X</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_tensor_args</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">transformed_X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="n">train_Y</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_num_outputs</span> <span class="o">=</span> <span class="n">train_Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">batch_shape</span><span class="p">,</span> <span class="n">ard_num_dims</span> <span class="o">=</span> <span class="n">train_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">train_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">num_tasks</span> <span class="o">=</span> <span class="n">train_Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">rank</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">rank</span> <span class="o">=</span> <span class="n">num_tasks</span>
        <span class="k">if</span> <span class="n">likelihood</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">noise_prior</span> <span class="o">=</span> <span class="n">LogNormalPrior</span><span class="p">(</span><span class="n">loc</span><span class="o">=-</span><span class="mf">4.0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
            <span class="n">likelihood</span> <span class="o">=</span> <span class="n">MultitaskGaussianLikelihood</span><span class="p">(</span>
                <span class="n">num_tasks</span><span class="o">=</span><span class="n">num_tasks</span><span class="p">,</span>
                <span class="n">batch_shape</span><span class="o">=</span><span class="n">batch_shape</span><span class="p">,</span>
                <span class="n">noise_prior</span><span class="o">=</span><span class="n">noise_prior</span><span class="p">,</span>
                <span class="n">noise_constraint</span><span class="o">=</span><span class="n">GreaterThan</span><span class="p">(</span>
                    <span class="n">MIN_INFERRED_NOISE_LEVEL</span><span class="p">,</span>
                    <span class="n">transform</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                    <span class="n">initial_value</span><span class="o">=</span><span class="n">noise_prior</span><span class="o">.</span><span class="n">mode</span><span class="p">,</span>
                <span class="p">),</span>
                <span class="n">rank</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;likelihood_rank&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">task_covar_prior</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">task_covar_prior</span> <span class="o">=</span> <span class="n">LKJCovariancePrior</span><span class="p">(</span>
                <span class="n">n</span><span class="o">=</span><span class="n">num_tasks</span><span class="p">,</span>
                <span class="n">eta</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;eta&quot;</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">train_X</span><span class="p">),</span>
                <span class="n">sd_prior</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                    <span class="s2">&quot;sd_prior&quot;</span><span class="p">,</span>
                    <span class="n">SmoothedBoxPrior</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mi">6</span><span class="p">),</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mf">1.25</span><span class="p">),</span> <span class="mf">0.05</span><span class="p">),</span>
                <span class="p">),</span>
            <span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean_module</span> <span class="o">=</span> <span class="n">MultitaskMean</span><span class="p">(</span>
            <span class="n">base_means</span><span class="o">=</span><span class="n">ConstantMean</span><span class="p">(</span><span class="n">batch_shape</span><span class="o">=</span><span class="n">batch_shape</span><span class="p">),</span> <span class="n">num_tasks</span><span class="o">=</span><span class="n">num_tasks</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">data_covar_module</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">data_covar_module</span> <span class="o">=</span> <span class="n">get_covar_module_with_dim_scaled_prior</span><span class="p">(</span>
                <span class="n">ard_num_dims</span><span class="o">=</span><span class="n">ard_num_dims</span><span class="p">,</span>
                <span class="n">batch_shape</span><span class="o">=</span><span class="n">batch_shape</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">data_covar_module</span> <span class="o">=</span> <span class="n">data_covar_module</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">covar_module</span> <span class="o">=</span> <span class="n">MultitaskKernel</span><span class="p">(</span>
            <span class="n">data_covar_module</span><span class="o">=</span><span class="n">data_covar_module</span><span class="p">,</span>
            <span class="n">num_tasks</span><span class="o">=</span><span class="n">num_tasks</span><span class="p">,</span>
            <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span>
            <span class="n">batch_shape</span><span class="o">=</span><span class="n">batch_shape</span><span class="p">,</span>
            <span class="n">task_covar_prior</span><span class="o">=</span><span class="n">task_covar_prior</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">outcome_transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">outcome_transform</span> <span class="o">=</span> <span class="n">outcome_transform</span>
        <span class="k">if</span> <span class="n">input_transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">input_transform</span> <span class="o">=</span> <span class="n">input_transform</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">train_X</span><span class="p">)</span>

<div class="viewcode-block" id="KroneckerMultiTaskGP.forward">
<a class="viewcode-back" href="../../../models.html#botorch.models.multitask.KroneckerMultiTaskGP.forward">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MultitaskMultivariateNormal</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_inputs</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="n">mean_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_module</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">covar_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">covar_module</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">MultitaskMultivariateNormal</span><span class="p">(</span><span class="n">mean_x</span><span class="p">,</span> <span class="n">covar_x</span><span class="p">)</span></div>


    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_task_covar_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">covar_module</span><span class="o">.</span><span class="n">task_covar_module</span><span class="o">.</span><span class="n">covar_matrix</span>
        <span class="k">if</span> <span class="n">detach_test_caches</span><span class="o">.</span><span class="n">on</span><span class="p">():</span>
            <span class="n">res</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">res</span>

    <span class="nd">@property</span>
    <span class="nd">@cached</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;train_full_covar&quot;</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">train_full_covar</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">train_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_inputs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="c1"># construct Kxx \otimes Ktt</span>
        <span class="n">train_full_covar</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">covar_module</span><span class="p">(</span><span class="n">train_x</span><span class="p">)</span><span class="o">.</span><span class="n">evaluate_kernel</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">detach_test_caches</span><span class="o">.</span><span class="n">on</span><span class="p">():</span>
            <span class="n">train_full_covar</span> <span class="o">=</span> <span class="n">train_full_covar</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">train_full_covar</span>

    <span class="nd">@property</span>
    <span class="nd">@cached</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;predictive_mean_cache&quot;</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">predictive_mean_cache</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">train_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_inputs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">train_noise</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span><span class="o">.</span><span class="n">_shaped_noise_covar</span><span class="p">(</span><span class="n">train_x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">detach_test_caches</span><span class="o">.</span><span class="n">on</span><span class="p">():</span>
            <span class="n">train_noise</span> <span class="o">=</span> <span class="n">train_noise</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

        <span class="n">train_diff</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_targets</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_module</span><span class="p">(</span><span class="n">train_x</span><span class="p">)</span>
        <span class="n">train_solve</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_full_covar</span> <span class="o">+</span> <span class="n">train_noise</span><span class="p">)</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span>
            <span class="n">train_diff</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="n">train_diff</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">detach_test_caches</span><span class="o">.</span><span class="n">on</span><span class="p">():</span>
            <span class="n">train_solve</span> <span class="o">=</span> <span class="n">train_solve</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">train_solve</span>

<div class="viewcode-block" id="KroneckerMultiTaskGP.posterior">
<a class="viewcode-back" href="../../../models.html#botorch.models.multitask.KroneckerMultiTaskGP.posterior">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">posterior</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">output_indices</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">observation_noise</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">PosteriorTransform</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MultitaskGPPosterior</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">posterior_transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># this could be very costly, disallow for now</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="s2">&quot;Posterior transforms currently not supported for &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_inputs</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">train_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_inputs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="c1"># construct Ktt</span>
        <span class="n">task_covar</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_task_covar_matrix</span>
        <span class="n">task_rootlt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_task_covar_matrix</span><span class="o">.</span><span class="n">root_decomposition</span><span class="p">(</span>
            <span class="n">method</span><span class="o">=</span><span class="s2">&quot;diagonalization&quot;</span>
        <span class="p">)</span>
        <span class="n">task_root</span> <span class="o">=</span> <span class="n">task_rootlt</span><span class="o">.</span><span class="n">root</span>
        <span class="k">if</span> <span class="n">task_covar</span><span class="o">.</span><span class="n">batch_shape</span> <span class="o">!=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]:</span>
            <span class="n">task_covar</span> <span class="o">=</span> <span class="n">BatchRepeatLinearOperator</span><span class="p">(</span>
                <span class="n">task_covar</span><span class="p">,</span> <span class="n">batch_repeat</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
            <span class="p">)</span>
            <span class="n">task_root</span> <span class="o">=</span> <span class="n">BatchRepeatLinearOperator</span><span class="p">(</span>
                <span class="n">to_linear_operator</span><span class="p">(</span><span class="n">task_root</span><span class="p">),</span> <span class="n">batch_repeat</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
            <span class="p">)</span>

        <span class="n">task_covar_rootlt</span> <span class="o">=</span> <span class="n">RootLinearOperator</span><span class="p">(</span><span class="n">task_root</span><span class="p">)</span>

        <span class="c1"># construct RR&#39; \approx Kxx</span>
        <span class="n">data_data_covar</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_full_covar</span><span class="o">.</span><span class="n">linear_ops</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># populate the diagonalziation caches for the root and inverse root</span>
        <span class="c1"># decomposition</span>
        <span class="n">data_data_evals</span><span class="p">,</span> <span class="n">data_data_evecs</span> <span class="o">=</span> <span class="n">data_data_covar</span><span class="o">.</span><span class="n">diagonalization</span><span class="p">()</span>

        <span class="c1"># pad the eigenvalue and eigenvectors with zeros if we are using lanczos</span>
        <span class="k">if</span> <span class="n">data_data_evecs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">data_data_evecs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]:</span>
            <span class="n">cols_to_add</span> <span class="o">=</span> <span class="n">data_data_evecs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="n">data_data_evecs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">zero_evecs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                <span class="o">*</span><span class="n">data_data_evecs</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                <span class="n">cols_to_add</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">data_data_evals</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="n">data_data_evals</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">zero_evals</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                <span class="o">*</span><span class="n">data_data_evecs</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span>
                <span class="n">cols_to_add</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">data_data_evals</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="n">data_data_evals</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">data_data_evecs</span> <span class="o">=</span> <span class="n">CatLinearOperator</span><span class="p">(</span>
                <span class="n">data_data_evecs</span><span class="p">,</span>
                <span class="n">to_linear_operator</span><span class="p">(</span><span class="n">zero_evecs</span><span class="p">),</span>
                <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">output_device</span><span class="o">=</span><span class="n">data_data_evals</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">data_data_evals</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">data_data_evals</span><span class="p">,</span> <span class="n">zero_evals</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># construct K_{xt, x}</span>
        <span class="n">test_data_covar</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">covar_module</span><span class="o">.</span><span class="n">data_covar_module</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">train_x</span><span class="p">)</span>
        <span class="c1"># construct K_{xt, xt}</span>
        <span class="n">test_test_covar</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">covar_module</span><span class="o">.</span><span class="n">data_covar_module</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="c1"># now update root so that \tilde{R}\tilde{R}&#39; \approx K_{(x,xt), (x,xt)}</span>
        <span class="c1"># cloning preserves the gradient history</span>
        <span class="n">updated_linear_op</span> <span class="o">=</span> <span class="n">data_data_covar</span><span class="o">.</span><span class="n">cat_rows</span><span class="p">(</span>
            <span class="n">cross_mat</span><span class="o">=</span><span class="n">test_data_covar</span><span class="o">.</span><span class="n">clone</span><span class="p">(),</span>
            <span class="n">new_mat</span><span class="o">=</span><span class="n">test_test_covar</span><span class="p">,</span>
            <span class="n">method</span><span class="o">=</span><span class="s2">&quot;diagonalization&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">updated_root</span> <span class="o">=</span> <span class="n">updated_linear_op</span><span class="o">.</span><span class="n">root_decomposition</span><span class="p">()</span><span class="o">.</span><span class="n">root</span>
        <span class="c1"># occasionally, there&#39;s device errors so enforce this comes out right</span>
        <span class="n">updated_root</span> <span class="o">=</span> <span class="n">updated_root</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">data_data_covar</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># build a root decomposition of the joint train/test covariance matrix</span>
        <span class="c1"># construct (\tilde{R} \otimes M)(\tilde{R} \otimes M)&#39; \approx</span>
        <span class="c1"># (K_{(x,xt), (x,xt)} \otimes Ktt)</span>
        <span class="n">joint_covar</span> <span class="o">=</span> <span class="n">RootLinearOperator</span><span class="p">(</span>
            <span class="n">KroneckerProductLinearOperator</span><span class="p">(</span>
                <span class="n">updated_root</span><span class="p">,</span> <span class="n">task_covar_rootlt</span><span class="o">.</span><span class="n">root</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># construct K_{xt, x} \otimes Ktt</span>
        <span class="n">test_obs_kernel</span> <span class="o">=</span> <span class="n">KroneckerProductLinearOperator</span><span class="p">(</span><span class="n">test_data_covar</span><span class="p">,</span> <span class="n">task_covar</span><span class="p">)</span>

        <span class="c1"># collect y - \mu(x) and \mu(X)</span>
        <span class="n">train_diff</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_targets</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_module</span><span class="p">(</span><span class="n">train_x</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">detach_test_caches</span><span class="o">.</span><span class="n">on</span><span class="p">():</span>
            <span class="n">train_diff</span> <span class="o">=</span> <span class="n">train_diff</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
        <span class="n">test_mean</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_module</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="n">train_noise</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span><span class="o">.</span><span class="n">_shaped_noise_covar</span><span class="p">(</span><span class="n">train_x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">diagonal_noise</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">train_noise</span><span class="p">,</span> <span class="n">DiagLinearOperator</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">detach_test_caches</span><span class="o">.</span><span class="n">on</span><span class="p">():</span>
            <span class="n">train_noise</span> <span class="o">=</span> <span class="n">train_noise</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
        <span class="n">test_noise</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span><span class="o">.</span><span class="n">_shaped_noise_covar</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">observation_noise</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="p">)</span>

        <span class="c1"># predictive mean and variance for the mvn</span>
        <span class="c1"># first the predictive mean</span>
        <span class="n">pred_mean</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">test_obs_kernel</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">predictive_mean_cache</span><span class="p">)</span><span class="o">.</span><span class="n">reshape_as</span><span class="p">(</span><span class="n">test_mean</span><span class="p">)</span>
            <span class="o">+</span> <span class="n">test_mean</span>
        <span class="p">)</span>
        <span class="c1"># next the predictive variance, assume diagonal noise</span>
        <span class="n">test_var_term</span> <span class="o">=</span> <span class="n">KroneckerProductLinearOperator</span><span class="p">(</span>
            <span class="n">test_test_covar</span><span class="p">,</span> <span class="n">task_covar</span>
        <span class="p">)</span><span class="o">.</span><span class="n">diagonal</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">diagonal_noise</span><span class="p">:</span>
            <span class="n">task_evals</span><span class="p">,</span> <span class="n">task_evecs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_task_covar_matrix</span><span class="o">.</span><span class="n">diagonalization</span><span class="p">()</span>
            <span class="c1"># TODO: make this be the default KPMatmulLT diagonal method in gpytorch</span>
            <span class="n">full_data_inv_evals</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">KroneckerProductDiagLinearOperator</span><span class="p">(</span>
                    <span class="n">DiagLinearOperator</span><span class="p">(</span><span class="n">data_data_evals</span><span class="p">),</span> <span class="n">DiagLinearOperator</span><span class="p">(</span><span class="n">task_evals</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="o">+</span> <span class="n">train_noise</span>
            <span class="p">)</span><span class="o">.</span><span class="n">inverse</span><span class="p">()</span>
            <span class="n">test_train_hadamard</span> <span class="o">=</span> <span class="n">KroneckerProductLinearOperator</span><span class="p">(</span>
                <span class="n">test_data_covar</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">data_data_evecs</span><span class="p">)</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span>
                <span class="n">task_covar</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">task_evecs</span><span class="p">)</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">data_var_term</span> <span class="o">=</span> <span class="n">test_train_hadamard</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">full_data_inv_evals</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># if non-diagonal noise (but still kronecker structured), we have to pull</span>
            <span class="c1"># across the noise because the inverse is not closed form</span>
            <span class="c1"># should be a kronecker lt, R = \Sigma_X^{-1/2} \kron \Sigma_T^{-1/2}</span>
            <span class="c1"># TODO: enforce the diagonalization to return a KPLT for all shapes in</span>
            <span class="c1"># gpytorch or dense linear algebra for small shapes</span>
            <span class="n">data_noise</span><span class="p">,</span> <span class="n">task_noise</span> <span class="o">=</span> <span class="n">train_noise</span><span class="o">.</span><span class="n">linear_ops</span>
            <span class="n">data_noise_root</span> <span class="o">=</span> <span class="n">data_noise</span><span class="o">.</span><span class="n">root_inv_decomposition</span><span class="p">(</span>
                <span class="n">method</span><span class="o">=</span><span class="s2">&quot;diagonalization&quot;</span>
            <span class="p">)</span>
            <span class="n">task_noise_root</span> <span class="o">=</span> <span class="n">task_noise</span><span class="o">.</span><span class="n">root_inv_decomposition</span><span class="p">(</span>
                <span class="n">method</span><span class="o">=</span><span class="s2">&quot;diagonalization&quot;</span>
            <span class="p">)</span>

            <span class="c1"># ultimately we need to compute the diagonal of</span>
            <span class="c1"># (K_{x* X} \kron K_T)(K_{XX} \kron K_T + \Sigma_X \kron \Sigma_T)^{-1}</span>
            <span class="c1">#                           (K_{x* X} \kron K_T)^T</span>
            <span class="c1"># = (K_{x* X} \Sigma_X^{-1/2} Q_R)(\Lambda_R + I)^{-1}</span>
            <span class="c1">#                       (K_{x* X} \Sigma_X^{-1/2} Q_R)^T</span>
            <span class="c1"># where R = (\Sigma_X^{-1/2T}K_{XX}\Sigma_X^{-1/2} \kron</span>
            <span class="c1">#                   \Sigma_T^{-1/2T}K_{T}\Sigma_T^{-1/2})</span>
            <span class="c1"># first we construct the components of R&#39;s eigen-decomposition</span>
            <span class="c1"># TODO: make this be the default KPMatmulLT diagonal method in gpytorch</span>
            <span class="n">whitened_data_covar</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">data_noise_root</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span>
                <span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">data_data_covar</span><span class="p">)</span>
                <span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">data_noise_root</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">w_data_evals</span><span class="p">,</span> <span class="n">w_data_evecs</span> <span class="o">=</span> <span class="n">whitened_data_covar</span><span class="o">.</span><span class="n">diagonalization</span><span class="p">()</span>
            <span class="n">whitened_task_covar</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">task_noise_root</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span>
                <span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_task_covar_matrix</span><span class="p">)</span>
                <span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">task_noise_root</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">w_task_evals</span><span class="p">,</span> <span class="n">w_task_evecs</span> <span class="o">=</span> <span class="n">whitened_task_covar</span><span class="o">.</span><span class="n">diagonalization</span><span class="p">()</span>

            <span class="c1"># we add one to the eigenvalues as above (not just for stability)</span>
            <span class="n">full_data_inv_evals</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">KroneckerProductDiagLinearOperator</span><span class="p">(</span>
                    <span class="n">DiagLinearOperator</span><span class="p">(</span><span class="n">w_data_evals</span><span class="p">),</span> <span class="n">DiagLinearOperator</span><span class="p">(</span><span class="n">w_task_evals</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="o">.</span><span class="n">add_jitter</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
                <span class="o">.</span><span class="n">inverse</span><span class="p">()</span>
            <span class="p">)</span>

            <span class="n">test_data_comp</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">test_data_covar</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">data_noise_root</span><span class="p">)</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">w_data_evecs</span><span class="p">)</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span>
                <span class="o">**</span> <span class="mi">2</span>
            <span class="p">)</span>
            <span class="n">task_comp</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">task_covar</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">task_noise_root</span><span class="p">)</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">w_task_evecs</span><span class="p">)</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span> <span class="o">**</span> <span class="mi">2</span>
            <span class="p">)</span>

            <span class="n">test_train_hadamard</span> <span class="o">=</span> <span class="n">KroneckerProductLinearOperator</span><span class="p">(</span>
                <span class="n">test_data_comp</span><span class="p">,</span> <span class="n">task_comp</span>
            <span class="p">)</span>
            <span class="n">data_var_term</span> <span class="o">=</span> <span class="n">test_train_hadamard</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">full_data_inv_evals</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">pred_variance</span> <span class="o">=</span> <span class="n">test_var_term</span> <span class="o">-</span> <span class="n">data_var_term</span>
        <span class="n">specialized_mvn</span> <span class="o">=</span> <span class="n">MultitaskMultivariateNormal</span><span class="p">(</span>
            <span class="n">pred_mean</span><span class="p">,</span> <span class="n">DiagLinearOperator</span><span class="p">(</span><span class="n">pred_variance</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">observation_noise</span><span class="p">:</span>
            <span class="n">specialized_mvn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span><span class="p">(</span><span class="n">specialized_mvn</span><span class="p">)</span>

        <span class="n">posterior</span> <span class="o">=</span> <span class="n">MultitaskGPPosterior</span><span class="p">(</span>
            <span class="n">distribution</span><span class="o">=</span><span class="n">specialized_mvn</span><span class="p">,</span>
            <span class="n">joint_covariance_matrix</span><span class="o">=</span><span class="n">joint_covar</span><span class="p">,</span>
            <span class="n">test_train_covar</span><span class="o">=</span><span class="n">test_obs_kernel</span><span class="p">,</span>
            <span class="n">train_diff</span><span class="o">=</span><span class="n">train_diff</span><span class="p">,</span>
            <span class="n">test_mean</span><span class="o">=</span><span class="n">test_mean</span><span class="p">,</span>
            <span class="n">train_train_covar</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_full_covar</span><span class="p">,</span>
            <span class="n">train_noise</span><span class="o">=</span><span class="n">train_noise</span><span class="p">,</span>
            <span class="n">test_noise</span><span class="o">=</span><span class="n">test_noise</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;outcome_transform&quot;</span><span class="p">):</span>
            <span class="n">posterior</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">outcome_transform</span><span class="o">.</span><span class="n">untransform_posterior</span><span class="p">(</span><span class="n">posterior</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">posterior</span></div>


<div class="viewcode-block" id="KroneckerMultiTaskGP.train">
<a class="viewcode-back" href="../../../models.html#botorch.models.multitask.KroneckerMultiTaskGP.train">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">val</span><span class="p">:</span>
            <span class="n">fixed_cache_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;data_data_roots&quot;</span><span class="p">,</span> <span class="s2">&quot;train_full_covar&quot;</span><span class="p">,</span> <span class="s2">&quot;task_root&quot;</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">fixed_cache_names</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">pop_from_cache</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
                <span class="k">except</span> <span class="n">CachingError</span><span class="p">:</span>
                    <span class="k">pass</span>

        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>
</div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p></p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>