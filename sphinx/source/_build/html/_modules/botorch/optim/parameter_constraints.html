

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>botorch.optim.parameter_constraints &mdash; BoTorch  documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=03e43079" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../../_static/custom.css?v=ca3e82f4" />

  
      <script src="../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../_static/documentation_options.js?v=5929fcd5"></script>
      <script src="../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            BoTorch
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../acquisition.html">botorch.acquisition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models.html">botorch.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generation.html">botorch.generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../posteriors.html">botorch.posteriors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../optim.html">botorch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../fit.html">botorch.fit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../sampling.html">botorch.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cross_validation.html">botorch.cross_validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../settings.html">botorch.settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../logging.html">botorch.logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../test_functions.html">botorch.test_functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../test_utils.html">botorch.test_utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../exceptions.html">botorch.exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../utils.html">botorch.utils</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">BoTorch</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">botorch.optim.parameter_constraints</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for botorch.optim.parameter_constraints</h1><div class="highlight"><pre>
<span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="c1"># Copyright (c) Meta Platforms, Inc. and affiliates.</span>
<span class="c1">#</span>
<span class="c1"># This source code is licensed under the MIT license found in the</span>
<span class="c1"># LICENSE file in the root directory of this source tree.</span>

<span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Utility functions for constrained optimization.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">__future__</span><span class="w"> </span><span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">collections.abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">Callable</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">functools</span><span class="w"> </span><span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Union</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy.typing</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">npt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.exceptions.errors</span><span class="w"> </span><span class="kn">import</span> <span class="n">CandidateGenerationError</span><span class="p">,</span> <span class="n">UnsupportedError</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.optimize</span><span class="w"> </span><span class="kn">import</span> <span class="n">Bounds</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">Tensor</span>


<span class="n">ScipyConstraintDict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">[</span>
    <span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="nb">float</span><span class="p">],</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]</span>
<span class="p">]</span>
<span class="n">CONST_TOL</span> <span class="o">=</span> <span class="mf">1e-6</span>


<div class="viewcode-block" id="make_scipy_bounds">
<a class="viewcode-back" href="../../../optim.html#botorch.optim.parameter_constraints.make_scipy_bounds">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">make_scipy_bounds</span><span class="p">(</span>
    <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">lower_bounds</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">upper_bounds</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Bounds</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Creates a scipy Bounds object for optimziation</span>

<span class="sd">    Args:</span>
<span class="sd">        X: `... x d` tensor</span>
<span class="sd">        lower_bounds: Lower bounds on each column (last dimension) of `X`. If</span>
<span class="sd">            this is a single float, then all columns have the same bound.</span>
<span class="sd">        upper_bounds: Lower bounds on each column (last dimension) of `X`. If</span>
<span class="sd">            this is a single float, then all columns have the same bound.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A scipy `Bounds` object if either lower_bounds or upper_bounds is not</span>
<span class="sd">        None, and None otherwise.</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; X = torch.rand(5, 2)</span>
<span class="sd">        &gt;&gt;&gt; scipy_bounds = make_scipy_bounds(X, 0.1, 0.8)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">lower_bounds</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">upper_bounds</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_expand</span><span class="p">(</span><span class="n">bounds</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">lower</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">bounds</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ebounds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;-inf&quot;</span> <span class="k">if</span> <span class="n">lower</span> <span class="k">else</span> <span class="s2">&quot;inf&quot;</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">bounds</span><span class="p">):</span>
                <span class="n">bounds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">bounds</span><span class="p">)</span>
            <span class="n">ebounds</span> <span class="o">=</span> <span class="n">bounds</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">_arrayify</span><span class="p">(</span><span class="n">ebounds</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

    <span class="n">lb</span> <span class="o">=</span> <span class="n">_expand</span><span class="p">(</span><span class="n">bounds</span><span class="o">=</span><span class="n">lower_bounds</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">ub</span> <span class="o">=</span> <span class="n">_expand</span><span class="p">(</span><span class="n">bounds</span><span class="o">=</span><span class="n">upper_bounds</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Bounds</span><span class="p">(</span><span class="n">lb</span><span class="o">=</span><span class="n">lb</span><span class="p">,</span> <span class="n">ub</span><span class="o">=</span><span class="n">ub</span><span class="p">,</span> <span class="n">keep_feasible</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></div>



<div class="viewcode-block" id="make_scipy_linear_constraints">
<a class="viewcode-back" href="../../../optim.html#botorch.optim.parameter_constraints.make_scipy_linear_constraints">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">make_scipy_linear_constraints</span><span class="p">(</span>
    <span class="n">shapeX</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">,</span>
    <span class="n">inequality_constraints</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">equality_constraints</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">ScipyConstraintDict</span><span class="p">]:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Generate scipy constraints from torch representation.</span>

<span class="sd">    Args:</span>
<span class="sd">        shapeX: The shape of the torch.Tensor to optimize over (i.e. `(b) x q x d`)</span>
<span class="sd">        inequality constraints: A list of tuples (indices, coefficients, rhs),</span>
<span class="sd">            with each tuple encoding an inequality constraint of the form</span>
<span class="sd">            `\sum_i (X[indices[i]] * coefficients[i]) &gt;= rhs`, where</span>
<span class="sd">            `indices` is a single-dimensional index tensor (long dtype) containing</span>
<span class="sd">            indices into the last dimension of `X`, `coefficients` is a</span>
<span class="sd">            single-dimensional tensor of coefficients of the same length, and</span>
<span class="sd">            rhs is a scalar.</span>
<span class="sd">        equality constraints: A list of tuples (indices, coefficients, rhs),</span>
<span class="sd">            with each tuple encoding an inequality constraint of the form</span>
<span class="sd">            `\sum_i (X[indices[i]] * coefficients[i]) == rhs` (with `indices`</span>
<span class="sd">            and `coefficients` of the same form as in `inequality_constraints`).</span>

<span class="sd">    Returns:</span>
<span class="sd">        A list of dictionaries containing callables for constraint function</span>
<span class="sd">        values and Jacobians and a string indicating the associated constraint</span>
<span class="sd">        type (&quot;eq&quot;, &quot;ineq&quot;), as expected by `scipy.minimize`.</span>

<span class="sd">    This function assumes that constraints are the same for each input batch,</span>
<span class="sd">    and broadcasts the constraints accordingly to the input batch shape. This</span>
<span class="sd">    function does support constraints across elements of a q-batch if the</span>
<span class="sd">    indices are a 2-d Tensor.</span>

<span class="sd">    Example:</span>
<span class="sd">        The following will enforce that `x[1] + 0.5 x[3] &gt;= -0.1` for each `x`</span>
<span class="sd">        in both elements of the q-batch, and each of the 3 t-batches:</span>

<span class="sd">        &gt;&gt;&gt; constraints = make_scipy_linear_constraints(</span>
<span class="sd">        &gt;&gt;&gt;     torch.Size([3, 2, 4]),</span>
<span class="sd">        &gt;&gt;&gt;     [(torch.tensor([1, 3]), torch.tensor([1.0, 0.5]), -0.1)],</span>
<span class="sd">        &gt;&gt;&gt; )</span>

<span class="sd">        The following will enforce that `x[0, 1] + 0.5 x[1, 3] &gt;= -0.1` where</span>
<span class="sd">        x[0, :] is the first element of the q-batch and x[1, :] is the second</span>
<span class="sd">        element of the q-batch, for each of the 3 t-batches:</span>

<span class="sd">        &gt;&gt;&gt; constraints = make_scipy_linear_constraints(</span>
<span class="sd">        &gt;&gt;&gt;     torch.size([3, 2, 4])</span>
<span class="sd">        &gt;&gt;&gt;     [(torch.tensor([[0, 1], [1, 3]), torch.tensor([1.0, 0.5]), -0.1)],</span>
<span class="sd">        &gt;&gt;&gt; )</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">constraints</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="n">inequality_constraints</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">indcs</span><span class="p">,</span> <span class="n">coeffs</span><span class="p">,</span> <span class="n">rhs</span> <span class="ow">in</span> <span class="n">inequality_constraints</span><span class="p">:</span>
            <span class="n">constraints</span> <span class="o">+=</span> <span class="n">_make_linear_constraints</span><span class="p">(</span>
                <span class="n">indices</span><span class="o">=</span><span class="n">indcs</span><span class="p">,</span> <span class="n">coefficients</span><span class="o">=</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">rhs</span><span class="o">=</span><span class="n">rhs</span><span class="p">,</span> <span class="n">shapeX</span><span class="o">=</span><span class="n">shapeX</span><span class="p">,</span> <span class="n">eq</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>
    <span class="k">if</span> <span class="n">equality_constraints</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">indcs</span><span class="p">,</span> <span class="n">coeffs</span><span class="p">,</span> <span class="n">rhs</span> <span class="ow">in</span> <span class="n">equality_constraints</span><span class="p">:</span>
            <span class="n">constraints</span> <span class="o">+=</span> <span class="n">_make_linear_constraints</span><span class="p">(</span>
                <span class="n">indices</span><span class="o">=</span><span class="n">indcs</span><span class="p">,</span> <span class="n">coefficients</span><span class="o">=</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">rhs</span><span class="o">=</span><span class="n">rhs</span><span class="p">,</span> <span class="n">shapeX</span><span class="o">=</span><span class="n">shapeX</span><span class="p">,</span> <span class="n">eq</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>
    <span class="k">return</span> <span class="n">constraints</span></div>



<div class="viewcode-block" id="eval_lin_constraint">
<a class="viewcode-back" href="../../../optim.html#botorch.optim.parameter_constraints.eval_lin_constraint">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">eval_lin_constraint</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">,</span> <span class="n">flat_idxr</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">coeffs</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">,</span> <span class="n">rhs</span><span class="p">:</span> <span class="nb">float</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Evaluate a single linear constraint.</span>

<span class="sd">    Args:</span>
<span class="sd">        x: The input array.</span>
<span class="sd">        flat_idxr: The indices in `x` to consider.</span>
<span class="sd">        coeffs: The coefficients corresponding to the indices.</span>
<span class="sd">        rhs: The right-hand-side of the constraint.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The evaluted constraint: `\sum_i (coeffs[i] * x[i]) - rhs`</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">flat_idxr</span><span class="p">]</span> <span class="o">*</span> <span class="n">coeffs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">rhs</span></div>



<div class="viewcode-block" id="lin_constraint_jac">
<a class="viewcode-back" href="../../../optim.html#botorch.optim.parameter_constraints.lin_constraint_jac">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">lin_constraint_jac</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">,</span> <span class="n">flat_idxr</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">coeffs</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">,</span> <span class="n">n</span><span class="p">:</span> <span class="nb">int</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Return the Jacobian associated with a linear constraint.</span>

<span class="sd">    Args:</span>
<span class="sd">        x: The input array.</span>
<span class="sd">        flat_idxr: The indices for the elements of x that appear in the constraint.</span>
<span class="sd">        coeffs: The coefficients corresponding to the indices.</span>
<span class="sd">        n: number of elements</span>

<span class="sd">    Returns:</span>
<span class="sd">        The Jacobian.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Use sparse representation (not sure if scipy optim supports that)</span>
    <span class="n">jac</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="n">jac</span><span class="p">[</span><span class="n">flat_idxr</span><span class="p">]</span> <span class="o">=</span> <span class="n">coeffs</span>
    <span class="k">return</span> <span class="n">jac</span></div>



<span class="k">def</span><span class="w"> </span><span class="nf">_arrayify</span><span class="p">(</span><span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Convert a torch.Tensor (any dtype or device) to a numpy (double) array.</span>

<span class="sd">    Args:</span>
<span class="sd">        X: The input tensor.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A numpy array of double dtype with the same shape and data as `X`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">X</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">double</span><span class="p">()</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_validate_linear_constraints_shape_input</span><span class="p">(</span><span class="n">shapeX</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Validate `shapeX` input to `_make_linear_constraints`.</span>

<span class="sd">    Check that it has either 2 or 3 dimensions, and add a scalar batch</span>
<span class="sd">    dimension if it is only 2d.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shapeX</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">):</span>
        <span class="k">raise</span> <span class="n">UnsupportedError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;`shapeX` must be `(b) x q x d` (at least two-dimensional). It is &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">shapeX</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shapeX</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">shapeX</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">shapeX</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">shapeX</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_validate_linear_constraints_indices_input</span><span class="p">(</span><span class="n">indices</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">q</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">d</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">indices</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">UnsupportedError</span><span class="p">(</span>
            <span class="s2">&quot;Linear constraints supported only on individual candidates and &quot;</span>
            <span class="s2">&quot;across q-batches, not across general batch shapes.&quot;</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="n">indices</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">indices</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">&gt;</span> <span class="n">q</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Index out of bounds for </span><span class="si">{</span><span class="n">q</span><span class="si">}</span><span class="s2">-batch&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">indices</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">&gt;</span> <span class="n">d</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Index out of bounds for </span><span class="si">{</span><span class="n">d</span><span class="si">}</span><span class="s2">-dim parameter tensor&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">indices</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">indices</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">&gt;</span> <span class="n">d</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Index out of bounds for </span><span class="si">{</span><span class="n">d</span><span class="si">}</span><span class="s2">-dim parameter tensor&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`indices` must be at least one-dimensional&quot;</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_make_linear_constraints</span><span class="p">(</span>
    <span class="n">indices</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">coefficients</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">rhs</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">shapeX</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">,</span>
    <span class="n">eq</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">ScipyConstraintDict</span><span class="p">]:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Create linear constraints to be used by `scipy.minimize`.</span>

<span class="sd">    Encodes constraints of the form</span>
<span class="sd">    `\sum_i (coefficients[i] * X[..., indices[i]]) ? rhs`</span>
<span class="sd">    where `?` can be designated either as `&gt;=` by setting `eq=False`, or as</span>
<span class="sd">    `=` by setting `eq=True`.</span>

<span class="sd">    If indices is one-dimensional, the constraints are broadcasted across</span>
<span class="sd">    all elements of the q-batch. If indices is two-dimensional, then</span>
<span class="sd">    constraints are applied across elements of a q-batch. In either case,</span>
<span class="sd">    constraints are created for all t-batches.</span>

<span class="sd">    Args:</span>
<span class="sd">        indices: A tensor of shape `c` or `c x 2`, where c is the number of terms</span>
<span class="sd">            in the constraint. If single-dimensional, contains the indices of</span>
<span class="sd">            the dimensions of the feature space that occur in the linear</span>
<span class="sd">            constraint. If two-dimensional, contains pairs of indices of the</span>
<span class="sd">            q-batch (0) and the feature space (1) that occur in the linear</span>
<span class="sd">            constraint.</span>
<span class="sd">        coefficients: A single-dimensional tensor of coefficients with the same</span>
<span class="sd">            number of elements as `indices`.</span>
<span class="sd">        rhs: The right hand side of the constraint.</span>
<span class="sd">        shapeX: The shape of the torch tensor to construct the constraints for</span>
<span class="sd">            (i.e. `(b) x q x d`). Must have two or three dimensions.</span>
<span class="sd">        eq: If True, return an equality constraint, o/w return an inequality</span>
<span class="sd">            constraint (indicated by &quot;eq&quot; / &quot;ineq&quot; value of the `type` key).</span>

<span class="sd">    Returns:</span>
<span class="sd">        A list of constraint dictionaries with the following keys</span>

<span class="sd">        - &quot;type&quot;: Indicates the type of the constraint (&quot;eq&quot; if `eq=True`, &quot;ineq&quot; o/w)</span>
<span class="sd">        - &quot;fun&quot;: A callable evaluating the constraint value on `x`, a flattened</span>
<span class="sd">            version of the input tensor `X`, returning a scalar.</span>
<span class="sd">        - &quot;jac&quot;: A callable evaluating the constraint&#39;s Jacobian on `x`, a flattened</span>
<span class="sd">            version of the input tensor `X`, returning a numpy array.</span>

<span class="sd">    &gt;&gt;&gt; shapeX = torch.Size([3, 5, 4])</span>
<span class="sd">    &gt;&gt;&gt; constraints = _make_linear_constraints(</span>
<span class="sd">    ...     indices=torch.tensor([1., 2.]),</span>
<span class="sd">    ...     coefficients=torch.tensor([-0.5, 1.3]),</span>
<span class="sd">    ...     rhs=0.49,</span>
<span class="sd">    ...     shapeX=shapeX,</span>
<span class="sd">    ...     eq=True</span>
<span class="sd">    ... )</span>
<span class="sd">    &gt;&gt;&gt; len(constraints)</span>
<span class="sd">    15</span>
<span class="sd">    &gt;&gt;&gt; constraints[0].keys()</span>
<span class="sd">    dict_keys([&#39;type&#39;, &#39;fun&#39;, &#39;jac&#39;])</span>
<span class="sd">    &gt;&gt;&gt; x = np.arange(60).reshape(shapeX)</span>
<span class="sd">    &gt;&gt;&gt; constraints[0][&quot;fun&quot;](x)</span>
<span class="sd">    1.61  # 1 * -0.5 + 2 * 1.3 - 0.49</span>
<span class="sd">    &gt;&gt;&gt; constraints[0][&quot;jac&quot;](x)</span>
<span class="sd">    [0., -0.5, 1.3, 0., 0., ...]</span>
<span class="sd">    &gt;&gt;&gt; constraints[1][&quot;fun&quot;](x)  #</span>
<span class="sd">    4.81</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">shapeX</span> <span class="o">=</span> <span class="n">_validate_linear_constraints_shape_input</span><span class="p">(</span><span class="n">shapeX</span><span class="p">)</span>

    <span class="n">b</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="n">shapeX</span>
    <span class="n">_validate_linear_constraints_indices_input</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">shapeX</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
    <span class="n">constraints</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">ScipyConstraintDict</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">coeffs</span> <span class="o">=</span> <span class="n">_arrayify</span><span class="p">(</span><span class="n">coefficients</span><span class="p">)</span>
    <span class="n">ctype</span> <span class="o">=</span> <span class="s2">&quot;eq&quot;</span> <span class="k">if</span> <span class="n">eq</span> <span class="k">else</span> <span class="s2">&quot;ineq&quot;</span>

    <span class="n">offsets</span> <span class="o">=</span> <span class="p">[</span><span class="n">q</span> <span class="o">*</span> <span class="n">d</span><span class="p">,</span> <span class="n">d</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">indices</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="c1"># indices has two dimensions (potential constraints across q-batch elements)</span>
        <span class="c1"># rule is [i, j, k] is at</span>
        <span class="c1"># i * offsets[0] + j * offsets[1] + k</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">b</span><span class="p">):</span>
            <span class="n">list_ind</span> <span class="o">=</span> <span class="p">(</span><span class="n">idx</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">)</span>
            <span class="n">idxr</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">offsets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">idx</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">offsets</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">idx</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">list_ind</span><span class="p">]</span>
            <span class="n">fun</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
                <span class="n">eval_lin_constraint</span><span class="p">,</span> <span class="n">flat_idxr</span><span class="o">=</span><span class="n">idxr</span><span class="p">,</span> <span class="n">coeffs</span><span class="o">=</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">rhs</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="n">rhs</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">jac</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">lin_constraint_jac</span><span class="p">,</span> <span class="n">flat_idxr</span><span class="o">=</span><span class="n">idxr</span><span class="p">,</span> <span class="n">coeffs</span><span class="o">=</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
            <span class="n">constraints</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="n">ctype</span><span class="p">,</span> <span class="s2">&quot;fun&quot;</span><span class="p">:</span> <span class="n">fun</span><span class="p">,</span> <span class="s2">&quot;jac&quot;</span><span class="p">:</span> <span class="n">jac</span><span class="p">})</span>
    <span class="k">elif</span> <span class="n">indices</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># indices is one-dim - broadcast constraints across q-batches and t-batches</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">b</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">q</span><span class="p">):</span>
                <span class="n">idxr</span> <span class="o">=</span> <span class="p">(</span><span class="n">i</span> <span class="o">*</span> <span class="n">offsets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">j</span> <span class="o">*</span> <span class="n">offsets</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">indices</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
                <span class="n">fun</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
                    <span class="n">eval_lin_constraint</span><span class="p">,</span> <span class="n">flat_idxr</span><span class="o">=</span><span class="n">idxr</span><span class="p">,</span> <span class="n">coeffs</span><span class="o">=</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">rhs</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="n">rhs</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="n">jac</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">lin_constraint_jac</span><span class="p">,</span> <span class="n">flat_idxr</span><span class="o">=</span><span class="n">idxr</span><span class="p">,</span> <span class="n">coeffs</span><span class="o">=</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
                <span class="n">constraints</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="n">ctype</span><span class="p">,</span> <span class="s2">&quot;fun&quot;</span><span class="p">:</span> <span class="n">fun</span><span class="p">,</span> <span class="s2">&quot;jac&quot;</span><span class="p">:</span> <span class="n">jac</span><span class="p">})</span>
    <span class="k">return</span> <span class="n">constraints</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_make_nonlinear_constraints</span><span class="p">(</span>
    <span class="n">f_np_wrapper</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">nlc</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">is_intrapoint</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">shapeX</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">ScipyConstraintDict</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Create nonlinear constraints to be used by `scipy.minimize`.</span>

<span class="sd">    Args:</span>
<span class="sd">        f_np_wrapper: A wrapper function that given a constraint evaluates</span>
<span class="sd">            the value and gradient (using autograd) of a numpy input and returns both</span>
<span class="sd">            the objective and the gradient.</span>
<span class="sd">        nlc: Callable representing a constraint of the form `callable(x) &gt;= 0`. In case</span>
<span class="sd">            of an intra-point constraint, `callable()`takes in an one-dimensional tensor</span>
<span class="sd">            of shape `d` and returns a scalar. In case of an inter-point constraint,</span>
<span class="sd">            `callable()` takes a two dimensional tensor of shape `q x d` and again</span>
<span class="sd">            returns a scalar.</span>
<span class="sd">        is_intrapoint: A Boolean indicating if a constraint is an intra-point or</span>
<span class="sd">            inter-point constraint (see the docstring of the `inequality_constraints`</span>
<span class="sd">            argument to `optimize_acqf()`).</span>
<span class="sd">        shapeX: Shape of the three-dimensional batch X, that should be optimized.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A list of constraint dictionaries with the following keys</span>

<span class="sd">        - &quot;type&quot;: Indicates the type of the constraint, here always &quot;ineq&quot;.</span>
<span class="sd">        - &quot;fun&quot;: A callable evaluating the constraint value on `x`, a flattened</span>
<span class="sd">            version of the input tensor `X`, returning a scalar.</span>
<span class="sd">        - &quot;jac&quot;: A callable evaluating the constraint&#39;s Jacobian on `x`, a flattened</span>
<span class="sd">            version of the input tensor `X`, returning a numpy array.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">shapeX</span> <span class="o">=</span> <span class="n">_validate_linear_constraints_shape_input</span><span class="p">(</span><span class="n">shapeX</span><span class="p">)</span>
    <span class="n">b</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">shapeX</span>
    <span class="n">constraints</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_intrapoint_constraint</span><span class="p">(</span><span class="n">b</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">q</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">nlc</span><span class="p">:</span> <span class="n">Callable</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">:</span>
        <span class="k">return</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">nlc</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="n">q</span><span class="p">])</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_interpoint_constraint</span><span class="p">(</span><span class="n">b</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">nlc</span><span class="p">:</span> <span class="n">Callable</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">:</span>
        <span class="k">return</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">nlc</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">b</span><span class="p">])</span>

    <span class="k">if</span> <span class="n">is_intrapoint</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">b</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">q</span><span class="p">):</span>
                <span class="n">f_obj</span><span class="p">,</span> <span class="n">f_grad</span> <span class="o">=</span> <span class="n">_make_f_and_grad_nonlinear_inequality_constraints</span><span class="p">(</span>
                    <span class="n">f_np_wrapper</span><span class="o">=</span><span class="n">f_np_wrapper</span><span class="p">,</span>
                    <span class="n">nlc</span><span class="o">=</span><span class="n">get_intrapoint_constraint</span><span class="p">(</span><span class="n">b</span><span class="o">=</span><span class="n">i</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="n">j</span><span class="p">,</span> <span class="n">nlc</span><span class="o">=</span><span class="n">nlc</span><span class="p">),</span>
                <span class="p">)</span>
                <span class="n">constraints</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;ineq&quot;</span><span class="p">,</span> <span class="s2">&quot;fun&quot;</span><span class="p">:</span> <span class="n">f_obj</span><span class="p">,</span> <span class="s2">&quot;jac&quot;</span><span class="p">:</span> <span class="n">f_grad</span><span class="p">})</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">b</span><span class="p">):</span>
            <span class="n">f_obj</span><span class="p">,</span> <span class="n">f_grad</span> <span class="o">=</span> <span class="n">_make_f_and_grad_nonlinear_inequality_constraints</span><span class="p">(</span>
                <span class="n">f_np_wrapper</span><span class="o">=</span><span class="n">f_np_wrapper</span><span class="p">,</span>
                <span class="n">nlc</span><span class="o">=</span><span class="n">get_interpoint_constraint</span><span class="p">(</span><span class="n">b</span><span class="o">=</span><span class="n">i</span><span class="p">,</span> <span class="n">nlc</span><span class="o">=</span><span class="n">nlc</span><span class="p">),</span>
            <span class="p">)</span>
            <span class="n">constraints</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;ineq&quot;</span><span class="p">,</span> <span class="s2">&quot;fun&quot;</span><span class="p">:</span> <span class="n">f_obj</span><span class="p">,</span> <span class="s2">&quot;jac&quot;</span><span class="p">:</span> <span class="n">f_grad</span><span class="p">})</span>

    <span class="k">return</span> <span class="n">constraints</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_generate_unfixed_nonlin_constraints</span><span class="p">(</span>
    <span class="n">constraints</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">],</span> <span class="nb">bool</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">fixed_features</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span>
    <span class="n">dimension</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Given a dictionary of fixed features, returns a list of callables for</span>
<span class="sd">    nonlinear inequality constraints expecting only a tensor with the non-fixed</span>
<span class="sd">    features as input.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">constraints</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">constraints</span>

    <span class="n">selector</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">idx_X</span><span class="p">,</span> <span class="n">idx_f</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">dimension</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">fixed_features</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">dimension</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">fixed_features</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">selector</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">idx_f</span><span class="p">)</span>
            <span class="n">idx_f</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">selector</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">idx_X</span><span class="p">)</span>
            <span class="n">idx_X</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="n">values</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">fixed_features</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">double</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_wrap_nonlin_constraint</span><span class="p">(</span>
        <span class="n">constraint</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]:</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">new_nonlin_constraint</span><span class="p">(</span><span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
            <span class="n">ivalues</span> <span class="o">=</span> <span class="n">values</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">*</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="nb">len</span><span class="p">(</span><span class="n">fixed_features</span><span class="p">))</span>
            <span class="n">X_perm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">X</span><span class="p">,</span> <span class="n">ivalues</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">constraint</span><span class="p">(</span><span class="n">X_perm</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">selector</span><span class="p">])</span>

        <span class="k">return</span> <span class="n">new_nonlin_constraint</span>

    <span class="k">return</span> <span class="p">[</span>
        <span class="p">(</span><span class="n">_wrap_nonlin_constraint</span><span class="p">(</span><span class="n">constraint</span><span class="o">=</span><span class="n">nlc</span><span class="p">),</span> <span class="n">is_intrapoint</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">nlc</span><span class="p">,</span> <span class="n">is_intrapoint</span> <span class="ow">in</span> <span class="n">constraints</span>
    <span class="p">]</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_generate_unfixed_lin_constraints</span><span class="p">(</span>
    <span class="n">constraints</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">fixed_features</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span>
    <span class="n">dimension</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">eq</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
    <span class="c1"># If constraints is None or an empty list, then return itself</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">constraints</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">constraints</span>

    <span class="c1"># replace_index generates the new indices for the unfixed dimensions</span>
    <span class="c1"># after eliminating the fixed dimensions.</span>
    <span class="c1"># Example: dimension = 5, ff.keys() = [1, 3], replace_index = {0: 0, 2: 1, 4: 2}</span>
    <span class="n">unfixed_keys</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">dimension</span><span class="p">))</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="n">fixed_features</span><span class="p">))</span>
    <span class="n">unfixed_keys</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">unfixed_keys</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">constraints</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">replace_index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">dimension</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">fixed_features</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">constraints</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>

    <span class="n">new_constraints</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># parse constraints one-by-one</span>
    <span class="k">for</span> <span class="n">constraint_id</span><span class="p">,</span> <span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">coefficients</span><span class="p">,</span> <span class="n">rhs</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">constraints</span><span class="p">):</span>
        <span class="n">new_rhs</span> <span class="o">=</span> <span class="n">rhs</span>
        <span class="n">new_indices</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">new_coefficients</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># the following unsqueeze is done to facilitate a simpler for-loop.</span>
        <span class="n">indices_2dim</span> <span class="o">=</span> <span class="n">indices</span> <span class="k">if</span> <span class="n">indices</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span> <span class="k">else</span> <span class="n">indices</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">coefficient</span><span class="p">,</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">coefficients</span><span class="p">,</span> <span class="n">indices_2dim</span><span class="p">):</span>
            <span class="n">ffval_or_None</span> <span class="o">=</span> <span class="n">fixed_features</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">index</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            <span class="c1"># if ffval_or_None is None, then the index is not fixed</span>
            <span class="k">if</span> <span class="n">ffval_or_None</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">new_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
                <span class="n">new_coefficients</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">coefficient</span><span class="p">)</span>
            <span class="c1"># otherwise, we &quot;remove&quot; the constraints corresponding to that index</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">new_rhs</span> <span class="o">=</span> <span class="n">new_rhs</span> <span class="o">-</span> <span class="n">coefficient</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">ffval_or_None</span>

        <span class="c1"># all indices were fixed, so the constraint is gone.</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">new_indices</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">eq</span> <span class="ow">and</span> <span class="n">new_rhs</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="ow">not</span> <span class="n">eq</span> <span class="ow">and</span> <span class="n">new_rhs</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">):</span>
                <span class="n">prefix</span> <span class="o">=</span> <span class="s2">&quot;Eq&quot;</span> <span class="k">if</span> <span class="n">eq</span> <span class="k">else</span> <span class="s2">&quot;Ineq&quot;</span>
                <span class="k">raise</span> <span class="n">CandidateGenerationError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">uality constraint </span><span class="si">{</span><span class="n">constraint_id</span><span class="si">}</span><span class="s2"> not met &quot;</span>
                    <span class="s2">&quot;with fixed_features.&quot;</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># However, one key transformation has to be noted.</span>
            <span class="c1"># new_indices is with respect to the older (fuller) domain, and so it will</span>
            <span class="c1"># have to be converted using replace_index.</span>
            <span class="n">new_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">new_indices</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="c1"># generate new index location after the removal of fixed_features indices</span>
            <span class="n">new_indices_dim_d</span> <span class="o">=</span> <span class="n">new_indices</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">new_indices_dim_d</span> <span class="o">=</span> <span class="n">replace_index</span><span class="p">[</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">new_indices_dim_d</span> <span class="o">==</span> <span class="n">unfixed_keys</span><span class="p">,</span> <span class="n">as_tuple</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
            <span class="p">]</span>
            <span class="n">new_indices</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_indices_dim_d</span>
            <span class="c1"># squeeze(-1) is a no-op if dim -1 is not singleton</span>
            <span class="n">new_indices</span><span class="o">.</span><span class="n">squeeze_</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="c1"># convert new_coefficients to Tensor</span>
            <span class="n">new_coefficients</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">new_coefficients</span><span class="p">)</span>
            <span class="n">new_constraints</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">new_indices</span><span class="p">,</span> <span class="n">new_coefficients</span><span class="p">,</span> <span class="n">new_rhs</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">new_constraints</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_make_f_and_grad_nonlinear_inequality_constraints</span><span class="p">(</span>
    <span class="n">f_np_wrapper</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">nlc</span><span class="p">:</span> <span class="n">Callable</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">],</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create callables for objective + grad for the nonlinear inequality constraints.</span>
<span class="sd">    The Scipy interface requires specifying separate callables and we use caching to</span>
<span class="sd">    avoid evaluating the same input twice. This caching only works if</span>
<span class="sd">    the returned functions are evaluated on the same input in immediate</span>
<span class="sd">    sequence (i.e., calling `f_obj(X_1)`, `f_grad(X_1)` will result in a</span>
<span class="sd">    single forward pass, while `f_obj(X_1)`, `f_grad(X_2)`, `f_obj(X_1)`</span>
<span class="sd">    will result in three forward passes).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">f_obj_and_grad</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
        <span class="n">obj</span><span class="p">,</span> <span class="n">grad</span> <span class="o">=</span> <span class="n">f_np_wrapper</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">f</span><span class="o">=</span><span class="n">nlc</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">obj</span><span class="p">,</span> <span class="n">grad</span>

    <span class="n">cache</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;X&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;obj&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;grad&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">f_obj</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
        <span class="n">X_c</span> <span class="o">=</span> <span class="n">cache</span><span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">X_c</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">X_c</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
            <span class="n">cache</span><span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="n">cache</span><span class="p">[</span><span class="s2">&quot;obj&quot;</span><span class="p">],</span> <span class="n">cache</span><span class="p">[</span><span class="s2">&quot;grad&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">f_obj_and_grad</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">cache</span><span class="p">[</span><span class="s2">&quot;obj&quot;</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">f_grad</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
        <span class="n">X_c</span> <span class="o">=</span> <span class="n">cache</span><span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">X_c</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">X_c</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
            <span class="n">cache</span><span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="n">cache</span><span class="p">[</span><span class="s2">&quot;obj&quot;</span><span class="p">],</span> <span class="n">cache</span><span class="p">[</span><span class="s2">&quot;grad&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">f_obj_and_grad</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">cache</span><span class="p">[</span><span class="s2">&quot;grad&quot;</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">f_obj</span><span class="p">,</span> <span class="n">f_grad</span>


<div class="viewcode-block" id="nonlinear_constraint_is_feasible">
<a class="viewcode-back" href="../../../optim.html#botorch.optim.parameter_constraints.nonlinear_constraint_is_feasible">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">nonlinear_constraint_is_feasible</span><span class="p">(</span>
    <span class="n">nonlinear_inequality_constraint</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
    <span class="n">is_intrapoint</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">tolerance</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">CONST_TOL</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Checks if a nonlinear inequality constraint is fulfilled (within tolerance).</span>

<span class="sd">    Args:</span>
<span class="sd">        nonlinear_inequality_constraint: Callable to evaluate the</span>
<span class="sd">            constraint.</span>
<span class="sd">        intra: If True, the constraint is an intra-point constraint that</span>
<span class="sd">            is applied pointwise and is broadcasted over the q-batch. Else, the</span>
<span class="sd">            constraint has to evaluated over the whole q-batch and is a an</span>
<span class="sd">            inter-point constraint.</span>
<span class="sd">        x: Tensor of shape (batch x q x d).</span>
<span class="sd">        tolerance: Rather than using the exact `const(x) &gt;= 0` constraint, this helper</span>
<span class="sd">            checks feasibility of `const(x) &gt;= -tolerance`. This avoids marking the</span>
<span class="sd">            candidates as infeasible due to tiny violations.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A boolean tensor of shape (batch) indicating if the constraint is</span>
<span class="sd">        satified by the corresponding batch of `x`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">check_x</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_arrayify</span><span class="p">(</span><span class="n">nonlinear_inequality_constraint</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="o">-</span><span class="n">tolerance</span>

    <span class="n">x_flat</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:])</span>
    <span class="n">is_feasible</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">x_flat</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x_</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">x_flat</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">is_intrapoint</span><span class="p">:</span>
            <span class="n">is_feasible</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&amp;=</span> <span class="nb">all</span><span class="p">(</span><span class="n">check_x</span><span class="p">(</span><span class="n">x__</span><span class="p">)</span> <span class="k">for</span> <span class="n">x__</span> <span class="ow">in</span> <span class="n">x_</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">is_feasible</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&amp;=</span> <span class="n">check_x</span><span class="p">(</span><span class="n">x_</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">is_feasible</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span></div>



<div class="viewcode-block" id="make_scipy_nonlinear_inequality_constraints">
<a class="viewcode-back" href="../../../optim.html#botorch.optim.parameter_constraints.make_scipy_nonlinear_inequality_constraints">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">make_scipy_nonlinear_inequality_constraints</span><span class="p">(</span>
    <span class="n">nonlinear_inequality_constraints</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="n">Callable</span><span class="p">,</span> <span class="nb">bool</span><span class="p">]],</span>
    <span class="n">f_np_wrapper</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
    <span class="n">x0</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">shapeX</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">]:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Generate Scipy nonlinear inequality constraints from callables.</span>

<span class="sd">    Args:</span>
<span class="sd">        nonlinear_inequality_constraints: A list of tuples representing the nonlinear</span>
<span class="sd">            inequality constraints. The first element in the tuple is a callable</span>
<span class="sd">            representing a constraint of the form `callable(x) &gt;= 0`. In case of an</span>
<span class="sd">            intra-point constraint, `callable()`takes in an one-dimensional tensor of</span>
<span class="sd">            shape `d` and returns a scalar. In case of an inter-point constraint,</span>
<span class="sd">            `callable()` takes a two dimensional tensor of shape `q x d` and again</span>
<span class="sd">            returns a scalar. The second element is a boolean, indicating if it is an</span>
<span class="sd">            intra-point or inter-point constraint (`True` for intra-point. `False` for</span>
<span class="sd">            inter-point). For more information on intra-point vs inter-point</span>
<span class="sd">            constraints, see the docstring of the `inequality_constraints` argument to</span>
<span class="sd">            `optimize_acqf()`. The constraints will later be passed to the scipy</span>
<span class="sd">            solver.</span>
<span class="sd">        f_np_wrapper: A wrapper function that given a constraint evaluates the value</span>
<span class="sd">             and gradient (using autograd) of a numpy input and returns both the</span>
<span class="sd">             objective and the gradient.</span>
<span class="sd">        x0: The starting point for SLSQP. We return this starting point in (rare)</span>
<span class="sd">            cases where SLSQP fails and thus require it to be feasible.</span>
<span class="sd">        shapeX: Shape of the three-dimensional batch X, that should be optimized.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A list of dictionaries containing callables for constraint function</span>
<span class="sd">        values and Jacobians and a string indicating the associated constraint</span>
<span class="sd">        type (&quot;eq&quot;, &quot;ineq&quot;), as expected by `scipy.minimize`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">scipy_nonlinear_inequality_constraints</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">constraint</span> <span class="ow">in</span> <span class="n">nonlinear_inequality_constraints</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">constraint</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;A nonlinear constraint has to be a tuple, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">constraint</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">constraint</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;A nonlinear constraint has to be a tuple of length 2, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;got length </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">constraint</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
        <span class="n">nlc</span><span class="p">,</span> <span class="n">is_intrapoint</span> <span class="o">=</span> <span class="n">constraint</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">nonlinear_constraint_is_feasible</span><span class="p">(</span>
            <span class="n">nlc</span><span class="p">,</span> <span class="n">is_intrapoint</span><span class="o">=</span><span class="n">is_intrapoint</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x0</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">shapeX</span><span class="p">)</span>
        <span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;`batch_initial_conditions` must satisfy the non-linear inequality &quot;</span>
                <span class="s2">&quot;constraints.&quot;</span>
            <span class="p">)</span>

        <span class="n">scipy_nonlinear_inequality_constraints</span> <span class="o">+=</span> <span class="n">_make_nonlinear_constraints</span><span class="p">(</span>
            <span class="n">f_np_wrapper</span><span class="o">=</span><span class="n">f_np_wrapper</span><span class="p">,</span>
            <span class="n">nlc</span><span class="o">=</span><span class="n">nlc</span><span class="p">,</span>
            <span class="n">is_intrapoint</span><span class="o">=</span><span class="n">is_intrapoint</span><span class="p">,</span>
            <span class="n">shapeX</span><span class="o">=</span><span class="n">shapeX</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">scipy_nonlinear_inequality_constraints</span></div>



<div class="viewcode-block" id="evaluate_feasibility">
<a class="viewcode-back" href="../../../optim.html#botorch.optim.parameter_constraints.evaluate_feasibility">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">evaluate_feasibility</span><span class="p">(</span>
    <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">inequality_constraints</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">equality_constraints</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">nonlinear_inequality_constraints</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="n">Callable</span><span class="p">,</span> <span class="nb">bool</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">tolerance</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">CONST_TOL</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Evaluate feasibility of candidate points (within a tolerance).</span>

<span class="sd">    Args:</span>
<span class="sd">        X: The candidate tensor of shape `batch x q x d`.</span>
<span class="sd">        inequality_constraints: A list of tuples (indices, coefficients, rhs),</span>
<span class="sd">            with each tuple encoding an inequality constraint of the form</span>
<span class="sd">            `\sum_i (X[indices[i]] * coefficients[i]) &gt;= rhs`. `indices` and</span>
<span class="sd">            `coefficients` should be torch tensors. See the docstring of</span>
<span class="sd">            `make_scipy_linear_constraints` for an example. When q=1, or when</span>
<span class="sd">            applying the same constraint to each candidate in the batch</span>
<span class="sd">            (intra-point constraint), `indices` should be a 1-d tensor.</span>
<span class="sd">            For inter-point constraints, in which the constraint is applied to the</span>
<span class="sd">            whole batch of candidates, `indices` must be a 2-d tensor, where</span>
<span class="sd">            in each row `indices[i] =(k_i, l_i)` the first index `k_i` corresponds</span>
<span class="sd">            to the `k_i`-th element of the `q`-batch and the second index `l_i`</span>
<span class="sd">            corresponds to the `l_i`-th feature of that element.</span>
<span class="sd">        equality_constraints: A list of tuples (indices, coefficients, rhs),</span>
<span class="sd">            with each tuple encoding an equality constraint of the form</span>
<span class="sd">            `\sum_i (X[indices[i]] * coefficients[i]) = rhs`. See the docstring of</span>
<span class="sd">            `make_scipy_linear_constraints` for an example.</span>
<span class="sd">        nonlinear_inequality_constraints: A list of tuples representing the nonlinear</span>
<span class="sd">            inequality constraints. The first element in the tuple is a callable</span>
<span class="sd">            representing a constraint of the form `callable(x) &gt;= 0`. In case of an</span>
<span class="sd">            intra-point constraint, `callable()`takes in an one-dimensional tensor of</span>
<span class="sd">            shape `d` and returns a scalar. In case of an inter-point constraint,</span>
<span class="sd">            `callable()` takes a two dimensional tensor of shape `q x d` and again</span>
<span class="sd">            returns a scalar. The second element is a boolean, indicating if it is an</span>
<span class="sd">            intra-point or inter-point constraint (`True` for intra-point. `False` for</span>
<span class="sd">            inter-point). For more information on intra-point vs inter-point</span>
<span class="sd">            constraints, see the docstring of the `inequality_constraints` argument.</span>
<span class="sd">        tolerance: The tolerance used to check the feasibility of constraints.</span>
<span class="sd">            For inequality constraints, we check if `const(X) &gt;= rhs - tolerance`.</span>
<span class="sd">            For equality constraints, we check if `abs(const(X) - rhs) &lt; tolerance`.</span>
<span class="sd">            For non-linear inequality constraints, we check if `const(X) &gt;= -tolerance`.</span>
<span class="sd">            This avoids marking the candidates as infeasible due to tiny violations.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A boolean tensor of shape `batch` indicating if the corresponding candidate of</span>
<span class="sd">        shape `q x d` is feasible.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">is_feasible</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">inequality_constraints</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">coef</span><span class="p">,</span> <span class="n">rhs</span> <span class="ow">in</span> <span class="n">inequality_constraints</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">idx</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="c1"># Intra-point constraints.</span>
                <span class="n">is_feasible</span> <span class="o">&amp;=</span> <span class="p">(</span>
                    <span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">idx</span><span class="p">]</span> <span class="o">*</span> <span class="n">coef</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">rhs</span> <span class="o">-</span> <span class="n">tolerance</span>
                <span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Inter-point constraints.</span>
                <span class="n">is_feasible</span> <span class="o">&amp;=</span> <span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">idx</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">idx</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">*</span> <span class="n">coef</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
                    <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span>
                <span class="p">)</span> <span class="o">&gt;=</span> <span class="n">rhs</span> <span class="o">-</span> <span class="n">tolerance</span>
    <span class="k">if</span> <span class="n">equality_constraints</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">coef</span><span class="p">,</span> <span class="n">rhs</span> <span class="ow">in</span> <span class="n">equality_constraints</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">idx</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="c1"># Intra-point constraints.</span>
                <span class="n">is_feasible</span> <span class="o">&amp;=</span> <span class="p">(</span>
                    <span class="p">((</span><span class="n">X</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">idx</span><span class="p">]</span> <span class="o">*</span> <span class="n">coef</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">rhs</span><span class="p">)</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">tolerance</span>
                <span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Inter-point constraints.</span>
                <span class="n">is_feasible</span> <span class="o">&amp;=</span> <span class="p">(</span>
                    <span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">idx</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">idx</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">*</span> <span class="n">coef</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">rhs</span>
                <span class="p">)</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">tolerance</span>
    <span class="k">if</span> <span class="n">nonlinear_inequality_constraints</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">const</span><span class="p">,</span> <span class="n">intra</span> <span class="ow">in</span> <span class="n">nonlinear_inequality_constraints</span><span class="p">:</span>
            <span class="n">is_feasible</span> <span class="o">&amp;=</span> <span class="n">nonlinear_constraint_is_feasible</span><span class="p">(</span>
                <span class="n">nonlinear_inequality_constraint</span><span class="o">=</span><span class="n">const</span><span class="p">,</span>
                <span class="n">is_intrapoint</span><span class="o">=</span><span class="n">intra</span><span class="p">,</span>
                <span class="n">x</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
                <span class="n">tolerance</span><span class="o">=</span><span class="n">tolerance</span><span class="p">,</span>
            <span class="p">)</span>
    <span class="k">return</span> <span class="n">is_feasible</span></div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p></p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>