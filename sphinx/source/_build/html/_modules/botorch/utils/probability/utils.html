

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>botorch.utils.probability.utils &mdash; BoTorch  documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=03e43079" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/custom.css?v=ca3e82f4" />

  
      <script src="../../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../../_static/documentation_options.js?v=5929fcd5"></script>
      <script src="../../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../index.html" class="icon icon-home">
            BoTorch
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../acquisition.html">botorch.acquisition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../models.html">botorch.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../generation.html">botorch.generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../posteriors.html">botorch.posteriors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../optim.html">botorch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../fit.html">botorch.fit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../sampling.html">botorch.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../cross_validation.html">botorch.cross_validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../settings.html">botorch.settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../logging.html">botorch.logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../test_functions.html">botorch.test_functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../test_utils.html">botorch.test_utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../exceptions.html">botorch.exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../utils.html">botorch.utils</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">BoTorch</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">botorch.utils.probability.utils</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for botorch.utils.probability.utils</h1><div class="highlight"><pre>
<span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="c1"># Copyright (c) Meta Platforms, Inc. and affiliates.</span>
<span class="c1">#</span>
<span class="c1"># This source code is licensed under the MIT license found in the</span>
<span class="c1"># LICENSE file in the root directory of this source tree.</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">__future__</span><span class="w"> </span><span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections.abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">,</span> <span class="n">Iterator</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">functools</span><span class="w"> </span><span class="kn">import</span> <span class="n">lru_cache</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">pi</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">numbers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Number</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.utils.safe_math</span><span class="w"> </span><span class="kn">import</span> <span class="n">logdiffexp</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">numpy.polynomial.legendre</span><span class="w"> </span><span class="kn">import</span> <span class="n">leggauss</span> <span class="k">as</span> <span class="n">numpy_leggauss</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">BoolTensor</span><span class="p">,</span> <span class="n">LongTensor</span><span class="p">,</span> <span class="n">Tensor</span>

<span class="n">CaseNd</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[],</span> <span class="n">BoolTensor</span><span class="p">],</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">BoolTensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]]</span>

<span class="n">_log_2</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">_sqrt_pi</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">pi</span><span class="p">)</span>
<span class="n">_inv_sqrt_pi</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">_sqrt_pi</span>
<span class="n">_inv_sqrt_2pi</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">pi</span><span class="p">)</span>
<span class="n">_inv_sqrt_2</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">_neg_inv_sqrt_2</span> <span class="o">=</span> <span class="o">-</span><span class="n">_inv_sqrt_2</span>
<span class="n">_log_sqrt_2pi</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">pi</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
<span class="n">STANDARDIZED_RANGE</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mf">1e6</span><span class="p">,</span> <span class="mf">1e6</span><span class="p">)</span>
<span class="n">_log_two_inv_sqrt_2pi</span> <span class="o">=</span> <span class="n">_log_2</span> <span class="o">-</span> <span class="n">_log_sqrt_2pi</span>  <span class="c1"># = log(2 / sqrt(2 * pi))</span>


<div class="viewcode-block" id="case_dispatcher">
<a class="viewcode-back" href="../../../../utils.html#botorch.utils.probability.utils.case_dispatcher">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">case_dispatcher</span><span class="p">(</span>
    <span class="n">out</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">cases</span><span class="p">:</span> <span class="n">Iterable</span><span class="p">[</span><span class="n">CaseNd</span><span class="p">]</span> <span class="o">=</span> <span class="p">(),</span>
    <span class="n">default</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">BoolTensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Basic implementation of a tensorized switching case statement.</span>

<span class="sd">    Args:</span>
<span class="sd">        out: Tensor to which case outcomes are written.</span>
<span class="sd">        cases: Iterable of function pairs (pred, func), where `mask=pred()` specifies</span>
<span class="sd">            whether `func` is applicable for each entry in `out`. Note that cases are</span>
<span class="sd">            resolved first-come, first-serve.</span>
<span class="sd">        default: Optional `func` to which all unclaimed entries of `out` are dispatched.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">active</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">for</span> <span class="n">closure</span><span class="p">,</span> <span class="n">func</span> <span class="ow">in</span> <span class="n">cases</span><span class="p">:</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">closure</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">pred</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
            <span class="k">continue</span>

        <span class="n">mask</span> <span class="o">=</span> <span class="n">pred</span> <span class="k">if</span> <span class="p">(</span><span class="n">active</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="k">else</span> <span class="n">pred</span> <span class="o">&amp;</span> <span class="n">active</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">mask</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
            <span class="k">continue</span>

        <span class="k">if</span> <span class="n">mask</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>  <span class="c1"># where possible, use Ellipsis to avoid indexing</span>
            <span class="n">out</span><span class="p">[</span><span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">out</span>

        <span class="n">out</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">active</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">active</span> <span class="o">=</span> <span class="o">~</span><span class="n">mask</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">active</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">active</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
            <span class="k">break</span>

    <span class="k">if</span> <span class="n">default</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">active</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out</span><span class="p">[</span><span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="n">default</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">active</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
            <span class="n">out</span><span class="p">[</span><span class="n">active</span><span class="p">]</span> <span class="o">=</span> <span class="n">default</span><span class="p">(</span><span class="n">active</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">out</span></div>



<div class="viewcode-block" id="get_constants">
<a class="viewcode-back" href="../../../../utils.html#botorch.utils.probability.utils.get_constants">[docs]</a>
<span class="nd">@lru_cache</span><span class="p">(</span><span class="n">maxsize</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">get_constants</span><span class="p">(</span>
    <span class="n">values</span><span class="p">:</span> <span class="n">Number</span> <span class="o">|</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">Number</span><span class="p">],</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">]:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns scalar-valued Tensors containing each of the given constants.</span>
<span class="sd">    Used to expedite tensor operations involving scalar arithmetic. Note that</span>
<span class="sd">    the returned Tensors should not be modified in-place.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">Number</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((),</span> <span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

    <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((),</span> <span class="n">val</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">values</span><span class="p">)</span></div>



<div class="viewcode-block" id="get_constants_like">
<a class="viewcode-back" href="../../../../utils.html#botorch.utils.probability.utils.get_constants_like">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">get_constants_like</span><span class="p">(</span>
    <span class="n">values</span><span class="p">:</span> <span class="n">Number</span> <span class="o">|</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">Number</span><span class="p">],</span>
    <span class="n">ref</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]:</span>
    <span class="k">return</span> <span class="n">get_constants</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">ref</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ref</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span></div>



<div class="viewcode-block" id="gen_positional_indices">
<a class="viewcode-back" href="../../../../utils.html#botorch.utils.probability.utils.gen_positional_indices">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">gen_positional_indices</span><span class="p">(</span>
    <span class="n">shape</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">,</span>
    <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]:</span>
    <span class="n">ndim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">_dim</span> <span class="o">=</span> <span class="n">ndim</span> <span class="o">+</span> <span class="n">dim</span> <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">dim</span>
    <span class="k">if</span> <span class="n">_dim</span> <span class="o">&gt;=</span> <span class="n">ndim</span> <span class="ow">or</span> <span class="n">_dim</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;dim=</span><span class="si">{</span><span class="n">dim</span><span class="si">}</span><span class="s2"> invalid for shape </span><span class="si">{</span><span class="n">shape</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

    <span class="n">cumsize</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="n">_dim</span> <span class="o">+</span> <span class="mi">1</span> <span class="p">:]</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="n">shape</span><span class="p">[:</span> <span class="n">_dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])):</span>
        <span class="k">yield</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">s</span> <span class="o">*</span> <span class="n">cumsize</span><span class="p">,</span> <span class="n">cumsize</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)[(</span><span class="o">...</span><span class="p">,)</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="p">(</span><span class="kc">None</span><span class="p">,)]</span>
        <span class="n">cumsize</span> <span class="o">*=</span> <span class="n">s</span></div>



<div class="viewcode-block" id="build_positional_indices">
<a class="viewcode-back" href="../../../../utils.html#botorch.utils.probability.utils.build_positional_indices">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">build_positional_indices</span><span class="p">(</span>
    <span class="n">shape</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">,</span>
    <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">LongTensor</span><span class="p">:</span>
    <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">gen_positional_indices</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">))</span></div>



<div class="viewcode-block" id="leggauss">
<a class="viewcode-back" href="../../../../utils.html#botorch.utils.probability.utils.leggauss">[docs]</a>
<span class="nd">@lru_cache</span><span class="p">(</span><span class="n">maxsize</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">leggauss</span><span class="p">(</span><span class="n">deg</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">numpy_leggauss</span><span class="p">(</span><span class="n">deg</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">)</span></div>



<div class="viewcode-block" id="ndtr">
<a class="viewcode-back" href="../../../../utils.html#botorch.utils.probability.utils.ndtr">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">ndtr</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Standard normal CDF.&quot;&quot;&quot;</span>
    <span class="n">half</span><span class="p">,</span> <span class="n">neg_inv_sqrt_2</span> <span class="o">=</span> <span class="n">get_constants_like</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">_neg_inv_sqrt_2</span><span class="p">),</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">half</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">erfc</span><span class="p">(</span><span class="n">neg_inv_sqrt_2</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span></div>



<div class="viewcode-block" id="phi">
<a class="viewcode-back" href="../../../../utils.html#botorch.utils.probability.utils.phi">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">phi</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Standard normal PDF.&quot;&quot;&quot;</span>
    <span class="n">inv_sqrt_2pi</span><span class="p">,</span> <span class="n">neg_half</span> <span class="o">=</span> <span class="n">get_constants_like</span><span class="p">((</span><span class="n">_inv_sqrt_2pi</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">),</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">inv_sqrt_2pi</span> <span class="o">*</span> <span class="p">(</span><span class="n">neg_half</span> <span class="o">*</span> <span class="n">x</span><span class="o">.</span><span class="n">square</span><span class="p">())</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span></div>



<div class="viewcode-block" id="log_phi">
<a class="viewcode-back" href="../../../../utils.html#botorch.utils.probability.utils.log_phi">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">log_phi</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Logarithm of standard normal pdf&quot;&quot;&quot;</span>
    <span class="n">log_sqrt_2pi</span><span class="p">,</span> <span class="n">neg_half</span> <span class="o">=</span> <span class="n">get_constants_like</span><span class="p">((</span><span class="n">_log_sqrt_2pi</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">),</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">neg_half</span> <span class="o">*</span> <span class="n">x</span><span class="o">.</span><span class="n">square</span><span class="p">()</span> <span class="o">-</span> <span class="n">log_sqrt_2pi</span></div>



<div class="viewcode-block" id="log_ndtr">
<a class="viewcode-back" href="../../../../utils.html#botorch.utils.probability.utils.log_ndtr">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">log_ndtr</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Implementation of log_ndtr that remedies problems of torch.special&#39;s version</span>
<span class="sd">    for large negative x, where the torch implementation yields Inf or NaN gradients.</span>

<span class="sd">    Args:</span>
<span class="sd">        x: An input tensor with dtype torch.float32 or torch.float64.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A tensor of values of the same type and shape as x containing log(ndtr(x)).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span> <span class="ow">or</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;log_Phi only supports torch.float32 and torch.float64 &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;dtypes, but received </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="si">=}</span><span class="s2">.&quot;</span>
        <span class="p">)</span>
    <span class="n">neg_inv_sqrt_2</span><span class="p">,</span> <span class="n">log_2</span> <span class="o">=</span> <span class="n">get_constants_like</span><span class="p">((</span><span class="n">_neg_inv_sqrt_2</span><span class="p">,</span> <span class="n">_log_2</span><span class="p">),</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">log_erfc</span><span class="p">(</span><span class="n">neg_inv_sqrt_2</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="n">log_2</span></div>



<div class="viewcode-block" id="log_erfc">
<a class="viewcode-back" href="../../../../utils.html#botorch.utils.probability.utils.log_erfc">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">log_erfc</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Computes the logarithm of the complementary error function in a numerically</span>
<span class="sd">    stable manner. The GitHub issue https://github.com/pytorch/pytorch/issues/31945</span>
<span class="sd">    tracks progress toward moving this feature into PyTorch in C++.</span>

<span class="sd">    Args:</span>
<span class="sd">        x: An input tensor with dtype torch.float32 or torch.float64.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A tensor of values of the same type and shape as x containing log(erfc(x)).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span> <span class="ow">or</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;log_erfc only supports torch.float32 and torch.float64 &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;dtypes, but received </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="si">=}</span><span class="s2">.&quot;</span>
        <span class="p">)</span>
    <span class="n">is_pos</span> <span class="o">=</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span>
    <span class="n">x_pos</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="o">~</span><span class="n">is_pos</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">x_neg</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">is_pos</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
        <span class="n">is_pos</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">erfcx</span><span class="p">(</span><span class="n">x_pos</span><span class="p">))</span> <span class="o">-</span> <span class="n">x_pos</span><span class="o">.</span><span class="n">square</span><span class="p">(),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">erfc</span><span class="p">(</span><span class="n">x_neg</span><span class="p">)),</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="log_erfcx">
<a class="viewcode-back" href="../../../../utils.html#botorch.utils.probability.utils.log_erfcx">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">log_erfcx</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Computes the logarithm of the complementary scaled error function in a</span>
<span class="sd">    numerically stable manner. The GitHub issue tracks progress toward moving this</span>
<span class="sd">    feature into PyTorch in C++: https://github.com/pytorch/pytorch/issues/31945.</span>

<span class="sd">    Args:</span>
<span class="sd">        x: An input tensor with dtype torch.float32 or torch.float64.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A tensor of values of the same type and shape as x containing log(erfcx(x)).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">is_pos</span> <span class="o">=</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span>
    <span class="n">x_pos</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="o">~</span><span class="n">is_pos</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">x_neg</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">is_pos</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
        <span class="n">is_pos</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">erfcx</span><span class="p">(</span><span class="n">x_pos</span><span class="p">)</span><span class="o">.</span><span class="n">log</span><span class="p">(),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">erfc</span><span class="p">(</span><span class="n">x_neg</span><span class="p">)</span><span class="o">.</span><span class="n">log</span><span class="p">()</span> <span class="o">+</span> <span class="n">x</span><span class="o">.</span><span class="n">square</span><span class="p">(),</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="standard_normal_log_hazard">
<a class="viewcode-back" href="../../../../utils.html#botorch.utils.probability.utils.standard_normal_log_hazard">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">standard_normal_log_hazard</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Computes the logarithm of the hazard function of the standard normal</span>
<span class="sd">    distribution, i.e. `log(phi(x) / Phi(-x))`.</span>

<span class="sd">    Args:</span>
<span class="sd">        x: A tensor of any shape, with either float32 or float64 dtypes.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A Tensor of the same shape `x`, containing the values of the logarithm of the</span>
<span class="sd">        hazard function evaluated at `x`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># NOTE: using _inv_sqrt_2 instead of _neg_inv_sqrt_2 means we are computing Phi(-x).</span>
    <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">get_constants_like</span><span class="p">((</span><span class="n">_log_two_inv_sqrt_2pi</span><span class="p">,</span> <span class="n">_inv_sqrt_2</span><span class="p">),</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">a</span> <span class="o">-</span> <span class="n">log_erfcx</span><span class="p">(</span><span class="n">b</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span></div>



<div class="viewcode-block" id="log_prob_normal_in">
<a class="viewcode-back" href="../../../../utils.html#botorch.utils.probability.utils.log_prob_normal_in">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">log_prob_normal_in</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the probability that a standard normal random variable takes a value</span>
<span class="sd">    in \[a, b\], i.e. log(Phi(b) - Phi(a)), where Phi is the standard normal CDF.</span>
<span class="sd">    Returns accurate values and permits numerically stable backward passes for inputs</span>
<span class="sd">    in [-1e100, 1e100] for double precision and [-1e20, 1e20] for single precision.</span>
<span class="sd">    In contrast, a naive approach is not numerically accurate beyond [-10, 10].</span>

<span class="sd">    Args:</span>
<span class="sd">        a: Tensor of lower integration bounds of the Gaussian probability measure.</span>
<span class="sd">        b: Tensor of upper integration bounds of the Gaussian probability measure.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor of the log probabilities.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">a</span> <span class="o">&lt;</span> <span class="n">b</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Received input tensors a, b for which not all a &lt; b.&quot;</span><span class="p">)</span>
    <span class="c1"># if abs(b) &gt; abs(a), we use Phi(b) - Phi(a) = Phi(-a) - Phi(-b), since the</span>
    <span class="c1"># right tail converges to 0 from below, leading to digit cancellation issues, while</span>
    <span class="c1"># the left tail of log_ndtr is well behaved and results in large negative numbers</span>
    <span class="n">rev_cond</span> <span class="o">=</span> <span class="n">b</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span> <span class="o">&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span>  <span class="c1"># condition for reversal of inputs</span>
    <span class="k">if</span> <span class="n">rev_cond</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
        <span class="n">c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">rev_cond</span><span class="p">,</span> <span class="o">-</span><span class="n">b</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">rev_cond</span><span class="p">,</span> <span class="o">-</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">c</span>  <span class="c1"># after we updated b, can assign c to a</span>
    <span class="k">return</span> <span class="n">logdiffexp</span><span class="p">(</span><span class="n">log_a</span><span class="o">=</span><span class="n">log_ndtr</span><span class="p">(</span><span class="n">a</span><span class="p">),</span> <span class="n">log_b</span><span class="o">=</span><span class="n">log_ndtr</span><span class="p">(</span><span class="n">b</span><span class="p">))</span></div>



<div class="viewcode-block" id="swap_along_dim_">
<a class="viewcode-back" href="../../../../utils.html#botorch.utils.probability.utils.swap_along_dim_">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">swap_along_dim_</span><span class="p">(</span>
    <span class="n">values</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">i</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="n">LongTensor</span><span class="p">,</span>
    <span class="n">j</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="n">LongTensor</span><span class="p">,</span>
    <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">buffer</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Swaps Tensor slices in-place along dimension `dim`.</span>

<span class="sd">    When passed as Tensors, `i` (and `j`) should be `dim`-dimensional tensors</span>
<span class="sd">    with the same shape as `values.shape[:dim]`. The xception to this rule occurs</span>
<span class="sd">    when `dim=0`, in which case `i` (and `j`) should be (at most) one-dimensional</span>
<span class="sd">    when passed as a Tensor.</span>

<span class="sd">    Args:</span>
<span class="sd">        values: Tensor whose values are to be swapped.</span>
<span class="sd">        i: Indices for slices along dimension `dim`.</span>
<span class="sd">        j: Indices for slices along dimension `dim`.</span>
<span class="sd">        dim: The dimension of `values` along which to swap slices.</span>
<span class="sd">        buffer: Optional buffer used internally to store copied values.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The original `values` tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dim</span> <span class="o">=</span> <span class="n">values</span><span class="o">.</span><span class="n">ndim</span> <span class="o">+</span> <span class="n">dim</span> <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">dim</span>
    <span class="k">if</span> <span class="n">dim</span> <span class="ow">and</span> <span class="p">(</span>
        <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">i</span><span class="o">.</span><span class="n">ndim</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">j</span><span class="o">.</span><span class="n">ndim</span><span class="p">)</span>
    <span class="p">):</span>
        <span class="c1"># Handle n-dimensional batches of heterogeneous swaps via linear indexing</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">i</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">values</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="n">dim</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Batch shapes of `i` and `values` do not match.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">j</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">values</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="n">dim</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Batch shapes of `j` and `values` do not match.&quot;</span><span class="p">)</span>

        <span class="n">pidx</span> <span class="o">=</span> <span class="n">build_positional_indices</span><span class="p">(</span>
            <span class="n">shape</span><span class="o">=</span><span class="n">values</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span> <span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">values</span><span class="o">.</span><span class="n">device</span>
        <span class="p">)</span>

        <span class="n">swap_along_dim_</span><span class="p">(</span>
            <span class="n">values</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">values</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span> <span class="p">:]),</span>
            <span class="n">i</span><span class="o">=</span><span class="p">(</span><span class="n">pidx</span> <span class="o">+</span> <span class="n">i</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">j</span><span class="o">=</span><span class="p">(</span><span class="n">pidx</span> <span class="o">+</span> <span class="n">j</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">buffer</span><span class="o">=</span><span class="n">buffer</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Base cases: homogeneous swaps and 1-dimenensional heterogeneous swaps</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">i</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Tensor `i` must be at most 1-dimensional when `dim=0`.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">j</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Tensor `j` must be at most 1-dimensional when `dim=0`.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">dim</span><span class="p">:</span>
            <span class="n">ctx</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">dim</span><span class="p">))</span>
            <span class="n">i</span> <span class="o">=</span> <span class="n">ctx</span> <span class="o">+</span> <span class="p">(</span><span class="n">i</span><span class="p">,)</span>
            <span class="n">j</span> <span class="o">=</span> <span class="n">ctx</span> <span class="o">+</span> <span class="p">(</span><span class="n">j</span><span class="p">,)</span>

        <span class="k">if</span> <span class="n">buffer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">buffer</span> <span class="o">=</span> <span class="n">values</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">buffer</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">values</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

        <span class="n">values</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">values</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
        <span class="n">values</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">buffer</span>

    <span class="k">return</span> <span class="n">values</span></div>



<div class="viewcode-block" id="compute_log_prob_feas_from_bounds">
<a class="viewcode-back" href="../../../../utils.html#botorch.utils.probability.utils.compute_log_prob_feas_from_bounds">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">compute_log_prob_feas_from_bounds</span><span class="p">(</span>
    <span class="n">con_lower_inds</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">con_upper_inds</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">con_both_inds</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">con_lower</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">con_upper</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">con_both</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">means</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">sigmas</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Compute logarithm of the feasibility probability for each batch of mean/sigma.</span>

<span class="sd">    Args:</span>
<span class="sd">        means: A `(b) x m`-dim Tensor of means.</span>
<span class="sd">        sigmas: A `(b) x m`-dim Tensor of standard deviations.</span>
<span class="sd">        con_lower_inds: 1d Tensor of indices con_lower applies to</span>
<span class="sd">            in the second dimension of means and sigmas.</span>
<span class="sd">        con_upper_inds: 1d Tensor of indices con_upper applies to</span>
<span class="sd">            in the second dimension of means and sigmas.</span>
<span class="sd">        con_both_inds: 1d Tensor of indices con_both applies to</span>
<span class="sd">            in the second dimension of means and sigmas.</span>
<span class="sd">        con_lower: 1d Tensor of lower bounds on the constraints</span>
<span class="sd">            equal in dimension to con_lower_inds.</span>
<span class="sd">        con_upper: 1d Tensor of upper bounds on the constraints</span>
<span class="sd">            equal in dimension to con_upper_inds.</span>
<span class="sd">        con_both: 2d Tensor of &quot;both&quot; bounds on the constraints</span>
<span class="sd">            equal in length to con_both_inds.</span>
<span class="sd">    Returns:</span>
<span class="sd">        A `b`-dim tensor of log feasibility probabilities</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">log_prob</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">means</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">con_lower_inds</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">i</span> <span class="o">=</span> <span class="n">con_lower_inds</span>
        <span class="n">dist_l</span> <span class="o">=</span> <span class="p">(</span><span class="n">con_lower</span> <span class="o">-</span> <span class="n">means</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">])</span> <span class="o">/</span> <span class="n">sigmas</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>
        <span class="n">log_prob</span> <span class="o">=</span> <span class="n">log_prob</span> <span class="o">+</span> <span class="n">log_ndtr</span><span class="p">(</span><span class="o">-</span><span class="n">dist_l</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># 1 - Phi(x) = Phi(-x)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">con_upper_inds</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">i</span> <span class="o">=</span> <span class="n">con_upper_inds</span>
        <span class="n">dist_u</span> <span class="o">=</span> <span class="p">(</span><span class="n">con_upper</span> <span class="o">-</span> <span class="n">means</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">])</span> <span class="o">/</span> <span class="n">sigmas</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>
        <span class="n">log_prob</span> <span class="o">=</span> <span class="n">log_prob</span> <span class="o">+</span> <span class="n">log_ndtr</span><span class="p">(</span><span class="n">dist_u</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">con_both_inds</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">i</span> <span class="o">=</span> <span class="n">con_both_inds</span>
        <span class="n">con_lower</span><span class="p">,</span> <span class="n">con_upper</span> <span class="o">=</span> <span class="n">con_both</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">con_both</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
        <span class="c1"># scaled distance to lower and upper constraint boundary:</span>
        <span class="n">dist_l</span> <span class="o">=</span> <span class="p">(</span><span class="n">con_lower</span> <span class="o">-</span> <span class="n">means</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">])</span> <span class="o">/</span> <span class="n">sigmas</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>
        <span class="n">dist_u</span> <span class="o">=</span> <span class="p">(</span><span class="n">con_upper</span> <span class="o">-</span> <span class="n">means</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">])</span> <span class="o">/</span> <span class="n">sigmas</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>
        <span class="n">log_prob</span> <span class="o">=</span> <span class="n">log_prob</span> <span class="o">+</span> <span class="n">log_prob_normal_in</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="n">dist_l</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="n">dist_u</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">log_prob</span></div>



<div class="viewcode-block" id="percentile_of_score">
<a class="viewcode-back" href="../../../../utils.html#botorch.utils.probability.utils.percentile_of_score">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">percentile_of_score</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">score</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the percentile rank of `score` relative to `data`.</span>
<span class="sd">    For example, if this function returns 70 then 70% of the</span>
<span class="sd">    values in `data` are below `score`.</span>

<span class="sd">    This implementation is based on `scipy.stats.percentileofscore`,</span>
<span class="sd">    with `kind=&#39;rank&#39;` and `nan_policy=&#39;propagate&#39;`, which is the default.</span>

<span class="sd">    Args:</span>
<span class="sd">        data: A `... x n x output_shape`-dim Tensor of data.</span>
<span class="sd">        score: A `... x 1 x output_shape`-dim Tensor of scores.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A `... x output_shape`-dim Tensor of percentile ranks.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># based on scipy.stats.percentileofscore</span>
    <span class="n">left</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">data</span> <span class="o">&lt;</span> <span class="n">score</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span>
    <span class="n">right</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">data</span> <span class="o">&lt;=</span> <span class="n">score</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span>
    <span class="n">plus1</span> <span class="o">=</span> <span class="n">left</span> <span class="o">&lt;</span> <span class="n">right</span>
    <span class="n">perct</span> <span class="o">=</span> <span class="p">(</span><span class="n">left</span> <span class="o">+</span> <span class="n">right</span> <span class="o">+</span> <span class="n">plus1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mf">50.0</span> <span class="o">/</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">])</span>
    <span class="c1"># perct shape: `... x output_shape`</span>
    <span class="c1"># fill in nans due to current trial progression being nan</span>
    <span class="n">nan_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">score</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="p">)),</span> <span class="n">perct</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">perct</span><span class="p">[</span><span class="n">nan_mask</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nan</span>
    <span class="c1"># fill in nans due to previous trial progressions being nan</span>
    <span class="n">nan_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">),</span> <span class="n">perct</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">perct</span><span class="p">[</span><span class="n">nan_mask</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nan</span>
    <span class="k">return</span> <span class="n">perct</span></div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p></p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>