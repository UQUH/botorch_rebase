

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>botorch.acquisition.knowledge_gradient &mdash; BoTorch  documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=03e43079" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../../_static/custom.css?v=ca3e82f4" />

  
      <script src="../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../_static/documentation_options.js?v=5929fcd5"></script>
      <script src="../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            BoTorch
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../acquisition.html">botorch.acquisition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models.html">botorch.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generation.html">botorch.generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../posteriors.html">botorch.posteriors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../optim.html">botorch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../fit.html">botorch.fit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../sampling.html">botorch.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cross_validation.html">botorch.cross_validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../settings.html">botorch.settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../logging.html">botorch.logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../test_functions.html">botorch.test_functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../test_utils.html">botorch.test_utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../exceptions.html">botorch.exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../utils.html">botorch.utils</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">BoTorch</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">botorch.acquisition.knowledge_gradient</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for botorch.acquisition.knowledge_gradient</h1><div class="highlight"><pre>
<span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="c1"># Copyright (c) Meta Platforms, Inc. and affiliates.</span>
<span class="c1">#</span>
<span class="c1"># This source code is licensed under the MIT license found in the</span>
<span class="c1"># LICENSE file in the root directory of this source tree.</span>

<span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Batch Knowledge Gradient (KG) via one-shot optimization as introduced in</span>
<span class="sd">[Balandat2020botorch]_. For broader discussion of KG see also [Frazier2008knowledge]_</span>
<span class="sd">and [Wu2016parallelkg]_.</span>

<span class="sd">.. [Balandat2020botorch]</span>
<span class="sd">    M. Balandat, B. Karrer, D. R. Jiang, S. Daulton, B. Letham, A. G. Wilson, and</span>
<span class="sd">    E. Bakshy. BoTorch: A Framework for Efficient Monte-Carlo Bayesian Optimization.</span>
<span class="sd">    Advances in Neural Information Processing Systems 33, 2020.</span>

<span class="sd">.. [Frazier2008knowledge]</span>
<span class="sd">    P. Frazier, W. Powell, and S. Dayanik. A Knowledge-Gradient policy for</span>
<span class="sd">    sequential information collection. SIAM Journal on Control and Optimization,</span>
<span class="sd">    2008.</span>

<span class="sd">.. [Wu2016parallelkg]</span>
<span class="sd">    J. Wu and P. Frazier. The parallel knowledge gradient method for batch</span>
<span class="sd">    bayesian optimization. NIPS 2016.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">__future__</span><span class="w"> </span><span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">collections.abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">Callable</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">copy</span><span class="w"> </span><span class="kn">import</span> <span class="n">deepcopy</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch</span><span class="w"> </span><span class="kn">import</span> <span class="n">settings</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.acquisition.acquisition</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">AcquisitionFunction</span><span class="p">,</span>
    <span class="n">MCSamplerMixin</span><span class="p">,</span>
    <span class="n">OneShotAcquisitionFunction</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.acquisition.analytic</span><span class="w"> </span><span class="kn">import</span> <span class="n">PosteriorMean</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.acquisition.cost_aware</span><span class="w"> </span><span class="kn">import</span> <span class="n">CostAwareUtility</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.acquisition.monte_carlo</span><span class="w"> </span><span class="kn">import</span> <span class="n">MCAcquisitionFunction</span><span class="p">,</span> <span class="n">qSimpleRegret</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.acquisition.objective</span><span class="w"> </span><span class="kn">import</span> <span class="n">MCAcquisitionObjective</span><span class="p">,</span> <span class="n">PosteriorTransform</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.exceptions.errors</span><span class="w"> </span><span class="kn">import</span> <span class="n">UnsupportedError</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.models.model</span><span class="w"> </span><span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.sampling.base</span><span class="w"> </span><span class="kn">import</span> <span class="n">MCSampler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.sampling.normal</span><span class="w"> </span><span class="kn">import</span> <span class="n">SobolQMCNormalSampler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.utils.transforms</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">concatenate_pending_points</span><span class="p">,</span>
    <span class="n">match_batch_shape</span><span class="p">,</span>
    <span class="n">t_batch_mode_transform</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">Tensor</span>


<div class="viewcode-block" id="qKnowledgeGradient">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.knowledge_gradient.qKnowledgeGradient">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">qKnowledgeGradient</span><span class="p">(</span><span class="n">MCAcquisitionFunction</span><span class="p">,</span> <span class="n">OneShotAcquisitionFunction</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Batch Knowledge Gradient using one-shot optimization.</span>

<span class="sd">    This computes the batch Knowledge Gradient using fantasies for the outer</span>
<span class="sd">    expectation and either the model posterior mean or MC-sampling for the inner</span>
<span class="sd">    expectation.</span>

<span class="sd">    In addition to the design variables, the input `X` also includes variables</span>
<span class="sd">    for the optimal designs for each of the fantasy models. For a fixed number</span>
<span class="sd">    of fantasies, all parts of `X` can be optimized in a &quot;one-shot&quot; fashion.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span>
        <span class="n">num_fantasies</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span>
        <span class="n">sampler</span><span class="p">:</span> <span class="n">MCSampler</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">objective</span><span class="p">:</span> <span class="n">MCAcquisitionObjective</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">PosteriorTransform</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">inner_sampler</span><span class="p">:</span> <span class="n">MCSampler</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">X_pending</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">current_value</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;q-Knowledge Gradient (one-shot optimization).</span>

<span class="sd">        Args:</span>
<span class="sd">            model: A fitted model. Must support fantasizing.</span>
<span class="sd">            num_fantasies: The number of fantasy points to use. More fantasy</span>
<span class="sd">                points result in a better approximation, at the expense of</span>
<span class="sd">                memory and wall time. Unused if `sampler` is specified.</span>
<span class="sd">            sampler: The sampler used to sample fantasy observations. Optional</span>
<span class="sd">                if `num_fantasies` is specified.</span>
<span class="sd">            objective: The objective under which the samples are evaluated. If</span>
<span class="sd">                `None`, then the analytic posterior mean is used. Otherwise, the</span>
<span class="sd">                objective is MC-evaluated (using inner_sampler).</span>
<span class="sd">            posterior_transform: An optional PosteriorTransform. If given, this</span>
<span class="sd">                transforms the posterior before evaluation. If `objective is None`,</span>
<span class="sd">                then the analytic posterior mean of the transformed posterior is</span>
<span class="sd">                used. If `objective` is given, the `inner_sampler` is used to draw</span>
<span class="sd">                samples from the transformed posterior, which are then evaluated under</span>
<span class="sd">                the `objective`.</span>
<span class="sd">            inner_sampler: The sampler used for inner sampling. Ignored if the</span>
<span class="sd">                objective is `None`.</span>
<span class="sd">            X_pending: A `m x d`-dim Tensor of `m` design points that have</span>
<span class="sd">                points that have been submitted for function evaluation</span>
<span class="sd">                but have not yet been evaluated.</span>
<span class="sd">            current_value: The current value, i.e. the expected best objective</span>
<span class="sd">                given the observed points `D`. If omitted, forward will not</span>
<span class="sd">                return the actual KG value, but the expected best objective</span>
<span class="sd">                given the data set `D u X`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">sampler</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">num_fantasies</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Must specify `num_fantasies` if no `sampler` is provided.&quot;</span>
                <span class="p">)</span>
            <span class="c1"># base samples should be fixed for joint optimization over X, X_fantasies</span>
            <span class="n">sampler</span> <span class="o">=</span> <span class="n">SobolQMCNormalSampler</span><span class="p">(</span><span class="n">sample_shape</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">num_fantasies</span><span class="p">]))</span>
        <span class="k">elif</span> <span class="n">num_fantasies</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">sampler</span><span class="o">.</span><span class="n">sample_shape</span> <span class="o">!=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">num_fantasies</span><span class="p">]):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;The sampler shape must match num_fantasies=</span><span class="si">{</span><span class="n">num_fantasies</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">num_fantasies</span> <span class="o">=</span> <span class="n">sampler</span><span class="o">.</span><span class="n">sample_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MCAcquisitionFunction</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
        <span class="n">MCSamplerMixin</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">)</span>
        <span class="c1"># if not explicitly specified, we use the posterior mean for linear objs</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">MCAcquisitionObjective</span><span class="p">)</span> <span class="ow">and</span> <span class="n">inner_sampler</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">inner_sampler</span> <span class="o">=</span> <span class="n">SobolQMCNormalSampler</span><span class="p">(</span><span class="n">sample_shape</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">128</span><span class="p">]))</span>
        <span class="k">elif</span> <span class="n">objective</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">objective</span><span class="p">,</span> <span class="n">MCAcquisitionObjective</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="n">UnsupportedError</span><span class="p">(</span>
                <span class="s2">&quot;Objectives that are not an `MCAcquisitionObjective` are not supported.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">objective</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">model</span><span class="o">.</span><span class="n">num_outputs</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">posterior_transform</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">UnsupportedError</span><span class="p">(</span>
                    <span class="s2">&quot;Must specify an objective or a posterior transform when using &quot;</span>
                    <span class="s2">&quot;a multi-output model.&quot;</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="ow">not</span> <span class="n">posterior_transform</span><span class="o">.</span><span class="n">scalarize</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">UnsupportedError</span><span class="p">(</span>
                    <span class="s2">&quot;If using a multi-output model without an objective, &quot;</span>
                    <span class="s2">&quot;posterior_transform must scalarize the output.&quot;</span>
                <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">objective</span> <span class="o">=</span> <span class="n">objective</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">posterior_transform</span> <span class="o">=</span> <span class="n">posterior_transform</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_X_pending</span><span class="p">(</span><span class="n">X_pending</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X_pending</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_pending</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inner_sampler</span> <span class="o">=</span> <span class="n">inner_sampler</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_fantasies</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">num_fantasies</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">current_value</span> <span class="o">=</span> <span class="n">current_value</span>

<div class="viewcode-block" id="qKnowledgeGradient.forward">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.knowledge_gradient.qKnowledgeGradient.forward">[docs]</a>
    <span class="nd">@t_batch_mode_transform</span><span class="p">()</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Evaluate qKnowledgeGradient on the candidate set `X`.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: A `b x (q + num_fantasies) x d` Tensor with `b` t-batches of</span>
<span class="sd">                `q + num_fantasies` design points each. We split this X tensor</span>
<span class="sd">                into two parts in the `q` dimension (`dim=-2`). The first `q`</span>
<span class="sd">                are the q-batch of design points and the last num_fantasies are</span>
<span class="sd">                the current solutions of the inner optimization problem.</span>

<span class="sd">                `X_fantasies = X[..., -num_fantasies:, :]`</span>
<span class="sd">                `X_fantasies.shape = b x num_fantasies x d`</span>

<span class="sd">                `X_actual = X[..., :-num_fantasies, :]`</span>
<span class="sd">                `X_actual.shape = b x q x d`</span>

<span class="sd">        Returns:</span>
<span class="sd">            A Tensor of shape `b`. For t-batch b, the q-KG value of the design</span>
<span class="sd">                `X_actual[b]` is averaged across the fantasy models, where</span>
<span class="sd">                `X_fantasies[b, i]` is chosen as the final selection for the</span>
<span class="sd">                `i`-th fantasy model.</span>
<span class="sd">                NOTE: If `current_value` is not provided, then this is not the</span>
<span class="sd">                true KG value of `X_actual[b]`, and `X_fantasies[b, : ]` must be</span>
<span class="sd">                maximized at fixed `X_actual[b]`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X_actual</span><span class="p">,</span> <span class="n">X_fantasies</span> <span class="o">=</span> <span class="n">_split_fantasy_points</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">n_f</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_fantasies</span><span class="p">)</span>

        <span class="c1"># We only concatenate X_pending into the X part after splitting</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_pending</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">X_actual</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                <span class="p">[</span><span class="n">X_actual</span><span class="p">,</span> <span class="n">match_batch_shape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_pending</span><span class="p">,</span> <span class="n">X_actual</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span>
            <span class="p">)</span>

        <span class="c1"># construct the fantasy model of shape `num_fantasies x b`</span>
        <span class="n">fantasy_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fantasize</span><span class="p">(</span>
            <span class="n">X</span><span class="o">=</span><span class="n">X_actual</span><span class="p">,</span>
            <span class="n">sampler</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sampler</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># get the value function</span>
        <span class="n">value_function</span> <span class="o">=</span> <span class="n">_get_value_function</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">fantasy_model</span><span class="p">,</span>
            <span class="n">objective</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">objective</span><span class="p">,</span>
            <span class="n">posterior_transform</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">posterior_transform</span><span class="p">,</span>
            <span class="n">sampler</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">inner_sampler</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># make sure to propagate gradients to the fantasy model train inputs</span>
        <span class="k">with</span> <span class="n">settings</span><span class="o">.</span><span class="n">propagate_grads</span><span class="p">(</span><span class="kc">True</span><span class="p">):</span>
            <span class="n">values</span> <span class="o">=</span> <span class="n">value_function</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X_fantasies</span><span class="p">)</span>  <span class="c1"># num_fantasies x b</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">values</span> <span class="o">=</span> <span class="n">values</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_value</span>

        <span class="c1"># return average over the fantasy samples</span>
        <span class="k">return</span> <span class="n">values</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></div>


<div class="viewcode-block" id="qKnowledgeGradient.evaluate">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.knowledge_gradient.qKnowledgeGradient.evaluate">[docs]</a>
    <span class="nd">@concatenate_pending_points</span>
    <span class="nd">@t_batch_mode_transform</span><span class="p">()</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">bounds</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Evaluate qKnowledgeGradient on the candidate set `X_actual` by</span>
<span class="sd">        solving the inner optimization problem.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: A `b x q x d` Tensor with `b` t-batches of `q` design points</span>
<span class="sd">                each. Unlike `forward()`, this does not include solutions of the</span>
<span class="sd">                inner optimization problem.</span>
<span class="sd">            bounds: A `2 x d` tensor of lower and upper bounds for each column of</span>
<span class="sd">                the solutions to the inner problem.</span>
<span class="sd">            kwargs: Additional keyword arguments. This includes the options for</span>
<span class="sd">                optimization of the inner problem, i.e. `num_restarts`, `raw_samples`,</span>
<span class="sd">                an `options` dictionary to be passed on to the optimization helpers, and</span>
<span class="sd">                a `scipy_options` dictionary to be passed to `scipy.minimize`.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A Tensor of shape `b`. For t-batch b, the q-KG value of the design</span>
<span class="sd">                `X[b]` is averaged across the fantasy models.</span>
<span class="sd">                NOTE: If `current_value` is not provided, then this is not the</span>
<span class="sd">                true KG value of `X[b]`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;expand&quot;</span><span class="p">):</span>
            <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="c1"># construct the fantasy model of shape `num_fantasies x b`</span>
        <span class="n">fantasy_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fantasize</span><span class="p">(</span>
            <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
            <span class="n">sampler</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sampler</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># get the value function</span>
        <span class="n">value_function</span> <span class="o">=</span> <span class="n">_get_value_function</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">fantasy_model</span><span class="p">,</span>
            <span class="n">objective</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">objective</span><span class="p">,</span>
            <span class="n">posterior_transform</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">posterior_transform</span><span class="p">,</span>
            <span class="n">sampler</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">inner_sampler</span><span class="p">,</span>
            <span class="n">project</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;project&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="kn">from</span><span class="w"> </span><span class="nn">botorch.generation.gen</span><span class="w"> </span><span class="kn">import</span> <span class="n">gen_candidates_scipy</span>

        <span class="c1"># optimize the inner problem</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">botorch.optim.initializers</span><span class="w"> </span><span class="kn">import</span> <span class="n">gen_value_function_initial_conditions</span>

        <span class="n">initial_conditions</span> <span class="o">=</span> <span class="n">gen_value_function_initial_conditions</span><span class="p">(</span>
            <span class="n">acq_function</span><span class="o">=</span><span class="n">value_function</span><span class="p">,</span>
            <span class="n">bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">,</span>
            <span class="n">num_restarts</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;num_restarts&quot;</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span>
            <span class="n">raw_samples</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;raw_samples&quot;</span><span class="p">,</span> <span class="mi">1024</span><span class="p">),</span>
            <span class="n">current_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="o">**</span><span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;options&quot;</span><span class="p">,</span> <span class="p">{}),</span> <span class="o">**</span><span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;scipy_options&quot;</span><span class="p">,</span> <span class="p">{})},</span>
        <span class="p">)</span>

        <span class="n">_</span><span class="p">,</span> <span class="n">values</span> <span class="o">=</span> <span class="n">gen_candidates_scipy</span><span class="p">(</span>
            <span class="n">initial_conditions</span><span class="o">=</span><span class="n">initial_conditions</span><span class="p">,</span>
            <span class="n">acquisition_function</span><span class="o">=</span><span class="n">value_function</span><span class="p">,</span>
            <span class="n">lower_bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">upper_bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
            <span class="n">options</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;scipy_options&quot;</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="c1"># get the maximizer for each batch</span>
        <span class="n">values</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">values</span> <span class="o">=</span> <span class="n">values</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_value</span>
        <span class="c1"># NOTE: using getattr to cover both no-attribute with qKG and None with qMFKG</span>
        <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;cost_aware_utility&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cost_aware_utility</span><span class="p">(</span>
                <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">deltas</span><span class="o">=</span><span class="n">values</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cost_sampler</span>
            <span class="p">)</span>
        <span class="c1"># return average over the fantasy samples</span>
        <span class="k">return</span> <span class="n">values</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></div>


<div class="viewcode-block" id="qKnowledgeGradient.get_augmented_q_batch_size">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.knowledge_gradient.qKnowledgeGradient.get_augmented_q_batch_size">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_augmented_q_batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Get augmented q batch size for one-shot optimization.</span>

<span class="sd">        Args:</span>
<span class="sd">            q: The number of candidates to consider jointly.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The augmented size for one-shot optimization (including variables</span>
<span class="sd">            parameterizing the fantasy solutions).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">q</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_fantasies</span></div>


<div class="viewcode-block" id="qKnowledgeGradient.extract_candidates">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.knowledge_gradient.qKnowledgeGradient.extract_candidates">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">extract_candidates</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_full</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;We only return X as the set of candidates post-optimization.</span>

<span class="sd">        Args:</span>
<span class="sd">            X_full: A `b x (q + num_fantasies) x d`-dim Tensor with `b`</span>
<span class="sd">                t-batches of `q + num_fantasies` design points each.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `b x q x d`-dim Tensor with `b` t-batches of `q` design points each.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">X_full</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">num_fantasies</span><span class="p">,</span> <span class="p">:]</span></div>
</div>



<div class="viewcode-block" id="qMultiFidelityKnowledgeGradient">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.knowledge_gradient.qMultiFidelityKnowledgeGradient">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">qMultiFidelityKnowledgeGradient</span><span class="p">(</span><span class="n">qKnowledgeGradient</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Batch Knowledge Gradient for multi-fidelity optimization.</span>

<span class="sd">    A version of `qKnowledgeGradient` that supports multi-fidelity optimization</span>
<span class="sd">    via a `CostAwareUtility` and the `project` and `expand` operators. If none</span>
<span class="sd">    of these are set, this acquisition function reduces to `qKnowledgeGradient`.</span>
<span class="sd">    Through `valfunc_cls` and `valfunc_argfac`, this can be changed into a custom</span>
<span class="sd">    multi-fidelity acquisition function (it is only KG if the terminal value is</span>
<span class="sd">    computed using a posterior mean).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span>
        <span class="n">num_fantasies</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span>
        <span class="n">sampler</span><span class="p">:</span> <span class="n">MCSampler</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">objective</span><span class="p">:</span> <span class="n">MCAcquisitionObjective</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">PosteriorTransform</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">inner_sampler</span><span class="p">:</span> <span class="n">MCSampler</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">X_pending</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">current_value</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">cost_aware_utility</span><span class="p">:</span> <span class="n">CostAwareUtility</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">project</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">X</span><span class="p">:</span> <span class="n">X</span><span class="p">,</span>
        <span class="n">expand</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">X</span><span class="p">:</span> <span class="n">X</span><span class="p">,</span>
        <span class="n">valfunc_cls</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="n">AcquisitionFunction</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">valfunc_argfac</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Model</span><span class="p">],</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Multi-Fidelity q-Knowledge Gradient (one-shot optimization).</span>

<span class="sd">        Args:</span>
<span class="sd">            model: A fitted model. Must support fantasizing.</span>
<span class="sd">            num_fantasies: The number of fantasy points to use. More fantasy</span>
<span class="sd">                points result in a better approximation, at the expense of</span>
<span class="sd">                memory and wall time. Unused if `sampler` is specified.</span>
<span class="sd">            sampler: The sampler used to sample fantasy observations. Optional</span>
<span class="sd">                if `num_fantasies` is specified.</span>
<span class="sd">            objective: The objective under which the samples are evaluated. If</span>
<span class="sd">                `None`, then the analytic posterior mean is used. Otherwise, the</span>
<span class="sd">                objective is MC-evaluated (using inner_sampler).</span>
<span class="sd">            posterior_transform: An optional PosteriorTransform. If given, this</span>
<span class="sd">                transforms the posterior before evaluation. If `objective is None`,</span>
<span class="sd">                then the analytic posterior mean of the transformed posterior is</span>
<span class="sd">                used. If `objective` is given, the `inner_sampler` is used to draw</span>
<span class="sd">                samples from the transformed posterior, which are then evaluated under</span>
<span class="sd">                the `objective`.</span>
<span class="sd">            inner_sampler: The sampler used for inner sampling. Ignored if the</span>
<span class="sd">                objective is `None`.</span>
<span class="sd">            X_pending: A `m x d`-dim Tensor of `m` design points that have</span>
<span class="sd">                points that have been submitted for function evaluation</span>
<span class="sd">                but have not yet been evaluated.</span>
<span class="sd">            current_value: The current value, i.e. the expected best objective</span>
<span class="sd">                given the observed points `D`. If omitted, forward will not</span>
<span class="sd">                return the actual KG value, but the expected best objective</span>
<span class="sd">                given the data set `D u X`.</span>
<span class="sd">            cost_aware_utility: A CostAwareUtility computing the cost-transformed</span>
<span class="sd">                utility from a candidate set and samples of increases in utility.</span>
<span class="sd">            project: A callable mapping a `batch_shape x q x d` tensor of design</span>
<span class="sd">                points to a tensor with shape `batch_shape x q_term x d` projected</span>
<span class="sd">                to the desired target set (e.g. the target fidelities in case of</span>
<span class="sd">                multi-fidelity optimization). For the basic case, `q_term = q`.</span>
<span class="sd">            expand: A callable mapping a `batch_shape x q x d` input tensor to</span>
<span class="sd">                a `batch_shape x (q + q_e)&#39; x d`-dim output tensor, where the</span>
<span class="sd">                `q_e` additional points in each q-batch correspond to</span>
<span class="sd">                additional (&quot;trace&quot;) observations.</span>
<span class="sd">            valfunc_cls: An acquisition function class to be used as the terminal</span>
<span class="sd">                value function.</span>
<span class="sd">            valfunc_argfac: An argument factory, i.e. callable that maps a `Model`</span>
<span class="sd">                to a dictionary of kwargs for the terminal value function (e.g.</span>
<span class="sd">                `best_f` for `ExpectedImprovement`).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">current_value</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">cost_aware_utility</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">UnsupportedError</span><span class="p">(</span>
                <span class="s2">&quot;Cost-aware KG requires current_value to be specified.&quot;</span>
            <span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">num_fantasies</span><span class="o">=</span><span class="n">num_fantasies</span><span class="p">,</span>
            <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">,</span>
            <span class="n">objective</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
            <span class="n">posterior_transform</span><span class="o">=</span><span class="n">posterior_transform</span><span class="p">,</span>
            <span class="n">inner_sampler</span><span class="o">=</span><span class="n">inner_sampler</span><span class="p">,</span>
            <span class="n">X_pending</span><span class="o">=</span><span class="n">X_pending</span><span class="p">,</span>
            <span class="n">current_value</span><span class="o">=</span><span class="n">current_value</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cost_aware_utility</span> <span class="o">=</span> <span class="n">cost_aware_utility</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">project</span> <span class="o">=</span> <span class="n">project</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">expand</span> <span class="o">=</span> <span class="n">expand</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cost_sampler</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">valfunc_cls</span> <span class="o">=</span> <span class="n">valfunc_cls</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">valfunc_argfac</span> <span class="o">=</span> <span class="n">valfunc_argfac</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">cost_sampler</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cost_sampler</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Note: Using the deepcopy here is essential. Removing this poses a</span>
            <span class="c1"># problem if the base model and the cost model have a different number</span>
            <span class="c1"># of outputs or test points (this would be caused by expand), as this</span>
            <span class="c1"># would trigger re-sampling the base samples in the fantasy sampler.</span>
            <span class="c1"># By cloning the sampler here, the right thing will happen if the</span>
            <span class="c1"># the sizes are compatible, if they are not this will result in</span>
            <span class="c1"># samples being drawn using different base samples, but it will at</span>
            <span class="c1"># least avoid changing state of the fantasy sampler.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_cost_sampler</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sampler</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cost_sampler</span>

<div class="viewcode-block" id="qMultiFidelityKnowledgeGradient.forward">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.knowledge_gradient.qMultiFidelityKnowledgeGradient.forward">[docs]</a>
    <span class="nd">@t_batch_mode_transform</span><span class="p">()</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Evaluate qMultiFidelityKnowledgeGradient on the candidate set `X`.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: A `b x (q + num_fantasies) x d` Tensor with `b` t-batches of</span>
<span class="sd">                `q + num_fantasies` design points each. We split this X tensor</span>
<span class="sd">                into two parts in the `q` dimension (`dim=-2`). The first `q`</span>
<span class="sd">                are the q-batch of design points and the last num_fantasies are</span>
<span class="sd">                the current solutions of the inner optimization problem.</span>

<span class="sd">                `X_fantasies = X[..., -num_fantasies:, :]`</span>
<span class="sd">                `X_fantasies.shape = b x num_fantasies x d`</span>

<span class="sd">                `X_actual = X[..., :-num_fantasies, :]`</span>
<span class="sd">                `X_actual.shape = b x q x d`</span>

<span class="sd">                In addition, `X` may be augmented with fidelity parameters as</span>
<span class="sd">                part of thee `d`-dimension. Projecting fidelities to the target</span>
<span class="sd">                fidelity is handled by `project`.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A Tensor of shape `b`. For t-batch b, the q-KG value of the design</span>
<span class="sd">                `X_actual[b]` is averaged across the fantasy models, where</span>
<span class="sd">                `X_fantasies[b, i]` is chosen as the final selection for the</span>
<span class="sd">                `i`-th fantasy model.</span>
<span class="sd">                NOTE: If `current_value` is not provided, then this is not the</span>
<span class="sd">                true KG value of `X_actual[b]`, and `X_fantasies[b, : ]` must be</span>
<span class="sd">                maximized at fixed `X_actual[b]`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X_actual</span><span class="p">,</span> <span class="n">X_fantasies</span> <span class="o">=</span> <span class="n">_split_fantasy_points</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">n_f</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_fantasies</span><span class="p">)</span>

        <span class="c1"># We only concatenate X_pending into the X part after splitting</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_pending</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">X_eval</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                <span class="p">[</span><span class="n">X_actual</span><span class="p">,</span> <span class="n">match_batch_shape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_pending</span><span class="p">,</span> <span class="n">X_actual</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">X_eval</span> <span class="o">=</span> <span class="n">X_actual</span>

        <span class="c1"># construct the fantasy model of shape `num_fantasies x b`</span>
        <span class="c1"># expand X (to potentially add trace observations)</span>
        <span class="n">fantasy_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fantasize</span><span class="p">(</span>
            <span class="n">X</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">X_eval</span><span class="p">),</span>
            <span class="n">sampler</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sampler</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># get the value function</span>
        <span class="n">value_function</span> <span class="o">=</span> <span class="n">_get_value_function</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">fantasy_model</span><span class="p">,</span>
            <span class="n">objective</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">objective</span><span class="p">,</span>
            <span class="n">posterior_transform</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">posterior_transform</span><span class="p">,</span>
            <span class="n">sampler</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">inner_sampler</span><span class="p">,</span>
            <span class="n">project</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">project</span><span class="p">,</span>
            <span class="n">valfunc_cls</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">valfunc_cls</span><span class="p">,</span>
            <span class="n">valfunc_argfac</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">valfunc_argfac</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># make sure to propagate gradients to the fantasy model train inputs</span>
        <span class="c1"># project the fantasy points</span>
        <span class="k">with</span> <span class="n">settings</span><span class="o">.</span><span class="n">propagate_grads</span><span class="p">(</span><span class="kc">True</span><span class="p">):</span>
            <span class="n">values</span> <span class="o">=</span> <span class="n">value_function</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X_fantasies</span><span class="p">)</span>  <span class="c1"># num_fantasies x b</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">values</span> <span class="o">=</span> <span class="n">values</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_value</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cost_aware_utility</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cost_aware_utility</span><span class="p">(</span>
                <span class="n">X</span><span class="o">=</span><span class="n">X_actual</span><span class="p">,</span> <span class="n">deltas</span><span class="o">=</span><span class="n">values</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cost_sampler</span>
            <span class="p">)</span>

        <span class="c1"># return average over the fantasy samples</span>
        <span class="k">return</span> <span class="n">values</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></div>
</div>



<div class="viewcode-block" id="ProjectedAcquisitionFunction">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.knowledge_gradient.ProjectedAcquisitionFunction">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">ProjectedAcquisitionFunction</span><span class="p">(</span><span class="n">AcquisitionFunction</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Defines a wrapper around  an `AcquisitionFunction` that incorporates the project</span>
<span class="sd">    operator. Typically used to handle value functions in look-ahead methods.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">base_value_function</span><span class="p">:</span> <span class="n">AcquisitionFunction</span><span class="p">,</span>
        <span class="n">project</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            base_value_function: The wrapped `AcquisitionFunction`.</span>
<span class="sd">            project: A callable mapping a `batch_shape x q x d` tensor of design</span>
<span class="sd">                points to a tensor with shape `batch_shape x q_term x d` projected</span>
<span class="sd">                to the desired target set (e.g. the target fidelities in case of</span>
<span class="sd">                multi-fidelity optimization). For the basic case, `q_term = q`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">base_value_function</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_value_function</span> <span class="o">=</span> <span class="n">base_value_function</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">project</span> <span class="o">=</span> <span class="n">project</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">objective</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">base_value_function</span><span class="p">,</span> <span class="s2">&quot;objective&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">posterior_transform</span> <span class="o">=</span> <span class="n">base_value_function</span><span class="o">.</span><span class="n">posterior_transform</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sampler</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">base_value_function</span><span class="p">,</span> <span class="s2">&quot;sampler&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

<div class="viewcode-block" id="ProjectedAcquisitionFunction.forward">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.knowledge_gradient.ProjectedAcquisitionFunction.forward">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_value_function</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">project</span><span class="p">(</span><span class="n">X</span><span class="p">))</span></div>
</div>



<span class="k">def</span><span class="w"> </span><span class="nf">_get_value_function</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span>
    <span class="n">objective</span><span class="p">:</span> <span class="n">MCAcquisitionObjective</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">PosteriorTransform</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">sampler</span><span class="p">:</span> <span class="n">MCSampler</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">project</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">valfunc_cls</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="n">AcquisitionFunction</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">valfunc_argfac</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Model</span><span class="p">],</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">AcquisitionFunction</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Construct value function (i.e. inner acquisition function).&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">valfunc_cls</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">common_kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="n">model</span><span class="p">,</span>
            <span class="s2">&quot;posterior_transform&quot;</span><span class="p">:</span> <span class="n">posterior_transform</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="nb">issubclass</span><span class="p">(</span><span class="n">valfunc_cls</span><span class="p">,</span> <span class="n">MCAcquisitionFunction</span><span class="p">):</span>
            <span class="n">common_kwargs</span><span class="p">[</span><span class="s2">&quot;sampler&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sampler</span>
            <span class="n">common_kwargs</span><span class="p">[</span><span class="s2">&quot;objective&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">objective</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="n">valfunc_argfac</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span> <span class="k">if</span> <span class="n">valfunc_argfac</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}</span>
        <span class="n">base_value_function</span> <span class="o">=</span> <span class="n">valfunc_cls</span><span class="p">(</span><span class="o">**</span><span class="n">common_kwargs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">objective</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">base_value_function</span> <span class="o">=</span> <span class="n">qSimpleRegret</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
                <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">,</span>
                <span class="n">objective</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
                <span class="n">posterior_transform</span><span class="o">=</span><span class="n">posterior_transform</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">base_value_function</span> <span class="o">=</span> <span class="n">PosteriorMean</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">posterior_transform</span><span class="o">=</span><span class="n">posterior_transform</span>
            <span class="p">)</span>

    <span class="k">if</span> <span class="n">project</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">base_value_function</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ProjectedAcquisitionFunction</span><span class="p">(</span>
            <span class="n">base_value_function</span><span class="o">=</span><span class="n">base_value_function</span><span class="p">,</span>
            <span class="n">project</span><span class="o">=</span><span class="n">project</span><span class="p">,</span>
        <span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_split_fantasy_points</span><span class="p">(</span><span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">n_f</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Split a one-shot optimization input into actual and fantasy points</span>

<span class="sd">    Args:</span>
<span class="sd">        X: A `batch_shape x (q + n_f) x d`-dim tensor of actual and fantasy</span>
<span class="sd">            points</span>

<span class="sd">    Returns:</span>
<span class="sd">        2-element tuple containing</span>

<span class="sd">        - A `batch_shape x q x d`-dim tensor `X_actual` of input candidates.</span>
<span class="sd">        - A `n_f x batch_shape x 1 x d`-dim tensor `X_fantasies` of fantasy</span>
<span class="sd">            points, where `X_fantasies[i, batch_idx]` is the i-th fantasy point</span>
<span class="sd">            associated with the batch indexed by `batch_idx`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">n_f</span> <span class="o">&gt;</span> <span class="n">X</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;n_f (</span><span class="si">{</span><span class="n">n_f</span><span class="si">}</span><span class="s2">) must be less than the q-batch dimension of X (</span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2">)&quot;</span>
        <span class="p">)</span>
    <span class="n">split_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="n">X</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">n_f</span><span class="p">,</span> <span class="n">n_f</span><span class="p">]</span>
    <span class="n">X_actual</span><span class="p">,</span> <span class="n">X_fantasies</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">split_sizes</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>
    <span class="c1"># X_fantasies is b x num_fantasies x d, needs to be num_fantasies x b x 1 x d</span>
    <span class="c1"># for batch mode evaluation with batch shape num_fantasies x b.</span>
    <span class="c1"># b x num_fantasies x d --&gt; num_fantasies x b x d</span>
    <span class="n">X_fantasies</span> <span class="o">=</span> <span class="n">X_fantasies</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">*</span><span class="nb">range</span><span class="p">(</span><span class="n">X_fantasies</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">-</span> <span class="mi">2</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># num_fantasies x b x 1 x d</span>
    <span class="n">X_fantasies</span> <span class="o">=</span> <span class="n">X_fantasies</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">X_actual</span><span class="p">,</span> <span class="n">X_fantasies</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p></p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>