

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>botorch.acquisition.utils &mdash; BoTorch  documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=03e43079" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../../_static/custom.css?v=ca3e82f4" />

  
      <script src="../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../_static/documentation_options.js?v=5929fcd5"></script>
      <script src="../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            BoTorch
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../acquisition.html">botorch.acquisition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models.html">botorch.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generation.html">botorch.generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../posteriors.html">botorch.posteriors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../optim.html">botorch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../fit.html">botorch.fit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../sampling.html">botorch.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cross_validation.html">botorch.cross_validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../settings.html">botorch.settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../logging.html">botorch.logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../test_functions.html">botorch.test_functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../test_utils.html">botorch.test_utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../exceptions.html">botorch.exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../utils.html">botorch.utils</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">BoTorch</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">botorch.acquisition.utils</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for botorch.acquisition.utils</h1><div class="highlight"><pre>
<span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="c1"># Copyright (c) Meta Platforms, Inc. and affiliates.</span>
<span class="c1">#</span>
<span class="c1"># This source code is licensed under the MIT license found in the</span>
<span class="c1"># LICENSE file in the root directory of this source tree.</span>

<span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Utilities for acquisition functions.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">__future__</span><span class="w"> </span><span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections.abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">Callable</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.acquisition.objective</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">MCAcquisitionObjective</span><span class="p">,</span>
    <span class="n">PosteriorTransform</span><span class="p">,</span>
    <span class="n">ScalarizedPosteriorTransform</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.exceptions.errors</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">BotorchTensorDimensionError</span><span class="p">,</span>
    <span class="n">DeprecationError</span><span class="p">,</span>
    <span class="n">UnsupportedError</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.models.fully_bayesian</span><span class="w"> </span><span class="kn">import</span> <span class="n">MCMC_DIM</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.models.model</span><span class="w"> </span><span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.sampling.base</span><span class="w"> </span><span class="kn">import</span> <span class="n">MCSampler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.sampling.get_sampler</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_sampler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.sampling.pathwise.posterior_samplers</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_matheron_path_model</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.utils.objective</span><span class="w"> </span><span class="kn">import</span> <span class="n">compute_feasibility_indicator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.utils.sampling</span><span class="w"> </span><span class="kn">import</span> <span class="n">optimize_posterior_samples</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.utils.transforms</span><span class="w"> </span><span class="kn">import</span> <span class="n">is_ensemble</span><span class="p">,</span> <span class="n">normalize_indices</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">GP</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyre_extensions</span><span class="w"> </span><span class="kn">import</span> <span class="n">none_throws</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">Tensor</span>


<div class="viewcode-block" id="get_acquisition_function">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.utils.get_acquisition_function">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">get_acquisition_function</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">raise</span> <span class="n">DeprecationError</span><span class="p">(</span>
        <span class="s2">&quot;`get_acquisition_function` has been moved to `botorch.acquisition.factory`.&quot;</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="repeat_to_match_aug_dim">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.utils.repeat_to_match_aug_dim">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">repeat_to_match_aug_dim</span><span class="p">(</span><span class="n">target_tensor</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">reference_tensor</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Repeat target_tensor until it has the same first dimension as reference_tensor</span>
<span class="sd">    This works regardless of the batch shapes and q.</span>
<span class="sd">    This is useful as we sometimes modify sample shapes such as in LearnedObjective.</span>

<span class="sd">    Args:</span>
<span class="sd">        target_tensor: A `sample_size x batch_shape x q x m`-dim Tensor</span>
<span class="sd">        reference_tensor: A `(augmented_sample * sample_size) x batch_shape x q`-dim</span>
<span class="sd">            Tensor. `augmented_sample` could be 1.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The content of `target_tensor` potentially repeated so that its first dimension</span>
<span class="sd">        matches that of `reference_tensor`.</span>
<span class="sd">        The shape will be `(augmented_sample * sample_size) x batch_shape x q x m`.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; target_tensor = torch.arange(3).repeat(2, 1).T</span>
<span class="sd">        &gt;&gt;&gt; target_tensor</span>
<span class="sd">        tensor([[0, 0],</span>
<span class="sd">                [1, 1],</span>
<span class="sd">                [2, 2]])</span>
<span class="sd">        &gt;&gt;&gt; repeat_to_match_aug_dim(target_tensor, torch.zeros(6))</span>
<span class="sd">        tensor([[0, 0],</span>
<span class="sd">                [1, 1],</span>
<span class="sd">                [2, 2],</span>
<span class="sd">                [0, 0],</span>
<span class="sd">                [1, 1],</span>
<span class="sd">                [2, 2]])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">augmented_sample_num</span><span class="p">,</span> <span class="n">remainder</span> <span class="o">=</span> <span class="nb">divmod</span><span class="p">(</span>
        <span class="n">reference_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">target_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">remainder</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;The first dimension of reference_tensor must &quot;</span>
            <span class="s2">&quot;be a multiple of target_tensor&#39;s.&quot;</span>
        <span class="p">)</span>

    <span class="c1"># using repeat here as obj might be constructed as</span>
    <span class="c1"># obj.reshape(-1, *samples.shape[2:]) where the first 2 dimensions are</span>
    <span class="c1"># of shape `augmented_samples x sample_shape`.</span>
    <span class="n">repeat_size</span> <span class="o">=</span> <span class="p">(</span><span class="n">augmented_sample_num</span><span class="p">,)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="o">*</span> <span class="p">(</span><span class="n">target_tensor</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">target_tensor</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="o">*</span><span class="n">repeat_size</span><span class="p">)</span></div>



<div class="viewcode-block" id="compute_best_feasible_objective">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.utils.compute_best_feasible_objective">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">compute_best_feasible_objective</span><span class="p">(</span>
    <span class="n">samples</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">obj</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">constraints</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">Model</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">objective</span><span class="p">:</span> <span class="n">MCAcquisitionObjective</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">PosteriorTransform</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">X_baseline</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">infeasible_obj</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Computes the largest `obj` value that is feasible under the `constraints`. If</span>
<span class="sd">    `constraints` is None, returns the best unconstrained objective value.</span>

<span class="sd">    When no feasible observations exist and `infeasible_obj` is not `None`, returns</span>
<span class="sd">    `infeasible_obj` (potentially reshaped). When no feasible observations exist and</span>
<span class="sd">    `infeasible_obj` is `None`, uses `model`, `objective`, `posterior_transform`, and</span>
<span class="sd">    `X_baseline` to infer and return an `infeasible_obj` `M` s.t. `M &lt; min_x f(x)`.</span>

<span class="sd">    Args:</span>
<span class="sd">        samples: `(sample_shape) x batch_shape x q x m`-dim posterior samples.</span>
<span class="sd">        obj: A `(sample_shape) x batch_shape x q`-dim Tensor of MC objective values.</span>
<span class="sd">        constraints: A list of constraint callables which map posterior samples to</span>
<span class="sd">            a scalar. The associated constraint is considered satisfied if this</span>
<span class="sd">            scalar is less than zero.</span>
<span class="sd">        model: A Model, only required when there are no feasible observations.</span>
<span class="sd">        objective: An MCAcquisitionObjective, only optionally used when there are no</span>
<span class="sd">            feasible observations.</span>
<span class="sd">        posterior_transform: A PosteriorTransform, only optionally used when there are</span>
<span class="sd">            no feasible observations.</span>
<span class="sd">        X_baseline: A `batch_shape x d`-dim Tensor of baseline points, only required</span>
<span class="sd">            when there are no feasible observations.</span>
<span class="sd">        infeasible_obj: A Tensor to be returned when no feasible points exist.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A `(sample_shape) x batch_shape`-dim Tensor of best feasible objectives.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">constraints</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># unconstrained case</span>
        <span class="c1"># we don&#39;t need to differentiate through X_baseline for now, so taking</span>
        <span class="c1"># the regular max over the n points to get best_f is fine</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">return</span> <span class="n">obj</span><span class="o">.</span><span class="n">amax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="n">is_feasible</span> <span class="o">=</span> <span class="n">compute_feasibility_indicator</span><span class="p">(</span>
        <span class="n">constraints</span><span class="o">=</span><span class="n">constraints</span><span class="p">,</span> <span class="n">samples</span><span class="o">=</span><span class="n">samples</span>
    <span class="p">)</span>  <span class="c1"># sample_shape x batch_shape x q</span>

    <span class="k">if</span> <span class="n">is_feasible</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
        <span class="n">infeasible_value</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">inf</span>

    <span class="k">elif</span> <span class="n">infeasible_obj</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">infeasible_value</span> <span class="o">=</span> <span class="n">infeasible_obj</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Must specify `model` when no feasible observation exists.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">X_baseline</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Must specify `X_baseline` when no feasible observation exists.&quot;</span>
            <span class="p">)</span>
        <span class="n">infeasible_value</span> <span class="o">=</span> <span class="n">_estimate_objective_lower_bound</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">objective</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
            <span class="n">posterior_transform</span><span class="o">=</span><span class="n">posterior_transform</span><span class="p">,</span>
            <span class="n">X</span><span class="o">=</span><span class="n">X_baseline</span><span class="p">,</span>
        <span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="n">is_feasible</span> <span class="o">=</span> <span class="n">repeat_to_match_aug_dim</span><span class="p">(</span>
        <span class="n">target_tensor</span><span class="o">=</span><span class="n">is_feasible</span><span class="p">,</span> <span class="n">reference_tensor</span><span class="o">=</span><span class="n">obj</span>
    <span class="p">)</span>
    <span class="n">obj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">is_feasible</span><span class="p">,</span> <span class="n">obj</span><span class="p">,</span> <span class="n">infeasible_value</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">return</span> <span class="n">obj</span><span class="o">.</span><span class="n">amax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></div>



<span class="k">def</span><span class="w"> </span><span class="nf">_estimate_objective_lower_bound</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span>
    <span class="n">objective</span><span class="p">:</span> <span class="n">MCAcquisitionObjective</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">PosteriorTransform</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Estimates a lower bound on the objective values by evaluating the model at convex</span>
<span class="sd">    combinations of `X`, returning the 6-sigma lower bound of the computed statistics.</span>

<span class="sd">    Args:</span>
<span class="sd">        model: A fitted model.</span>
<span class="sd">        objective: An MCAcquisitionObjective with `m` outputs.</span>
<span class="sd">        posterior_transform: A PosteriorTransform.</span>
<span class="sd">        X: A `n x d`-dim Tensor of design points from which to draw convex combinations.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A `m`-dimensional Tensor of lower bounds of the objectives.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">convex_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span>
        <span class="mi">32</span><span class="p">,</span>
        <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">weights_sum</span> <span class="o">=</span> <span class="n">convex_weights</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">convex_weights</span> <span class="o">=</span> <span class="n">convex_weights</span> <span class="o">/</span> <span class="n">weights_sum</span>
    <span class="c1"># infeasible cost M is such that -M &lt; min_x f(x), thus</span>
    <span class="c1"># 0 &lt; min_x f(x) - (-M), so we should take -M as a lower</span>
    <span class="c1"># bound on the best feasible objective</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">get_infeasible_cost</span><span class="p">(</span>
        <span class="n">X</span><span class="o">=</span><span class="n">convex_weights</span> <span class="o">@</span> <span class="n">X</span><span class="p">,</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">objective</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
        <span class="n">posterior_transform</span><span class="o">=</span><span class="n">posterior_transform</span><span class="p">,</span>
    <span class="p">)</span>


<div class="viewcode-block" id="get_infeasible_cost">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.utils.get_infeasible_cost">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">get_infeasible_cost</span><span class="p">(</span>
    <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span>
    <span class="n">objective</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">PosteriorTransform</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Get infeasible cost for a model and objective.</span>

<span class="sd">    For each outcome, computes an infeasible cost `M` such that</span>
<span class="sd">    `-M &lt; min_x f(x)` almost always, so that feasible points are preferred.</span>

<span class="sd">    Args:</span>
<span class="sd">        X: A `n x d` Tensor of `n` design points to use in evaluating the</span>
<span class="sd">            minimum. These points should cover the design space well. The more</span>
<span class="sd">            points the better the estimate, at the expense of added computation.</span>
<span class="sd">        model: A fitted botorch model with `m` outcomes.</span>
<span class="sd">        objective: The objective with which to evaluate the model output.</span>
<span class="sd">        posterior_transform: A PosteriorTransform (optional).</span>

<span class="sd">    Returns:</span>
<span class="sd">        An `m`-dim tensor of infeasible cost values.</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; model = SingleTaskGP(train_X, train_Y)</span>
<span class="sd">        &gt;&gt;&gt; objective = lambda Y: Y[..., -1] ** 2</span>
<span class="sd">        &gt;&gt;&gt; M = get_infeasible_cost(train_X, model, obj)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">objective</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">objective</span><span class="p">(</span><span class="n">Y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">Y</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">posterior</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">posterior</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">posterior_transform</span><span class="o">=</span><span class="n">posterior_transform</span><span class="p">)</span>
    <span class="n">lb</span> <span class="o">=</span> <span class="n">objective</span><span class="p">(</span><span class="n">posterior</span><span class="o">.</span><span class="n">mean</span> <span class="o">-</span> <span class="mi">6</span> <span class="o">*</span> <span class="n">posterior</span><span class="o">.</span><span class="n">variance</span><span class="o">.</span><span class="n">clamp_min</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(),</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">lb</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&lt;</span> <span class="n">posterior</span><span class="o">.</span><span class="n">mean</span><span class="o">.</span><span class="n">ndim</span><span class="p">:</span>
        <span class="n">lb</span> <span class="o">=</span> <span class="n">lb</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># Take outcome-wise min. Looping in to handle batched models.</span>
    <span class="k">while</span> <span class="n">lb</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">lb</span> <span class="o">=</span> <span class="n">lb</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
    <span class="k">return</span> <span class="o">-</span><span class="p">(</span><span class="n">lb</span><span class="o">.</span><span class="n">clamp_max</span><span class="p">(</span><span class="mf">0.0</span><span class="p">))</span></div>



<span class="k">def</span><span class="w"> </span><span class="nf">_prune_inferior_shared_processing</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span>
    <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">is_moo</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">objective</span><span class="p">:</span> <span class="n">MCAcquisitionObjective</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">PosteriorTransform</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">constraints</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">num_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2048</span><span class="p">,</span>
    <span class="n">max_frac</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="n">sampler</span><span class="p">:</span> <span class="n">MCSampler</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">marginalize_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Shared data processing for `prune_inferior_points` and</span>
<span class="sd">    `prune_inferior_points_multi_objective`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        - max_points: The maximum number of points to keep.</span>
<span class="sd">        - obj_vals: The objective values of the points in `X`.</span>
<span class="sd">        - infeas: A boolean tensor indicating feasibility of `X`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">func_name</span> <span class="o">=</span> <span class="p">(</span>
        <span class="s2">&quot;prune_inferior_points_multi_objective&quot;</span> <span class="k">if</span> <span class="n">is_moo</span> <span class="k">else</span> <span class="s2">&quot;prune_inferior_points&quot;</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">marginalize_dim</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">is_ensemble</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
        <span class="n">marginalize_dim</span> <span class="o">=</span> <span class="n">MCMC_DIM</span>

    <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">UnsupportedError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Batched inputs `X` are currently unsupported by `</span><span class="si">{</span><span class="n">func_name</span><span class="si">}</span><span class="s2">`&quot;</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;X must have at least one point.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">max_frac</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">max_frac</span> <span class="o">&gt;</span> <span class="mf">1.0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;max_frac must take values in (0, 1], is </span><span class="si">{</span><span class="n">max_frac</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">max_points</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">max_frac</span> <span class="o">*</span> <span class="n">X</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">))</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">posterior</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">posterior</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">posterior_transform</span><span class="o">=</span><span class="n">posterior_transform</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">sampler</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">sampler</span> <span class="o">=</span> <span class="n">get_sampler</span><span class="p">(</span>
            <span class="n">posterior</span><span class="o">=</span><span class="n">posterior</span><span class="p">,</span> <span class="n">sample_shape</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">num_samples</span><span class="p">])</span>
        <span class="p">)</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="n">sampler</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">objective</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">obj_vals</span> <span class="o">=</span> <span class="n">objective</span><span class="p">(</span><span class="n">samples</span><span class="o">=</span><span class="n">samples</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">is_moo</span><span class="p">:</span>
        <span class="n">obj_vals</span> <span class="o">=</span> <span class="n">samples</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">obj_vals</span> <span class="o">=</span> <span class="n">samples</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">obj_vals</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="p">(</span><span class="mi">2</span> <span class="o">+</span> <span class="n">is_moo</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">obj_vals</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="p">(</span><span class="mi">3</span> <span class="o">+</span> <span class="n">is_moo</span><span class="p">)</span> <span class="ow">and</span> <span class="n">marginalize_dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">marginalize_dim</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="c1"># Update `marginalize_dim` to be positive while accounting for</span>
                <span class="c1"># removal of output dimension in SOO.</span>
                <span class="n">marginalize_dim</span> <span class="o">=</span> <span class="p">(</span><span class="ow">not</span> <span class="n">is_moo</span><span class="p">)</span> <span class="o">+</span> <span class="n">none_throws</span><span class="p">(</span>
                    <span class="n">normalize_indices</span><span class="p">([</span><span class="n">marginalize_dim</span><span class="p">],</span> <span class="n">d</span><span class="o">=</span><span class="n">obj_vals</span><span class="o">.</span><span class="n">ndim</span><span class="p">)</span>
                <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">obj_vals</span> <span class="o">=</span> <span class="n">obj_vals</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="n">marginalize_dim</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">UnsupportedError</span><span class="p">(</span>
                <span class="s2">&quot;Models with multiple batch dims are currently unsupported by &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;`</span><span class="si">{</span><span class="n">func_name</span><span class="si">}</span><span class="s2">`.&quot;</span>
            <span class="p">)</span>
    <span class="n">infeas</span> <span class="o">=</span> <span class="o">~</span><span class="n">compute_feasibility_indicator</span><span class="p">(</span>
        <span class="n">constraints</span><span class="o">=</span><span class="n">constraints</span><span class="p">,</span>
        <span class="n">samples</span><span class="o">=</span><span class="n">samples</span><span class="p">,</span>
        <span class="n">marginalize_dim</span><span class="o">=</span><span class="n">marginalize_dim</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">max_points</span><span class="p">,</span> <span class="n">obj_vals</span><span class="p">,</span> <span class="n">infeas</span>


<div class="viewcode-block" id="prune_inferior_points">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.utils.prune_inferior_points">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">prune_inferior_points</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span>
    <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">objective</span><span class="p">:</span> <span class="n">MCAcquisitionObjective</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">PosteriorTransform</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">constraints</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">num_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2048</span><span class="p">,</span>
    <span class="n">max_frac</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="n">sampler</span><span class="p">:</span> <span class="n">MCSampler</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">marginalize_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Prune points from an input tensor that are unlikely to be the best point.</span>

<span class="sd">    Given a model, an objective, and an input tensor `X`, this function returns</span>
<span class="sd">    the subset of points in `X` that have some probability of being the best</span>
<span class="sd">    point under the objective. This function uses sampling to estimate the</span>
<span class="sd">    probabilities, the higher the number of points `n` in `X` the higher the</span>
<span class="sd">    number of samples `num_samples` should be to obtain accurate estimates.</span>

<span class="sd">    Args:</span>
<span class="sd">        model: A fitted model. Batched models are currently not supported.</span>
<span class="sd">        X: An input tensor of shape `n x d`. Batched inputs are currently not</span>
<span class="sd">            supported.</span>
<span class="sd">        objective: The objective under which to evaluate the posterior.</span>
<span class="sd">        posterior_transform: A PosteriorTransform (optional).</span>
<span class="sd">        constraints: A list of constraint callables which map a Tensor of posterior</span>
<span class="sd">            samples of dimension `sample_shape x batch-shape x q x m`-dim to a</span>
<span class="sd">            `sample_shape x batch-shape x q`-dim Tensor. The associated constraints</span>
<span class="sd">            are satisfied if `constraint(samples) &lt; 0`.</span>
<span class="sd">        num_samples: The number of samples used to compute empirical</span>
<span class="sd">            probabilities of being the best point.</span>
<span class="sd">        max_frac: The maximum fraction of points to retain. Must satisfy</span>
<span class="sd">            `0 &lt; max_frac &lt;= 1`. Ensures that the number of elements in the</span>
<span class="sd">            returned tensor does not exceed `ceil(max_frac * n)`.</span>
<span class="sd">        sampler: If provided, will use this customized sampler instead of</span>
<span class="sd">            automatically constructing one with `num_samples`.</span>
<span class="sd">        marginalize_dim: A batch dimension that should be marginalized.</span>
<span class="sd">            For example, this is useful when using a batched fully Bayesian</span>
<span class="sd">            model.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A `n&#39; x d` with subset of points in `X`, where</span>

<span class="sd">            n&#39; = min(N_nz, ceil(max_frac * n))</span>

<span class="sd">        with `N_nz` the number of points in `X` that have non-zero (empirical,</span>
<span class="sd">        under `num_samples` samples) probability of being the best point.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">max_points</span><span class="p">,</span> <span class="n">obj_vals</span><span class="p">,</span> <span class="n">infeas</span> <span class="o">=</span> <span class="n">_prune_inferior_shared_processing</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
        <span class="n">is_moo</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">objective</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
        <span class="n">posterior_transform</span><span class="o">=</span><span class="n">posterior_transform</span><span class="p">,</span>
        <span class="n">constraints</span><span class="o">=</span><span class="n">constraints</span><span class="p">,</span>
        <span class="n">num_samples</span><span class="o">=</span><span class="n">num_samples</span><span class="p">,</span>
        <span class="n">max_frac</span><span class="o">=</span><span class="n">max_frac</span><span class="p">,</span>
        <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">,</span>
        <span class="n">marginalize_dim</span><span class="o">=</span><span class="n">marginalize_dim</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">infeas</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
        <span class="c1"># set infeasible points to worse than worst objective across all samples</span>
        <span class="c1"># Use clone() here to avoid deprecated `index_put_` on an expanded tensor</span>
        <span class="n">obj_vals</span> <span class="o">=</span> <span class="n">obj_vals</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">obj_vals</span><span class="p">[</span><span class="n">infeas</span><span class="p">]</span> <span class="o">=</span> <span class="n">obj_vals</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span>

    <span class="n">is_best</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">obj_vals</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">idcs</span><span class="p">,</span> <span class="n">counts</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">is_best</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">idcs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">max_points</span><span class="p">:</span>
        <span class="n">counts</span><span class="p">,</span> <span class="n">order_idcs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">counts</span><span class="p">,</span> <span class="n">stable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">idcs</span> <span class="o">=</span> <span class="n">order_idcs</span><span class="p">[:</span><span class="n">max_points</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">X</span><span class="p">[</span><span class="n">idcs</span><span class="p">]</span></div>



<div class="viewcode-block" id="project_to_target_fidelity">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.utils.project_to_target_fidelity">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">project_to_target_fidelity</span><span class="p">(</span>
    <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">target_fidelities</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">d</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Project `X` onto the target set of fidelities.</span>

<span class="sd">    This function assumes that the set of feasible fidelities is a box, so</span>
<span class="sd">    projecting here just means setting each fidelity parameter to its target</span>
<span class="sd">    value. If X does not contain the fidelity dimensions, this will insert</span>
<span class="sd">    them and set them to their target values.</span>

<span class="sd">    Args:</span>
<span class="sd">        X: A `batch_shape x q x (d or d-d_f)`-dim Tensor of with `q` `d` or</span>
<span class="sd">            `d-d_f`-dim design points for each t-batch, where d_f is the</span>
<span class="sd">            number of fidelity dimensions. If the argument `d` is not provided,</span>
<span class="sd">            `X` must include the fidelity dimensions and have a trailing`X` must</span>
<span class="sd">            include the fidelity dimensions and have a trailing</span>
<span class="sd">        target_fidelities: A dictionary mapping a subset of columns of `X` (the</span>
<span class="sd">            fidelity parameters) to their respective target fidelity value. If</span>
<span class="sd">            omitted, assumes that the last column of X is the fidelity parameter</span>
<span class="sd">            with a target value of 1.0.</span>
<span class="sd">        d: The total dimension `d`.</span>

<span class="sd">    Return:</span>
<span class="sd">        A `batch_shape x q x d`-dim Tensor `X_proj` with fidelity parameters</span>
<span class="sd">            projected to the provided fidelity values.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">target_fidelities</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">target_fidelities</span> <span class="o">=</span> <span class="p">{</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">}</span>
    <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># assume X contains the fidelity dimensions</span>
        <span class="n">d</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="c1"># normalize to positive indices</span>
    <span class="n">tfs</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span> <span class="k">if</span> <span class="n">k</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">d</span> <span class="o">+</span> <span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">target_fidelities</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    <span class="n">ones</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="o">*</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">d</span><span class="p">:</span>
        <span class="c1"># X contains fidelity dimensions</span>
        <span class="c1"># here we&#39;re looping through the feature dimension of X - this could be</span>
        <span class="c1"># slow for large `d`, we should optimize this for that case</span>
        <span class="n">X_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
            <span class="p">[</span><span class="n">X</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">tfs</span> <span class="k">else</span> <span class="n">tfs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">ones</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">d</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">d</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">target_fidelities</span><span class="p">):</span>
        <span class="c1"># need to insert fidelity dimensions</span>
        <span class="n">cols</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">X_idx</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">d</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">tfs</span><span class="p">:</span>
                <span class="n">cols</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">X_idx</span><span class="p">])</span>
                <span class="n">X_idx</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">cols</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tfs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">ones</span><span class="p">)</span>
        <span class="n">X_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">cols</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">BotorchTensorDimensionError</span><span class="p">(</span>
            <span class="s2">&quot;X must have a last dimension with size `d` or `d-d_f`,&quot;</span>
            <span class="sa">f</span><span class="s2">&quot; but got </span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">X_proj</span></div>



<div class="viewcode-block" id="expand_trace_observations">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.utils.expand_trace_observations">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">expand_trace_observations</span><span class="p">(</span>
    <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">fidelity_dims</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">num_trace_obs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Expand `X` with trace observations.</span>

<span class="sd">    Expand a tensor of inputs with &quot;trace observations&quot; that are obtained during</span>
<span class="sd">    the evaluation of the candidate set. This is used in multi-fidelity</span>
<span class="sd">    optimization. It can be though of as augmenting the `q`-batch with additional</span>
<span class="sd">    points that are the expected trace observations.</span>

<span class="sd">    Let `f_i` be the `i`-th fidelity parameter. Then this functions assumes that</span>
<span class="sd">    for each element of the q-batch, besides the fidelity `f_i`, we will observe</span>
<span class="sd">    additonal fidelities `f_i1, ..., f_iK`, where `K = num_trace_obs`, during</span>
<span class="sd">    evaluation of the candidate set `X`. Specifically, this function assumes</span>
<span class="sd">    that `f_ij = (K-j) / (num_trace_obs + 1) * f_i` for all `i`. That is, the</span>
<span class="sd">    expansion is performed in parallel for all fidelities (it does not expand</span>
<span class="sd">    out all possible combinations).</span>

<span class="sd">    Args:</span>
<span class="sd">        X: A `batch_shape x q x d`-dim Tensor of with `q` `d`-dim design points</span>
<span class="sd">            (incl. the fidelity parameters) for each t-batch.</span>
<span class="sd">        fidelity_dims: The indices of the fidelity parameters. If omitted,</span>
<span class="sd">            assumes that the last column of X contains the fidelity parameters.</span>
<span class="sd">        num_trace_obs: The number of trace observations to use.</span>

<span class="sd">    Return:</span>
<span class="sd">        A `batch_shape x (q + num_trace_obs x q) x d` Tensor `X_expanded` that</span>
<span class="sd">            expands `X` with trace observations.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">num_trace_obs</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># No need to expand if we don&#39;t use trace observations</span>
        <span class="k">return</span> <span class="n">X</span>

    <span class="k">if</span> <span class="n">fidelity_dims</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">fidelity_dims</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># The general strategy in the following is to expand `X` to the desired</span>
    <span class="c1"># shape, and then multiply it (point-wise) with a tensor of scaling factors</span>
    <span class="n">reps</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span> <span class="o">+</span> <span class="n">num_trace_obs</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">X_expanded</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="o">*</span><span class="n">reps</span><span class="p">)</span>  <span class="c1"># batch_shape x (q + num_trace_obs x q) x d</span>
    <span class="n">scale_fac</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">X_expanded</span><span class="p">)</span>
    <span class="n">s_pad</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="n">num_trace_obs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="c1"># tensor of  num_trace_obs scaling factors equally space between 1-s_pad and s_pad</span>
    <span class="n">sf</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">s_pad</span><span class="p">,</span> <span class="n">s_pad</span><span class="p">,</span> <span class="n">num_trace_obs</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="c1"># repeat each element q times</span>
    <span class="n">q</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">sf</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">sf</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span>  <span class="c1"># num_trace_obs * q</span>
    <span class="c1"># now expand this to num_trace_obs x q x num_fidelities</span>
    <span class="n">sf</span> <span class="o">=</span> <span class="n">sf</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">X_expanded</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">q</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">fidelity_dims</span><span class="p">))</span>
    <span class="c1"># change relevant entries of the scaling tensor</span>
    <span class="n">scale_fac</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">q</span><span class="p">:,</span> <span class="n">fidelity_dims</span><span class="p">]</span> <span class="o">=</span> <span class="n">sf</span>
    <span class="k">return</span> <span class="n">scale_fac</span> <span class="o">*</span> <span class="n">X_expanded</span></div>



<div class="viewcode-block" id="project_to_sample_points">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.utils.project_to_sample_points">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">project_to_sample_points</span><span class="p">(</span><span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">sample_points</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Augment `X` with sample points at which to take weighted average.</span>

<span class="sd">    Args:</span>
<span class="sd">        X: A `batch_shape x 1 x d`-dim Tensor of with one d`-dim design points</span>
<span class="sd">            for each t-batch.</span>
<span class="sd">        sample_points: `p x d&#39;`-dim Tensor (`d&#39; &lt; d`) of `d&#39;`-dim sample points at</span>
<span class="sd">            which to compute the expectation. The `d&#39;`-dims refer to the trailing</span>
<span class="sd">            columns of X.</span>
<span class="sd">    Returns:</span>
<span class="sd">        A `batch_shape x p x d` Tensor where the q-batch includes the `p` sample points.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">batch_shape</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">p</span><span class="p">,</span> <span class="n">d_prime</span> <span class="o">=</span> <span class="n">sample_points</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">X_new</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">batch_shape</span><span class="p">),</span> <span class="n">p</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># batch_shape x p x d</span>
    <span class="n">X_new</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="n">d_prime</span><span class="p">:]</span> <span class="o">=</span> <span class="n">sample_points</span>
    <span class="k">return</span> <span class="n">X_new</span></div>



<div class="viewcode-block" id="get_optimal_samples">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.utils.get_optimal_samples">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">get_optimal_samples</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">GP</span><span class="p">,</span>
    <span class="n">bounds</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">num_optima</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">raw_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">,</span>
    <span class="n">num_restarts</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
    <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">ScalarizedPosteriorTransform</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">objective</span><span class="p">:</span> <span class="n">MCAcquisitionObjective</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">return_transformed</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Draws sample paths from the posterior and maximizes the samples using GD.</span>

<span class="sd">    Args:</span>
<span class="sd">        model: The model from which samples are drawn.</span>
<span class="sd">        bounds: Bounds of the search space. If the model inputs are</span>
<span class="sd">            normalized, the bounds should be normalized as well.</span>
<span class="sd">        num_optima: The number of paths to be drawn and optimized.</span>
<span class="sd">        raw_samples: The number of candidates randomly sample.</span>
<span class="sd">            Defaults to 1024.</span>
<span class="sd">        num_restarts: The number of candidates to do gradient-based</span>
<span class="sd">            optimization on. Defaults to 20.</span>
<span class="sd">        posterior_transform: A ScalarizedPosteriorTransform (may e.g. be used to</span>
<span class="sd">            scalarize multi-output models or negate the objective).</span>
<span class="sd">        objective: An MCAcquisitionObjective, used to negate the objective or otherwise</span>
<span class="sd">            transform sample outputs. Cannot be combined with `posterior_transform`.</span>
<span class="sd">        return_transformed: If True, return the transformed samples.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The optimal input locations and corresponding outputs, x* and f*.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">posterior_transform</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span>
        <span class="n">posterior_transform</span><span class="p">,</span> <span class="n">ScalarizedPosteriorTransform</span>
    <span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Only the ScalarizedPosteriorTransform is supported for &quot;</span>
            <span class="s2">&quot;get_optimal_samples.&quot;</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">posterior_transform</span> <span class="ow">and</span> <span class="n">objective</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Only one of `posterior_transform` and `objective` can be specified.&quot;</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">posterior_transform</span><span class="p">:</span>
        <span class="n">sample_transform</span> <span class="o">=</span> <span class="n">posterior_transform</span><span class="o">.</span><span class="n">evaluate</span>
    <span class="k">elif</span> <span class="n">objective</span><span class="p">:</span>
        <span class="n">sample_transform</span> <span class="o">=</span> <span class="n">objective</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">sample_transform</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="n">paths</span> <span class="o">=</span> <span class="n">get_matheron_path_model</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">sample_shape</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">num_optima</span><span class="p">]))</span>
    <span class="n">optimal_inputs</span><span class="p">,</span> <span class="n">optimal_outputs</span> <span class="o">=</span> <span class="n">optimize_posterior_samples</span><span class="p">(</span>
        <span class="n">paths</span><span class="o">=</span><span class="n">paths</span><span class="p">,</span>
        <span class="n">bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">,</span>
        <span class="n">raw_samples</span><span class="o">=</span><span class="n">raw_samples</span><span class="p">,</span>
        <span class="n">num_restarts</span><span class="o">=</span><span class="n">num_restarts</span><span class="p">,</span>
        <span class="n">sample_transform</span><span class="o">=</span><span class="n">sample_transform</span><span class="p">,</span>
        <span class="n">return_transformed</span><span class="o">=</span><span class="n">return_transformed</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">optimal_inputs</span><span class="p">,</span> <span class="n">optimal_outputs</span></div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p></p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>