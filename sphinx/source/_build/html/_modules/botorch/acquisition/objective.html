

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>botorch.acquisition.objective &mdash; BoTorch  documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=03e43079" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../../_static/custom.css?v=ca3e82f4" />

  
      <script src="../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../_static/documentation_options.js?v=5929fcd5"></script>
      <script src="../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            BoTorch
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../acquisition.html">botorch.acquisition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models.html">botorch.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generation.html">botorch.generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../posteriors.html">botorch.posteriors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../optim.html">botorch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../fit.html">botorch.fit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../sampling.html">botorch.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cross_validation.html">botorch.cross_validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../settings.html">botorch.settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../logging.html">botorch.logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../test_functions.html">botorch.test_functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../test_utils.html">botorch.test_utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../exceptions.html">botorch.exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../utils.html">botorch.utils</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">BoTorch</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">botorch.acquisition.objective</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for botorch.acquisition.objective</h1><div class="highlight"><pre>
<span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="c1"># Copyright (c) Meta Platforms, Inc. and affiliates.</span>
<span class="c1">#</span>
<span class="c1"># This source code is licensed under the MIT license found in the</span>
<span class="c1"># LICENSE file in the root directory of this source tree.</span>

<span class="sa">r</span><span class="sd">&quot;&quot;&quot;Objective Modules to be used with acquisition functions.&quot;&quot;&quot;</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">__future__</span><span class="w"> </span><span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">ABC</span><span class="p">,</span> <span class="n">abstractmethod</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections.abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">Callable</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">TYPE_CHECKING</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.exceptions.errors</span><span class="w"> </span><span class="kn">import</span> <span class="n">UnsupportedError</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.exceptions.warnings</span><span class="w"> </span><span class="kn">import</span> <span class="n">InputDataWarning</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.models.model</span><span class="w"> </span><span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.posteriors.gpytorch</span><span class="w"> </span><span class="kn">import</span> <span class="n">GPyTorchPosterior</span><span class="p">,</span> <span class="n">scalarize_posterior</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.sampling</span><span class="w"> </span><span class="kn">import</span> <span class="n">IIDNormalSampler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">apply_constraints</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpytorch.distributions</span><span class="w"> </span><span class="kn">import</span> <span class="n">MultitaskMultivariateNormal</span><span class="p">,</span> <span class="n">MultivariateNormal</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">linear_operator.operators.dense_linear_operator</span><span class="w"> </span><span class="kn">import</span> <span class="n">to_linear_operator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">Module</span>

<span class="k">if</span> <span class="n">TYPE_CHECKING</span><span class="p">:</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">botorch.posteriors.posterior</span><span class="w"> </span><span class="kn">import</span> <span class="n">Posterior</span>  <span class="c1"># pragma: no cover</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">botorch.posteriors.posterior_list</span><span class="w"> </span><span class="kn">import</span> <span class="n">PosteriorList</span>  <span class="c1"># pragma: no cover</span>

<span class="n">DEFAULT_NUM_PREF_SAMPLES</span> <span class="o">=</span> <span class="mi">16</span>


<div class="viewcode-block" id="PosteriorTransform">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.objective.PosteriorTransform">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">PosteriorTransform</span><span class="p">(</span><span class="n">Module</span><span class="p">,</span> <span class="n">ABC</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Abstract base class for objectives that transform the posterior.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="PosteriorTransform.evaluate">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.objective.PosteriorTransform.evaluate">[docs]</a>
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Evaluate the transform on a set of outcomes.</span>

<span class="sd">        Args:</span>
<span class="sd">            Y: A `batch_shape x q x m`-dim tensor of outcomes.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `batch_shape x q&#39; [x m&#39;]`-dim tensor of transformed outcomes.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span>  <span class="c1"># pragma: no cover</span></div>


<div class="viewcode-block" id="PosteriorTransform.forward">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.objective.PosteriorTransform.forward">[docs]</a>
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">posterior</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Posterior</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Compute the transformed posterior.</span>

<span class="sd">        Args:</span>
<span class="sd">            posterior: The posterior to be transformed.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The transformed posterior object.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span>  <span class="c1"># pragma: no cover</span></div>
</div>



<span class="c1"># import DeterministicModel after PosteriorTransform to avoid circular import</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.models.deterministic</span><span class="w"> </span><span class="kn">import</span> <span class="n">DeterministicModel</span>  <span class="c1"># noqa</span>


<div class="viewcode-block" id="ScalarizedPosteriorTransform">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.objective.ScalarizedPosteriorTransform">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">ScalarizedPosteriorTransform</span><span class="p">(</span><span class="n">PosteriorTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;An affine posterior transform for scalarizing multi-output posteriors.</span>

<span class="sd">    For a Gaussian posterior at a single point (`q=1`) with mean `mu` and</span>
<span class="sd">    covariance matrix `Sigma`, this yields a single-output posterior with mean</span>
<span class="sd">    `weights^T * mu` and variance `weights^T Sigma w`.</span>

<span class="sd">    Example:</span>
<span class="sd">        Example for a model with two outcomes:</span>

<span class="sd">        &gt;&gt;&gt; weights = torch.tensor([0.5, 0.25])</span>
<span class="sd">        &gt;&gt;&gt; posterior_transform = ScalarizedPosteriorTransform(weights)</span>
<span class="sd">        &gt;&gt;&gt; EI = ExpectedImprovement(</span>
<span class="sd">        ... model, best_f=0.1, posterior_transform=posterior_transform</span>
<span class="sd">        ... )</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">scalarize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weights</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">offset</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            weights: A one-dimensional tensor with `m` elements representing the</span>
<span class="sd">                linear weights on the outputs.</span>
<span class="sd">            offset: An offset to be added to posterior mean.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">weights</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;weights must be a one-dimensional tensor.&quot;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;weights&quot;</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">offset</span> <span class="o">=</span> <span class="n">offset</span>

<div class="viewcode-block" id="ScalarizedPosteriorTransform.evaluate">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.objective.ScalarizedPosteriorTransform.evaluate">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Evaluate the transform on a set of outcomes.</span>

<span class="sd">        Args:</span>
<span class="sd">            Y: A `batch_shape x q x m`-dim tensor of outcomes.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `batch_shape x q`-dim tensor of transformed outcomes.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">offset</span> <span class="o">+</span> <span class="n">Y</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span></div>


<div class="viewcode-block" id="ScalarizedPosteriorTransform.forward">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.objective.ScalarizedPosteriorTransform.forward">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">posterior</span><span class="p">:</span> <span class="n">GPyTorchPosterior</span> <span class="o">|</span> <span class="n">PosteriorList</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">GPyTorchPosterior</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Compute the posterior of the affine transformation.</span>

<span class="sd">        Args:</span>
<span class="sd">            posterior: A posterior with the same number of outputs as the</span>
<span class="sd">                elements in `self.weights`.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A single-output posterior.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">scalarize_posterior</span><span class="p">(</span>
            <span class="n">posterior</span><span class="o">=</span><span class="n">posterior</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">offset</span>
        <span class="p">)</span></div>
</div>



<div class="viewcode-block" id="ExpectationPosteriorTransform">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.objective.ExpectationPosteriorTransform">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">ExpectationPosteriorTransform</span><span class="p">(</span><span class="n">PosteriorTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Transform the `batch x (q * n_w) x m` posterior into a `batch x q x m`</span>
<span class="sd">    posterior of the expectation. The expectation is calculated over each</span>
<span class="sd">    consecutive `n_w` block of points in the posterior.</span>

<span class="sd">    This is intended for use with `InputPerturbation` or `AppendFeatures` for</span>
<span class="sd">    optimizing the expectation over `n_w` points. This should not be used when</span>
<span class="sd">    there are constraints present, since this does not take into account</span>
<span class="sd">    the feasibility of the objectives.</span>

<span class="sd">    Note: This is different than `ScalarizedPosteriorTransform` in that</span>
<span class="sd">    this operates over the q-batch dimension.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_w</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">weights</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;A posterior transform calculating the expectation over the q-batch</span>
<span class="sd">        dimension.</span>

<span class="sd">        Args:</span>
<span class="sd">            n_w: The number of points in the q-batch of the posterior to compute</span>
<span class="sd">                the expectation over. This corresponds to the size of the</span>
<span class="sd">                `feature_set` of `AppendFeatures` or the size of the `perturbation_set`</span>
<span class="sd">                of `InputPerturbation`.</span>
<span class="sd">            weights: An optional `n_w x m`-dim tensor of weights. Can be used to</span>
<span class="sd">                compute a weighted expectation. Weights are normalized before use.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">weights</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">!=</span> <span class="mi">2</span> <span class="ow">or</span> <span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">n_w</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`weights` must be a tensor of size `n_w x m`.&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">weights</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`weights` must be non-negative.&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_w</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="c1"># Normalize the weights.</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span> <span class="o">/</span> <span class="n">weights</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;weights&quot;</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_w</span> <span class="o">=</span> <span class="n">n_w</span>

<div class="viewcode-block" id="ExpectationPosteriorTransform.evaluate">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.objective.ExpectationPosteriorTransform.evaluate">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Evaluate the expectation of a set of outcomes.</span>

<span class="sd">        Args:</span>
<span class="sd">            Y: A `batch_shape x (q * n_w) x m`-dim tensor of outcomes.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `batch_shape x q x m`-dim tensor of expectation outcomes.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">batch_shape</span><span class="p">,</span> <span class="n">m</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">weighted_Y</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">batch_shape</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_w</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">weighted_Y</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span></div>


<div class="viewcode-block" id="ExpectationPosteriorTransform.forward">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.objective.ExpectationPosteriorTransform.forward">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">posterior</span><span class="p">:</span> <span class="n">GPyTorchPosterior</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">GPyTorchPosterior</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Compute the posterior of the expectation.</span>

<span class="sd">        Args:</span>
<span class="sd">            posterior: An `m`-outcome joint posterior over `q * n_w` points.</span>

<span class="sd">        Returns:</span>
<span class="sd">            An `m`-outcome joint posterior over `q` expectations.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">org_mvn</span> <span class="o">=</span> <span class="n">posterior</span><span class="o">.</span><span class="n">distribution</span>
        <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">org_mvn</span><span class="p">,</span> <span class="s2">&quot;_interleaved&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">UnsupportedError</span><span class="p">(</span>
                <span class="s2">&quot;`ExpectationPosteriorTransform` does not support &quot;</span>
                <span class="s2">&quot;interleaved posteriors.&quot;</span>
            <span class="p">)</span>
        <span class="c1"># Initialize the weight matrix of shape compatible with the mvn.</span>
        <span class="n">org_event_shape</span> <span class="o">=</span> <span class="n">org_mvn</span><span class="o">.</span><span class="n">event_shape</span>
        <span class="n">batch_shape</span> <span class="o">=</span> <span class="n">org_mvn</span><span class="o">.</span><span class="n">batch_shape</span>
        <span class="n">q</span> <span class="o">=</span> <span class="n">org_event_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_w</span>
        <span class="n">m</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">org_event_shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">org_event_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">tkwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;device&quot;</span><span class="p">:</span> <span class="n">org_mvn</span><span class="o">.</span><span class="n">loc</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">:</span> <span class="n">org_mvn</span><span class="o">.</span><span class="n">loc</span><span class="o">.</span><span class="n">dtype</span><span class="p">}</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">q</span> <span class="o">*</span> <span class="n">m</span><span class="p">,</span> <span class="n">q</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_w</span> <span class="o">*</span> <span class="n">m</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">)</span>
        <span class="c1"># Make sure self.weights has the correct dtype/device and shape.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">org_mvn</span><span class="o">.</span><span class="n">loc</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_w</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>
        <span class="c1"># Fill in the non-zero entries of the weight matrix.</span>
        <span class="c1"># We want each row to have non-zero weights for the corresponding</span>
        <span class="c1"># `n_w` sized diagonal. The `m` outcomes are not interleaved.</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">q</span> <span class="o">*</span> <span class="n">m</span><span class="p">):</span>
            <span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_w</span> <span class="o">*</span> <span class="n">i</span> <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_w</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[:,</span> <span class="n">i</span> <span class="o">//</span> <span class="n">q</span><span class="p">]</span>
        <span class="c1"># Trasform the mean.</span>
        <span class="n">new_loc</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">(</span><span class="n">weights</span> <span class="o">@</span> <span class="n">org_mvn</span><span class="o">.</span><span class="n">loc</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
            <span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">batch_shape</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span>
            <span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="c1"># Transform the covariance matrix.</span>
        <span class="n">org_cov</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">org_mvn</span><span class="o">.</span><span class="n">lazy_covariance_matrix</span>
            <span class="k">if</span> <span class="n">org_mvn</span><span class="o">.</span><span class="n">islazy</span>
            <span class="k">else</span> <span class="n">org_mvn</span><span class="o">.</span><span class="n">covariance_matrix</span>
        <span class="p">)</span>
        <span class="n">new_cov</span> <span class="o">=</span> <span class="n">weights</span> <span class="o">@</span> <span class="p">(</span><span class="n">org_cov</span> <span class="o">@</span> <span class="n">weights</span><span class="o">.</span><span class="n">t</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">m</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">new_mvn</span> <span class="o">=</span> <span class="n">MultivariateNormal</span><span class="p">(</span>
                <span class="n">new_loc</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">to_linear_operator</span><span class="p">(</span><span class="n">new_cov</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Using MTMVN since we pass a single loc and covar for all `m` outputs.</span>
            <span class="n">new_mvn</span> <span class="o">=</span> <span class="n">MultitaskMultivariateNormal</span><span class="p">(</span>
                <span class="n">new_loc</span><span class="p">,</span> <span class="n">to_linear_operator</span><span class="p">(</span><span class="n">new_cov</span><span class="p">),</span> <span class="n">interleaved</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">GPyTorchPosterior</span><span class="p">(</span><span class="n">distribution</span><span class="o">=</span><span class="n">new_mvn</span><span class="p">)</span></div>
</div>



<div class="viewcode-block" id="MCAcquisitionObjective">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.objective.MCAcquisitionObjective">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">MCAcquisitionObjective</span><span class="p">(</span><span class="n">Module</span><span class="p">,</span> <span class="n">ABC</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Abstract base class for MC-based objectives.</span>

<span class="sd">    Args:</span>
<span class="sd">        _verify_output_shape: If True and `X` is given, check that the q-batch</span>
<span class="sd">            shape of the objectives agrees with that of X.</span>
<span class="sd">        _is_mo: A boolean denoting whether the objectives are multi-output.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_verify_output_shape</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">_is_mo</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>

<div class="viewcode-block" id="MCAcquisitionObjective.forward">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.objective.MCAcquisitionObjective.forward">[docs]</a>
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">samples</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Evaluate the objective on the samples.</span>

<span class="sd">        Args:</span>
<span class="sd">            samples: A `sample_shape x batch_shape x q x m`-dim Tensors of</span>
<span class="sd">                samples from a model posterior.</span>
<span class="sd">            X: A `batch_shape x q x d`-dim tensor of inputs. Relevant only if</span>
<span class="sd">                the objective depends on the inputs explicitly.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor: A `sample_shape x batch_shape x q`-dim Tensor of objective</span>
<span class="sd">            values (assuming maximization).</span>

<span class="sd">        This method is usually not called directly, but via the objectives.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; # `__call__` method:</span>
<span class="sd">            &gt;&gt;&gt; samples = sampler(posterior)</span>
<span class="sd">            &gt;&gt;&gt; outcome = mc_obj(samples)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span>  <span class="c1"># pragma: no cover</span></div>


    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">samples</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="n">output</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__call__</span><span class="p">(</span><span class="n">samples</span><span class="o">=</span><span class="n">samples</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="c1"># q-batch dimension is at -1 for single-output objectives and at</span>
        <span class="c1"># -2 for multi-output objectives.</span>
        <span class="n">q_batch_idx</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_mo</span> <span class="k">else</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="n">X</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_verify_output_shape</span>
            <span class="ow">and</span> <span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">q_batch_idx</span><span class="p">]</span> <span class="o">!=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;The q-batch shape of the objective values does not agree with &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;the q-batch shape of X. Got </span><span class="si">{</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">q_batch_idx</span><span class="p">]</span><span class="si">}</span><span class="s2"> and &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span><span class="si">}</span><span class="s2">. This may happen if you used a one-to-many input &quot;</span>
                <span class="s2">&quot;transform but forgot to use a corresponding objective.&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span></div>



<div class="viewcode-block" id="IdentityMCObjective">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.objective.IdentityMCObjective">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">IdentityMCObjective</span><span class="p">(</span><span class="n">MCAcquisitionObjective</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Trivial objective extracting the last dimension.</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; identity_objective = IdentityMCObjective()</span>
<span class="sd">        &gt;&gt;&gt; samples = sampler(posterior)</span>
<span class="sd">        &gt;&gt;&gt; objective = identity_objective(samples)</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="IdentityMCObjective.forward">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.objective.IdentityMCObjective.forward">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">samples</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">samples</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span></div>
</div>



<div class="viewcode-block" id="LinearMCObjective">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.objective.LinearMCObjective">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">LinearMCObjective</span><span class="p">(</span><span class="n">MCAcquisitionObjective</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Linear objective constructed from a weight tensor.</span>

<span class="sd">    For input `samples` and `mc_obj = LinearMCObjective(weights)`, this produces</span>
<span class="sd">    `mc_obj(samples) = sum_{i} weights[i] * samples[..., i]`</span>

<span class="sd">    Example:</span>
<span class="sd">        Example for a model with two outcomes:</span>

<span class="sd">        &gt;&gt;&gt; weights = torch.tensor([0.75, 0.25])</span>
<span class="sd">        &gt;&gt;&gt; linear_objective = LinearMCObjective(weights)</span>
<span class="sd">        &gt;&gt;&gt; samples = sampler(posterior)</span>
<span class="sd">        &gt;&gt;&gt; objective = linear_objective(samples)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weights</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            weights: A one-dimensional tensor with `m` elements representing the</span>
<span class="sd">                linear weights on the outputs.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">weights</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;weights must be a one-dimensional tensor.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;weights&quot;</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>

<div class="viewcode-block" id="LinearMCObjective.forward">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.objective.LinearMCObjective.forward">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">samples</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Evaluate the linear objective on the samples.</span>

<span class="sd">        Args:</span>
<span class="sd">            samples: A `sample_shape x batch_shape x q x m`-dim tensors of</span>
<span class="sd">                samples from a model posterior.</span>
<span class="sd">            X: A `batch_shape x q x d`-dim tensor of inputs. Relevant only if</span>
<span class="sd">                the objective depends on the inputs explicitly.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `sample_shape x batch_shape x q`-dim tensor of objective values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Output shape of samples not equal to that of weights&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;...m, m&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">])</span></div>
</div>



<div class="viewcode-block" id="GenericMCObjective">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.objective.GenericMCObjective">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">GenericMCObjective</span><span class="p">(</span><span class="n">MCAcquisitionObjective</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Objective generated from a generic callable.</span>

<span class="sd">    Allows to construct arbitrary MC-objective functions from a generic</span>
<span class="sd">    callable. In order to be able to use gradient-based acquisition function</span>
<span class="sd">    optimization it should be possible to backpropagate through the callable.</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; generic_objective = GenericMCObjective(</span>
<span class="sd">                lambda Y, X: torch.sqrt(Y).sum(dim=-1),</span>
<span class="sd">            )</span>
<span class="sd">        &gt;&gt;&gt; samples = sampler(posterior)</span>
<span class="sd">        &gt;&gt;&gt; objective = generic_objective(samples)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">objective</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            objective: A callable `f(samples, X)` mapping a</span>
<span class="sd">                `sample_shape x batch-shape x q x m`-dim Tensor `samples` and</span>
<span class="sd">                an optional `batch-shape x q x d`-dim Tensor `X` to a</span>
<span class="sd">                `sample_shape x batch-shape x q`-dim Tensor of objective values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">objective</span> <span class="o">=</span> <span class="n">objective</span>

<div class="viewcode-block" id="GenericMCObjective.forward">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.objective.GenericMCObjective.forward">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">samples</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Evaluate the objective on the samples.</span>

<span class="sd">        Args:</span>
<span class="sd">            samples: A `sample_shape x batch_shape x q x m`-dim Tensors of</span>
<span class="sd">                samples from a model posterior.</span>
<span class="sd">            X: A `batch_shape x q x d`-dim tensor of inputs. Relevant only if</span>
<span class="sd">                the objective depends on the inputs explicitly.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `sample_shape x batch_shape x q`-dim Tensor of objective values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">)</span></div>
</div>



<div class="viewcode-block" id="ConstrainedMCObjective">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.objective.ConstrainedMCObjective">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">ConstrainedMCObjective</span><span class="p">(</span><span class="n">GenericMCObjective</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Feasibility-weighted objective.</span>

<span class="sd">    An Objective allowing to maximize some scalable objective on the model</span>
<span class="sd">    outputs subject to a number of constraints. Constraint feasibilty is</span>
<span class="sd">    approximated by a sigmoid function.</span>

<span class="sd">        mc_acq(X) = (</span>
<span class="sd">        (objective(X) + infeasible_cost) * \prod_i (1  - sigmoid(constraint_i(X)))</span>
<span class="sd">        ) - infeasible_cost</span>

<span class="sd">    See `botorch.utils.objective.apply_constraints` for details on the constraint</span>
<span class="sd">    handling.</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; bound = 0.0</span>
<span class="sd">        &gt;&gt;&gt; objective = lambda Y: Y[..., 0]</span>
<span class="sd">        &gt;&gt;&gt; # apply non-negativity constraint on f(x)[1]</span>
<span class="sd">        &gt;&gt;&gt; constraint = lambda Y: bound - Y[..., 1]</span>
<span class="sd">        &gt;&gt;&gt; constrained_objective = ConstrainedMCObjective(objective, [constraint])</span>
<span class="sd">        &gt;&gt;&gt; samples = sampler(posterior)</span>
<span class="sd">        &gt;&gt;&gt; objective = constrained_objective(samples)</span>

<span class="sd">    TODO: Deprecate this as default way to handle constraints with MC acquisition</span>
<span class="sd">    functions once we have data on how well SampleReducingMCAcquisitionFunction works.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">objective</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">],</span>
        <span class="n">constraints</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]],</span>
        <span class="n">infeasible_cost</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="n">eta</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            objective: A callable `f(samples, X)` mapping a</span>
<span class="sd">                `sample_shape x batch-shape x q x m`-dim Tensor `samples` and</span>
<span class="sd">                an optional `batch-shape x q x d`-dim Tensor `X` to a</span>
<span class="sd">                `sample_shape x batch-shape x q`-dim Tensor of objective values.</span>
<span class="sd">            constraints: A list of callables, each mapping a Tensor of dimension</span>
<span class="sd">                `sample_shape x batch-shape x q x m` to a Tensor of dimension</span>
<span class="sd">                `sample_shape x batch-shape x q`, where negative values imply</span>
<span class="sd">                feasibility.</span>
<span class="sd">            infeasible_cost: The cost of a design if all associated samples are</span>
<span class="sd">                infeasible.</span>
<span class="sd">            eta: The temperature parameter of the sigmoid function approximating</span>
<span class="sd">                the constraint. Can be either a float or a 1-dim tensor. In case</span>
<span class="sd">                of a float the same eta is used for every constraint in</span>
<span class="sd">                constraints. In case of a tensor the length of the tensor must</span>
<span class="sd">                match the number of provided constraints. The i-th constraint is</span>
<span class="sd">                then estimated with the i-th eta value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">objective</span><span class="o">=</span><span class="n">objective</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">constraints</span> <span class="o">=</span> <span class="n">constraints</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">eta</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">Tensor</span><span class="p">:</span>
            <span class="n">eta</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">constraints</span><span class="p">),),</span> <span class="n">eta</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;eta&quot;</span><span class="p">,</span> <span class="n">eta</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;infeasible_cost&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">infeasible_cost</span><span class="p">))</span>

<div class="viewcode-block" id="ConstrainedMCObjective.forward">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.objective.ConstrainedMCObjective.forward">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">samples</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Evaluate the feasibility-weighted objective on the samples.</span>

<span class="sd">        Args:</span>
<span class="sd">            samples: A `sample_shape x batch_shape x q x m`-dim Tensors of</span>
<span class="sd">                samples from a model posterior.</span>
<span class="sd">            X: A `batch_shape x q x d`-dim tensor of inputs. Relevant only if</span>
<span class="sd">                the objective depends on the inputs explicitly.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `sample_shape x batch_shape x q`-dim Tensor of objective values</span>
<span class="sd">            weighted by feasibility (assuming maximization).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">obj</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">samples</span><span class="o">=</span><span class="n">samples</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">apply_constraints</span><span class="p">(</span>
            <span class="n">obj</span><span class="o">=</span><span class="n">obj</span><span class="p">,</span>
            <span class="n">constraints</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">constraints</span><span class="p">,</span>
            <span class="n">samples</span><span class="o">=</span><span class="n">samples</span><span class="p">,</span>
            <span class="n">infeasible_cost</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">infeasible_cost</span><span class="p">,</span>
            <span class="n">eta</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eta</span><span class="p">,</span>
        <span class="p">)</span></div>
</div>



<span class="n">LEARNED_OBJECTIVE_PREF_MODEL_MIXED_DTYPE_WARN</span> <span class="o">=</span> <span class="p">(</span>
    <span class="s2">&quot;pref_model has double-precision data, but single-precision data &quot;</span>
    <span class="s2">&quot;was passed to the LearnedObjective. Upcasting to double.&quot;</span>
<span class="p">)</span>


<div class="viewcode-block" id="LearnedObjective">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.objective.LearnedObjective">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">LearnedObjective</span><span class="p">(</span><span class="n">MCAcquisitionObjective</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Learned preference objective constructed from a preference model.</span>

<span class="sd">    For input `samples`, it samples each individual sample again from the latent</span>
<span class="sd">    preference posterior distribution using `pref_model` and return the posterior mean.</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; train_X = torch.rand(2, 2)</span>
<span class="sd">        &gt;&gt;&gt; train_comps = torch.LongTensor([[0, 1]])</span>
<span class="sd">        &gt;&gt;&gt; pref_model = PairwiseGP(train_X, train_comps)</span>
<span class="sd">        &gt;&gt;&gt; learned_pref_obj = LearnedObjective(pref_model)</span>
<span class="sd">        &gt;&gt;&gt; samples = sampler(posterior)</span>
<span class="sd">        &gt;&gt;&gt; objective = learned_pref_obj(samples)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">pref_model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span>
        <span class="n">sample_shape</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            pref_model: A BoTorch model, which models the latent preference/utility</span>
<span class="sd">                function. Given an input tensor of size</span>
<span class="sd">                `sample_size x batch_shape x q x d`, its `posterior` method should</span>
<span class="sd">                return a `Posterior` object with single outcome representing the</span>
<span class="sd">                utility values of the input.</span>
<span class="sd">            sample_shape: Determines the number of preference-model samples drawn</span>
<span class="sd">                *per outcome-model sample* when the `LearnedObjective` is called.</span>
<span class="sd">                Note that this is an additional layer of sampling relative to what</span>
<span class="sd">                is needed when evaluating most MC acquisition functions in order to</span>
<span class="sd">                account for uncertainty in the preference model. If `None`, it will</span>
<span class="sd">                default to `torch.Size([16])`, so that 16 samples will be drawn</span>
<span class="sd">                from the preference model at each outcome sample. This number is</span>
<span class="sd">                relatively high because sampling from the preference model is general</span>
<span class="sd">                cheap relative to generating the outcome model posterior.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pref_model</span> <span class="o">=</span> <span class="n">pref_model</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">pref_model</span><span class="p">,</span> <span class="n">DeterministicModel</span><span class="p">):</span>
            <span class="k">assert</span> <span class="n">sample_shape</span> <span class="ow">is</span> <span class="kc">None</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sampler</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">sample_shape</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">sample_shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">DEFAULT_NUM_PREF_SAMPLES</span><span class="p">])</span>
            <span class="c1"># using an IIDNormalSampler instead of a SobolQMCNormalSampler by default</span>
            <span class="c1"># because SobolQMCNormalSampler can support up to 21201 total samples and</span>
            <span class="c1"># becomes noticeably slower than uniform sampling when the sample size is</span>
            <span class="c1"># large.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sampler</span> <span class="o">=</span> <span class="n">IIDNormalSampler</span><span class="p">(</span><span class="n">sample_shape</span><span class="o">=</span><span class="n">sample_shape</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sampler</span><span class="o">.</span><span class="n">batch_range_override</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<div class="viewcode-block" id="LearnedObjective.forward">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.objective.LearnedObjective.forward">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">samples</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Sample each element of samples.</span>

<span class="sd">        Args:</span>
<span class="sd">            samples: A `sample_size x batch_shape x q x d`-dim Tensors of</span>
<span class="sd">                samples from a model posterior.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `(sample_size * num_samples) x batch_shape x q`-dim Tensor of</span>
<span class="sd">            objective values sampled from utility posterior using `pref_model`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">samples</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float64</span> <span class="ow">and</span> <span class="nb">any</span><span class="p">(</span>
            <span class="n">d</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">float64</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">pref_model</span><span class="o">.</span><span class="n">dtypes_of_buffers</span>
        <span class="p">):</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="n">LEARNED_OBJECTIVE_PREF_MODEL_MIXED_DTYPE_WARN</span><span class="p">,</span>
                <span class="n">InputDataWarning</span><span class="p">,</span>
                <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">samples</span> <span class="o">=</span> <span class="n">samples</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">samples</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;samples should have at least 3 dimensions.&quot;</span><span class="p">)</span>

        <span class="n">posterior</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pref_model</span><span class="o">.</span><span class="n">posterior</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pref_model</span><span class="p">,</span> <span class="n">DeterministicModel</span><span class="p">):</span>
            <span class="c1"># return preference posterior mean</span>
            <span class="k">return</span> <span class="n">posterior</span><span class="o">.</span><span class="n">mean</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># return preference posterior augmented samples</span>
            <span class="n">samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampler</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">samples</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:])</span>  <span class="c1"># batch_shape x N</span></div>
</div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p></p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>