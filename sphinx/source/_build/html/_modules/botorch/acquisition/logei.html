

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>botorch.acquisition.logei &mdash; BoTorch  documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=03e43079" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../../_static/custom.css?v=ca3e82f4" />

  
      <script src="../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../_static/documentation_options.js?v=5929fcd5"></script>
      <script src="../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            BoTorch
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../acquisition.html">botorch.acquisition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models.html">botorch.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generation.html">botorch.generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../posteriors.html">botorch.posteriors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../optim.html">botorch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../fit.html">botorch.fit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../sampling.html">botorch.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cross_validation.html">botorch.cross_validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../settings.html">botorch.settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../logging.html">botorch.logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../test_functions.html">botorch.test_functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../test_utils.html">botorch.test_utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../exceptions.html">botorch.exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../utils.html">botorch.utils</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">BoTorch</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">botorch.acquisition.logei</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for botorch.acquisition.logei</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright (c) Meta Platforms, Inc. and affiliates.</span>
<span class="c1">#</span>
<span class="c1"># This source code is licensed under the MIT license found in the</span>
<span class="c1"># LICENSE file in the root directory of this source tree.</span>

<span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Monte-Carlo variants of the LogEI family of improvements-based acquisition functions,</span>
<span class="sd">see [Ament2023logei]_ for details.</span>

<span class="sd">References</span>

<span class="sd">.. [Ament2023logei]</span>
<span class="sd">    S. Ament, S. Daulton, D. Eriksson, M. Balandat, and E. Bakshy.</span>
<span class="sd">    Unexpected Improvements to Expected Improvement for Bayesian Optimization. Advances</span>
<span class="sd">    in Neural Information Processing Systems 36, 2023.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">__future__</span><span class="w"> </span><span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">collections.abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">Callable</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">copy</span><span class="w"> </span><span class="kn">import</span> <span class="n">deepcopy</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">functools</span><span class="w"> </span><span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">TypeVar</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.acquisition.cached_cholesky</span><span class="w"> </span><span class="kn">import</span> <span class="n">CachedCholeskyMCSamplerMixin</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.acquisition.monte_carlo</span><span class="w"> </span><span class="kn">import</span> <span class="n">SampleReducingMCAcquisitionFunction</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.acquisition.objective</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">ConstrainedMCObjective</span><span class="p">,</span>
    <span class="n">MCAcquisitionObjective</span><span class="p">,</span>
    <span class="n">PosteriorTransform</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.acquisition.utils</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">compute_best_feasible_objective</span><span class="p">,</span>
    <span class="n">prune_inferior_points</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.exceptions.errors</span><span class="w"> </span><span class="kn">import</span> <span class="n">BotorchError</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.models.model</span><span class="w"> </span><span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.sampling.base</span><span class="w"> </span><span class="kn">import</span> <span class="n">MCSampler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.utils.safe_math</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">fatmax</span><span class="p">,</span>
    <span class="n">log_fatplus</span><span class="p">,</span>
    <span class="n">log_softplus</span><span class="p">,</span>
    <span class="n">logmeanexp</span><span class="p">,</span>
    <span class="n">smooth_amax</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.utils.transforms</span><span class="w"> </span><span class="kn">import</span> <span class="n">match_batch_shape</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">Tensor</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">NOTE: On the default temperature parameters:</span>

<span class="sd">tau_relu: It is generally important to set `tau_relu` to be very small, in particular,</span>
<span class="sd">smaller than the expected improvement value. Otherwise, the optimization can stagnate.</span>
<span class="sd">By setting `tau_relu=1e-6` by default, stagnation is exceedingly unlikely to occur due</span>
<span class="sd">to the smooth ReLU approximation for practical applications of BO.</span>
<span class="sd">IDEA: We could consider shrinking `tau_relu` with the progression of the optimization.</span>

<span class="sd">tau_max: This is only relevant for the batch (`q &gt; 1`) case, and `tau_max=1e-2` is</span>
<span class="sd">sufficient to get a good approximation to the maximum improvement in the batch of</span>
<span class="sd">candidates. If `fat=False`, the smooth approximation to the maximum can saturate</span>
<span class="sd">numerically. It is therefore recommended to use `fat=True` when optimizing batches</span>
<span class="sd">of `q &gt; 1` points.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">TAU_RELU</span> <span class="o">=</span> <span class="mf">1e-6</span>
<span class="n">TAU_MAX</span> <span class="o">=</span> <span class="mf">1e-2</span>
<span class="n">FloatOrTensor</span> <span class="o">=</span> <span class="n">TypeVar</span><span class="p">(</span><span class="s2">&quot;FloatOrTensor&quot;</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span>


<div class="viewcode-block" id="LogImprovementMCAcquisitionFunction">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.logei.LogImprovementMCAcquisitionFunction">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">LogImprovementMCAcquisitionFunction</span><span class="p">(</span><span class="n">SampleReducingMCAcquisitionFunction</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Abstract base class for Monte-Carlo-based batch LogEI acquisition functions.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_log</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span>
        <span class="n">sampler</span><span class="p">:</span> <span class="n">MCSampler</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">objective</span><span class="p">:</span> <span class="n">MCAcquisitionObjective</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">PosteriorTransform</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">X_pending</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">constraints</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">eta</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">,</span>
        <span class="n">fat</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">tau_max</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">TAU_MAX</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            model: A fitted model.</span>
<span class="sd">            sampler: The sampler used to draw base samples. If not given,</span>
<span class="sd">                a sampler is generated using `get_sampler`.</span>
<span class="sd">                NOTE: For posteriors that do not support base samples,</span>
<span class="sd">                a sampler compatible with intended use case must be provided.</span>
<span class="sd">                See `ForkedRNGSampler` and `StochasticSampler` as examples.</span>
<span class="sd">            objective: The MCAcquisitionObjective under which the samples are</span>
<span class="sd">                evaluated. Defaults to `IdentityMCObjective()`.</span>
<span class="sd">            posterior_transform: A PosteriorTransform (optional).</span>
<span class="sd">            X_pending: A `batch_shape, m x d`-dim Tensor of `m` design points</span>
<span class="sd">                that have points that have been submitted for function evaluation</span>
<span class="sd">                but have not yet been evaluated.</span>
<span class="sd">            constraints: A list of constraint callables which map a Tensor of posterior</span>
<span class="sd">                samples of dimension `sample_shape x batch-shape x q x m`-dim to a</span>
<span class="sd">                `sample_shape x batch-shape x q`-dim Tensor. The associated constraints</span>
<span class="sd">                are satisfied if `constraint(samples) &lt; 0`.</span>
<span class="sd">            eta: Temperature parameter(s) governing the smoothness of the sigmoid</span>
<span class="sd">                approximation to the constraint indicators. See the docs of</span>
<span class="sd">                `compute_(log_)constraint_indicator` for more details on this parameter.</span>
<span class="sd">            fat: Toggles the logarithmic / linear asymptotic behavior of the smooth</span>
<span class="sd">                approximation to the ReLU.</span>
<span class="sd">            tau_max: Temperature parameter controlling the sharpness of the</span>
<span class="sd">                approximation to the `max` operator over the `q` candidate points.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">ConstrainedMCObjective</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">BotorchError</span><span class="p">(</span>
                <span class="s2">&quot;Log-Improvement should not be used with `ConstrainedMCObjective`.&quot;</span>
                <span class="s2">&quot;Please pass the `constraints` directly to the constructor of the &quot;</span>
                <span class="s2">&quot;acquisition function.&quot;</span>
            <span class="p">)</span>
        <span class="n">q_reduction</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">fatmax</span> <span class="k">if</span> <span class="n">fat</span> <span class="k">else</span> <span class="n">smooth_amax</span><span class="p">,</span> <span class="n">tau</span><span class="o">=</span><span class="n">tau_max</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">,</span>
            <span class="n">objective</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
            <span class="n">posterior_transform</span><span class="o">=</span><span class="n">posterior_transform</span><span class="p">,</span>
            <span class="n">X_pending</span><span class="o">=</span><span class="n">X_pending</span><span class="p">,</span>
            <span class="n">sample_reduction</span><span class="o">=</span><span class="n">logmeanexp</span><span class="p">,</span>
            <span class="n">q_reduction</span><span class="o">=</span><span class="n">q_reduction</span><span class="p">,</span>
            <span class="n">constraints</span><span class="o">=</span><span class="n">constraints</span><span class="p">,</span>
            <span class="n">eta</span><span class="o">=</span><span class="n">eta</span><span class="p">,</span>
            <span class="n">fat</span><span class="o">=</span><span class="n">fat</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tau_max</span> <span class="o">=</span> <span class="n">tau_max</span></div>



<div class="viewcode-block" id="qLogExpectedImprovement">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.logei.qLogExpectedImprovement">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">qLogExpectedImprovement</span><span class="p">(</span><span class="n">LogImprovementMCAcquisitionFunction</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;MC-based batch Log Expected Improvement.</span>

<span class="sd">    This computes qLogEI by</span>
<span class="sd">    (1) sampling the joint posterior over q points,</span>
<span class="sd">    (2) evaluating the smoothed log improvement over the current best for each sample,</span>
<span class="sd">    (3) smoothly maximizing over q, and</span>
<span class="sd">    (4) averaging over the samples in log space.</span>

<span class="sd">    See [Ament2023logei]_ for details. Formally,</span>

<span class="sd">    `qLogEI(X) ~ log(qEI(X)) = log(E(max(max Y - best_f, 0)))`.</span>

<span class="sd">    where `Y ~ f(X)`, and `X = (x_1,...,x_q)`, .</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; model = SingleTaskGP(train_X, train_Y)</span>
<span class="sd">        &gt;&gt;&gt; best_f = train_Y.max()[0]</span>
<span class="sd">        &gt;&gt;&gt; sampler = SobolQMCNormalSampler(1024)</span>
<span class="sd">        &gt;&gt;&gt; qLogEI = qLogExpectedImprovement(model, best_f, sampler)</span>
<span class="sd">        &gt;&gt;&gt; qei = qLogEI(test_X)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span>
        <span class="n">best_f</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">sampler</span><span class="p">:</span> <span class="n">MCSampler</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">objective</span><span class="p">:</span> <span class="n">MCAcquisitionObjective</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">PosteriorTransform</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">X_pending</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">constraints</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">eta</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">,</span>
        <span class="n">fat</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">tau_max</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">TAU_MAX</span><span class="p">,</span>
        <span class="n">tau_relu</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">TAU_RELU</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;q-Log Expected Improvement.</span>

<span class="sd">        Args:</span>
<span class="sd">            model: A fitted model.</span>
<span class="sd">            best_f: The best objective value observed so far (assumed noiseless). Can be</span>
<span class="sd">                a scalar, or a `batch_shape`-dim tensor. In case of a batched model, the</span>
<span class="sd">                tensor can specify different values for each element of the batch.</span>
<span class="sd">            sampler: The sampler used to draw base samples. See `MCAcquisitionFunction`</span>
<span class="sd">                more details.</span>
<span class="sd">            objective: The MCAcquisitionObjective under which the samples are evaluated.</span>
<span class="sd">                Defaults to `IdentityMCObjective()`.</span>
<span class="sd">            posterior_transform: A PosteriorTransform (optional).</span>
<span class="sd">            X_pending:  A `m x d`-dim Tensor of `m` design points that have been</span>
<span class="sd">                submitted for function evaluation but have not yet been evaluated.</span>
<span class="sd">                Concatenated into `X` upon forward call. Copied and set to have no</span>
<span class="sd">                gradient.</span>
<span class="sd">            constraints: A list of constraint callables which map a Tensor of posterior</span>
<span class="sd">                samples of dimension `sample_shape x batch-shape x q x m`-dim to a</span>
<span class="sd">                `sample_shape x batch-shape x q`-dim Tensor. The associated constraints</span>
<span class="sd">                are satisfied if `constraint(samples) &lt; 0`.</span>
<span class="sd">            eta: Temperature parameter(s) governing the smoothness of the sigmoid</span>
<span class="sd">                approximation to the constraint indicators. See the docs of</span>
<span class="sd">                `compute_(log_)smoothed_constraint_indicator` for details.</span>
<span class="sd">            fat: Toggles the logarithmic / linear asymptotic behavior of the smooth</span>
<span class="sd">                approximation to the ReLU.</span>
<span class="sd">            tau_max: Temperature parameter controlling the sharpness of the smooth</span>
<span class="sd">                approximations to max.</span>
<span class="sd">            tau_relu: Temperature parameter controlling the sharpness of the smooth</span>
<span class="sd">                approximations to ReLU.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">,</span>
            <span class="n">objective</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
            <span class="n">posterior_transform</span><span class="o">=</span><span class="n">posterior_transform</span><span class="p">,</span>
            <span class="n">X_pending</span><span class="o">=</span><span class="n">X_pending</span><span class="p">,</span>
            <span class="n">constraints</span><span class="o">=</span><span class="n">constraints</span><span class="p">,</span>
            <span class="n">eta</span><span class="o">=</span><span class="n">eta</span><span class="p">,</span>
            <span class="n">tau_max</span><span class="o">=</span><span class="n">check_tau</span><span class="p">(</span><span class="n">tau_max</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;tau_max&quot;</span><span class="p">),</span>
            <span class="n">fat</span><span class="o">=</span><span class="n">fat</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;best_f&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">best_f</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tau_relu</span> <span class="o">=</span> <span class="n">check_tau</span><span class="p">(</span><span class="n">tau_relu</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;tau_relu&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_sample_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Evaluate qLogExpectedImprovement on the candidate set `X`.</span>

<span class="sd">        Args:</span>
<span class="sd">            obj: `mc_shape x batch_shape x q`-dim Tensor of MC objective values.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `mc_shape x batch_shape x q`-dim Tensor of expected improvement values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">li</span> <span class="o">=</span> <span class="n">_log_improvement</span><span class="p">(</span>
            <span class="n">Y</span><span class="o">=</span><span class="n">obj</span><span class="p">,</span>
            <span class="n">best_f</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">best_f</span><span class="p">,</span>
            <span class="n">tau</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tau_relu</span><span class="p">,</span>
            <span class="n">fat</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_fat</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">li</span></div>



<div class="viewcode-block" id="qLogNoisyExpectedImprovement">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.logei.qLogNoisyExpectedImprovement">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">qLogNoisyExpectedImprovement</span><span class="p">(</span>
    <span class="n">LogImprovementMCAcquisitionFunction</span><span class="p">,</span> <span class="n">CachedCholeskyMCSamplerMixin</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;MC-based batch Log Noisy Expected Improvement.</span>

<span class="sd">    This function does not assume a `best_f` is known (which would require</span>
<span class="sd">    noiseless observations). Instead, it uses samples from the joint posterior</span>
<span class="sd">    over the `q` test points and previously observed points. A smooth approximation</span>
<span class="sd">    to the canonical improvement over previously observed points is computed</span>
<span class="sd">    for each sample and the logarithm of the average is returned.</span>

<span class="sd">    See [Ament2023logei]_ for details. Formally,</span>

<span class="sd">    `qLogNEI(X) ~ log(qNEI(X)) = Log E(max(max Y - max Y_baseline, 0))`,</span>

<span class="sd">    where `(Y, Y_baseline) ~ f((X, X_baseline)), X = (x_1,...,x_q)`.</span>

<span class="sd">    For optimizing a batch of `q &gt; 1` points using sequential greedy optimization,</span>
<span class="sd">    the incremental improvement from the latest point is computed and returned by</span>
<span class="sd">    default. I.e. the pending points are treated X_baseline. Often, the incremental</span>
<span class="sd">    EI is easier to optimize.</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; model = SingleTaskGP(train_X, train_Y)</span>
<span class="sd">        &gt;&gt;&gt; sampler = SobolQMCNormalSampler(1024)</span>
<span class="sd">        &gt;&gt;&gt; qLogNEI = qLogNoisyExpectedImprovement(model, train_X, sampler)</span>
<span class="sd">        &gt;&gt;&gt; acqval = qLogNEI(test_X)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span>
        <span class="n">X_baseline</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">sampler</span><span class="p">:</span> <span class="n">MCSampler</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">objective</span><span class="p">:</span> <span class="n">MCAcquisitionObjective</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">PosteriorTransform</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">X_pending</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">constraints</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">eta</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">,</span>
        <span class="n">fat</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">prune_baseline</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">cache_root</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">tau_max</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">TAU_MAX</span><span class="p">,</span>
        <span class="n">tau_relu</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">TAU_RELU</span><span class="p">,</span>
        <span class="n">marginalize_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">incremental</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;q-Noisy Expected Improvement.</span>

<span class="sd">        Args:</span>
<span class="sd">            model: A fitted model.</span>
<span class="sd">            X_baseline: A `batch_shape x r x d`-dim Tensor of `r` design points</span>
<span class="sd">                that have already been observed. These points are considered as</span>
<span class="sd">                the potential best design point.</span>
<span class="sd">            sampler: The sampler used to draw base samples. See `MCAcquisitionFunction`</span>
<span class="sd">                more details.</span>
<span class="sd">            objective: The MCAcquisitionObjective under which the samples are</span>
<span class="sd">                evaluated. Defaults to `IdentityMCObjective()`.</span>
<span class="sd">            posterior_transform: A PosteriorTransform (optional).</span>
<span class="sd">            X_pending: A `batch_shape x m x d`-dim Tensor of `m` design points</span>
<span class="sd">                that have points that have been submitted for function evaluation</span>
<span class="sd">                but have not yet been evaluated. Concatenated into `X` upon</span>
<span class="sd">                forward call. Copied and set to have no gradient.</span>
<span class="sd">            constraints: A list of constraint callables which map a Tensor of posterior</span>
<span class="sd">                samples of dimension `sample_shape x batch-shape x q x m`-dim to a</span>
<span class="sd">                `sample_shape x batch-shape x q`-dim Tensor. The associated constraints</span>
<span class="sd">                are satisfied if `constraint(samples) &lt; 0`.</span>
<span class="sd">            eta: Temperature parameter(s) governing the smoothness of the sigmoid</span>
<span class="sd">                approximation to the constraint indicators. See the docs of</span>
<span class="sd">                `compute_(log_)smoothed_constraint_indicator` for details.</span>
<span class="sd">            fat: Toggles the logarithmic / linear asymptotic behavior of the smooth</span>
<span class="sd">                approximation to the ReLU.</span>
<span class="sd">            prune_baseline: If True, remove points in `X_baseline` that are</span>
<span class="sd">                highly unlikely to be the best point. This can significantly</span>
<span class="sd">                improve performance and is generally recommended. In order to</span>
<span class="sd">                customize pruning parameters, instead manually call</span>
<span class="sd">                `botorch.acquisition.utils.prune_inferior_points` on `X_baseline`</span>
<span class="sd">                before instantiating the acquisition function.</span>
<span class="sd">            cache_root: A boolean indicating whether to cache the root</span>
<span class="sd">                decomposition over `X_baseline` and use low-rank updates.</span>
<span class="sd">            tau_max: Temperature parameter controlling the sharpness of the smooth</span>
<span class="sd">                approximations to max.</span>
<span class="sd">            tau_relu: Temperature parameter controlling the sharpness of the smooth</span>
<span class="sd">                approximations to ReLU.</span>
<span class="sd">            marginalize_dim: The dimension to marginalize over.</span>
<span class="sd">            incremental: Whether to compute incremental EI over the pending points</span>
<span class="sd">                or compute EI of the joint batch improvement (including pending</span>
<span class="sd">                points).</span>

<span class="sd">        TODO: similar to qNEHVI, when we are using sequential greedy candidate</span>
<span class="sd">        selection, we could incorporate pending points X_baseline and compute</span>
<span class="sd">        the incremental q(Log)NEI from the new point. This would greatly increase</span>
<span class="sd">        efficiency for large batches.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># TODO: separate out baseline variables initialization and other functions</span>
        <span class="c1"># in qNEI to avoid duplication of both code and work at runtime.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">incremental</span> <span class="o">=</span> <span class="n">incremental</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">,</span>
            <span class="n">objective</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
            <span class="n">posterior_transform</span><span class="o">=</span><span class="n">posterior_transform</span><span class="p">,</span>
            <span class="c1"># we set X_pending in init_baseline for incremental NEI</span>
            <span class="n">X_pending</span><span class="o">=</span><span class="n">X_pending</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">incremental</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">constraints</span><span class="o">=</span><span class="n">constraints</span><span class="p">,</span>
            <span class="n">eta</span><span class="o">=</span><span class="n">eta</span><span class="p">,</span>
            <span class="n">fat</span><span class="o">=</span><span class="n">fat</span><span class="p">,</span>
            <span class="n">tau_max</span><span class="o">=</span><span class="n">tau_max</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tau_relu</span> <span class="o">=</span> <span class="n">tau_relu</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prune_baseline</span> <span class="o">=</span> <span class="n">prune_baseline</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">marginalize_dim</span> <span class="o">=</span> <span class="n">marginalize_dim</span>
        <span class="k">if</span> <span class="n">incremental</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">X_pending</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># required to initialize attribute for optimize_acqf</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_init_baseline</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">X_baseline</span><span class="o">=</span><span class="n">X_baseline</span><span class="p">,</span>
            <span class="c1"># This is ignored in incremental=False</span>
            <span class="n">X_pending</span><span class="o">=</span><span class="n">X_pending</span><span class="p">,</span>
            <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">,</span>
            <span class="n">objective</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
            <span class="n">posterior_transform</span><span class="o">=</span><span class="n">posterior_transform</span><span class="p">,</span>
            <span class="n">cache_root</span><span class="o">=</span><span class="n">cache_root</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_sample_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Evaluate qLogNoisyExpectedImprovement per sample on the candidate set `X`.</span>

<span class="sd">        Args:</span>
<span class="sd">            obj: `mc_shape x batch_shape x q`-dim Tensor of MC objective values.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `sample_shape x batch_shape x q`-dim Tensor of log noisy expected smoothed</span>
<span class="sd">            improvement values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">_log_improvement</span><span class="p">(</span>
            <span class="n">Y</span><span class="o">=</span><span class="n">obj</span><span class="p">,</span>
            <span class="n">best_f</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">compute_best_f</span><span class="p">(</span><span class="n">obj</span><span class="p">),</span>
            <span class="n">tau</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tau_relu</span><span class="p">,</span>
            <span class="n">fat</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_fat</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_init_baseline</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span>
        <span class="n">X_baseline</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">X_pending</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">sampler</span><span class="p">:</span> <span class="n">MCSampler</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">objective</span><span class="p">:</span> <span class="n">MCAcquisitionObjective</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">PosteriorTransform</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">cache_root</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">CachedCholeskyMCSamplerMixin</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">cache_root</span><span class="o">=</span><span class="n">cache_root</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">prune_baseline</span><span class="p">:</span>
            <span class="n">X_baseline</span> <span class="o">=</span> <span class="n">prune_inferior_points</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
                <span class="n">X</span><span class="o">=</span><span class="n">X_baseline</span><span class="p">,</span>
                <span class="n">objective</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
                <span class="n">posterior_transform</span><span class="o">=</span><span class="n">posterior_transform</span><span class="p">,</span>
                <span class="n">marginalize_dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">marginalize_dim</span><span class="p">,</span>
                <span class="n">constraints</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_constraints</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;_X_baseline&quot;</span><span class="p">,</span> <span class="n">X_baseline</span><span class="p">)</span>
        <span class="c1"># full_X_baseline is the set of points that should be considered as the</span>
        <span class="c1"># incumbent. For incremental EI, this contains the previously evaluated</span>
        <span class="c1"># points (X_baseline) and pending points (X_pending). For non-incremental</span>
        <span class="c1"># EI, this contains the  previously evaluated points (X_baseline).</span>
        <span class="k">if</span> <span class="n">X_pending</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">incremental</span><span class="p">:</span>
            <span class="n">full_X_baseline</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">X_baseline</span><span class="p">,</span> <span class="n">X_pending</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">full_X_baseline</span> <span class="o">=</span> <span class="n">X_baseline</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;_full_X_baseline&quot;</span><span class="p">,</span> <span class="n">full_X_baseline</span><span class="p">)</span>
        <span class="c1"># registering buffers for _get_samples_and_objectives in the next `if` block</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;baseline_samples&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;baseline_obj&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cache_root</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">q_in</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
            <span class="c1"># set baseline samples</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>  <span class="c1"># this is _get_samples_and_objectives(X_baseline)</span>
                <span class="n">posterior</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">posterior</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">X_baseline</span><span class="p">,</span> <span class="n">posterior_transform</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">posterior_transform</span>
                <span class="p">)</span>
                <span class="c1"># Note: The root decomposition is cached in two different places. It</span>
                <span class="c1"># may be confusing to have two different caches, but this is not</span>
                <span class="c1"># trivial to change since each is needed for a different reason:</span>
                <span class="c1"># - LinearOperator caching to `posterior.mvn` allows for reuse within</span>
                <span class="c1">#   this function, which may be helpful if the same root decomposition</span>
                <span class="c1">#   is produced by the calls to `self.base_sampler` and</span>
                <span class="c1">#   `self._cache_root_decomposition`.</span>
                <span class="c1"># - self._baseline_L allows a root decomposition to be persisted outside</span>
                <span class="c1">#   this method.</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">baseline_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_posterior_samples</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">baseline_obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">baseline_samples</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">X_baseline</span>
                <span class="p">)</span>

            <span class="c1"># We make a copy here because we will write an attribute `base_samples`</span>
            <span class="c1"># to `self.base_sampler.base_samples`, and we don&#39;t want to mutate</span>
            <span class="c1"># `self.sampler`.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">base_sampler</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sampler</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
                <span class="s2">&quot;_baseline_best_f&quot;</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_compute_best_feasible_objective</span><span class="p">(</span>
                    <span class="n">samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">baseline_samples</span><span class="p">,</span> <span class="n">obj</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">baseline_obj</span>
                <span class="p">),</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_baseline_L</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_root_decomposition</span><span class="p">(</span><span class="n">posterior</span><span class="o">=</span><span class="n">posterior</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">X_baseline</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the set of pointsthat should be considered as the incumbent.</span>

<span class="sd">        For incremental EI, this contains the previously evaluated points</span>
<span class="sd">        (X_baseline) and pending points (X_pending). For non-incremental</span>
<span class="sd">        EI, this contains the  previously evaluated points (X_baseline).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_full_X_baseline</span>

<div class="viewcode-block" id="qLogNoisyExpectedImprovement.set_X_pending">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.logei.qLogNoisyExpectedImprovement.set_X_pending">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">set_X_pending</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_pending</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Informs the acquisition function about pending design points.</span>

<span class="sd">        Here pending points are concatenated with X_baseline and incremental</span>
<span class="sd">        NEI is computed.</span>

<span class="sd">        Args:</span>
<span class="sd">            X_pending: `n x d` Tensor with `n` `d`-dim design points that have</span>
<span class="sd">                been submitted for evaluation but have not yet been evaluated.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">incremental</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">set_X_pending</span><span class="p">(</span><span class="n">X_pending</span><span class="o">=</span><span class="n">X_pending</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">X_pending</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_full_X_baseline&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_full_X_baseline</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_X_baseline</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
            <span class="p">):</span>
                <span class="k">return</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># reset pending points</span>
                <span class="n">X_pending</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_init_baseline</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="n">X_baseline</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_X_baseline</span><span class="p">,</span>
            <span class="n">X_pending</span><span class="o">=</span><span class="n">X_pending</span><span class="p">,</span>
            <span class="n">sampler</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sampler</span><span class="p">,</span>
            <span class="n">objective</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">objective</span><span class="p">,</span>
            <span class="n">posterior_transform</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">posterior_transform</span><span class="p">,</span>
            <span class="n">cache_root</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_cache_root</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="qLogNoisyExpectedImprovement.compute_best_f">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.logei.qLogNoisyExpectedImprovement.compute_best_f">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">compute_best_f</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Computes the best (feasible) noisy objective value.</span>

<span class="sd">        Args:</span>
<span class="sd">            obj: `sample_shape x batch_shape x q`-dim Tensor of objectives in forward.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `sample_shape x batch_shape`-dim Tensor of best feasible objectives.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cache_root</span><span class="p">:</span>
            <span class="n">val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_baseline_best_f</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_best_feasible_objective</span><span class="p">(</span>
                <span class="n">samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">baseline_samples</span><span class="p">,</span> <span class="n">obj</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">baseline_obj</span>
            <span class="p">)</span>
        <span class="c1"># ensuring shape, dtype, device compatibility with obj</span>
        <span class="n">n_sample_dims</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_shape</span><span class="p">)</span>
        <span class="n">view_shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="o">*</span><span class="n">val</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="n">n_sample_dims</span><span class="p">],</span>  <span class="c1"># sample dimensions</span>
                <span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="o">*</span> <span class="p">(</span><span class="n">obj</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="n">val</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span>  <span class="c1"># pad to match obj without `q`-dim</span>
                <span class="o">*</span><span class="n">val</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">n_sample_dims</span><span class="p">:],</span>  <span class="c1"># the rest</span>
            <span class="p">]</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">val</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">view_shape</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>  <span class="c1"># obj.shape[:-1], i.e. without `q`-dim`</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_get_samples_and_objectives</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Compute samples at new points, using the cached root decomposition.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: A `batch_shape x q x d`-dim tensor of inputs.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A two-tuple `(samples, obj)`, where `samples` is a tensor of posterior</span>
<span class="sd">            samples with shape `sample_shape x batch_shape x q x m`, and `obj` is a</span>
<span class="sd">            tensor of MC objective values with shape `sample_shape x batch_shape x q`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">n_baseline</span><span class="p">,</span> <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_baseline</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">X_full</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">match_batch_shape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_baseline</span><span class="p">,</span> <span class="n">X</span><span class="p">),</span> <span class="n">X</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>
        <span class="c1"># TODO: Implement more efficient way to compute posterior over both training and</span>
        <span class="c1"># test points in GPyTorch (https://github.com/cornellius-gp/gpytorch/issues/567)</span>
        <span class="n">posterior</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">posterior</span><span class="p">(</span>
            <span class="n">X_full</span><span class="p">,</span> <span class="n">posterior_transform</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">posterior_transform</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cache_root</span><span class="p">:</span>
            <span class="n">samples_full</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_posterior_samples</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
            <span class="n">obj_full</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective</span><span class="p">(</span><span class="n">samples_full</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X_full</span><span class="p">)</span>
            <span class="c1"># Calculate the positive index for splitting the samples &amp; objective values.</span>
            <span class="n">split_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">obj_full</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
            <span class="c1"># assigning baseline buffers so `best_f` can be computed in _sample_forward</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">baseline_samples</span><span class="p">,</span> <span class="n">samples</span> <span class="o">=</span> <span class="n">samples_full</span><span class="o">.</span><span class="n">split</span><span class="p">(</span>
                <span class="p">[</span><span class="n">n_baseline</span><span class="p">,</span> <span class="n">q</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="n">split_dim</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">baseline_obj</span><span class="p">,</span> <span class="n">obj</span> <span class="o">=</span> <span class="n">obj_full</span><span class="o">.</span><span class="n">split</span><span class="p">([</span><span class="n">n_baseline</span><span class="p">,</span> <span class="n">q</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="n">split_dim</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">samples</span><span class="p">,</span> <span class="n">obj</span>

        <span class="c1"># handle one-to-many input transforms</span>
        <span class="n">n_plus_q</span> <span class="o">=</span> <span class="n">X_full</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">n_w</span> <span class="o">=</span> <span class="n">posterior</span><span class="o">.</span><span class="n">_extended_shape</span><span class="p">()[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">//</span> <span class="n">n_plus_q</span>
        <span class="n">q_in</span> <span class="o">=</span> <span class="n">q</span> <span class="o">*</span> <span class="n">n_w</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set_sampler</span><span class="p">(</span><span class="n">q_in</span><span class="o">=</span><span class="n">q_in</span><span class="p">,</span> <span class="n">posterior</span><span class="o">=</span><span class="n">posterior</span><span class="p">)</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_f_X_samples</span><span class="p">(</span><span class="n">posterior</span><span class="o">=</span><span class="n">posterior</span><span class="p">,</span> <span class="n">q_in</span><span class="o">=</span><span class="n">q_in</span><span class="p">)</span>
        <span class="n">obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X_full</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="n">q</span><span class="p">:,</span> <span class="p">:])</span>
        <span class="k">return</span> <span class="n">samples</span><span class="p">,</span> <span class="n">obj</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_best_feasible_objective</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">samples</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">obj</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes best feasible objective value from samples.</span>

<span class="sd">        Args:</span>
<span class="sd">            samples: `sample_shape x batch_shape x q x m`-dim posterior samples.</span>
<span class="sd">            obj: A `sample_shape x batch_shape x q`-dim Tensor of MC objective values.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `sample_shape x batch_shape`-dim Tensor of best feasible objectives.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">compute_best_feasible_objective</span><span class="p">(</span>
            <span class="n">samples</span><span class="o">=</span><span class="n">samples</span><span class="p">,</span>
            <span class="n">obj</span><span class="o">=</span><span class="n">obj</span><span class="p">,</span>
            <span class="n">constraints</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_constraints</span><span class="p">,</span>
            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="n">objective</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">objective</span><span class="p">,</span>
            <span class="n">posterior_transform</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">posterior_transform</span><span class="p">,</span>
            <span class="n">X_baseline</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">X_baseline</span><span class="p">,</span>
        <span class="p">)</span></div>



<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">###################################### utils ##########################################</span>
<span class="sd">&quot;&quot;&quot;</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_log_improvement</span><span class="p">(</span>
    <span class="n">Y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">best_f</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">tau</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">fat</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Computes the logarithm of the softplus-smoothed improvement, i.e.</span>
<span class="sd">    `log_softplus(Y - best_f, beta=(1 / tau))`.</span>
<span class="sd">    Note that softplus is an approximation to the regular ReLU objective whose maximum</span>
<span class="sd">    pointwise approximation error is linear with respect to tau as tau goes to zero.</span>

<span class="sd">    Args:</span>
<span class="sd">        obj: `mc_samples x batch_shape x q`-dim Tensor of output samples.</span>
<span class="sd">        best_f: Best previously observed objective value(s), broadcastable with</span>
<span class="sd">            `mc_samples x batch_shape`-dim Tensor, i.e. `obj`&#39;s dims without `q`.</span>
<span class="sd">        tau: Temperature parameter for smooth approximation of ReLU.</span>
<span class="sd">            as `tau -&gt; 0`, maximum pointwise approximation error is linear w.r.t. `tau`.</span>
<span class="sd">        fat: Toggles the logarithmic / linear asymptotic behavior of the</span>
<span class="sd">            smooth approximation to ReLU.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A `mc_samples x batch_shape x q`-dim Tensor of improvement values.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">log_soft_clamp</span> <span class="o">=</span> <span class="n">log_fatplus</span> <span class="k">if</span> <span class="n">fat</span> <span class="k">else</span> <span class="n">log_softplus</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">Y</span> <span class="o">-</span> <span class="n">best_f</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">log_soft_clamp</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">tau</span><span class="o">=</span><span class="n">tau</span><span class="p">)</span>  <span class="c1"># ~ ((Y - best_f) / Y_std).clamp(0)</span>


<div class="viewcode-block" id="check_tau">
<a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.logei.check_tau">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">check_tau</span><span class="p">(</span><span class="n">tau</span><span class="p">:</span> <span class="n">FloatOrTensor</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">FloatOrTensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Checks the validity of the tau arguments of the functions below, and returns</span>
<span class="sd">    `tau` if it is valid.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tau</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">tau</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> is not a scalar: </span><span class="si">{</span><span class="n">tau</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span><span class="si">=}</span><span class="s2">.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">tau</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> is non-positive: </span><span class="si">{</span><span class="n">tau</span><span class="si">=}</span><span class="s2">.&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tau</span></div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p></p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>