

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>botorch.acquisition &mdash; BoTorch  documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="_static/custom.css?v=ca3e82f4" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=5929fcd5"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="botorch.models" href="models.html" />
    <link rel="prev" title="BoTorch API Reference" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            BoTorch
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">botorch.acquisition</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#acquisition-function-apis">Acquisition Function APIs</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.acquisition.acquisition">Abstract Acquisition Function APIs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.acquisition.AcquisitionFunction"><code class="docutils literal notranslate"><span class="pre">AcquisitionFunction</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.acquisition.OneShotAcquisitionFunction"><code class="docutils literal notranslate"><span class="pre">OneShotAcquisitionFunction</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.acquisition.MCSamplerMixin"><code class="docutils literal notranslate"><span class="pre">MCSamplerMixin</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.acquisition.MultiModelAcquisitionFunction"><code class="docutils literal notranslate"><span class="pre">MultiModelAcquisitionFunction</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#analytic-acquisition-function-api">Analytic Acquisition Function API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.analytic.AnalyticAcquisitionFunction"><code class="docutils literal notranslate"><span class="pre">AnalyticAcquisitionFunction</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.acquisition.cached_cholesky">Cached Cholesky Acquisition Function API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.cached_cholesky.supports_cache_root"><code class="docutils literal notranslate"><span class="pre">supports_cache_root()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.cached_cholesky.CachedCholeskyMCSamplerMixin"><code class="docutils literal notranslate"><span class="pre">CachedCholeskyMCSamplerMixin</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.acquisition.decoupled">Decoupled Acquisition Function API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.decoupled.DecoupledAcquisitionFunction"><code class="docutils literal notranslate"><span class="pre">DecoupledAcquisitionFunction</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#monte-carlo-acquisition-function-api">Monte-Carlo Acquisition Function API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.monte_carlo.MCAcquisitionFunction"><code class="docutils literal notranslate"><span class="pre">MCAcquisitionFunction</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.acquisition.multi_objective.base">Base Classes for Multi-Objective Acquisition Function API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.multi_objective.base.MultiObjectiveAnalyticAcquisitionFunction"><code class="docutils literal notranslate"><span class="pre">MultiObjectiveAnalyticAcquisitionFunction</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.multi_objective.base.MultiObjectiveMCAcquisitionFunction"><code class="docutils literal notranslate"><span class="pre">MultiObjectiveMCAcquisitionFunction</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#acquisition-functions">Acquisition Functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.acquisition.analytic">Analytic Acquisition Functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.analytic.LogProbabilityOfImprovement"><code class="docutils literal notranslate"><span class="pre">LogProbabilityOfImprovement</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.analytic.ProbabilityOfImprovement"><code class="docutils literal notranslate"><span class="pre">ProbabilityOfImprovement</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.analytic.qAnalyticProbabilityOfImprovement"><code class="docutils literal notranslate"><span class="pre">qAnalyticProbabilityOfImprovement</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.analytic.ExpectedImprovement"><code class="docutils literal notranslate"><span class="pre">ExpectedImprovement</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.analytic.LogExpectedImprovement"><code class="docutils literal notranslate"><span class="pre">LogExpectedImprovement</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.analytic.LogConstrainedExpectedImprovement"><code class="docutils literal notranslate"><span class="pre">LogConstrainedExpectedImprovement</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.analytic.ConstrainedExpectedImprovement"><code class="docutils literal notranslate"><span class="pre">ConstrainedExpectedImprovement</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.analytic.LogNoisyExpectedImprovement"><code class="docutils literal notranslate"><span class="pre">LogNoisyExpectedImprovement</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.analytic.NoisyExpectedImprovement"><code class="docutils literal notranslate"><span class="pre">NoisyExpectedImprovement</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.analytic.UpperConfidenceBound"><code class="docutils literal notranslate"><span class="pre">UpperConfidenceBound</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.analytic.PosteriorMean"><code class="docutils literal notranslate"><span class="pre">PosteriorMean</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.analytic.ScalarizedPosteriorMean"><code class="docutils literal notranslate"><span class="pre">ScalarizedPosteriorMean</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.analytic.PosteriorStandardDeviation"><code class="docutils literal notranslate"><span class="pre">PosteriorStandardDeviation</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.acquisition.monte_carlo">Monte-Carlo Acquisition Functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.monte_carlo.SampleReductionProtocol"><code class="docutils literal notranslate"><span class="pre">SampleReductionProtocol</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.monte_carlo.SampleReducingMCAcquisitionFunction"><code class="docutils literal notranslate"><span class="pre">SampleReducingMCAcquisitionFunction</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.monte_carlo.qExpectedImprovement"><code class="docutils literal notranslate"><span class="pre">qExpectedImprovement</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.monte_carlo.qNoisyExpectedImprovement"><code class="docutils literal notranslate"><span class="pre">qNoisyExpectedImprovement</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.monte_carlo.qProbabilityOfImprovement"><code class="docutils literal notranslate"><span class="pre">qProbabilityOfImprovement</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.monte_carlo.qSimpleRegret"><code class="docutils literal notranslate"><span class="pre">qSimpleRegret</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.monte_carlo.qUpperConfidenceBound"><code class="docutils literal notranslate"><span class="pre">qUpperConfidenceBound</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.monte_carlo.qLowerConfidenceBound"><code class="docutils literal notranslate"><span class="pre">qLowerConfidenceBound</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.monte_carlo.qPosteriorStandardDeviation"><code class="docutils literal notranslate"><span class="pre">qPosteriorStandardDeviation</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.logei.LogImprovementMCAcquisitionFunction"><code class="docutils literal notranslate"><span class="pre">LogImprovementMCAcquisitionFunction</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.logei.qLogExpectedImprovement"><code class="docutils literal notranslate"><span class="pre">qLogExpectedImprovement</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.logei.qLogNoisyExpectedImprovement"><code class="docutils literal notranslate"><span class="pre">qLogNoisyExpectedImprovement</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.logei.check_tau"><code class="docutils literal notranslate"><span class="pre">check_tau()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.acquisition.multi_objective.analytic">Multi-Objective Analytic Acquisition Functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.multi_objective.analytic.ExpectedHypervolumeImprovement"><code class="docutils literal notranslate"><span class="pre">ExpectedHypervolumeImprovement</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.acquisition.multi_objective.hypervolume_knowledge_gradient">Multi-Objective Hypervolume Knowledge Gradient Acquisition Functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.multi_objective.hypervolume_knowledge_gradient.qHypervolumeKnowledgeGradient"><code class="docutils literal notranslate"><span class="pre">qHypervolumeKnowledgeGradient</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.multi_objective.hypervolume_knowledge_gradient.qMultiFidelityHypervolumeKnowledgeGradient"><code class="docutils literal notranslate"><span class="pre">qMultiFidelityHypervolumeKnowledgeGradient</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.acquisition.multi_objective.joint_entropy_search">Multi-Objective Joint Entropy Search Acquisition Functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.multi_objective.joint_entropy_search.LowerBoundMultiObjectiveEntropySearch"><code class="docutils literal notranslate"><span class="pre">LowerBoundMultiObjectiveEntropySearch</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.multi_objective.joint_entropy_search.qLowerBoundMultiObjectiveJointEntropySearch"><code class="docutils literal notranslate"><span class="pre">qLowerBoundMultiObjectiveJointEntropySearch</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.acquisition.multi_objective.max_value_entropy_search">Multi-Objective Max-value Entropy Search Acquisition Functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.multi_objective.max_value_entropy_search.qMultiObjectiveMaxValueEntropy"><code class="docutils literal notranslate"><span class="pre">qMultiObjectiveMaxValueEntropy</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.multi_objective.max_value_entropy_search.qLowerBoundMultiObjectiveMaxValueEntropySearch"><code class="docutils literal notranslate"><span class="pre">qLowerBoundMultiObjectiveMaxValueEntropySearch</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.acquisition.multi_objective.monte_carlo">Multi-Objective Monte-Carlo Acquisition Functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.multi_objective.monte_carlo.qExpectedHypervolumeImprovement"><code class="docutils literal notranslate"><span class="pre">qExpectedHypervolumeImprovement</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.multi_objective.monte_carlo.qNoisyExpectedHypervolumeImprovement"><code class="docutils literal notranslate"><span class="pre">qNoisyExpectedHypervolumeImprovement</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.multi_objective.logei.qLogExpectedHypervolumeImprovement"><code class="docutils literal notranslate"><span class="pre">qLogExpectedHypervolumeImprovement</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.multi_objective.logei.qLogNoisyExpectedHypervolumeImprovement"><code class="docutils literal notranslate"><span class="pre">qLogNoisyExpectedHypervolumeImprovement</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.acquisition.multi_objective.multi_fidelity">Multi-Objective Multi-Fidelity Acquisition Functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.multi_objective.multi_fidelity.MOMF"><code class="docutils literal notranslate"><span class="pre">MOMF</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.acquisition.multi_objective.predictive_entropy_search">Multi-Objective Predictive Entropy Search Acquisition Functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.multi_objective.predictive_entropy_search.qMultiObjectivePredictiveEntropySearch"><code class="docutils literal notranslate"><span class="pre">qMultiObjectivePredictiveEntropySearch</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.multi_objective.predictive_entropy_search.log_cdf_robust"><code class="docutils literal notranslate"><span class="pre">log_cdf_robust()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.acquisition.multi_objective.parego">ParEGO: Multi-Objective Acquisition Function with Chebyshev Scalarization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.multi_objective.parego.qLogNParEGO"><code class="docutils literal notranslate"><span class="pre">qLogNParEGO</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.acquisition.knowledge_gradient">The One-Shot Knowledge Gradient</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.knowledge_gradient.qKnowledgeGradient"><code class="docutils literal notranslate"><span class="pre">qKnowledgeGradient</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.knowledge_gradient.qMultiFidelityKnowledgeGradient"><code class="docutils literal notranslate"><span class="pre">qMultiFidelityKnowledgeGradient</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.knowledge_gradient.ProjectedAcquisitionFunction"><code class="docutils literal notranslate"><span class="pre">ProjectedAcquisitionFunction</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.acquisition.multi_step_lookahead">Multi-Step Lookahead Acquisition Functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.multi_step_lookahead.qMultiStepLookahead"><code class="docutils literal notranslate"><span class="pre">qMultiStepLookahead</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.multi_step_lookahead.warmstart_multistep"><code class="docutils literal notranslate"><span class="pre">warmstart_multistep()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.multi_step_lookahead.make_best_f"><code class="docutils literal notranslate"><span class="pre">make_best_f()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.acquisition.max_value_entropy_search">Max-value Entropy Search Acquisition Functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.max_value_entropy_search.MaxValueBase"><code class="docutils literal notranslate"><span class="pre">MaxValueBase</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.max_value_entropy_search.qMaxValueEntropy"><code class="docutils literal notranslate"><span class="pre">qMaxValueEntropy</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.max_value_entropy_search.qLowerBoundMaxValueEntropy"><code class="docutils literal notranslate"><span class="pre">qLowerBoundMaxValueEntropy</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.max_value_entropy_search.qMultiFidelityMaxValueEntropy"><code class="docutils literal notranslate"><span class="pre">qMultiFidelityMaxValueEntropy</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.max_value_entropy_search.qMultiFidelityLowerBoundMaxValueEntropy"><code class="docutils literal notranslate"><span class="pre">qMultiFidelityLowerBoundMaxValueEntropy</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.acquisition.joint_entropy_search">Joint Entropy Search Acquisition Functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.joint_entropy_search.qJointEntropySearch"><code class="docutils literal notranslate"><span class="pre">qJointEntropySearch</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.acquisition.predictive_entropy_search">Predictive Entropy Search Acquisition Functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.predictive_entropy_search.qPredictiveEntropySearch"><code class="docutils literal notranslate"><span class="pre">qPredictiveEntropySearch</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.acquisition.active_learning">Active Learning Acquisition Functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.active_learning.qNegIntegratedPosteriorVariance"><code class="docutils literal notranslate"><span class="pre">qNegIntegratedPosteriorVariance</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.active_learning.PairwiseMCPosteriorVariance"><code class="docutils literal notranslate"><span class="pre">PairwiseMCPosteriorVariance</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.acquisition.bayesian_active_learning">Bayesian Active Learning Acquisition Functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.bayesian_active_learning.check_negative_info_gain"><code class="docutils literal notranslate"><span class="pre">check_negative_info_gain()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.bayesian_active_learning.FullyBayesianAcquisitionFunction"><code class="docutils literal notranslate"><span class="pre">FullyBayesianAcquisitionFunction</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.bayesian_active_learning.qBayesianActiveLearningByDisagreement"><code class="docutils literal notranslate"><span class="pre">qBayesianActiveLearningByDisagreement</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.acquisition.preference">Preference Acquisition Functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.preference.AnalyticExpectedUtilityOfBestOption"><code class="docutils literal notranslate"><span class="pre">AnalyticExpectedUtilityOfBestOption</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.preference.qExpectedUtilityOfBestOption"><code class="docutils literal notranslate"><span class="pre">qExpectedUtilityOfBestOption</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.preference.PairwiseBayesianActiveLearningByDisagreement"><code class="docutils literal notranslate"><span class="pre">PairwiseBayesianActiveLearningByDisagreement</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#objectives-and-cost-aware-utilities">Objectives and Cost-Aware Utilities</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.acquisition.objective">Objectives</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform"><code class="docutils literal notranslate"><span class="pre">PosteriorTransform</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.objective.ScalarizedPosteriorTransform"><code class="docutils literal notranslate"><span class="pre">ScalarizedPosteriorTransform</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.objective.ExpectationPosteriorTransform"><code class="docutils literal notranslate"><span class="pre">ExpectationPosteriorTransform</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective"><code class="docutils literal notranslate"><span class="pre">MCAcquisitionObjective</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.objective.IdentityMCObjective"><code class="docutils literal notranslate"><span class="pre">IdentityMCObjective</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.objective.LinearMCObjective"><code class="docutils literal notranslate"><span class="pre">LinearMCObjective</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.objective.GenericMCObjective"><code class="docutils literal notranslate"><span class="pre">GenericMCObjective</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.objective.ConstrainedMCObjective"><code class="docutils literal notranslate"><span class="pre">ConstrainedMCObjective</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.objective.LearnedObjective"><code class="docutils literal notranslate"><span class="pre">LearnedObjective</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.acquisition.multi_objective.objective">Multi-Objective Objectives</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.multi_objective.objective.MCMultiOutputObjective"><code class="docutils literal notranslate"><span class="pre">MCMultiOutputObjective</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.multi_objective.objective.GenericMCMultiOutputObjective"><code class="docutils literal notranslate"><span class="pre">GenericMCMultiOutputObjective</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.multi_objective.objective.IdentityMCMultiOutputObjective"><code class="docutils literal notranslate"><span class="pre">IdentityMCMultiOutputObjective</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.multi_objective.objective.WeightedMCMultiOutputObjective"><code class="docutils literal notranslate"><span class="pre">WeightedMCMultiOutputObjective</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.multi_objective.objective.FeasibilityWeightedMCMultiOutputObjective"><code class="docutils literal notranslate"><span class="pre">FeasibilityWeightedMCMultiOutputObjective</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.acquisition.cost_aware">Cost-Aware Utility</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.cost_aware.CostAwareUtility"><code class="docutils literal notranslate"><span class="pre">CostAwareUtility</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.cost_aware.GenericCostAwareUtility"><code class="docutils literal notranslate"><span class="pre">GenericCostAwareUtility</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.cost_aware.InverseCostWeightedUtility"><code class="docutils literal notranslate"><span class="pre">InverseCostWeightedUtility</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.acquisition.risk_measures">Risk Measures</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.risk_measures.RiskMeasureMCObjective"><code class="docutils literal notranslate"><span class="pre">RiskMeasureMCObjective</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.risk_measures.CVaR"><code class="docutils literal notranslate"><span class="pre">CVaR</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.risk_measures.VaR"><code class="docutils literal notranslate"><span class="pre">VaR</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.risk_measures.WorstCase"><code class="docutils literal notranslate"><span class="pre">WorstCase</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.risk_measures.Expectation"><code class="docutils literal notranslate"><span class="pre">Expectation</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.acquisition.thompson_sampling">Thompson Sampling</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.thompson_sampling.PathwiseThompsonSampling"><code class="docutils literal notranslate"><span class="pre">PathwiseThompsonSampling</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.acquisition.multi_objective.multi_output_risk_measures">Multi-Output Risk Measures</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.multi_objective.multi_output_risk_measures.MultiOutputRiskMeasureMCObjective"><code class="docutils literal notranslate"><span class="pre">MultiOutputRiskMeasureMCObjective</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.multi_objective.multi_output_risk_measures.MultiOutputExpectation"><code class="docutils literal notranslate"><span class="pre">MultiOutputExpectation</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.multi_objective.multi_output_risk_measures.IndependentCVaR"><code class="docutils literal notranslate"><span class="pre">IndependentCVaR</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.multi_objective.multi_output_risk_measures.IndependentVaR"><code class="docutils literal notranslate"><span class="pre">IndependentVaR</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.multi_objective.multi_output_risk_measures.MultiOutputWorstCase"><code class="docutils literal notranslate"><span class="pre">MultiOutputWorstCase</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.multi_objective.multi_output_risk_measures.MVaR"><code class="docutils literal notranslate"><span class="pre">MVaR</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.multi_objective.multi_output_risk_measures.MARS"><code class="docutils literal notranslate"><span class="pre">MARS</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#utilities">Utilities</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.acquisition.fixed_feature">Fixed Feature Acquisition Function</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.fixed_feature.get_dtype_of_sequence"><code class="docutils literal notranslate"><span class="pre">get_dtype_of_sequence()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.fixed_feature.get_device_of_sequence"><code class="docutils literal notranslate"><span class="pre">get_device_of_sequence()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.fixed_feature.FixedFeatureAcquisitionFunction"><code class="docutils literal notranslate"><span class="pre">FixedFeatureAcquisitionFunction</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.acquisition.input_constructors">Constructors for Acquisition Function Input Arguments</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.input_constructors.get_acqf_input_constructor"><code class="docutils literal notranslate"><span class="pre">get_acqf_input_constructor()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.input_constructors.allow_only_specific_variable_kwargs"><code class="docutils literal notranslate"><span class="pre">allow_only_specific_variable_kwargs()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.input_constructors.acqf_input_constructor"><code class="docutils literal notranslate"><span class="pre">acqf_input_constructor()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.input_constructors.construct_inputs_posterior_mean"><code class="docutils literal notranslate"><span class="pre">construct_inputs_posterior_mean()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.input_constructors.construct_inputs_best_f"><code class="docutils literal notranslate"><span class="pre">construct_inputs_best_f()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.input_constructors.construct_inputs_ucb"><code class="docutils literal notranslate"><span class="pre">construct_inputs_ucb()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.input_constructors.construct_inputs_noisy_ei"><code class="docutils literal notranslate"><span class="pre">construct_inputs_noisy_ei()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.input_constructors.construct_inputs_qSimpleRegret"><code class="docutils literal notranslate"><span class="pre">construct_inputs_qSimpleRegret()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.input_constructors.construct_inputs_qEI"><code class="docutils literal notranslate"><span class="pre">construct_inputs_qEI()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.input_constructors.construct_inputs_qLogEI"><code class="docutils literal notranslate"><span class="pre">construct_inputs_qLogEI()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.input_constructors.construct_inputs_qNEI"><code class="docutils literal notranslate"><span class="pre">construct_inputs_qNEI()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.input_constructors.construct_inputs_qLogNEI"><code class="docutils literal notranslate"><span class="pre">construct_inputs_qLogNEI()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.input_constructors.construct_inputs_qPI"><code class="docutils literal notranslate"><span class="pre">construct_inputs_qPI()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.input_constructors.construct_inputs_qUCB"><code class="docutils literal notranslate"><span class="pre">construct_inputs_qUCB()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.input_constructors.construct_inputs_EHVI"><code class="docutils literal notranslate"><span class="pre">construct_inputs_EHVI()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.input_constructors.construct_inputs_qEHVI"><code class="docutils literal notranslate"><span class="pre">construct_inputs_qEHVI()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.input_constructors.construct_inputs_qNEHVI"><code class="docutils literal notranslate"><span class="pre">construct_inputs_qNEHVI()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.input_constructors.construct_inputs_qLogNEHVI"><code class="docutils literal notranslate"><span class="pre">construct_inputs_qLogNEHVI()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.input_constructors.construct_inputs_qLogNParEGO"><code class="docutils literal notranslate"><span class="pre">construct_inputs_qLogNParEGO()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.input_constructors.construct_inputs_qMES"><code class="docutils literal notranslate"><span class="pre">construct_inputs_qMES()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.input_constructors.construct_inputs_mf_base"><code class="docutils literal notranslate"><span class="pre">construct_inputs_mf_base()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.input_constructors.construct_inputs_qKG"><code class="docutils literal notranslate"><span class="pre">construct_inputs_qKG()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.input_constructors.construct_inputs_qHVKG"><code class="docutils literal notranslate"><span class="pre">construct_inputs_qHVKG()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.input_constructors.construct_inputs_qMFKG"><code class="docutils literal notranslate"><span class="pre">construct_inputs_qMFKG()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.input_constructors.construct_inputs_qMFHVKG"><code class="docutils literal notranslate"><span class="pre">construct_inputs_qMFHVKG()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.input_constructors.construct_inputs_qMFMES"><code class="docutils literal notranslate"><span class="pre">construct_inputs_qMFMES()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.input_constructors.construct_inputs_analytic_eubo"><code class="docutils literal notranslate"><span class="pre">construct_inputs_analytic_eubo()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.input_constructors.construct_inputs_qeubo"><code class="docutils literal notranslate"><span class="pre">construct_inputs_qeubo()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.input_constructors.get_best_f_analytic"><code class="docutils literal notranslate"><span class="pre">get_best_f_analytic()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.input_constructors.get_best_f_mc"><code class="docutils literal notranslate"><span class="pre">get_best_f_mc()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.input_constructors.optimize_objective"><code class="docutils literal notranslate"><span class="pre">optimize_objective()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.input_constructors.construct_inputs_qJES"><code class="docutils literal notranslate"><span class="pre">construct_inputs_qJES()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.input_constructors.construct_inputs_BALD"><code class="docutils literal notranslate"><span class="pre">construct_inputs_BALD()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.input_constructors.construct_inputs_NIPV"><code class="docutils literal notranslate"><span class="pre">construct_inputs_NIPV()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.acquisition.penalized">Penalized Acquisition Function Wrapper</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.penalized.L2Penalty"><code class="docutils literal notranslate"><span class="pre">L2Penalty</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.penalized.L1Penalty"><code class="docutils literal notranslate"><span class="pre">L1Penalty</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.penalized.GaussianPenalty"><code class="docutils literal notranslate"><span class="pre">GaussianPenalty</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.penalized.GroupLassoPenalty"><code class="docutils literal notranslate"><span class="pre">GroupLassoPenalty</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.penalized.narrow_gaussian"><code class="docutils literal notranslate"><span class="pre">narrow_gaussian()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.penalized.nnz_approx"><code class="docutils literal notranslate"><span class="pre">nnz_approx()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.penalized.L0Approximation"><code class="docutils literal notranslate"><span class="pre">L0Approximation</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.penalized.L0PenaltyApprox"><code class="docutils literal notranslate"><span class="pre">L0PenaltyApprox</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.penalized.PenalizedAcquisitionFunction"><code class="docutils literal notranslate"><span class="pre">PenalizedAcquisitionFunction</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.penalized.group_lasso_regularizer"><code class="docutils literal notranslate"><span class="pre">group_lasso_regularizer()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.penalized.L1PenaltyObjective"><code class="docutils literal notranslate"><span class="pre">L1PenaltyObjective</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.penalized.PenalizedMCObjective"><code class="docutils literal notranslate"><span class="pre">PenalizedMCObjective</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.penalized.L0PenaltyApproxObjective"><code class="docutils literal notranslate"><span class="pre">L0PenaltyApproxObjective</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.acquisition.prior_guided">Prior-Guided Acquisition Function Wrapper</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.prior_guided.PriorGuidedAcquisitionFunction"><code class="docutils literal notranslate"><span class="pre">PriorGuidedAcquisitionFunction</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.acquisition.proximal">Proximal Acquisition Function Wrapper</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.proximal.ProximalAcquisitionFunction"><code class="docutils literal notranslate"><span class="pre">ProximalAcquisitionFunction</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.acquisition.factory">Factory Functions for Acquisition Functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.factory.get_acquisition_function"><code class="docutils literal notranslate"><span class="pre">get_acquisition_function()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.acquisition.utils">General Utilities for Acquisition Functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.utils.get_acquisition_function"><code class="docutils literal notranslate"><span class="pre">get_acquisition_function()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.utils.repeat_to_match_aug_dim"><code class="docutils literal notranslate"><span class="pre">repeat_to_match_aug_dim()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.utils.compute_best_feasible_objective"><code class="docutils literal notranslate"><span class="pre">compute_best_feasible_objective()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.utils.get_infeasible_cost"><code class="docutils literal notranslate"><span class="pre">get_infeasible_cost()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.utils.prune_inferior_points"><code class="docutils literal notranslate"><span class="pre">prune_inferior_points()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.utils.project_to_target_fidelity"><code class="docutils literal notranslate"><span class="pre">project_to_target_fidelity()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.utils.expand_trace_observations"><code class="docutils literal notranslate"><span class="pre">expand_trace_observations()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.utils.project_to_sample_points"><code class="docutils literal notranslate"><span class="pre">project_to_sample_points()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.utils.get_optimal_samples"><code class="docutils literal notranslate"><span class="pre">get_optimal_samples()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-botorch.acquisition.multi_objective.utils">Multi-Objective Utilities for Acquisition Functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.multi_objective.utils.get_default_partitioning_alpha"><code class="docutils literal notranslate"><span class="pre">get_default_partitioning_alpha()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.multi_objective.utils.prune_inferior_points_multi_objective"><code class="docutils literal notranslate"><span class="pre">prune_inferior_points_multi_objective()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.multi_objective.utils.compute_sample_box_decomposition"><code class="docutils literal notranslate"><span class="pre">compute_sample_box_decomposition()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.multi_objective.utils.random_search_optimizer"><code class="docutils literal notranslate"><span class="pre">random_search_optimizer()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#botorch.acquisition.multi_objective.utils.sample_optimal_points"><code class="docutils literal notranslate"><span class="pre">sample_optimal_points()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="models.html">botorch.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="generation.html">botorch.generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="posteriors.html">botorch.posteriors</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim.html">botorch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="fit.html">botorch.fit</a></li>
<li class="toctree-l1"><a class="reference internal" href="sampling.html">botorch.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="cross_validation.html">botorch.cross_validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="settings.html">botorch.settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="logging.html">botorch.logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_functions.html">botorch.test_functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_utils.html">botorch.test_utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="exceptions.html">botorch.exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">botorch.utils</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">BoTorch</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">botorch.acquisition</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/acquisition.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-botorch.acquisition">
<span id="botorch-acquisition"></span><h1>botorch.acquisition<a class="headerlink" href="#module-botorch.acquisition" title="Link to this heading"></a></h1>
<section id="acquisition-function-apis">
<h2>Acquisition Function APIs<a class="headerlink" href="#acquisition-function-apis" title="Link to this heading"></a></h2>
<section id="module-botorch.acquisition.acquisition">
<span id="abstract-acquisition-function-apis"></span><h3>Abstract Acquisition Function APIs<a class="headerlink" href="#module-botorch.acquisition.acquisition" title="Link to this heading"></a></h3>
<p>Abstract base module for all botorch acquisition functions.</p>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.acquisition.AcquisitionFunction">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.acquisition.</span></span><span class="sig-name descname"><span class="pre">AcquisitionFunction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/acquisition.html#AcquisitionFunction"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.acquisition.AcquisitionFunction" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>Abstract base class for acquisition functions.</p>
<p>Please note that if your acquisition requires a backwards call,
you will need to wrap the backwards call inside of an enable_grad
context to be able to optimize the acquisition. See #1164.</p>
<p>Constructor for the AcquisitionFunction base class.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted model.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.acquisition.AcquisitionFunction.set_X_pending">
<span class="sig-name descname"><span class="pre">set_X_pending</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/acquisition.html#AcquisitionFunction.set_X_pending"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.acquisition.AcquisitionFunction.set_X_pending" title="Link to this definition"></a></dt>
<dd><p>Informs the acquisition function about pending design points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – <cite>n x d</cite> Tensor with <cite>n</cite> <cite>d</cite>-dim design points that have
been submitted for evaluation but have not yet been evaluated.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.acquisition.AcquisitionFunction.forward">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/acquisition.html#AcquisitionFunction.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.acquisition.AcquisitionFunction.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate the acquisition function on the candidate set X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>(b) x q x d</cite>-dim Tensor of <cite>(b)</cite> t-batches with <cite>q</cite> <cite>d</cite>-dim
design points each.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>(b)</cite>-dim Tensor of acquisition function values at the given
design points <cite>X</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.acquisition.OneShotAcquisitionFunction">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.acquisition.</span></span><span class="sig-name descname"><span class="pre">OneShotAcquisitionFunction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/acquisition.html#OneShotAcquisitionFunction"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.acquisition.OneShotAcquisitionFunction" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">AcquisitionFunction</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>Abstract base class for acquisition functions using one-shot optimization</p>
<p>Constructor for the AcquisitionFunction base class.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted model.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.acquisition.OneShotAcquisitionFunction.get_augmented_q_batch_size">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_augmented_q_batch_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">q</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/acquisition.html#OneShotAcquisitionFunction.get_augmented_q_batch_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.acquisition.OneShotAcquisitionFunction.get_augmented_q_batch_size" title="Link to this definition"></a></dt>
<dd><p>Get augmented q batch size for one-shot optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>q</strong> (<em>int</em>) – The number of candidates to consider jointly.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The augmented size for one-shot optimization (including variables
parameterizing the fantasy solutions).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.acquisition.OneShotAcquisitionFunction.extract_candidates">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">extract_candidates</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X_full</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/acquisition.html#OneShotAcquisitionFunction.extract_candidates"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.acquisition.OneShotAcquisitionFunction.extract_candidates" title="Link to this definition"></a></dt>
<dd><p>Extract the candidates from a full “one-shot” parameterization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X_full</strong> (<em>Tensor</em>) – A <cite>b x q_aug x d</cite>-dim Tensor with <cite>b</cite> t-batches of <cite>q_aug</cite>
design points each.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>b x q x d</cite>-dim Tensor with <cite>b</cite> t-batches of <cite>q</cite> design points each.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.acquisition.MCSamplerMixin">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.acquisition.</span></span><span class="sig-name descname"><span class="pre">MCSamplerMixin</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/acquisition.html#MCSamplerMixin"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.acquisition.MCSamplerMixin" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>A mix-in for adding sampler functionality into an acquisition function class.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.acquisition.acquisition.MCSamplerMixin._default_sample_shape">
<span class="sig-name descname"><span class="pre">_default_sample_shape</span></span><a class="headerlink" href="#botorch.acquisition.acquisition.MCSamplerMixin._default_sample_shape" title="Link to this definition"></a></dt>
<dd><p>The <cite>sample_shape</cite> for the default sampler.</p>
</dd></dl>

<p>Register the sampler on the acquisition function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – The sampler used to draw base samples for MC-based acquisition
functions. If <cite>None</cite>, a sampler is generated on the fly within
the <cite>get_posterior_samples</cite> method using <cite>get_sampler</cite>.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.acquisition.MCSamplerMixin.get_posterior_samples">
<span class="sig-name descname"><span class="pre">get_posterior_samples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">posterior</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/acquisition.html#MCSamplerMixin.get_posterior_samples"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.acquisition.MCSamplerMixin.get_posterior_samples" title="Link to this definition"></a></dt>
<dd><p>Sample from the posterior using the sampler.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>posterior</strong> (<a class="reference internal" href="posteriors.html#botorch.posteriors.posterior.Posterior" title="botorch.posteriors.posterior.Posterior"><em>Posterior</em></a>) – The posterior to sample from.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.acquisition.acquisition.MCSamplerMixin.sample_shape">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">sample_shape</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Size</span></em><a class="headerlink" href="#botorch.acquisition.acquisition.MCSamplerMixin.sample_shape" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.acquisition.MultiModelAcquisitionFunction">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.acquisition.</span></span><span class="sig-name descname"><span class="pre">MultiModelAcquisitionFunction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_dict</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/acquisition.html#MultiModelAcquisitionFunction"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.acquisition.MultiModelAcquisitionFunction" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">AcquisitionFunction</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>Abstract base class for acquisition functions that require
multiple types of models.</p>
<p>The intended use case for these acquisition functions are those
where we have multiple models, each serving a distinct purpose.
As an example, we can have a “regression” model that predicts
one or more outcomes, and a “classification” model that predicts
the probabilty that a given parameterization is feasible. The
multi-model acquisition function can then weight the acquisition
value computed with the “regression” model with the feasibility
value predicted by the “classification” model to produce the
composite acquisition value.</p>
<p>This is currently only a placeholder to help with some development
in Ax. We plan to add some acquisition functions utilizing multiple
models in the future.</p>
<p>Constructor for the MultiModelAcquisitionFunction base class.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model_dict</strong> (<a class="reference internal" href="models.html#botorch.models.model.ModelDict" title="botorch.models.model.ModelDict"><em>ModelDict</em></a>) – A ModelDict mapping labels to models.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="analytic-acquisition-function-api">
<h3>Analytic Acquisition Function API<a class="headerlink" href="#analytic-acquisition-function-api" title="Link to this heading"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.analytic.AnalyticAcquisitionFunction">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.analytic.</span></span><span class="sig-name descname"><span class="pre">AnalyticAcquisitionFunction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/analytic.html#AnalyticAcquisitionFunction"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.analytic.AnalyticAcquisitionFunction" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">AcquisitionFunction</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>Base class for analytic acquisition functions.</p>
<p>Base constructor for analytic acquisition functions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted single-outcome model.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – A PosteriorTransform. If using a multi-output model,
a PosteriorTransform that transforms the multi-output posterior into a
single-output posterior is required.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.analytic.AnalyticAcquisitionFunction.set_X_pending">
<span class="sig-name descname"><span class="pre">set_X_pending</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/analytic.html#AnalyticAcquisitionFunction.set_X_pending"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.analytic.AnalyticAcquisitionFunction.set_X_pending" title="Link to this definition"></a></dt>
<dd><p>Informs the acquisition function about pending design points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – <cite>n x d</cite> Tensor with <cite>n</cite> <cite>d</cite>-dim design points that have
been submitted for evaluation but have not yet been evaluated.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-botorch.acquisition.cached_cholesky">
<span id="cached-cholesky-acquisition-function-api"></span><h3>Cached Cholesky Acquisition Function API<a class="headerlink" href="#module-botorch.acquisition.cached_cholesky" title="Link to this heading"></a></h3>
<p>Abstract class for acquisition functions leveraging a cached Cholesky
decomposition of the posterior covariance over f(X_baseline).</p>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.cached_cholesky.supports_cache_root">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.cached_cholesky.</span></span><span class="sig-name descname"><span class="pre">supports_cache_root</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/cached_cholesky.html#supports_cache_root"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.cached_cholesky.supports_cache_root" title="Link to this definition"></a></dt>
<dd><p>Checks if a model supports the cache_root functionality.
The two criteria are that the model is not multi-task and the model
produces a GPyTorchPosterior.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.cached_cholesky.CachedCholeskyMCSamplerMixin">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.cached_cholesky.</span></span><span class="sig-name descname"><span class="pre">CachedCholeskyMCSamplerMixin</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_root</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/cached_cholesky.html#CachedCholeskyMCSamplerMixin"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.cached_cholesky.CachedCholeskyMCSamplerMixin" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.acquisition.MCSamplerMixin" title="botorch.acquisition.acquisition.MCSamplerMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">MCSamplerMixin</span></code></a></p>
<p>Abstract Mixin class for acquisition functions using a cached Cholesky.</p>
<p>Specifically, this is for acquisition functions that require sampling from
the posterior P(f(X_baseline, X) | D). The Cholesky of the posterior
covariance over f(X_baseline) is cached.</p>
<p>Set class attributes and perform compatibility checks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A model.</p></li>
<li><p><strong>cache_root</strong> (<em>bool</em>) – A boolean indicating whether to cache the Cholesky.
This might be overridden in the model is not compatible.</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – An optional MCSampler object.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-botorch.acquisition.decoupled">
<span id="decoupled-acquisition-function-api"></span><h3>Decoupled Acquisition Function API<a class="headerlink" href="#module-botorch.acquisition.decoupled" title="Link to this heading"></a></h3>
<p>Abstract base module for decoupled acquisition functions.</p>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.decoupled.DecoupledAcquisitionFunction">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.decoupled.</span></span><span class="sig-name descname"><span class="pre">DecoupledAcquisitionFunction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_evaluation_mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/decoupled.html#DecoupledAcquisitionFunction"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.decoupled.DecoupledAcquisitionFunction" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">AcquisitionFunction</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>Abstract base class for decoupled acquisition functions.
A decoupled acquisition function where one may intend to
evaluate a design on only a subset of the outcomes.
Typically this would be handled by fantasizing, where one
would fantasize as to what the partial observation would
be if one were to evaluate a design on the subset of
outcomes (e.g. you only fantasize at those outcomes). The
<cite>X_evaluation_mask</cite> specifies which outcomes should be
evaluated for each design.  <cite>X_evaluation_mask</cite> is <cite>q x m</cite>,
where there are q design points in the batch and m outcomes.
In the asynchronous case, where there are n’ pending points,
we need to track which outcomes each pending point should be
evaluated on. In this case, we concatenate
<cite>X_pending_evaluation_mask</cite> with <cite>X_evaluation_mask</cite> to obtain
the full evaluation_mask.</p>
<p>This abstract class handles generating and updating an evaluation mask,
which is a boolean tensor indicating which outcomes a given design is
being evaluated on. The evaluation mask has shape <cite>(n’ + q) x m</cite>, where
n’ is the number of pending points and the q represents the new
candidates to be generated.</p>
<p>If <cite>X(_pending)_evaluation_mas`k is None, it is assumed that `X(_pending)</cite>
will be evaluated on all outcomes.</p>
<p>Initialize.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.ModelList" title="botorch.models.model.ModelList"><em>ModelList</em></a>) – A model</p></li>
<li><p><strong>X_evaluation_mask</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>q x m</cite>-dim boolean tensor
indicating which outcomes the decoupled acquisition
function should generate new candidates for.</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="botorch.acquisition.decoupled.DecoupledAcquisitionFunction.X_evaluation_mask">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">X_evaluation_mask</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#botorch.acquisition.decoupled.DecoupledAcquisitionFunction.X_evaluation_mask" title="Link to this definition"></a></dt>
<dd><p>Get the evaluation indices for the new candidate.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.decoupled.DecoupledAcquisitionFunction.set_X_pending">
<span class="sig-name descname"><span class="pre">set_X_pending</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending_evaluation_mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/decoupled.html#DecoupledAcquisitionFunction.set_X_pending"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.decoupled.DecoupledAcquisitionFunction.set_X_pending" title="Link to this definition"></a></dt>
<dd><p>Informs the AF about pending design points for different outcomes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>n’ x d</cite> Tensor with <cite>n’</cite> <cite>d</cite>-dim design points that have
been submitted for evaluation but have not yet been evaluated.</p></li>
<li><p><strong>X_pending_evaluation_mask</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>n’ x m</cite>-dim tensor of booleans indicating
for which outputs the pending point is being evaluated on. If
<cite>X_pending_evaluation_mask</cite> is <cite>None</cite>, it is assumed that
<cite>X_pending</cite> will be evaluated on all outcomes.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.decoupled.DecoupledAcquisitionFunction.construct_evaluation_mask">
<span class="sig-name descname"><span class="pre">construct_evaluation_mask</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/decoupled.html#DecoupledAcquisitionFunction.construct_evaluation_mask"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.decoupled.DecoupledAcquisitionFunction.construct_evaluation_mask" title="Link to this definition"></a></dt>
<dd><p>Construct the boolean evaluation mask for X and X_pending</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of designs.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>n + n’ x m</cite>-dim tensor of booleans indicating
which outputs should be evaluated.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em> | None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="monte-carlo-acquisition-function-api">
<h3>Monte-Carlo Acquisition Function API<a class="headerlink" href="#monte-carlo-acquisition-function-api" title="Link to this heading"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.monte_carlo.MCAcquisitionFunction">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.monte_carlo.</span></span><span class="sig-name descname"><span class="pre">MCAcquisitionFunction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/monte_carlo.html#MCAcquisitionFunction"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.monte_carlo.MCAcquisitionFunction" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">AcquisitionFunction</span></code></a>, <a class="reference internal" href="#botorch.acquisition.acquisition.MCSamplerMixin" title="botorch.acquisition.acquisition.MCSamplerMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">MCSamplerMixin</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>Abstract base class for Monte-Carlo based batch acquisition functions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted model.</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – The sampler used to draw base samples. If not given,
a sampler is generated on the fly within the
<cite>get_posterior_samples</cite> method using
<cite>botorch.sampling.get_sampler</cite>.
NOTE: For posteriors that do not support base samples,
a sampler compatible with intended use case must be provided.
See <cite>ForkedRNGSampler</cite> and <cite>StochasticSampler</cite> as examples.</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><em>MCAcquisitionObjective</em></a><em> | </em><em>None</em>) – The MCAcquisitionObjective under which the samples are
evaluated. Defaults to <cite>IdentityMCObjective()</cite>.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – A PosteriorTransform (optional).</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape, m x d</cite>-dim Tensor of <cite>m</cite> design points
that have points that have been submitted for function evaluation
but have not yet been evaluated.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.monte_carlo.MCAcquisitionFunction.forward">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/monte_carlo.html#MCAcquisitionFunction.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.monte_carlo.MCAcquisitionFunction.forward" title="Link to this definition"></a></dt>
<dd><p>Takes in a <cite>batch_shape x q x d</cite> X Tensor of t-batches with <cite>q</cite> <cite>d</cite>-dim
design points each, and returns a Tensor with shape <cite>batch_shape’</cite>, where
<cite>batch_shape’</cite> is the broadcasted batch shape of model and input <cite>X</cite>. Should
utilize the result of <cite>set_X_pending</cite> as needed to account for pending function
evaluations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-botorch.acquisition.multi_objective.base">
<span id="base-classes-for-multi-objective-acquisition-function-api"></span><h3>Base Classes for Multi-Objective Acquisition Function API<a class="headerlink" href="#module-botorch.acquisition.multi_objective.base" title="Link to this heading"></a></h3>
<p>Base classes for multi-objective acquisition functions.</p>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.base.MultiObjectiveAnalyticAcquisitionFunction">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.multi_objective.base.</span></span><span class="sig-name descname"><span class="pre">MultiObjectiveAnalyticAcquisitionFunction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/base.html#MultiObjectiveAnalyticAcquisitionFunction"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.base.MultiObjectiveAnalyticAcquisitionFunction" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">AcquisitionFunction</span></code></a></p>
<p>Abstract base class for Multi-Objective batch acquisition functions.</p>
<p>Constructor for the MultiObjectiveAnalyticAcquisitionFunction base class.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted model.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – A PosteriorTransform (optional).</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.base.MultiObjectiveAnalyticAcquisitionFunction.forward">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/base.html#MultiObjectiveAnalyticAcquisitionFunction.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.base.MultiObjectiveAnalyticAcquisitionFunction.forward" title="Link to this definition"></a></dt>
<dd><p>Takes in a <cite>batch_shape x 1 x d</cite> X Tensor of t-batches with <cite>1</cite> <cite>d</cite>-dim
design point each, and returns a Tensor with shape <cite>batch_shape’</cite>, where
<cite>batch_shape’</cite> is the broadcasted batch shape of model and input <cite>X</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.base.MultiObjectiveAnalyticAcquisitionFunction.set_X_pending">
<span class="sig-name descname"><span class="pre">set_X_pending</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/base.html#MultiObjectiveAnalyticAcquisitionFunction.set_X_pending"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.base.MultiObjectiveAnalyticAcquisitionFunction.set_X_pending" title="Link to this definition"></a></dt>
<dd><p>Informs the acquisition function about pending design points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – <cite>n x d</cite> Tensor with <cite>n</cite> <cite>d</cite>-dim design points that have
been submitted for evaluation but have not yet been evaluated.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.base.MultiObjectiveMCAcquisitionFunction">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.multi_objective.base.</span></span><span class="sig-name descname"><span class="pre">MultiObjectiveMCAcquisitionFunction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/base.html#MultiObjectiveMCAcquisitionFunction"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.base.MultiObjectiveMCAcquisitionFunction" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">AcquisitionFunction</span></code></a>, <a class="reference internal" href="#botorch.acquisition.acquisition.MCSamplerMixin" title="botorch.acquisition.acquisition.MCSamplerMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">MCSamplerMixin</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>Abstract base class for Multi-Objective batch acquisition functions.</p>
<p>NOTE: This does not inherit from <cite>MCAcquisitionFunction</cite> to avoid circular imports.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_default_sample_shape</strong> – The <cite>sample_shape</cite> for the default sampler.</p></li>
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>)</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>)</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.multi_objective.objective.MCMultiOutputObjective" title="botorch.acquisition.multi_objective.objective.MCMultiOutputObjective"><em>MCMultiOutputObjective</em></a><em> | </em><em>None</em>)</p></li>
<li><p><strong>constraints</strong> (<em>list</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>eta</strong> (<em>Tensor</em><em> | </em><em>float</em>)</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>)</p></li>
</ul>
</dd>
</dl>
<p>Constructor for the <cite>MultiObjectiveMCAcquisitionFunction</cite> base class.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted model.</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – The sampler used to draw base samples. If not given,
a sampler is generated using <cite>get_sampler</cite>.
NOTE: For posteriors that do not support base samples,
a sampler compatible with intended use case must be provided.
See <cite>ForkedRNGSampler</cite> and <cite>StochasticSampler</cite> as examples.</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.multi_objective.objective.MCMultiOutputObjective" title="botorch.acquisition.multi_objective.objective.MCMultiOutputObjective"><em>MCMultiOutputObjective</em></a><em> | </em><em>None</em>) – The MCMultiOutputObjective under which the samples are
evaluated. Defaults to <cite>IdentityMCMultiOutputObjective()</cite>.</p></li>
<li><p><strong>constraints</strong> (<em>list</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of callables, each mapping a Tensor of dimension
<cite>sample_shape x batch-shape x q x m</cite> to a Tensor of dimension
<cite>sample_shape x batch-shape x q</cite>, where negative values imply
feasibility.</p></li>
<li><p><strong>eta</strong> (<em>Tensor</em><em> | </em><em>float</em>) – The temperature parameter for the sigmoid function used for the
differentiable approximation of the constraints. In case of a float the
same eta is used for every constraint in constraints. In case of a
tensor the length of the tensor must match the number of provided
constraints. The i-th constraint is then estimated with the i-th
eta value.</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>m x d</cite>-dim Tensor of <cite>m</cite> design points that have
points that have been submitted for function evaluation
but have not yet been evaluated.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.base.MultiObjectiveMCAcquisitionFunction.forward">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/base.html#MultiObjectiveMCAcquisitionFunction.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.base.MultiObjectiveMCAcquisitionFunction.forward" title="Link to this definition"></a></dt>
<dd><p>Takes in a <cite>batch_shape x q x d</cite> X Tensor of t-batches with <cite>q</cite> <cite>d</cite>-dim
design points each, and returns a Tensor with shape <cite>batch_shape’</cite>, where
<cite>batch_shape’</cite> is the broadcasted batch shape of model and input <cite>X</cite>. Should
utilize the result of <cite>set_X_pending</cite> as needed to account for pending function
evaluations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="acquisition-functions">
<h2>Acquisition Functions<a class="headerlink" href="#acquisition-functions" title="Link to this heading"></a></h2>
<section id="module-botorch.acquisition.analytic">
<span id="analytic-acquisition-functions"></span><h3>Analytic Acquisition Functions<a class="headerlink" href="#module-botorch.acquisition.analytic" title="Link to this heading"></a></h3>
<p>Analytic Acquisition Functions that evaluate the posterior without performing
Monte-Carlo sampling.</p>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.analytic.LogProbabilityOfImprovement">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.analytic.</span></span><span class="sig-name descname"><span class="pre">LogProbabilityOfImprovement</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">best_f</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/analytic.html#LogProbabilityOfImprovement"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.analytic.LogProbabilityOfImprovement" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.analytic.AnalyticAcquisitionFunction" title="botorch.acquisition.analytic.AnalyticAcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">AnalyticAcquisitionFunction</span></code></a></p>
<p>Single-outcome Log Probability of Improvement.</p>
<p>Logarithm of the probability of improvement over the current best observed value,
computed using the analytic formula under a Normal posterior distribution. Only
supports the case of q=1. Requires the posterior to be Gaussian. The model must be
single-outcome.</p>
<p>The logarithm of the probability of improvement is numerically better behaved
than the original function, which can lead to significantly improved optimization
of the acquisition function. This is analogous to the common practice of optimizing
the <em>log</em> likelihood of a probabilistic model - rather the likelihood - for the
sake of maximium likelihood estimation.</p>
<p><cite>logPI(x) = log(P(y &gt;= best_f)), y ~ f(x)</cite></p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">LogPI</span> <span class="o">=</span> <span class="n">LogProbabilityOfImprovement</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">best_f</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">log_pi</span> <span class="o">=</span> <span class="n">LogPI</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
</pre></div>
</div>
<p>Single-outcome Probability of Improvement.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted single-outcome model.</p></li>
<li><p><strong>best_f</strong> (<em>float</em><em> | </em><em>Tensor</em>) – Either a scalar or a <cite>b</cite>-dim Tensor (batch mode) representing
the best function value observed so far (assumed noiseless).</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – A PosteriorTransform. If using a multi-output model,
a PosteriorTransform that transforms the multi-output posterior into a
single-output posterior is required.</p></li>
<li><p><strong>maximize</strong> (<em>bool</em>) – If True, consider the problem a maximization problem.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.analytic.LogProbabilityOfImprovement.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/analytic.html#LogProbabilityOfImprovement.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.analytic.LogProbabilityOfImprovement.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate the Log Probability of Improvement on the candidate set X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>(b1 x … bk) x 1 x d</cite>-dim batched tensor of <cite>d</cite>-dim design points.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>(b1 x … bk)</cite>-dim tensor of Log Probability of Improvement values at
the given design points <cite>X</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.analytic.ProbabilityOfImprovement">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.analytic.</span></span><span class="sig-name descname"><span class="pre">ProbabilityOfImprovement</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">best_f</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/analytic.html#ProbabilityOfImprovement"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.analytic.ProbabilityOfImprovement" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.analytic.AnalyticAcquisitionFunction" title="botorch.acquisition.analytic.AnalyticAcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">AnalyticAcquisitionFunction</span></code></a></p>
<p>Single-outcome Probability of Improvement.</p>
<p>Probability of improvement over the current best observed value, computed
using the analytic formula under a Normal posterior distribution. Only
supports the case of q=1. Requires the posterior to be Gaussian. The model
must be single-outcome.</p>
<p><cite>PI(x) = P(y &gt;= best_f), y ~ f(x)</cite></p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">PI</span> <span class="o">=</span> <span class="n">ProbabilityOfImprovement</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">best_f</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pi</span> <span class="o">=</span> <span class="n">PI</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
</pre></div>
</div>
<p>Single-outcome Probability of Improvement.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted single-outcome model.</p></li>
<li><p><strong>best_f</strong> (<em>float</em><em> | </em><em>Tensor</em>) – Either a scalar or a <cite>b</cite>-dim Tensor (batch mode) representing
the best function value observed so far (assumed noiseless).</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – A PosteriorTransform. If using a multi-output model,
a PosteriorTransform that transforms the multi-output posterior into a
single-output posterior is required.</p></li>
<li><p><strong>maximize</strong> (<em>bool</em>) – If True, consider the problem a maximization problem.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.analytic.ProbabilityOfImprovement.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/analytic.html#ProbabilityOfImprovement.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.analytic.ProbabilityOfImprovement.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate the Probability of Improvement on the candidate set X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>(b1 x … bk) x 1 x d</cite>-dim batched tensor of <cite>d</cite>-dim design points.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>(b1 x … bk)</cite>-dim tensor of Probability of Improvement values at the
given design points <cite>X</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.analytic.qAnalyticProbabilityOfImprovement">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.analytic.</span></span><span class="sig-name descname"><span class="pre">qAnalyticProbabilityOfImprovement</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">best_f</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/analytic.html#qAnalyticProbabilityOfImprovement"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.analytic.qAnalyticProbabilityOfImprovement" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.analytic.AnalyticAcquisitionFunction" title="botorch.acquisition.analytic.AnalyticAcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">AnalyticAcquisitionFunction</span></code></a></p>
<p>Approximate, single-outcome batch Probability of Improvement using MVNXPB.</p>
<p>This implementation uses MVNXPB, a bivariate conditioning algorithm for
approximating P(a &lt;= Y &lt;= b) for multivariate normal Y.
See <a class="reference internal" href="utils.html#trinh2015bivariate" id="id1"><span>[Trinh2015bivariate]</span></a>. This (analytic) approximate q-PI is given by
<cite>approx-qPI(X) = P(max Y &gt;= best_f) = 1 - P(Y &lt; best_f), Y ~ f(X),
X = (x_1,…,x_q)</cite>, where <cite>P(Y &lt; best_f)</cite> is estimated using MVNXPB.</p>
<p>qPI using an analytic approximation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted single-outcome model.</p></li>
<li><p><strong>best_f</strong> (<em>float</em><em> | </em><em>Tensor</em>) – Either a scalar or a <cite>b</cite>-dim Tensor (batch mode) representing
the best function value observed so far (assumed noiseless).</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – A PosteriorTransform. If using a multi-output model,
a PosteriorTransform that transforms the multi-output posterior into a
single-output posterior is required.</p></li>
<li><p><strong>maximize</strong> (<em>bool</em>) – If True, consider the problem a maximization problem.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.analytic.qAnalyticProbabilityOfImprovement.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/analytic.html#qAnalyticProbabilityOfImprovement.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.analytic.qAnalyticProbabilityOfImprovement.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate approximate qPI on the candidate set X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x q x d</cite>-dim Tensor of t-batches with <cite>q</cite> <cite>d</cite>-dim design
points each</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape</cite>-dim Tensor of approximate Probability of Improvement values
at the given design points <cite>X</cite>, where <cite>batch_shape’</cite> is the broadcasted
batch shape of model and input <cite>X</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.analytic.ExpectedImprovement">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.analytic.</span></span><span class="sig-name descname"><span class="pre">ExpectedImprovement</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">best_f</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/analytic.html#ExpectedImprovement"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.analytic.ExpectedImprovement" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.analytic.AnalyticAcquisitionFunction" title="botorch.acquisition.analytic.AnalyticAcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">AnalyticAcquisitionFunction</span></code></a></p>
<p>Single-outcome Expected Improvement (analytic).</p>
<p>Computes classic Expected Improvement over the current best observed value,
using the analytic formula for a Normal posterior distribution. Unlike the
MC-based acquisition functions, this relies on the posterior at single test
point being Gaussian (and require the posterior to implement <cite>mean</cite> and
<cite>variance</cite> properties). Only supports the case of <cite>q=1</cite>. The model must be
single-outcome.</p>
<p><cite>EI(x) = E(max(f(x) - best_f, 0)),</cite></p>
<p>where the expectation is taken over the value of stochastic function <cite>f</cite> at <cite>x</cite>.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">EI</span> <span class="o">=</span> <span class="n">ExpectedImprovement</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">best_f</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ei</span> <span class="o">=</span> <span class="n">EI</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
</pre></div>
</div>
<p>NOTE: It is strongly recommended to use LogExpectedImprovement instead of regular
EI, as it can lead to substantially improved BO performance through improved
numerics. See <a class="reference external" href="https://arxiv.org/abs/2310.20708">https://arxiv.org/abs/2310.20708</a> for details.</p>
<p>Single-outcome Expected Improvement (analytic).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted single-outcome model.</p></li>
<li><p><strong>best_f</strong> (<em>float</em><em> | </em><em>Tensor</em>) – Either a scalar or a <cite>b</cite>-dim Tensor (batch mode) representing
the best function value observed so far (assumed noiseless).</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – A PosteriorTransform. If using a multi-output model,
a PosteriorTransform that transforms the multi-output posterior into a
single-output posterior is required.</p></li>
<li><p><strong>maximize</strong> (<em>bool</em>) – If True, consider the problem a maximization problem.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.analytic.ExpectedImprovement.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/analytic.html#ExpectedImprovement.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.analytic.ExpectedImprovement.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate Expected Improvement on the candidate set X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>(b1 x … bk) x 1 x d</cite>-dim batched tensor of <cite>d</cite>-dim design points.
Expected Improvement is computed for each point individually,
i.e., what is considered are the marginal posteriors, not the
joint.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>(b1 x … bk)</cite>-dim tensor of Expected Improvement values at the
given design points <cite>X</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.analytic.LogExpectedImprovement">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.analytic.</span></span><span class="sig-name descname"><span class="pre">LogExpectedImprovement</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">best_f</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/analytic.html#LogExpectedImprovement"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.analytic.LogExpectedImprovement" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.analytic.AnalyticAcquisitionFunction" title="botorch.acquisition.analytic.AnalyticAcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">AnalyticAcquisitionFunction</span></code></a></p>
<p>Single-outcome Log Expected Improvement (analytic).</p>
<p>Computes the logarithm of the classic Expected Improvement acquisition function, in
a numerically robust manner. In particular, the implementation takes special care
to avoid numerical issues in the computation of the acquisition value and its
gradient in regions where improvement is predicted to be virtually impossible.</p>
<p>See <a class="reference internal" href="#ament2023logei" id="id2"><span>[Ament2023logei]</span></a> for details. Formally,</p>
<p><cite>LogEI(x) = log(E(max(f(x) - best_f, 0))),</cite></p>
<p>where the expectation is taken over the value of stochastic function <cite>f</cite> at <cite>x</cite>.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">LogEI</span> <span class="o">=</span> <span class="n">LogExpectedImprovement</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">best_f</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ei</span> <span class="o">=</span> <span class="n">LogEI</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
</pre></div>
</div>
<p>Logarithm of single-outcome Expected Improvement (analytic).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted single-outcome model.</p></li>
<li><p><strong>best_f</strong> (<em>float</em><em> | </em><em>Tensor</em>) – Either a scalar or a <cite>b</cite>-dim Tensor (batch mode) representing
the best function value observed so far (assumed noiseless).</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – A PosteriorTransform. If using a multi-output model,
a PosteriorTransform that transforms the multi-output posterior into a
single-output posterior is required.</p></li>
<li><p><strong>maximize</strong> (<em>bool</em>) – If True, consider the problem a maximization problem.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.analytic.LogExpectedImprovement.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/analytic.html#LogExpectedImprovement.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.analytic.LogExpectedImprovement.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate logarithm of Expected Improvement on the candidate set X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>(b1 x … bk) x 1 x d</cite>-dim batched tensor of <cite>d</cite>-dim design points.
Expected Improvement is computed for each point individually,
i.e., what is considered are the marginal posteriors, not the
joint.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>(b1 x … bk)</cite>-dim tensor of the logarithm of the Expected Improvement
values at the given design points <cite>X</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.analytic.LogConstrainedExpectedImprovement">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.analytic.</span></span><span class="sig-name descname"><span class="pre">LogConstrainedExpectedImprovement</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">best_f</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective_index</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraints</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/analytic.html#LogConstrainedExpectedImprovement"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.analytic.LogConstrainedExpectedImprovement" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.analytic.AnalyticAcquisitionFunction" title="botorch.acquisition.analytic.AnalyticAcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">AnalyticAcquisitionFunction</span></code></a></p>
<p>Log Constrained Expected Improvement (feasibility-weighted).</p>
<p>Computes the logarithm of the analytic expected improvement for a Normal posterior
distribution weighted by a probability of feasibility. The objective and
constraints are assumed to be independent and have Gaussian posterior
distributions. Only supports non-batch mode (i.e. <cite>q=1</cite>). The model should be
multi-outcome, with the index of the objective and constraints passed to
the constructor.</p>
<p>See <a class="reference internal" href="#ament2023logei" id="id3"><span>[Ament2023logei]</span></a> for details. Formally,</p>
<p><cite>LogConstrainedEI(x) = log(EI(x)) + Sum_i log(P(y_i in [lower_i, upper_i]))</cite>,</p>
<p>where <cite>y_i ~ constraint_i(x)</cite> and <cite>lower_i</cite>, <cite>upper_i</cite> are the lower and
upper bounds for the i-th constraint, respectively.</p>
<p class="rubric">Example</p>
<p># example where the 0th output has a non-negativity constraint and
# the 1st output is the objective
&gt;&gt;&gt; model = SingleTaskGP(train_X, train_Y)
&gt;&gt;&gt; constraints = {0: (0.0, None)}
&gt;&gt;&gt; LogCEI = LogConstrainedExpectedImprovement(model, 0.2, 1, constraints)
&gt;&gt;&gt; cei = LogCEI(test_X)</p>
<p>Analytic Log Constrained Expected Improvement.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted multi-output model.</p></li>
<li><p><strong>best_f</strong> (<em>float</em><em> | </em><em>Tensor</em>) – Either a scalar or a <cite>b</cite>-dim Tensor (batch mode) representing
the best feasible function value observed so far (assumed noiseless).</p></li>
<li><p><strong>objective_index</strong> (<em>int</em>) – The index of the objective.</p></li>
<li><p><strong>constraints</strong> (<em>dict</em><em>[</em><em>int</em><em>, </em><em>tuple</em><em>[</em><em>float</em><em> | </em><em>None</em><em>, </em><em>float</em><em> | </em><em>None</em><em>]</em><em>]</em>) – A dictionary of the form <cite>{i: [lower, upper]}</cite>, where
<cite>i</cite> is the output index, and <cite>lower</cite> and <cite>upper</cite> are lower and upper
bounds on that output (resp. interpreted as -Inf / Inf if None)</p></li>
<li><p><strong>maximize</strong> (<em>bool</em>) – If True, consider the problem a maximization problem.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.analytic.LogConstrainedExpectedImprovement.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/analytic.html#LogConstrainedExpectedImprovement.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.analytic.LogConstrainedExpectedImprovement.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate Constrained Log Expected Improvement on the candidate set X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>(b) x 1 x d</cite>-dim Tensor of <cite>(b)</cite> t-batches of <cite>d</cite>-dim design
points each.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>(b)</cite>-dim Tensor of Log Expected Improvement values at the given
design points <cite>X</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.analytic.ConstrainedExpectedImprovement">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.analytic.</span></span><span class="sig-name descname"><span class="pre">ConstrainedExpectedImprovement</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">best_f</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective_index</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraints</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/analytic.html#ConstrainedExpectedImprovement"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.analytic.ConstrainedExpectedImprovement" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.analytic.AnalyticAcquisitionFunction" title="botorch.acquisition.analytic.AnalyticAcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">AnalyticAcquisitionFunction</span></code></a></p>
<p>Constrained Expected Improvement (feasibility-weighted).</p>
<p>Computes the analytic expected improvement for a Normal posterior
distribution, weighted by a probability of feasibility. The objective and
constraints are assumed to be independent and have Gaussian posterior
distributions. Only supports non-batch mode (i.e. <cite>q=1</cite>). The model should be
multi-outcome, with the index of the objective and constraints passed to
the constructor.</p>
<p><cite>Constrained_EI(x) = EI(x) * Product_i P(y_i in [lower_i, upper_i])</cite>,
where <cite>y_i ~ constraint_i(x)</cite> and <cite>lower_i</cite>, <cite>upper_i</cite> are the lower and
upper bounds for the i-th constraint, respectively.</p>
<p class="rubric">Example</p>
<p># example where the 0th output has a non-negativity constraint and
# 1st output is the objective
&gt;&gt;&gt; model = SingleTaskGP(train_X, train_Y)
&gt;&gt;&gt; constraints = {0: (0.0, None)}
&gt;&gt;&gt; cEI = ConstrainedExpectedImprovement(model, 0.2, 1, constraints)
&gt;&gt;&gt; cei = cEI(test_X)</p>
<p>NOTE: It is strongly recommended to use LogConstrainedExpectedImprovement instead
of regular CEI, as it can lead to substantially improved BO performance through
improved numerics. See <a class="reference external" href="https://arxiv.org/abs/2310.20708">https://arxiv.org/abs/2310.20708</a> for details.</p>
<p>Analytic Constrained Expected Improvement.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted multi-output model.</p></li>
<li><p><strong>best_f</strong> (<em>float</em><em> | </em><em>Tensor</em>) – Either a scalar or a <cite>b</cite>-dim Tensor (batch mode) representing
the best feasible function value observed so far (assumed noiseless).</p></li>
<li><p><strong>objective_index</strong> (<em>int</em>) – The index of the objective.</p></li>
<li><p><strong>constraints</strong> (<em>dict</em><em>[</em><em>int</em><em>, </em><em>tuple</em><em>[</em><em>float</em><em> | </em><em>None</em><em>, </em><em>float</em><em> | </em><em>None</em><em>]</em><em>]</em>) – A dictionary of the form <cite>{i: [lower, upper]}</cite>, where
<cite>i</cite> is the output index, and <cite>lower</cite> and <cite>upper</cite> are lower and upper
bounds on that output (resp. interpreted as -Inf / Inf if None)</p></li>
<li><p><strong>maximize</strong> (<em>bool</em>) – If True, consider the problem a maximization problem.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.analytic.ConstrainedExpectedImprovement.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/analytic.html#ConstrainedExpectedImprovement.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.analytic.ConstrainedExpectedImprovement.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate Constrained Expected Improvement on the candidate set X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>(b) x 1 x d</cite>-dim Tensor of <cite>(b)</cite> t-batches of <cite>d</cite>-dim design
points each.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>(b)</cite>-dim Tensor of Expected Improvement values at the given
design points <cite>X</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.analytic.LogNoisyExpectedImprovement">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.analytic.</span></span><span class="sig-name descname"><span class="pre">LogNoisyExpectedImprovement</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_observed</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_fantasies</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/analytic.html#LogNoisyExpectedImprovement"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.analytic.LogNoisyExpectedImprovement" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.analytic.AnalyticAcquisitionFunction" title="botorch.acquisition.analytic.AnalyticAcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">AnalyticAcquisitionFunction</span></code></a></p>
<p>Single-outcome Log Noisy Expected Improvement (via fantasies).</p>
<p>This computes Log Noisy Expected Improvement by averaging over the Expected
Improvement values of a number of fantasy models. Only supports the case
<cite>q=1</cite>. Assumes that the posterior distribution of the model is Gaussian.
The model must be single-outcome.</p>
<p>See <a class="reference internal" href="#ament2023logei" id="id4"><span>[Ament2023logei]</span></a> for details. Formally,</p>
<p><cite>LogNEI(x) = log(E(max(y - max Y_base), 0))), (y, Y_base) ~ f((x, X_base))</cite>,</p>
<p>where <cite>X_base</cite> are previously observed points.</p>
<p>Note: This acquisition function currently relies on using a SingleTaskGP
with known observation noise. In other words, <cite>train_Yvar</cite> must be passed
to the model. (required for noiseless fantasies).</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">,</span> <span class="n">train_Yvar</span><span class="o">=</span><span class="n">train_Yvar</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">LogNEI</span> <span class="o">=</span> <span class="n">LogNoisyExpectedImprovement</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_X</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nei</span> <span class="o">=</span> <span class="n">LogNEI</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
</pre></div>
</div>
<p>Single-outcome Noisy Log Expected Improvement (via fantasies).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.gpytorch.GPyTorchModel" title="botorch.models.gpytorch.GPyTorchModel"><em>GPyTorchModel</em></a>) – A fitted single-outcome model. Only <cite>SingleTaskGP</cite> models with
known observation noise are currently supported.</p></li>
<li><p><strong>X_observed</strong> (<em>Tensor</em>) – A <cite>n x d</cite> Tensor of observed points that are likely to
be the best observed points so far.</p></li>
<li><p><strong>num_fantasies</strong> (<em>int</em>) – The number of fantasies to generate. The higher this
number the more accurate the model (at the expense of model
complexity and performance).</p></li>
<li><p><strong>maximize</strong> (<em>bool</em>) – If True, consider the problem a maximization problem.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.analytic.LogNoisyExpectedImprovement.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/analytic.html#LogNoisyExpectedImprovement.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.analytic.LogNoisyExpectedImprovement.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate logarithm of the mean Expected Improvement on the candidate set X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>b1 x … bk x 1 x d</cite>-dim batched tensor of <cite>d</cite>-dim design points.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>b1 x … bk</cite>-dim tensor of Log Noisy Expected Improvement values at
the given design points <cite>X</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.analytic.NoisyExpectedImprovement">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.analytic.</span></span><span class="sig-name descname"><span class="pre">NoisyExpectedImprovement</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_observed</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_fantasies</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/analytic.html#NoisyExpectedImprovement"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.analytic.NoisyExpectedImprovement" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.analytic.ExpectedImprovement" title="botorch.acquisition.analytic.ExpectedImprovement"><code class="xref py py-class docutils literal notranslate"><span class="pre">ExpectedImprovement</span></code></a></p>
<p>Single-outcome Noisy Expected Improvement (via fantasies).</p>
<p>This computes Noisy Expected Improvement by averaging over the Expected
Improvement values of a number of fantasy models. Only supports the case
<cite>q=1</cite>. Assumes that the posterior distribution of the model is Gaussian.
The model must be single-outcome.</p>
<p><cite>NEI(x) = E(max(y - max Y_baseline), 0)), (y, Y_baseline) ~ f((x, X_baseline))</cite>,
where <cite>X_baseline</cite> are previously observed points.</p>
<p>Note: This acquisition function currently relies on using a SingleTaskGP
with known observation noise. In other words, <cite>train_Yvar</cite> must be passed
to the model. (required for noiseless fantasies).</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">,</span> <span class="n">train_Yvar</span><span class="o">=</span><span class="n">train_Yvar</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">NEI</span> <span class="o">=</span> <span class="n">NoisyExpectedImprovement</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_X</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nei</span> <span class="o">=</span> <span class="n">NEI</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
</pre></div>
</div>
<p>NOTE: It is strongly recommended to use LogNoisyExpectedImprovement instead
of regular NEI, as it can lead to substantially improved BO performance through
improved numerics. See <a class="reference external" href="https://arxiv.org/abs/2310.20708">https://arxiv.org/abs/2310.20708</a> for details.</p>
<p>Single-outcome Noisy Expected Improvement (via fantasies).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.gpytorch.GPyTorchModel" title="botorch.models.gpytorch.GPyTorchModel"><em>GPyTorchModel</em></a>) – A fitted single-outcome model. Only <cite>SingleTaskGP</cite> models with
known observation noise are currently supported.</p></li>
<li><p><strong>X_observed</strong> (<em>Tensor</em>) – A <cite>n x d</cite> Tensor of observed points that are likely to
be the best observed points so far.</p></li>
<li><p><strong>num_fantasies</strong> (<em>int</em>) – The number of fantasies to generate. The higher this
number the more accurate the model (at the expense of model
complexity and performance).</p></li>
<li><p><strong>maximize</strong> (<em>bool</em>) – If True, consider the problem a maximization problem.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.analytic.NoisyExpectedImprovement.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/analytic.html#NoisyExpectedImprovement.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.analytic.NoisyExpectedImprovement.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate Expected Improvement on the candidate set X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>b1 x … bk x 1 x d</cite>-dim batched tensor of <cite>d</cite>-dim design points.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>b1 x … bk</cite>-dim tensor of Noisy Expected Improvement values at
the given design points <cite>X</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.analytic.UpperConfidenceBound">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.analytic.</span></span><span class="sig-name descname"><span class="pre">UpperConfidenceBound</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/analytic.html#UpperConfidenceBound"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.analytic.UpperConfidenceBound" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.analytic.AnalyticAcquisitionFunction" title="botorch.acquisition.analytic.AnalyticAcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">AnalyticAcquisitionFunction</span></code></a></p>
<p>Single-outcome Upper Confidence Bound (UCB).</p>
<p>Analytic upper confidence bound that comprises of the posterior mean plus an
additional term: the posterior standard deviation weighted by a trade-off
parameter, <cite>beta</cite>. Only supports the case of <cite>q=1</cite> (i.e. greedy, non-batch
selection of design points). The model must be single-outcome.</p>
<p><cite>UCB(x) = mu(x) + sqrt(beta) * sigma(x)</cite>, where <cite>mu</cite> and <cite>sigma</cite> are the
posterior mean and standard deviation, respectively.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">UCB</span> <span class="o">=</span> <span class="n">UpperConfidenceBound</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ucb</span> <span class="o">=</span> <span class="n">UCB</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
</pre></div>
</div>
<p>Single-outcome Upper Confidence Bound.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted single-outcome GP model (must be in batch mode if
candidate sets X will be)</p></li>
<li><p><strong>beta</strong> (<em>float</em><em> | </em><em>Tensor</em>) – Either a scalar or a one-dim tensor with <cite>b</cite> elements (batch mode)
representing the trade-off parameter between mean and covariance</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – A PosteriorTransform. If using a multi-output model,
a PosteriorTransform that transforms the multi-output posterior into a
single-output posterior is required.</p></li>
<li><p><strong>maximize</strong> (<em>bool</em>) – If True, consider the problem a maximization problem.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.analytic.UpperConfidenceBound.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/analytic.html#UpperConfidenceBound.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.analytic.UpperConfidenceBound.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate the Upper Confidence Bound on the candidate set X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>(b1 x … bk) x 1 x d</cite>-dim batched tensor of <cite>d</cite>-dim design points.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>(b1 x … bk)</cite>-dim tensor of Upper Confidence Bound values at the
given design points <cite>X</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.analytic.PosteriorMean">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.analytic.</span></span><span class="sig-name descname"><span class="pre">PosteriorMean</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/analytic.html#PosteriorMean"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.analytic.PosteriorMean" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.analytic.AnalyticAcquisitionFunction" title="botorch.acquisition.analytic.AnalyticAcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">AnalyticAcquisitionFunction</span></code></a></p>
<p>Single-outcome Posterior Mean.</p>
<p>Only supports the case of q=1. Requires the model’s posterior to have a
<cite>mean</cite> property. The model must be single-outcome.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">PM</span> <span class="o">=</span> <span class="n">PosteriorMean</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pm</span> <span class="o">=</span> <span class="n">PM</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
</pre></div>
</div>
<p>Single-outcome Posterior Mean.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted single-outcome GP model (must be in batch mode if
candidate sets X will be)</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – A PosteriorTransform. If using a multi-output model,
a PosteriorTransform that transforms the multi-output posterior into a
single-output posterior is required.</p></li>
<li><p><strong>maximize</strong> (<em>bool</em>) – If True, consider the problem a maximization problem. Note
that if <cite>maximize=False</cite>, the posterior mean is negated. As a
consequence <cite>optimize_acqf(PosteriorMean(gp, maximize=False))</cite>
actually returns -1 * minimum of the posterior mean.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.analytic.PosteriorMean.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/analytic.html#PosteriorMean.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.analytic.PosteriorMean.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate the posterior mean on the candidate set X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>(b1 x … bk) x 1 x d</cite>-dim batched tensor of <cite>d</cite>-dim design points.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>(b1 x … bk)</cite>-dim tensor of Posterior Mean values at the
given design points <cite>X</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.analytic.ScalarizedPosteriorMean">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.analytic.</span></span><span class="sig-name descname"><span class="pre">ScalarizedPosteriorMean</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/analytic.html#ScalarizedPosteriorMean"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.analytic.ScalarizedPosteriorMean" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.analytic.AnalyticAcquisitionFunction" title="botorch.acquisition.analytic.AnalyticAcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">AnalyticAcquisitionFunction</span></code></a></p>
<p>Scalarized Posterior Mean.</p>
<p>This acquisition function returns a scalarized (across the q-batch)
posterior mean given a vector of weights.</p>
<p>Scalarized Posterior Mean.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted single-outcome model.</p></li>
<li><p><strong>weights</strong> (<em>Tensor</em>) – A tensor of shape <cite>q</cite> for scalarization. In order to minimize
the scalarized posterior mean, pass -weights.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – A PosteriorTransform. If using a multi-output model,
a PosteriorTransform that transforms the multi-output posterior into a
single-output posterior is required.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.analytic.ScalarizedPosteriorMean.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/analytic.html#ScalarizedPosteriorMean.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.analytic.ScalarizedPosteriorMean.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate the scalarized posterior mean on the candidate set X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>(b) x q x d</cite>-dim Tensor of <cite>(b)</cite> t-batches of <cite>d</cite>-dim design
points each.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>(b)</cite>-dim Tensor of Posterior Mean values at the given design
points <cite>X</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.analytic.PosteriorStandardDeviation">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.analytic.</span></span><span class="sig-name descname"><span class="pre">PosteriorStandardDeviation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/analytic.html#PosteriorStandardDeviation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.analytic.PosteriorStandardDeviation" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.analytic.AnalyticAcquisitionFunction" title="botorch.acquisition.analytic.AnalyticAcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">AnalyticAcquisitionFunction</span></code></a></p>
<p>Single-outcome Posterior Standard Deviation.</p>
<p>An acquisition function for pure exploration.
Only supports the case of q=1. Requires the model’s posterior to have
<cite>mean</cite> and <cite>variance</cite> properties. The model must be either single-outcome
or combined with a <cite>posterior_transform</cite> to produce a single-output posterior.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">botorch.models.gp_regression</span><span class="w"> </span><span class="kn">import</span> <span class="n">SingleTaskGP</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">botorch.models.transforms.input</span><span class="w"> </span><span class="kn">import</span> <span class="n">Normalize</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">botorch.models.transforms.outcome</span><span class="w"> </span><span class="kn">import</span> <span class="n">Standardize</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Set up a model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">train_X</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">,</span> <span class="n">outcome_transform</span><span class="o">=</span><span class="n">Standardize</span><span class="p">(</span><span class="n">m</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">input_transform</span><span class="o">=</span><span class="n">Normalize</span><span class="p">(</span><span class="n">d</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Now set up the acquisition function</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">PSTD</span> <span class="o">=</span> <span class="n">PosteriorStandardDeviation</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">test_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">std</span> <span class="o">=</span> <span class="n">PSTD</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">std</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="go">0.16341639895667773</span>
</pre></div>
</div>
<p>Single-outcome Posterior Mean.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted single-outcome GP model (must be in batch mode if
candidate sets X will be)</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – A PosteriorTransform. If using a multi-output model,
a PosteriorTransform that transforms the multi-output posterior into a
single-output posterior is required.</p></li>
<li><p><strong>maximize</strong> (<em>bool</em>) – If True, consider the problem a maximization problem. Note
that if <cite>maximize=False</cite>, the posterior standard deviation is negated.
As a consequence,
<cite>optimize_acqf(PosteriorStandardDeviation(gp, maximize=False))</cite>
actually returns -1 * minimum of the posterior standard deviation.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.analytic.PosteriorStandardDeviation.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/analytic.html#PosteriorStandardDeviation.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.analytic.PosteriorStandardDeviation.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate the posterior standard deviation on the candidate set X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>(b1 x … bk) x 1 x d</cite>-dim batched tensor of <cite>d</cite>-dim design points.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>(b1 x … bk)</cite>-dim tensor of Posterior Mean values at the
given design points <cite>X</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-botorch.acquisition.monte_carlo">
<span id="monte-carlo-acquisition-functions"></span><h3>Monte-Carlo Acquisition Functions<a class="headerlink" href="#module-botorch.acquisition.monte_carlo" title="Link to this heading"></a></h3>
<p>Batch acquisition functions using the reparameterization trick in combination
with (quasi) Monte-Carlo sampling. See <a class="reference internal" href="#rezende2014reparam" id="id5"><span>[Rezende2014reparam]</span></a>, <a class="reference internal" href="#wilson2017reparam" id="id6"><span>[Wilson2017reparam]</span></a> and
<a class="reference internal" href="#balandat2020botorch" id="id7"><span>[Balandat2020botorch]</span></a>.</p>
<p>References</p>
<div role="list" class="citation-list">
<div class="citation" id="rezende2014reparam" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id5">Rezende2014reparam</a><span class="fn-bracket">]</span></span>
<p>D. J. Rezende, S. Mohamed, and D. Wierstra. Stochastic backpropagation and
approximate inference in deep generative models. ICML 2014.</p>
</div>
<div class="citation" id="wilson2017reparam" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id6">Wilson2017reparam</a><span class="fn-bracket">]</span></span>
<p>J. T. Wilson, R. Moriconi, F. Hutter, and M. P. Deisenroth.
The reparameterization trick for acquisition functions. ArXiv 2017.</p>
</div>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.monte_carlo.SampleReductionProtocol">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.monte_carlo.</span></span><span class="sig-name descname"><span class="pre">SampleReductionProtocol</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/monte_carlo.html#SampleReductionProtocol"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.monte_carlo.SampleReductionProtocol" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Protocol</span></code></p>
<p>For static type check of SampleReducingMCAcquisitionFunction’s mc_reduction.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.monte_carlo.SampleReducingMCAcquisitionFunction">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.monte_carlo.</span></span><span class="sig-name descname"><span class="pre">SampleReducingMCAcquisitionFunction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_reduction=&lt;built-in</span> <span class="pre">method</span> <span class="pre">mean</span> <span class="pre">of</span> <span class="pre">type</span> <span class="pre">object&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q_reduction=&lt;built-in</span> <span class="pre">method</span> <span class="pre">amax</span> <span class="pre">of</span> <span class="pre">type</span> <span class="pre">object&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraints=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta=0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fat=False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/monte_carlo.html#SampleReducingMCAcquisitionFunction"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.monte_carlo.SampleReducingMCAcquisitionFunction" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.monte_carlo.MCAcquisitionFunction" title="botorch.acquisition.monte_carlo.MCAcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">MCAcquisitionFunction</span></code></a></p>
<p>MC-based batch acquisition function that reduces across samples and implements
a general treatment of outcome constraints.</p>
<p>This class’s <cite>forward</cite> computes the - possibly constrained - acquisition value by
(1) computing the unconstrained utility for each MC sample using <cite>_sample_forward</cite>,
(2) weighing the utility values by the constraint indicator per MC sample, and
(3) reducing (e.g. averaging) the weighted utility values over the MC dimension.</p>
<p>NOTE: Do <em>NOT</em> override the <cite>forward</cite> method, unless you have thought about it well.</p>
<p><cite>forward</cite> is implemented generically to incorporate constraints in a principled way,
and takes care of reducing over the Monte Carlo and batch dimensions via the
<cite>sample_reduction</cite> and <cite>q_reduction</cite> arguments, which default to <cite>torch.mean</cite> and
<cite>torch.max</cite>, respectively.</p>
<p>In order to implement a custom SampleReducingMCAcquisitionFunction, we only need to
implement the <cite>_sample_forward(obj: Tensor) -&gt; Tensor</cite> method, which maps objective
samples to acquisition utility values without reducing the Monte Carlo and batch
(i.e. q) dimensions (see details in the docstring of <cite>_sample_forward</cite>).</p>
<p>A note on design choices:</p>
<p>The primary purpose of <cite>SampleReducingMCAcquisitionFunction`is to support outcome
constraints. On the surface, designing a wrapper `ConstrainedMCAcquisitionFunction</cite>
could be an elegant solution to this end, but it would still require the acquisition
functions to implement a <cite>_sample_forward</cite> method to weigh acquisition utilities at
the sample level. Further, <cite>qNoisyExpectedImprovement</cite> is a special case that is
hard to encompass in this pattern, since it requires the computation of the best
<em>feasible</em> objective, which requires access to the constraint functions. However,
if the constraints are stored in a wrapper class, they will be inaccessible to the
forward pass. These problems are circumvented by the design of this class.</p>
<p>Constructor of SampleReducingMCAcquisitionFunction.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted model.</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – The sampler used to draw base samples. If not given, a
sampler is generated on the fly within the
<cite>get_posterior_samples</cite> method using
<cite>botorch.sampling.get_sampler</cite>.
NOTE: For posteriors that do not support base samples,
a sampler compatible with intended use case must be provided.
See <cite>ForkedRNGSampler</cite> and <cite>StochasticSampler</cite> as examples.</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><em>MCAcquisitionObjective</em></a><em> | </em><em>None</em>) – The MCAcquisitionObjective under which the samples are
evaluated. Defaults to <cite>IdentityMCObjective()</cite>.
NOTE: <cite>ConstrainedMCObjective</cite> for outcome constraints is deprecated in
favor of passing the <cite>constraints</cite> directly to this constructor.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – A <cite>PosteriorTransform</cite> (optional).</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape, m x d</cite>-dim Tensor of <cite>m</cite> design points
that have points that have been submitted for function evaluation
but have not yet been evaluated.</p></li>
<li><p><strong>sample_reduction</strong> (<a class="reference internal" href="#botorch.acquisition.monte_carlo.SampleReductionProtocol" title="botorch.acquisition.monte_carlo.SampleReductionProtocol"><em>SampleReductionProtocol</em></a>) – A callable that takes in a <cite>sample_shape x batch_shape</cite>
Tensor of acquisition utility values, a keyword-argument <cite>dim</cite> that
specifies the sample dimensions to reduce over, and returns a
<cite>batch_shape</cite>-dim Tensor of acquisition values.</p></li>
<li><p><strong>q_reduction</strong> (<a class="reference internal" href="#botorch.acquisition.monte_carlo.SampleReductionProtocol" title="botorch.acquisition.monte_carlo.SampleReductionProtocol"><em>SampleReductionProtocol</em></a>) – A callable that takes in a <cite>sample_shape x batch_shape x q</cite>
Tensor of acquisition utility values, a keyword-argument <cite>dim</cite> that
specifies the q dimension to reduce over (i.e. -1), and returns a
<cite>sample_shape x batch_shape</cite>-dim Tensor of acquisition values.</p></li>
<li><p><strong>constraints</strong> (<em>list</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of constraint callables which map a Tensor of posterior
samples of dimension <cite>sample_shape x batch-shape x q x m</cite>-dim to a
<cite>sample_shape x batch-shape x q</cite>-dim Tensor. The associated constraints
are considered satisfied if the output is less than zero.
NOTE: Constraint-weighting is only compatible with non-negative
acquistion utilities, e.g. all improvement-based acquisition functions.</p></li>
<li><p><strong>eta</strong> (<em>Tensor</em><em> | </em><em>float</em>) – Temperature parameter(s) governing the smoothness of the sigmoid
approximation to the constraint indicators. For more details, on this
parameter, see the docs of <cite>compute_smoothed_feasibility_indicator</cite>.</p></li>
<li><p><strong>fat</strong> (<em>bool</em>) – Wether to apply a fat-tailed smooth approximation to the feasibility
indicator or the canonical sigmoid approximation.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.monte_carlo.SampleReducingMCAcquisitionFunction.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/monte_carlo.html#SampleReducingMCAcquisitionFunction.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.monte_carlo.SampleReducingMCAcquisitionFunction.forward" title="Link to this definition"></a></dt>
<dd><p>Computes the acquisition value associated with the input <cite>X</cite>. Weighs the
acquisition utility values by smoothed constraint indicators if <cite>constraints</cite>
was passed to the constructor of the class. Applies <cite>self.sample_reduction</cite> and
<cite>self.q_reduction</cite> to reduce over the Monte Carlo and batch (q) dimensions.</p>
<p>NOTE: Do <em>NOT</em> override the <cite>forward</cite> method for a custom acquisition function.
Instead, implement the <cite>_sample_forward</cite> method. See the docstring of this class
for details.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x q x d</cite> Tensor of t-batches with <cite>q</cite> <cite>d</cite>-dim
design points each.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A Tensor with shape <cite>batch_shape’</cite>, where <cite>batch_shape’</cite> is the broadcasted
batch shape of model and input <cite>X</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.monte_carlo.qExpectedImprovement">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.monte_carlo.</span></span><span class="sig-name descname"><span class="pre">qExpectedImprovement</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">best_f</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/monte_carlo.html#qExpectedImprovement"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.monte_carlo.qExpectedImprovement" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.monte_carlo.SampleReducingMCAcquisitionFunction" title="botorch.acquisition.monte_carlo.SampleReducingMCAcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">SampleReducingMCAcquisitionFunction</span></code></a></p>
<p>MC-based batch Expected Improvement.</p>
<p>This computes qEI by
(1) sampling the joint posterior over q points
(2) evaluating the improvement over the current best for each sample
(3) maximizing over q
(4) averaging over the samples</p>
<p><cite>qEI(X) = E(max(max Y - best_f, 0)), Y ~ f(X), where X = (x_1,…,x_q)</cite></p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">best_f</span> <span class="o">=</span> <span class="n">train_Y</span><span class="o">.</span><span class="n">max</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sampler</span> <span class="o">=</span> <span class="n">SobolQMCNormalSampler</span><span class="p">(</span><span class="mi">1024</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qEI</span> <span class="o">=</span> <span class="n">qExpectedImprovement</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">best_f</span><span class="p">,</span> <span class="n">sampler</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qei</span> <span class="o">=</span> <span class="n">qEI</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
</pre></div>
</div>
<p>NOTE: It is strongly recommended to use qLogExpectedImprovement instead
of regular qEI, as it can lead to substantially improved BO performance through
improved numerics. See <a class="reference external" href="https://arxiv.org/abs/2310.20708">https://arxiv.org/abs/2310.20708</a> for details.</p>
<p>q-Expected Improvement.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted model.</p></li>
<li><p><strong>best_f</strong> (<em>float</em><em> | </em><em>Tensor</em>) – The best objective value observed so far (assumed noiseless). Can be
a scalar, or a <cite>batch_shape</cite>-dim tensor. In case of a batched model, the
tensor can specify different values for each element of the batch.</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – The sampler used to draw base samples. See <cite>MCAcquisitionFunction</cite>
more details.</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><em>MCAcquisitionObjective</em></a><em> | </em><em>None</em>) – The MCAcquisitionObjective under which the samples are evaluated.
Defaults to <cite>IdentityMCObjective()</cite>.
NOTE: <cite>ConstrainedMCObjective</cite> for outcome constraints is deprecated in
favor of passing the <cite>constraints</cite> directly to this constructor.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – A PosteriorTransform (optional).</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>m x d</cite>-dim Tensor of <cite>m</cite> design points that have been
submitted for function evaluation but have not yet been evaluated.
Concatenated into X upon forward call. Copied and set to have no
gradient.</p></li>
<li><p><strong>constraints</strong> (<em>list</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of constraint callables which map a Tensor of posterior
samples of dimension <cite>sample_shape x batch-shape x q x m</cite>-dim to a
<cite>sample_shape x batch-shape x q</cite>-dim Tensor. The associated constraints
are considered satisfied if the output is less than zero.</p></li>
<li><p><strong>eta</strong> (<em>Tensor</em><em> | </em><em>float</em>) – Temperature parameter(s) governing the smoothness of the sigmoid
approximation to the constraint indicators. For more details, on this
parameter, see the docs of <cite>compute_smoothed_feasibility_indicator</cite>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.monte_carlo.qNoisyExpectedImprovement">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.monte_carlo.</span></span><span class="sig-name descname"><span class="pre">qNoisyExpectedImprovement</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_baseline</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prune_baseline</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_root</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">marginalize_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/monte_carlo.html#qNoisyExpectedImprovement"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.monte_carlo.qNoisyExpectedImprovement" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.monte_carlo.SampleReducingMCAcquisitionFunction" title="botorch.acquisition.monte_carlo.SampleReducingMCAcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">SampleReducingMCAcquisitionFunction</span></code></a>, <a class="reference internal" href="#botorch.acquisition.cached_cholesky.CachedCholeskyMCSamplerMixin" title="botorch.acquisition.cached_cholesky.CachedCholeskyMCSamplerMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">CachedCholeskyMCSamplerMixin</span></code></a></p>
<p>MC-based batch Noisy Expected Improvement.</p>
<p>This function does not assume a <cite>best_f</cite> is known (which would require
noiseless observations). Instead, it uses samples from the joint posterior
over the <cite>q</cite> test points and previously observed points. The improvement
over previously observed points is computed for each sample and averaged.</p>
<p><cite>qNEI(X) = E(max(max Y - max Y_baseline, 0))</cite>, where
<cite>(Y, Y_baseline) ~ f((X, X_baseline)), X = (x_1,…,x_q)</cite></p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sampler</span> <span class="o">=</span> <span class="n">SobolQMCNormalSampler</span><span class="p">(</span><span class="mi">1024</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qNEI</span> <span class="o">=</span> <span class="n">qNoisyExpectedImprovement</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_X</span><span class="p">,</span> <span class="n">sampler</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qnei</span> <span class="o">=</span> <span class="n">qNEI</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
</pre></div>
</div>
<p>NOTE: It is strongly recommended to use qLogNoisyExpectedImprovement instead
of regular qNEI, as it can lead to substantially improved BO performance through
improved numerics. See <a class="reference external" href="https://arxiv.org/abs/2310.20708">https://arxiv.org/abs/2310.20708</a> for details.</p>
<p>q-Noisy Expected Improvement.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted model.</p></li>
<li><p><strong>X_baseline</strong> (<em>Tensor</em>) – A <cite>batch_shape x r x d</cite>-dim Tensor of <cite>r</cite> design points
that have already been observed. These points are considered as
the potential best design point.</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – The sampler used to draw base samples. See <cite>MCAcquisitionFunction</cite>
more details.</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><em>MCAcquisitionObjective</em></a><em> | </em><em>None</em>) – The MCAcquisitionObjective under which the samples are
evaluated. Defaults to <cite>IdentityMCObjective()</cite>.
NOTE: <cite>ConstrainedMCObjective</cite> for outcome constraints is deprecated in
favor of passing the <cite>constraints</cite> directly to this constructor.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – A PosteriorTransform (optional).</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x m x d</cite>-dim Tensor of <cite>m</cite> design points
that have points that have been submitted for function evaluation
but have not yet been evaluated. Concatenated into <cite>X</cite> upon
forward call. Copied and set to have no gradient.</p></li>
<li><p><strong>prune_baseline</strong> (<em>bool</em>) – If True, remove points in <cite>X_baseline</cite> that are
highly unlikely to be the best point. This can significantly
improve performance and is generally recommended. In order to
customize pruning parameters, instead manually call
<cite>botorch.acquisition.utils.prune_inferior_points</cite> on <cite>X_baseline</cite>
before instantiating the acquisition function.</p></li>
<li><p><strong>cache_root</strong> (<em>bool</em>) – A boolean indicating whether to cache the root
decomposition over <cite>X_baseline</cite> and use low-rank updates.</p></li>
<li><p><strong>constraints</strong> (<em>list</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of constraint callables which map a Tensor of posterior
samples of dimension <cite>sample_shape x batch-shape x q x m</cite>-dim to a
<cite>sample_shape x batch-shape x q</cite>-dim Tensor. The associated constraints
are considered satisfied if the output is less than zero.</p></li>
<li><p><strong>eta</strong> (<em>Tensor</em><em> | </em><em>float</em>) – Temperature parameter(s) governing the smoothness of the sigmoid
approximation to the constraint indicators. For more details, on this
parameter, see the docs of <cite>compute_smoothed_feasibility_indicator</cite>.</p></li>
<li><p><strong>marginalize_dim</strong> (<em>int</em><em> | </em><em>None</em>) – The dimension to marginalize over.</p></li>
</ul>
</dd>
</dl>
<p>TODO: similar to qNEHVI, when we are using sequential greedy candidate
selection, we could incorporate pending points X_baseline and compute
the incremental qNEI from the new point. This would greatly increase
efficiency for large batches.</p>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.monte_carlo.qNoisyExpectedImprovement.compute_best_f">
<span class="sig-name descname"><span class="pre">compute_best_f</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obj</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/monte_carlo.html#qNoisyExpectedImprovement.compute_best_f"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.monte_carlo.qNoisyExpectedImprovement.compute_best_f" title="Link to this definition"></a></dt>
<dd><p>Computes the best (feasible) noisy objective value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>obj</strong> (<em>Tensor</em>) – <cite>sample_shape x batch_shape x q</cite>-dim Tensor of objectives in forward.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>sample_shape x batch_shape</cite>-dim Tensor of best feasible objectives.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.monte_carlo.qProbabilityOfImprovement">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.monte_carlo.</span></span><span class="sig-name descname"><span class="pre">qProbabilityOfImprovement</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">best_f</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/monte_carlo.html#qProbabilityOfImprovement"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.monte_carlo.qProbabilityOfImprovement" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.monte_carlo.SampleReducingMCAcquisitionFunction" title="botorch.acquisition.monte_carlo.SampleReducingMCAcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">SampleReducingMCAcquisitionFunction</span></code></a></p>
<p>MC-based batch Probability of Improvement.</p>
<p>Estimates the probability of improvement over the current best observed
value by sampling from the joint posterior distribution of the q-batch.
MC-based estimates of a probability involves taking expectation of an
indicator function; to support auto-differentiation, the indicator is
replaced with a sigmoid function with temperature parameter <cite>tau</cite>.</p>
<p><cite>qPI(X) = P(max Y &gt;= best_f), Y ~ f(X), X = (x_1,…,x_q)</cite></p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">best_f</span> <span class="o">=</span> <span class="n">train_Y</span><span class="o">.</span><span class="n">max</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sampler</span> <span class="o">=</span> <span class="n">SobolQMCNormalSampler</span><span class="p">(</span><span class="mi">1024</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qPI</span> <span class="o">=</span> <span class="n">qProbabilityOfImprovement</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">best_f</span><span class="p">,</span> <span class="n">sampler</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qpi</span> <span class="o">=</span> <span class="n">qPI</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
</pre></div>
</div>
<p>q-Probability of Improvement.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted model.</p></li>
<li><p><strong>best_f</strong> (<em>float</em><em> | </em><em>Tensor</em>) – The best objective value observed so far (assumed noiseless). Can
be a <cite>batch_shape</cite>-shaped tensor, which in case of a batched model
specifies potentially different values for each element of the batch.</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – The sampler used to draw base samples. See <cite>MCAcquisitionFunction</cite>
more details.</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><em>MCAcquisitionObjective</em></a><em> | </em><em>None</em>) – The MCAcquisitionObjective under which the samples are
evaluated. Defaults to <cite>IdentityMCObjective()</cite>.
NOTE: <cite>ConstrainedMCObjective</cite> for outcome constraints is deprecated in
favor of passing the <cite>constraints</cite> directly to this constructor.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – A PosteriorTransform (optional).</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>m x d</cite>-dim Tensor of <cite>m</cite> design points that have
points that have been submitted for function evaluation
but have not yet been evaluated.  Concatenated into X upon
forward call.  Copied and set to have no gradient.</p></li>
<li><p><strong>tau</strong> (<em>float</em>) – The temperature parameter used in the sigmoid approximation
of the step function. Smaller values yield more accurate
approximations of the function, but result in gradients
estimates with higher variance.</p></li>
<li><p><strong>constraints</strong> (<em>list</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of constraint callables which map posterior samples to
a scalar. The associated constraint is considered satisfied if this
scalar is less than zero.</p></li>
<li><p><strong>eta</strong> (<em>Tensor</em><em> | </em><em>float</em>) – Temperature parameter(s) governing the smoothness of the sigmoid
approximation to the constraint indicators. For more details, on this
parameter, see the docs of <cite>compute_smoothed_feasibility_indicator</cite>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.monte_carlo.qSimpleRegret">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.monte_carlo.</span></span><span class="sig-name descname"><span class="pre">qSimpleRegret</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/monte_carlo.html#qSimpleRegret"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.monte_carlo.qSimpleRegret" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.monte_carlo.SampleReducingMCAcquisitionFunction" title="botorch.acquisition.monte_carlo.SampleReducingMCAcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">SampleReducingMCAcquisitionFunction</span></code></a></p>
<p>MC-based batch Simple Regret.</p>
<p>Samples from the joint posterior over the q-batch and computes the simple regret.</p>
<p><cite>qSR(X) = E(max Y), Y ~ f(X), X = (x_1,…,x_q)</cite></p>
<p>Constraints should be provided as a <cite>ConstrainedMCObjective</cite>.
Passing <cite>constraints</cite> as an argument is not supported. This is because
<cite>SampleReducingMCAcquisitionFunction</cite> computes the acquisition values on the sample
level and then weights the sample-level acquisition values by a soft feasibility
indicator. Hence, it expects non-log acquisition function values to be
non-negative. <cite>qSimpleRegret</cite> acquisition values can be negative, so we instead use
a <cite>ConstrainedMCObjective</cite> which applies constraints to the objectives (e.g. before
computing the acquisition function) and shifts negative objective values using
an infeasible cost to ensure non-negativity (before applying constraints and
shifting them back).</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sampler</span> <span class="o">=</span> <span class="n">SobolQMCNormalSampler</span><span class="p">(</span><span class="mi">1024</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qSR</span> <span class="o">=</span> <span class="n">qSimpleRegret</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">sampler</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qsr</span> <span class="o">=</span> <span class="n">qSR</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
</pre></div>
</div>
<p>q-Simple Regret.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted model.</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – The sampler used to draw base samples. See <cite>MCAcquisitionFunction</cite>
more details.</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><em>MCAcquisitionObjective</em></a><em> | </em><em>None</em>) – The MCAcquisitionObjective under which the samples are
evaluated. Defaults to <cite>IdentityMCObjective()</cite>.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – A PosteriorTransform (optional).</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>m x d</cite>-dim Tensor of <cite>m</cite> design points that have
points that have been submitted for function evaluation
but have not yet been evaluated.  Concatenated into X upon
forward call.  Copied and set to have no gradient.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.monte_carlo.qUpperConfidenceBound">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.monte_carlo.</span></span><span class="sig-name descname"><span class="pre">qUpperConfidenceBound</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/monte_carlo.html#qUpperConfidenceBound"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.monte_carlo.qUpperConfidenceBound" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.monte_carlo.SampleReducingMCAcquisitionFunction" title="botorch.acquisition.monte_carlo.SampleReducingMCAcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">SampleReducingMCAcquisitionFunction</span></code></a></p>
<p>MC-based batch Upper Confidence Bound.</p>
<p>Uses a reparameterization to extend UCB to qUCB for q &gt; 1 (See Appendix A
of [Wilson2017reparam].)</p>
<p><cite>qUCB = E(max(mu + |Y_tilde - mu|))</cite>, where <cite>Y_tilde ~ N(mu, beta pi/2 Sigma)</cite>
and <cite>f(X)</cite> has distribution <cite>N(mu, Sigma)</cite>.</p>
<p>Constraints should be provided as a <cite>ConstrainedMCObjective</cite>.
Passing <cite>constraints</cite> as an argument is not supported. This is because
<cite>SampleReducingMCAcquisitionFunction</cite> computes the acquisition values on the sample
level and then weights the sample-level acquisition values by a soft feasibility
indicator. Hence, it expects non-log acquisition function values to be
non-negative. <cite>qUpperConfidenceBound</cite> acquisition values can be negative, so we
instead use a <cite>ConstrainedMCObjective</cite> which applies constraints to the objectives
(e.g. before computing the acquisition function) and shifts negative objective
values using an infeasible cost to ensure non-negativity (before applying
constraints and shifting them back).</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sampler</span> <span class="o">=</span> <span class="n">SobolQMCNormalSampler</span><span class="p">(</span><span class="mi">1024</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qUCB</span> <span class="o">=</span> <span class="n">qUpperConfidenceBound</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">sampler</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qucb</span> <span class="o">=</span> <span class="n">qUCB</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
</pre></div>
</div>
<p>q-Upper Confidence Bound.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted model.</p></li>
<li><p><strong>beta</strong> (<em>float</em>) – Controls tradeoff between mean and standard deviation in UCB.</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – The sampler used to draw base samples. See <cite>MCAcquisitionFunction</cite>
more details.</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><em>MCAcquisitionObjective</em></a><em> | </em><em>None</em>) – The MCAcquisitionObjective under which the samples are
evaluated. Defaults to <cite>IdentityMCObjective()</cite>.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – A PosteriorTransform (optional).</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x m x d</cite>-dim Tensor of <cite>m</cite> design points that have
points that have been submitted for function evaluation but have not yet
been evaluated. Concatenated into X upon forward call. Copied and set to
have no gradient.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.monte_carlo.qLowerConfidenceBound">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.monte_carlo.</span></span><span class="sig-name descname"><span class="pre">qLowerConfidenceBound</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/monte_carlo.html#qLowerConfidenceBound"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.monte_carlo.qLowerConfidenceBound" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.monte_carlo.qUpperConfidenceBound" title="botorch.acquisition.monte_carlo.qUpperConfidenceBound"><code class="xref py py-class docutils literal notranslate"><span class="pre">qUpperConfidenceBound</span></code></a></p>
<p>MC-based batched lower confidence bound.</p>
<p>This acquisition function is useful for confident/risk-averse decision making.
This acquisition function is intended to be maximized as with qUpperConfidenceBound,
but the qLowerConfidenceBound will be pessimistic in the face of uncertainty and
lead to conservative candidates.</p>
<p>q-Upper Confidence Bound.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted model.</p></li>
<li><p><strong>beta</strong> (<em>float</em>) – Controls tradeoff between mean and standard deviation in UCB.</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – The sampler used to draw base samples. See <cite>MCAcquisitionFunction</cite>
more details.</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><em>MCAcquisitionObjective</em></a><em> | </em><em>None</em>) – The MCAcquisitionObjective under which the samples are
evaluated. Defaults to <cite>IdentityMCObjective()</cite>.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – A PosteriorTransform (optional).</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x m x d</cite>-dim Tensor of <cite>m</cite> design points that have
points that have been submitted for function evaluation but have not yet
been evaluated. Concatenated into X upon forward call. Copied and set to
have no gradient.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.monte_carlo.qPosteriorStandardDeviation">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.monte_carlo.</span></span><span class="sig-name descname"><span class="pre">qPosteriorStandardDeviation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/monte_carlo.html#qPosteriorStandardDeviation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.monte_carlo.qPosteriorStandardDeviation" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.monte_carlo.SampleReducingMCAcquisitionFunction" title="botorch.acquisition.monte_carlo.SampleReducingMCAcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">SampleReducingMCAcquisitionFunction</span></code></a></p>
<p>MC-based batch Posterior Standard Deviation.</p>
<p>An acquisition function for pure exploration.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sampler</span> <span class="o">=</span> <span class="n">SobolQMCNormalSampler</span><span class="p">(</span><span class="mi">1024</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qPSTD</span> <span class="o">=</span> <span class="n">qPosteriorStandardDeviation</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">sampler</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">std</span> <span class="o">=</span> <span class="n">qPSTD</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
</pre></div>
</div>
<p>q-Posterior Standard Deviation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted model.</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – The sampler used to draw base samples. See <cite>MCAcquisitionFunction</cite>
more details.</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><em>MCAcquisitionObjective</em></a><em> | </em><em>None</em>) – The MCAcquisitionObjective under which the samples are
evaluated. Defaults to <cite>IdentityMCObjective()</cite>.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – A PosteriorTransform (optional).</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x m x d</cite>-dim Tensor of <cite>m</cite> design points that have
points that have been submitted for function evaluation but have not yet
been evaluated. Concatenated into X upon forward call. Copied and set to
have no gradient.</p></li>
<li><p><strong>constraints</strong> (<em>list</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of constraint callables which map a Tensor of posterior
samples of dimension <cite>sample_shape x batch-shape x q x m</cite>-dim to a
<cite>sample_shape x batch-shape x q</cite>-dim Tensor. The associated constraints
are considered satisfied if the output is less than zero.</p></li>
<li><p><strong>eta</strong> (<em>Tensor</em><em> | </em><em>float</em>) – Temperature parameter(s) governing the smoothness of the sigmoid
approximation to the constraint indicators. For more details, on this
parameter, see the docs of <cite>compute_smoothed_feasibility_indicator</cite>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<p id="module-botorch.acquisition.logei">Monte-Carlo variants of the LogEI family of improvements-based acquisition functions,
see <a class="reference internal" href="#ament2023logei" id="id8"><span>[Ament2023logei]</span></a> for details.</p>
<p>References</p>
<div role="list" class="citation-list">
<div class="citation" id="ament2023logei" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Ament2023logei<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id2">1</a>,<a role="doc-backlink" href="#id3">2</a>,<a role="doc-backlink" href="#id4">3</a>,<a role="doc-backlink" href="#id8">4</a>,<a role="doc-backlink" href="#id9">5</a>,<a role="doc-backlink" href="#id10">6</a>,<a role="doc-backlink" href="#id29">7</a>,<a role="doc-backlink" href="#id30">8</a>,<a role="doc-backlink" href="#id36">9</a>)</span>
<p>S. Ament, S. Daulton, D. Eriksson, M. Balandat, and E. Bakshy.
Unexpected Improvements to Expected Improvement for Bayesian Optimization. Advances
in Neural Information Processing Systems 36, 2023.</p>
</div>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.logei.LogImprovementMCAcquisitionFunction">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.logei.</span></span><span class="sig-name descname"><span class="pre">LogImprovementMCAcquisitionFunction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fat</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau_max</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/logei.html#LogImprovementMCAcquisitionFunction"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.logei.LogImprovementMCAcquisitionFunction" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.monte_carlo.SampleReducingMCAcquisitionFunction" title="botorch.acquisition.monte_carlo.SampleReducingMCAcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">SampleReducingMCAcquisitionFunction</span></code></a></p>
<p>Abstract base class for Monte-Carlo-based batch LogEI acquisition functions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted model.</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – The sampler used to draw base samples. If not given,
a sampler is generated using <cite>get_sampler</cite>.
NOTE: For posteriors that do not support base samples,
a sampler compatible with intended use case must be provided.
See <cite>ForkedRNGSampler</cite> and <cite>StochasticSampler</cite> as examples.</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><em>MCAcquisitionObjective</em></a><em> | </em><em>None</em>) – The MCAcquisitionObjective under which the samples are
evaluated. Defaults to <cite>IdentityMCObjective()</cite>.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – A PosteriorTransform (optional).</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape, m x d</cite>-dim Tensor of <cite>m</cite> design points
that have points that have been submitted for function evaluation
but have not yet been evaluated.</p></li>
<li><p><strong>constraints</strong> (<em>list</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of constraint callables which map a Tensor of posterior
samples of dimension <cite>sample_shape x batch-shape x q x m</cite>-dim to a
<cite>sample_shape x batch-shape x q</cite>-dim Tensor. The associated constraints
are satisfied if <cite>constraint(samples) &lt; 0</cite>.</p></li>
<li><p><strong>eta</strong> (<em>Tensor</em><em> | </em><em>float</em>) – Temperature parameter(s) governing the smoothness of the sigmoid
approximation to the constraint indicators. See the docs of
<cite>compute_(log_)constraint_indicator</cite> for more details on this parameter.</p></li>
<li><p><strong>fat</strong> (<em>bool</em>) – Toggles the logarithmic / linear asymptotic behavior of the smooth
approximation to the ReLU.</p></li>
<li><p><strong>tau_max</strong> (<em>float</em>) – Temperature parameter controlling the sharpness of the
approximation to the <cite>max</cite> operator over the <cite>q</cite> candidate points.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.logei.qLogExpectedImprovement">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.logei.</span></span><span class="sig-name descname"><span class="pre">qLogExpectedImprovement</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">best_f</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fat</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau_max</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau_relu</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-06</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/logei.html#qLogExpectedImprovement"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.logei.qLogExpectedImprovement" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.logei.LogImprovementMCAcquisitionFunction" title="botorch.acquisition.logei.LogImprovementMCAcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">LogImprovementMCAcquisitionFunction</span></code></a></p>
<p>MC-based batch Log Expected Improvement.</p>
<p>This computes qLogEI by
(1) sampling the joint posterior over q points,
(2) evaluating the smoothed log improvement over the current best for each sample,
(3) smoothly maximizing over q, and
(4) averaging over the samples in log space.</p>
<p>See <a class="reference internal" href="#ament2023logei" id="id9"><span>[Ament2023logei]</span></a> for details. Formally,</p>
<p><cite>qLogEI(X) ~ log(qEI(X)) = log(E(max(max Y - best_f, 0)))</cite>.</p>
<p>where <cite>Y ~ f(X)</cite>, and <cite>X = (x_1,…,x_q)</cite>, .</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">best_f</span> <span class="o">=</span> <span class="n">train_Y</span><span class="o">.</span><span class="n">max</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sampler</span> <span class="o">=</span> <span class="n">SobolQMCNormalSampler</span><span class="p">(</span><span class="mi">1024</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qLogEI</span> <span class="o">=</span> <span class="n">qLogExpectedImprovement</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">best_f</span><span class="p">,</span> <span class="n">sampler</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qei</span> <span class="o">=</span> <span class="n">qLogEI</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
</pre></div>
</div>
<p>q-Log Expected Improvement.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted model.</p></li>
<li><p><strong>best_f</strong> (<em>float</em><em> | </em><em>Tensor</em>) – The best objective value observed so far (assumed noiseless). Can be
a scalar, or a <cite>batch_shape</cite>-dim tensor. In case of a batched model, the
tensor can specify different values for each element of the batch.</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – The sampler used to draw base samples. See <cite>MCAcquisitionFunction</cite>
more details.</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><em>MCAcquisitionObjective</em></a><em> | </em><em>None</em>) – The MCAcquisitionObjective under which the samples are evaluated.
Defaults to <cite>IdentityMCObjective()</cite>.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – A PosteriorTransform (optional).</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>m x d</cite>-dim Tensor of <cite>m</cite> design points that have been
submitted for function evaluation but have not yet been evaluated.
Concatenated into <cite>X</cite> upon forward call. Copied and set to have no
gradient.</p></li>
<li><p><strong>constraints</strong> (<em>list</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of constraint callables which map a Tensor of posterior
samples of dimension <cite>sample_shape x batch-shape x q x m</cite>-dim to a
<cite>sample_shape x batch-shape x q</cite>-dim Tensor. The associated constraints
are satisfied if <cite>constraint(samples) &lt; 0</cite>.</p></li>
<li><p><strong>eta</strong> (<em>Tensor</em><em> | </em><em>float</em>) – Temperature parameter(s) governing the smoothness of the sigmoid
approximation to the constraint indicators. See the docs of
<cite>compute_(log_)smoothed_constraint_indicator</cite> for details.</p></li>
<li><p><strong>fat</strong> (<em>bool</em>) – Toggles the logarithmic / linear asymptotic behavior of the smooth
approximation to the ReLU.</p></li>
<li><p><strong>tau_max</strong> (<em>float</em>) – Temperature parameter controlling the sharpness of the smooth
approximations to max.</p></li>
<li><p><strong>tau_relu</strong> (<em>float</em>) – Temperature parameter controlling the sharpness of the smooth
approximations to ReLU.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.logei.qLogNoisyExpectedImprovement">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.logei.</span></span><span class="sig-name descname"><span class="pre">qLogNoisyExpectedImprovement</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_baseline</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fat</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prune_baseline</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_root</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau_max</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau_relu</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-06</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">marginalize_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">incremental</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/logei.html#qLogNoisyExpectedImprovement"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.logei.qLogNoisyExpectedImprovement" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.logei.LogImprovementMCAcquisitionFunction" title="botorch.acquisition.logei.LogImprovementMCAcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">LogImprovementMCAcquisitionFunction</span></code></a>, <a class="reference internal" href="#botorch.acquisition.cached_cholesky.CachedCholeskyMCSamplerMixin" title="botorch.acquisition.cached_cholesky.CachedCholeskyMCSamplerMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">CachedCholeskyMCSamplerMixin</span></code></a></p>
<p>MC-based batch Log Noisy Expected Improvement.</p>
<p>This function does not assume a <cite>best_f</cite> is known (which would require
noiseless observations). Instead, it uses samples from the joint posterior
over the <cite>q</cite> test points and previously observed points. A smooth approximation
to the canonical improvement over previously observed points is computed
for each sample and the logarithm of the average is returned.</p>
<p>See <a class="reference internal" href="#ament2023logei" id="id10"><span>[Ament2023logei]</span></a> for details. Formally,</p>
<p><cite>qLogNEI(X) ~ log(qNEI(X)) = Log E(max(max Y - max Y_baseline, 0))</cite>,</p>
<p>where <cite>(Y, Y_baseline) ~ f((X, X_baseline)), X = (x_1,…,x_q)</cite>.</p>
<p>For optimizing a batch of <cite>q &gt; 1</cite> points using sequential greedy optimization,
the incremental improvement from the latest point is computed and returned by
default. I.e. the pending points are treated X_baseline. Often, the incremental
EI is easier to optimize.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sampler</span> <span class="o">=</span> <span class="n">SobolQMCNormalSampler</span><span class="p">(</span><span class="mi">1024</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qLogNEI</span> <span class="o">=</span> <span class="n">qLogNoisyExpectedImprovement</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_X</span><span class="p">,</span> <span class="n">sampler</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">acqval</span> <span class="o">=</span> <span class="n">qLogNEI</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
</pre></div>
</div>
<p>q-Noisy Expected Improvement.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted model.</p></li>
<li><p><strong>X_baseline</strong> (<em>Tensor</em>) – A <cite>batch_shape x r x d</cite>-dim Tensor of <cite>r</cite> design points
that have already been observed. These points are considered as
the potential best design point.</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – The sampler used to draw base samples. See <cite>MCAcquisitionFunction</cite>
more details.</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><em>MCAcquisitionObjective</em></a><em> | </em><em>None</em>) – The MCAcquisitionObjective under which the samples are
evaluated. Defaults to <cite>IdentityMCObjective()</cite>.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – A PosteriorTransform (optional).</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x m x d</cite>-dim Tensor of <cite>m</cite> design points
that have points that have been submitted for function evaluation
but have not yet been evaluated. Concatenated into <cite>X</cite> upon
forward call. Copied and set to have no gradient.</p></li>
<li><p><strong>constraints</strong> (<em>list</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of constraint callables which map a Tensor of posterior
samples of dimension <cite>sample_shape x batch-shape x q x m</cite>-dim to a
<cite>sample_shape x batch-shape x q</cite>-dim Tensor. The associated constraints
are satisfied if <cite>constraint(samples) &lt; 0</cite>.</p></li>
<li><p><strong>eta</strong> (<em>Tensor</em><em> | </em><em>float</em>) – Temperature parameter(s) governing the smoothness of the sigmoid
approximation to the constraint indicators. See the docs of
<cite>compute_(log_)smoothed_constraint_indicator</cite> for details.</p></li>
<li><p><strong>fat</strong> (<em>bool</em>) – Toggles the logarithmic / linear asymptotic behavior of the smooth
approximation to the ReLU.</p></li>
<li><p><strong>prune_baseline</strong> (<em>bool</em>) – If True, remove points in <cite>X_baseline</cite> that are
highly unlikely to be the best point. This can significantly
improve performance and is generally recommended. In order to
customize pruning parameters, instead manually call
<cite>botorch.acquisition.utils.prune_inferior_points</cite> on <cite>X_baseline</cite>
before instantiating the acquisition function.</p></li>
<li><p><strong>cache_root</strong> (<em>bool</em>) – A boolean indicating whether to cache the root
decomposition over <cite>X_baseline</cite> and use low-rank updates.</p></li>
<li><p><strong>tau_max</strong> (<em>float</em>) – Temperature parameter controlling the sharpness of the smooth
approximations to max.</p></li>
<li><p><strong>tau_relu</strong> (<em>float</em>) – Temperature parameter controlling the sharpness of the smooth
approximations to ReLU.</p></li>
<li><p><strong>marginalize_dim</strong> (<em>int</em><em> | </em><em>None</em>) – The dimension to marginalize over.</p></li>
<li><p><strong>incremental</strong> (<em>bool</em>) – Whether to compute incremental EI over the pending points
or compute EI of the joint batch improvement (including pending
points).</p></li>
</ul>
</dd>
</dl>
<p>TODO: similar to qNEHVI, when we are using sequential greedy candidate
selection, we could incorporate pending points X_baseline and compute
the incremental q(Log)NEI from the new point. This would greatly increase
efficiency for large batches.</p>
<dl class="py property">
<dt class="sig sig-object py" id="botorch.acquisition.logei.qLogNoisyExpectedImprovement.X_baseline">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">X_baseline</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tensor</span></em><a class="headerlink" href="#botorch.acquisition.logei.qLogNoisyExpectedImprovement.X_baseline" title="Link to this definition"></a></dt>
<dd><p>Returns the set of pointsthat should be considered as the incumbent.</p>
<p>For incremental EI, this contains the previously evaluated points
(X_baseline) and pending points (X_pending). For non-incremental
EI, this contains the  previously evaluated points (X_baseline).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.logei.qLogNoisyExpectedImprovement.set_X_pending">
<span class="sig-name descname"><span class="pre">set_X_pending</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/logei.html#qLogNoisyExpectedImprovement.set_X_pending"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.logei.qLogNoisyExpectedImprovement.set_X_pending" title="Link to this definition"></a></dt>
<dd><p>Informs the acquisition function about pending design points.</p>
<p>Here pending points are concatenated with X_baseline and incremental
NEI is computed.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – <cite>n x d</cite> Tensor with <cite>n</cite> <cite>d</cite>-dim design points that have
been submitted for evaluation but have not yet been evaluated.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.logei.qLogNoisyExpectedImprovement.compute_best_f">
<span class="sig-name descname"><span class="pre">compute_best_f</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obj</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/logei.html#qLogNoisyExpectedImprovement.compute_best_f"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.logei.qLogNoisyExpectedImprovement.compute_best_f" title="Link to this definition"></a></dt>
<dd><p>Computes the best (feasible) noisy objective value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>obj</strong> (<em>Tensor</em>) – <cite>sample_shape x batch_shape x q</cite>-dim Tensor of objectives in forward.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>sample_shape x batch_shape</cite>-dim Tensor of best feasible objectives.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.logei.check_tau">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.logei.</span></span><span class="sig-name descname"><span class="pre">check_tau</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tau</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/logei.html#check_tau"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.logei.check_tau" title="Link to this definition"></a></dt>
<dd><p>Checks the validity of the tau arguments of the functions below, and returns
<cite>tau</cite> if it is valid.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tau</strong> (<em>FloatOrTensor</em>)</p></li>
<li><p><strong>name</strong> (<em>str</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>FloatOrTensor</em></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-botorch.acquisition.multi_objective.analytic">
<span id="multi-objective-analytic-acquisition-functions"></span><h3>Multi-Objective Analytic Acquisition Functions<a class="headerlink" href="#module-botorch.acquisition.multi_objective.analytic" title="Link to this heading"></a></h3>
<p>Analytic Acquisition Functions for Multi-objective Bayesian optimization.</p>
<p>References</p>
<div role="list" class="citation-list">
<div class="citation" id="yang2019" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Yang2019<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id11">1</a>,<a role="doc-backlink" href="#id13">2</a>,<a role="doc-backlink" href="#id14">3</a>,<a role="doc-backlink" href="#id15">4</a>,<a role="doc-backlink" href="#id16">5</a>)</span>
<p>Yang, K., Emmerich, M., Deutz, A. et al. Efficient computation of expected
hypervolume improvement using box decomposition algorithms. J Glob Optim 75,
3–34 (2019)</p>
</div>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.analytic.ExpectedHypervolumeImprovement">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.multi_objective.analytic.</span></span><span class="sig-name descname"><span class="pre">ExpectedHypervolumeImprovement</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ref_point</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">partitioning</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/analytic.html#ExpectedHypervolumeImprovement"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.analytic.ExpectedHypervolumeImprovement" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.multi_objective.base.MultiObjectiveAnalyticAcquisitionFunction" title="botorch.acquisition.multi_objective.base.MultiObjectiveAnalyticAcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiObjectiveAnalyticAcquisitionFunction</span></code></a></p>
<p>Expected Hypervolume Improvement supporting m&gt;=2 outcomes.</p>
<p>This implements the computes EHVI using the algorithm from <a class="reference internal" href="#yang2019" id="id11"><span>[Yang2019]</span></a>, but
additionally computes gradients via auto-differentiation as proposed by
<a class="reference internal" href="#daulton2020qehvi" id="id12"><span>[Daulton2020qehvi]</span></a>.</p>
<p>Note: this is currently inefficient in two ways due to the binary partitioning
algorithm that we use for the box decomposition:</p>
<blockquote>
<div><ul class="simple">
<li><p>We have more boxes in our decomposition</p></li>
<li><dl class="simple">
<dt>If we used a box decomposition that used <cite>inf</cite> as the upper bound for</dt><dd><p>the last dimension <em>in all hypercells</em>, then we could reduce the number
of terms we need to compute from 2^m to 2^(m-1). <a class="reference internal" href="#yang2019" id="id13"><span>[Yang2019]</span></a> do this
by using DKLV17 and LKF17 for the box decomposition.</p>
</dd>
</dl>
</li>
</ul>
</div></blockquote>
<p>TODO: Use DKLV17 and LKF17 for the box decomposition as in <a class="reference internal" href="#yang2019" id="id14"><span>[Yang2019]</span></a> for
greater efficiency.</p>
<p>TODO: Add support for outcome constraints.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ref_point</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">EHVI</span> <span class="o">=</span> <span class="n">ExpectedHypervolumeImprovement</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">ref_point</span><span class="p">,</span> <span class="n">partitioning</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ehvi</span> <span class="o">=</span> <span class="n">EHVI</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted model.</p></li>
<li><p><strong>ref_point</strong> (<em>list</em><em>[</em><em>float</em><em>]</em>) – A list with <cite>m</cite> elements representing the reference point
(in the outcome space) w.r.t. to which compute the hypervolume.
This is a reference point for the outcome values (i.e., after
applying <cite>posterior_transform</cite> if provided).</p></li>
<li><p><strong>partitioning</strong> (<a class="reference internal" href="utils.html#botorch.utils.multi_objective.box_decompositions.non_dominated.NondominatedPartitioning" title="botorch.utils.multi_objective.box_decompositions.non_dominated.NondominatedPartitioning"><em>NondominatedPartitioning</em></a>) – A <cite>NondominatedPartitioning</cite> module that provides the non-
dominated front and a partitioning of the non-dominated space in hyper-
rectangles.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – A <cite>PosteriorTransform</cite>.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.analytic.ExpectedHypervolumeImprovement.psi">
<span class="sig-name descname"><span class="pre">psi</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lower</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">upper</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mu</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/analytic.html#ExpectedHypervolumeImprovement.psi"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.analytic.ExpectedHypervolumeImprovement.psi" title="Link to this definition"></a></dt>
<dd><p>Compute Psi function.</p>
<p>For each cell i and outcome k:</p>
<blockquote>
<div><p>Psi(lower_{i,k}, upper_{i,k}, mu_k, sigma_k) = (
sigma_k * PDF((upper_{i,k} - mu_k) / sigma_k) + (
mu_k - lower_{i,k}
) * (1 - CDF(upper_{i,k} - mu_k) / sigma_k)
)</p>
</div></blockquote>
<p>See Equation 19 in <a class="reference internal" href="#yang2019" id="id15"><span>[Yang2019]</span></a> for more details.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lower</strong> (<em>Tensor</em>) – A <cite>num_cells x m</cite>-dim tensor of lower cell bounds</p></li>
<li><p><strong>upper</strong> (<em>Tensor</em>) – A <cite>num_cells x m</cite>-dim tensor of upper cell bounds</p></li>
<li><p><strong>mu</strong> (<em>Tensor</em>) – A <cite>batch_shape x 1 x m</cite>-dim tensor of means</p></li>
<li><p><strong>sigma</strong> (<em>Tensor</em>) – A <cite>batch_shape x 1 x m</cite>-dim tensor of standard deviations (clamped).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape x num_cells x m</cite>-dim tensor of values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.analytic.ExpectedHypervolumeImprovement.nu">
<span class="sig-name descname"><span class="pre">nu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lower</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">upper</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mu</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/analytic.html#ExpectedHypervolumeImprovement.nu"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.analytic.ExpectedHypervolumeImprovement.nu" title="Link to this definition"></a></dt>
<dd><p>Compute Nu function.</p>
<p>For each cell i and outcome k:</p>
<blockquote>
<div><p>nu(lower_{i,k}, upper_{i,k}, mu_k, sigma_k) = (
upper_{i,k} - lower_{i,k}
) * (1 - CDF((upper_{i,k} - mu_k) / sigma_k))</p>
</div></blockquote>
<p>See Equation 25 in <a class="reference internal" href="#yang2019" id="id16"><span>[Yang2019]</span></a> for more details.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lower</strong> (<em>Tensor</em>) – A <cite>num_cells x m</cite>-dim tensor of lower cell bounds</p></li>
<li><p><strong>upper</strong> (<em>Tensor</em>) – A <cite>num_cells x m</cite>-dim tensor of upper cell bounds</p></li>
<li><p><strong>mu</strong> (<em>Tensor</em>) – A <cite>batch_shape x 1 x m</cite>-dim tensor of means</p></li>
<li><p><strong>sigma</strong> (<em>Tensor</em>) – A <cite>batch_shape x 1 x m</cite>-dim tensor of standard deviations (clamped).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape x num_cells x m</cite>-dim tensor of values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.analytic.ExpectedHypervolumeImprovement.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/analytic.html#ExpectedHypervolumeImprovement.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.analytic.ExpectedHypervolumeImprovement.forward" title="Link to this definition"></a></dt>
<dd><p>Takes in a <cite>batch_shape x 1 x d</cite> X Tensor of t-batches with <cite>1</cite> <cite>d</cite>-dim
design point each, and returns a Tensor with shape <cite>batch_shape’</cite>, where
<cite>batch_shape’</cite> is the broadcasted batch shape of model and input <cite>X</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-botorch.acquisition.multi_objective.hypervolume_knowledge_gradient">
<span id="multi-objective-hypervolume-knowledge-gradient-acquisition-functions"></span><h3>Multi-Objective Hypervolume Knowledge Gradient Acquisition Functions<a class="headerlink" href="#module-botorch.acquisition.multi_objective.hypervolume_knowledge_gradient" title="Link to this heading"></a></h3>
<p>The hypervolume knowledge gradient acquisition function (HVKG).</p>
<p>References:</p>
<div role="list" class="citation-list">
<div class="citation" id="daulton2023hvkg" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Daulton2023hvkg<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id17">1</a>,<a role="doc-backlink" href="#id18">2</a>,<a role="doc-backlink" href="#id19">3</a>,<a role="doc-backlink" href="#id20">4</a>)</span>
<p>S. Daulton, M. Balandat, E. Bakshy. Hypervolume Knowledge Gradient: A
Lookahead Approach for Multi-Objective Bayesian Optimization with Partial
Information. Proceedings of the 40th International Conference on Machine
Learning, 2023.</p>
</div>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.hypervolume_knowledge_gradient.qHypervolumeKnowledgeGradient">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.multi_objective.hypervolume_knowledge_gradient.</span></span><span class="sig-name descname"><span class="pre">qHypervolumeKnowledgeGradient</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ref_point</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_fantasies</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_pareto</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inner_sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_evaluation_mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending_evaluation_mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">current_value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_posterior_mean</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cost_aware_utility</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/hypervolume_knowledge_gradient.html#qHypervolumeKnowledgeGradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.hypervolume_knowledge_gradient.qHypervolumeKnowledgeGradient" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.decoupled.DecoupledAcquisitionFunction" title="botorch.acquisition.decoupled.DecoupledAcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">DecoupledAcquisitionFunction</span></code></a>, <a class="reference internal" href="#botorch.acquisition.multi_objective.base.MultiObjectiveMCAcquisitionFunction" title="botorch.acquisition.multi_objective.base.MultiObjectiveMCAcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiObjectiveMCAcquisitionFunction</span></code></a>, <a class="reference internal" href="#botorch.acquisition.acquisition.OneShotAcquisitionFunction" title="botorch.acquisition.acquisition.OneShotAcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">OneShotAcquisitionFunction</span></code></a></p>
<p>Batch Hypervolume Knowledge Gradient using one-shot optimization.</p>
<p>The hypervolume knowledge gradient seeks to maximize the difference in
hypervolume of the hypervolume-maximizing set of a fixed size after
conditioning the unknown observation(s) that would be recevied if X where
evalauted. See <a class="reference internal" href="#daulton2023hvkg" id="id17"><span>[Daulton2023hvkg]</span></a> for details.</p>
<p>This computes the batch Hypervolume Knowledge Gradient using fantasies for
the outer expectation and MC-sampling for the inner expectation.</p>
<p>In addition to the design variables, the input <cite>X</cite> also includes variables
for the optimal designs for each of the fantasy models (Note this is
<cite>N x N_pareto</cite> optimal designs). For a fixed number of fantasies, all points
in <cite>X</cite> can be optimized in a “one-shot” fashion.</p>
<p>q-Hypervolume Knowledge Gradient.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted model. Must support fantasizing.</p></li>
<li><p><strong>ref_point</strong> (<em>Tensor</em>) – A <cite>m</cite>-dim tensor containing the reference point.</p></li>
<li><p><strong>num_fantasies</strong> (<em>int</em>) – The number of fantasy points to use. More fantasy
points result in a better approximation, at the expense of
memory and wall time. Unused if <cite>sampler</cite> is specified.</p></li>
<li><p><strong>num_pareto</strong> (<em>int</em>) – The number of pareto optimal designs to consider.</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.list_sampler.ListSampler" title="botorch.sampling.list_sampler.ListSampler"><em>ListSampler</em></a><em> | </em><em>None</em>) – The sampler used to sample fantasy observations. Optional
if <cite>num_fantasies</cite> is specified. The optimization performance
does not seem particularly sensitive to the number of fantasies.
As the number of fantasies increases, the estimation of the
expectation over fantasies becomes more accurate, but the one-
shot optimization problem gets harder as there are more “fantasy”
designs that need to be optimized.</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.multi_objective.objective.MCMultiOutputObjective" title="botorch.acquisition.multi_objective.objective.MCMultiOutputObjective"><em>MCMultiOutputObjective</em></a><em> | </em><em>None</em>) – The objective under which the samples are evaluated. If
<cite>None</cite>, then the analytic posterior mean is used. Otherwise, the
objective is MC-evaluated (using inner_sampler).</p></li>
<li><p><strong>inner_sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – The sampler used for inner sampling. Ignored if the
objective is <cite>None</cite>.</p></li>
<li><p><strong>X_evaluation_mask</strong> (<em>list</em><em>[</em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – A <cite>q x m</cite>-dim tensor of booleans indicating which
objective(s) each of the <cite>q</cite> points should be evaluated on.</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>n’ x d</cite>-dim Tensor of <cite>m</cite> design points that have
points that have been submitted for function evaluation
but have not yet been evaluated.</p></li>
<li><p><strong>X_pending_evaluation_mask</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>n’ x m</cite>-dim tensor of booleans indicating
which objective(s) each of the <cite>n’</cite> pending points are being
evaluated on.</p></li>
<li><p><strong>current_value</strong> (<em>Tensor</em><em> | </em><em>None</em>) – The current value, i.e. the expected best objective
given the observed points <cite>D</cite>. If omitted, forward will not
return the actual KG value, but the expected best objective
given the data set <cite>D u X</cite>. If pending points are used,
this should be the current value under the fantasy model
conditioned on the pending points so that the incremental KG value
from the new candidates (not pending points) is used.</p></li>
<li><p><strong>use_posterior_mean</strong> (<em>bool</em>) – If true, optimize the hypervolume of the posterior
mean, otherwise optimize the expected hypervolume. See
<a class="reference internal" href="#daulton2023hvkg" id="id18"><span>[Daulton2023hvkg]</span></a> for details.</p></li>
<li><p><strong>cost_aware_utility</strong> (<a class="reference internal" href="#botorch.acquisition.cost_aware.CostAwareUtility" title="botorch.acquisition.cost_aware.CostAwareUtility"><em>CostAwareUtility</em></a><em> | </em><em>None</em>) – A CostAwareUtility specifying the cost function for
evaluating the <cite>X</cite> on the objectives indicated by <cite>evaluation_mask</cite>.</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.hypervolume_knowledge_gradient.qHypervolumeKnowledgeGradient.cost_sampler">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">cost_sampler</span></span><a class="headerlink" href="#botorch.acquisition.multi_objective.hypervolume_knowledge_gradient.qHypervolumeKnowledgeGradient.cost_sampler" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.hypervolume_knowledge_gradient.qHypervolumeKnowledgeGradient.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/hypervolume_knowledge_gradient.html#qHypervolumeKnowledgeGradient.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.hypervolume_knowledge_gradient.qHypervolumeKnowledgeGradient.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate qKnowledgeGradient on the candidate set <cite>X</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – <p>A <cite>b x (q + num_fantasies) x d</cite> Tensor with <cite>b</cite> t-batches of
<cite>q + num_fantasies</cite> design points each. We split this X tensor
into two parts in the <cite>q</cite> dimension (<cite>dim=-2</cite>). The first <cite>q</cite>
are the q-batch of design points and the last num_fantasies are
the current solutions of the inner optimization problem.</p>
<p><cite>X_fantasies = X[…, -num_fantasies:, :]</cite>
<cite>X_fantasies.shape = b x num_fantasies x d</cite></p>
<p><cite>X_actual = X[…, :-num_fantasies, :]</cite>
<cite>X_actual.shape = b x q x d</cite></p>
</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>A Tensor of shape <cite>b</cite>. For t-batch b, the q-KG value of the design</dt><dd><p><cite>X_actual[b]</cite> is averaged across the fantasy models, where
<cite>X_fantasies[b, i]</cite> is chosen as the final selection for the
<cite>i</cite>-th fantasy model.
NOTE: If <cite>current_value</cite> is not provided, then this is not the
true KG value of <cite>X_actual[b]</cite>, and <cite>X_fantasies[b, : ]</cite> must be
maximized at fixed <cite>X_actual[b]</cite>.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.hypervolume_knowledge_gradient.qHypervolumeKnowledgeGradient.get_augmented_q_batch_size">
<span class="sig-name descname"><span class="pre">get_augmented_q_batch_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">q</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/hypervolume_knowledge_gradient.html#qHypervolumeKnowledgeGradient.get_augmented_q_batch_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.hypervolume_knowledge_gradient.qHypervolumeKnowledgeGradient.get_augmented_q_batch_size" title="Link to this definition"></a></dt>
<dd><p>Get augmented q batch size for one-shot optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>q</strong> (<em>int</em>) – The number of candidates to consider jointly.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The augmented size for one-shot optimization (including variables
parameterizing the fantasy solutions).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.hypervolume_knowledge_gradient.qHypervolumeKnowledgeGradient.extract_candidates">
<span class="sig-name descname"><span class="pre">extract_candidates</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X_full</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/hypervolume_knowledge_gradient.html#qHypervolumeKnowledgeGradient.extract_candidates"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.hypervolume_knowledge_gradient.qHypervolumeKnowledgeGradient.extract_candidates" title="Link to this definition"></a></dt>
<dd><p>We only return X as the set of candidates post-optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X_full</strong> (<em>Tensor</em>) – A <cite>b x (q + num_fantasies) x d</cite>-dim Tensor with <cite>b</cite>
t-batches of <cite>q + num_fantasies</cite> design points each.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>b x q x d</cite>-dim Tensor with <cite>b</cite> t-batches of <cite>q</cite> design points each.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.hypervolume_knowledge_gradient.qMultiFidelityHypervolumeKnowledgeGradient">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.multi_objective.hypervolume_knowledge_gradient.</span></span><span class="sig-name descname"><span class="pre">qMultiFidelityHypervolumeKnowledgeGradient</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ref_point</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_fidelities</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_fantasies=8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_pareto=10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inner_sampler=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_evaluation_mask=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending_evaluation_mask=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">current_value=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cost_aware_utility=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">project=&lt;function</span> <span class="pre">qMultiFidelityHypervolumeKnowledgeGradient.&lt;lambda&gt;&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">valfunc_cls=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">valfunc_argfac=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_posterior_mean=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">**kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/hypervolume_knowledge_gradient.html#qMultiFidelityHypervolumeKnowledgeGradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.hypervolume_knowledge_gradient.qMultiFidelityHypervolumeKnowledgeGradient" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.multi_objective.hypervolume_knowledge_gradient.qHypervolumeKnowledgeGradient" title="botorch.acquisition.multi_objective.hypervolume_knowledge_gradient.qHypervolumeKnowledgeGradient"><code class="xref py py-class docutils literal notranslate"><span class="pre">qHypervolumeKnowledgeGradient</span></code></a></p>
<p>Batch Hypervolume Knowledge Gradient for multi-fidelity optimization.</p>
<p>See <a class="reference internal" href="#daulton2023hvkg" id="id19"><span>[Daulton2023hvkg]</span></a> for details.</p>
<p>A version of <cite>qHypervolumeKnowledgeGradient</cite> that supports multi-fidelity
optimization via a <cite>CostAwareUtility</cite> and the <cite>project</cite> and <cite>expand</cite>
operators. If none of these are set, this acquisition function reduces to
<cite>qHypervolumeKnowledgeGradient</cite>. Through <cite>valfunc_cls</cite> and <cite>valfunc_argfac</cite>,
this can be changed into a custom multi-fidelity acquisition function.</p>
<p>Multi-Fidelity q-Knowledge Gradient (one-shot optimization).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted model. Must support fantasizing.</p></li>
<li><p><strong>ref_point</strong> (<em>Tensor</em>) – A <cite>m</cite>-dim tensor containing the reference point.</p></li>
<li><p><strong>num_fantasies</strong> (<em>int</em>) – The number of fantasy points to use. More fantasy
points result in a better approximation, at the expense of
memory and wall time. Unused if <cite>sampler</cite> is specified.</p></li>
<li><p><strong>num_pareto</strong> (<em>int</em>) – The number of pareto optimal designs to consider.</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – The sampler used to sample fantasy observations. Optional
if <cite>num_fantasies</cite> is specified.</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.multi_objective.objective.MCMultiOutputObjective" title="botorch.acquisition.multi_objective.objective.MCMultiOutputObjective"><em>MCMultiOutputObjective</em></a><em> | </em><em>None</em>) – The objective under which the samples are evaluated. If
<cite>None</cite>, then the analytic posterior mean is used. Otherwise, the
objective is MC-evaluated (using inner_sampler).</p></li>
<li><p><strong>inner_sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – The sampler used for inner sampling. Ignored if the
objective is <cite>None</cite>.</p></li>
<li><p><strong>X_evaluation_mask</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>q x m</cite>-dim tensor of booleans indicating which
objective(s) each of the <cite>q</cite> points should be evaluated on.</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>n’ x d</cite>-dim Tensor of <cite>m</cite> design points that have
points that have been submitted for function evaluation
but have not yet been evaluated.</p></li>
<li><p><strong>X_pending_evaluation_mask</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>n’ x m</cite>-dim tensor of booleans indicating
which objective(s) each of the <cite>n’</cite> pending points are being
evaluated on.</p></li>
<li><p><strong>current_value</strong> (<em>Tensor</em><em> | </em><em>None</em>) – The current value, i.e. the expected best objective
given the observed points <cite>D</cite>. If omitted, forward will not
return the actual KG value, but the expected best objective
given the data set <cite>D u X</cite>. If pending points are used,
this should be the current value under the fantasy model
conditioned on the pending points so that the incremental KG value
from the new candidates (not pending points) is used.</p></li>
<li><p><strong>use_posterior_mean</strong> (<em>bool</em>) – A boolean indicating whether to use the to optimize
the hypervolume of the posterior mean or whether to optimize the
expected hypervolume. See <a class="reference internal" href="#daulton2023hvkg" id="id20"><span>[Daulton2023hvkg]</span></a> for details.</p></li>
<li><p><strong>cost_aware_utility</strong> (<a class="reference internal" href="#botorch.acquisition.cost_aware.CostAwareUtility" title="botorch.acquisition.cost_aware.CostAwareUtility"><em>CostAwareUtility</em></a><em> | </em><em>None</em>) – A CostAwareUtility specifying the cost function for
evaluating the <cite>X</cite> on the objectives indicated by <cite>evaluation_mask</cite>.</p></li>
<li><p><strong>project</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em>) – A callable mapping a <cite>batch_shape x q x d</cite> tensor of design
points to a tensor with shape <cite>batch_shape x q_term x d</cite> projected
to the desired target set (e.g. the target fidelities in case of
multi-fidelity optimization). For the basic case, <cite>q_term = q</cite>.</p></li>
<li><p><strong>valfunc_cls</strong> (<em>type</em><em>[</em><a class="reference internal" href="#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><em>AcquisitionFunction</em></a><em>] </em><em>| </em><em>None</em>) – An acquisition function class to be used as the terminal
value function.</p></li>
<li><p><strong>valfunc_argfac</strong> (<em>Callable</em><em>[</em><em>[</em><a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a><em>]</em><em>, </em><em>dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>] </em><em>| </em><em>None</em>) – An argument factory, i.e. callable that maps a <cite>Model</cite>
to a dictionary of kwargs for the terminal value function (e.g.
<cite>best_f</cite> for <cite>ExpectedImprovement</cite>).</p></li>
<li><p><strong>target_fidelities</strong> (<em>dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>]</em>)</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.hypervolume_knowledge_gradient.qMultiFidelityHypervolumeKnowledgeGradient.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/hypervolume_knowledge_gradient.html#qMultiFidelityHypervolumeKnowledgeGradient.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.hypervolume_knowledge_gradient.qMultiFidelityHypervolumeKnowledgeGradient.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate qMultiFidelityKnowledgeGradient on the candidate set <cite>X</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – <p>A <cite>b x (q + num_fantasies) x d</cite> Tensor with <cite>b</cite> t-batches of
<cite>q + num_fantasies</cite> design points each. We split this X tensor
into two parts in the <cite>q</cite> dimension (<cite>dim=-2</cite>). The first <cite>q</cite>
are the q-batch of design points and the last num_fantasies are
the current solutions of the inner optimization problem.</p>
<p><cite>X_fantasies = X[…, -num_fantasies:, :]</cite>
<cite>X_fantasies.shape = b x num_fantasies x d</cite></p>
<p><cite>X_actual = X[…, :-num_fantasies, :]</cite>
<cite>X_actual.shape = b x q x d</cite></p>
<p>In addition, <cite>X</cite> may be augmented with fidelity parameteres as
part of thee <cite>d</cite>-dimension. Projecting fidelities to the target
fidelity is handled by <cite>project</cite>.</p>
</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>A Tensor of shape <cite>b</cite>. For t-batch b, the q-KG value of the design</dt><dd><p><cite>X_actual[b]</cite> is averaged across the fantasy models, where
<cite>X_fantasies[b, i]</cite> is chosen as the final selection for the
<cite>i</cite>-th fantasy model.
NOTE: If <cite>current_value</cite> is not provided, then this is not the
true KG value of <cite>X_actual[b]</cite>, and <cite>X_fantasies[b, : ]</cite> must be
maximized at fixed <cite>X_actual[b]</cite>.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-botorch.acquisition.multi_objective.joint_entropy_search">
<span id="multi-objective-joint-entropy-search-acquisition-functions"></span><h3>Multi-Objective Joint Entropy Search Acquisition Functions<a class="headerlink" href="#module-botorch.acquisition.multi_objective.joint_entropy_search" title="Link to this heading"></a></h3>
<p>Acquisition functions for joint entropy search for Bayesian optimization (JES).</p>
<p>References:</p>
<div role="list" class="citation-list">
<div class="citation" id="tu2022" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Tu2022<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id21">1</a>,<a role="doc-backlink" href="#id24">2</a>)</span>
<p>B. Tu, A. Gandy, N. Kantas and B.Shafei. Joint Entropy Search for Multi-Objective
Bayesian Optimization. Advances in Neural Information Processing Systems, 35.
2022.</p>
</div>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.joint_entropy_search.LowerBoundMultiObjectiveEntropySearch">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.multi_objective.joint_entropy_search.</span></span><span class="sig-name descname"><span class="pre">LowerBoundMultiObjectiveEntropySearch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pareto_sets</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pareto_fronts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hypercell_bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">estimation_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'LB'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/joint_entropy_search.html#LowerBoundMultiObjectiveEntropySearch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.joint_entropy_search.LowerBoundMultiObjectiveEntropySearch" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">AcquisitionFunction</span></code></a>, <a class="reference internal" href="#botorch.acquisition.acquisition.MCSamplerMixin" title="botorch.acquisition.acquisition.MCSamplerMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">MCSamplerMixin</span></code></a></p>
<p>Abstract base class for the lower bound multi-objective entropy search
acquisition functions.</p>
<p>Lower bound multi-objective entropy search acquisition function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted batch model with ‘M’ number of outputs.</p></li>
<li><p><strong>pareto_sets</strong> (<em>Tensor</em>) – A <cite>num_pareto_samples x num_pareto_points x d</cite>-dim Tensor
containing the sampled Pareto optimal sets of inputs.</p></li>
<li><p><strong>pareto_fronts</strong> (<em>Tensor</em>) – A <cite>num_pareto_samples x num_pareto_points x M</cite>-dim Tensor
containing the sampled Pareto optimal sets of outputs.</p></li>
<li><p><strong>hypercell_bounds</strong> (<em>Tensor</em>) – A <cite>num_pareto_samples x 2 x J x M</cite>-dim Tensor
containing the hyper-rectangle bounds for integration, where <cite>J</cite> is
the number of hyper-rectangles. In the unconstrained case, this gives
the partition of the dominated space. In the constrained case, this
gives the partition of the feasible dominated space union the
infeasible space.</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>m x d</cite>-dim Tensor of <cite>m</cite> design points that have been
submitted for function evaluation, but have not yet been evaluated.</p></li>
<li><p><strong>estimation_type</strong> (<em>str</em>) – A string to determine which entropy estimate is
computed: “0”, “LB”, “LB2”, or “MC”.</p></li>
<li><p><strong>num_samples</strong> (<em>int</em>) – The number of Monte Carlo samples for the Monte Carlo
estimate.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.joint_entropy_search.LowerBoundMultiObjectiveEntropySearch.forward">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/joint_entropy_search.html#LowerBoundMultiObjectiveEntropySearch.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.joint_entropy_search.LowerBoundMultiObjectiveEntropySearch.forward" title="Link to this definition"></a></dt>
<dd><p>Compute lower bound multi-objective entropy search at the design points
<cite>X</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x q x d</cite>-dim Tensor of <cite>batch_shape</cite> t-batches with <cite>q</cite></p></li>
<li><p><strong>each.</strong> (<em>d-dim design points</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape</cite>-dim Tensor of acquisition values at the given design
points <cite>X</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.joint_entropy_search.qLowerBoundMultiObjectiveJointEntropySearch">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.multi_objective.joint_entropy_search.</span></span><span class="sig-name descname"><span class="pre">qLowerBoundMultiObjectiveJointEntropySearch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pareto_sets</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pareto_fronts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hypercell_bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">estimation_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'LB'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/joint_entropy_search.html#qLowerBoundMultiObjectiveJointEntropySearch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.joint_entropy_search.qLowerBoundMultiObjectiveJointEntropySearch" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.multi_objective.joint_entropy_search.LowerBoundMultiObjectiveEntropySearch" title="botorch.acquisition.multi_objective.joint_entropy_search.LowerBoundMultiObjectiveEntropySearch"><code class="xref py py-class docutils literal notranslate"><span class="pre">LowerBoundMultiObjectiveEntropySearch</span></code></a></p>
<p>The acquisition function for the multi-objective joint entropy search, where
the batches <cite>q &gt; 1</cite> are supported through the lower bound formulation.</p>
<p>This acquisition function computes the mutual information between the observation
at a candidate point <cite>X</cite> and the Pareto optimal input-output pairs.</p>
<p>See <a class="reference internal" href="#tu2022" id="id21"><span>[Tu2022]</span></a> for a discussion on the estimation procedure.</p>
<p>NOTES:
(i) The estimated acquisition value could be negative.</p>
<p>(ii) The lower bound batch acquisition function might not be monotone in the
sense that adding more elements to the batch does not necessarily increase the
acquisition value. Specifically, the acquisition value can become smaller when
more inputs are added.</p>
<p>Lower bound multi-objective joint entropy search acquisition function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted batch model with ‘M’ number of outputs.</p></li>
<li><p><strong>pareto_sets</strong> (<em>Tensor</em>) – A <cite>num_pareto_samples x num_pareto_points x d</cite>-dim Tensor
containing the sampled Pareto optimal sets of inputs.</p></li>
<li><p><strong>pareto_fronts</strong> (<em>Tensor</em>) – A <cite>num_pareto_samples x num_pareto_points x M</cite>-dim Tensor
containing the sampled Pareto optimal sets of outputs.</p></li>
<li><p><strong>hypercell_bounds</strong> (<em>Tensor</em>) – A <cite>num_pareto_samples x 2 x J x M</cite>-dim Tensor
containing the hyper-rectangle bounds for integration. In the
unconstrained case, this gives the partition of the dominated space.
In the constrained case, this gives the partition of the feasible
dominated space union the infeasible space.</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>m x d</cite>-dim Tensor of <cite>m</cite> design points that have been
submitted for function evaluation, but have not yet been evaluated.</p></li>
<li><p><strong>estimation_type</strong> (<em>str</em>) – A string to determine which entropy estimate is
computed: “0”, “LB”, “LB2”, or “MC”.</p></li>
<li><p><strong>num_samples</strong> (<em>int</em>) – The number of Monte Carlo samples used for the Monte Carlo
estimate.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.joint_entropy_search.qLowerBoundMultiObjectiveJointEntropySearch.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/joint_entropy_search.html#qLowerBoundMultiObjectiveJointEntropySearch.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.joint_entropy_search.qLowerBoundMultiObjectiveJointEntropySearch.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluates qLowerBoundMultiObjectiveJointEntropySearch at the design
points <cite>X</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x q x d</cite>-dim Tensor of <cite>batch_shape</cite> t-batches with <cite>q</cite></p></li>
<li><p><strong>each.</strong> (<em>d-dim design points</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape</cite>-dim Tensor of acquisition values at the given design
points <cite>X</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-botorch.acquisition.multi_objective.max_value_entropy_search">
<span id="multi-objective-max-value-entropy-search-acquisition-functions"></span><h3>Multi-Objective Max-value Entropy Search Acquisition Functions<a class="headerlink" href="#module-botorch.acquisition.multi_objective.max_value_entropy_search" title="Link to this heading"></a></h3>
<p>Acquisition functions for max-value entropy search for multi-objective
Bayesian optimization (MESMO).</p>
<p>References</p>
<div role="list" class="citation-list">
<div class="citation" id="belakaria2019" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id22">Belakaria2019</a><span class="fn-bracket">]</span></span>
<p>S. Belakaria, A. Deshwal, J. R. Doppa. Max-value Entropy Search
for Multi-Objective Bayesian Optimization. Advances in Neural
Information Processing Systems, 32. 2019.</p>
</div>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.max_value_entropy_search.qMultiObjectiveMaxValueEntropy">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.multi_objective.max_value_entropy_search.</span></span><span class="sig-name descname"><span class="pre">qMultiObjectiveMaxValueEntropy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_pareto_frontiers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_fantasies</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">16</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/max_value_entropy_search.html#qMultiObjectiveMaxValueEntropy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.max_value_entropy_search.qMultiObjectiveMaxValueEntropy" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.max_value_entropy_search.qMaxValueEntropy" title="botorch.acquisition.max_value_entropy_search.qMaxValueEntropy"><code class="xref py py-class docutils literal notranslate"><span class="pre">qMaxValueEntropy</span></code></a>, <a class="reference internal" href="#botorch.acquisition.multi_objective.base.MultiObjectiveMCAcquisitionFunction" title="botorch.acquisition.multi_objective.base.MultiObjectiveMCAcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiObjectiveMCAcquisitionFunction</span></code></a></p>
<p>The acquisition function for MESMO.</p>
<p>This acquisition function computes the mutual information of
Pareto frontier and a candidate point. See <a class="reference internal" href="#belakaria2019" id="id22"><span>[Belakaria2019]</span></a> for
a detailed discussion.</p>
<p>q &gt; 1 is supported through cyclic optimization and fantasies.</p>
<p>Noisy observations are support by computing information gain with
observation noise as in Appendix C in <a class="reference internal" href="#takeno2020mfmves" id="id23"><span>[Takeno2020mfmves]</span></a>.</p>
<p>Note: this only supports maximization.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.max_value_entropy_search.qMultiObjectiveMaxValueEntropy._default_sample_shape">
<span class="sig-name descname"><span class="pre">_default_sample_shape</span></span><a class="headerlink" href="#botorch.acquisition.multi_objective.max_value_entropy_search.qMultiObjectiveMaxValueEntropy._default_sample_shape" title="Link to this definition"></a></dt>
<dd><p>The <cite>sample_shape</cite> for the default sampler.</p>
</dd></dl>

<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">,</span> <span class="n">outcome_transform</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">MESMO</span> <span class="o">=</span> <span class="n">qMultiObjectiveMaxValueEntropy</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">sample_pfs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mesmo</span> <span class="o">=</span> <span class="n">MESMO</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
</pre></div>
</div>
<p>Multi-objective max-value entropy search acquisition function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted multi-output model.</p></li>
<li><p><strong>sample_pareto_frontiers</strong> (<em>Callable</em><em>[</em><em>[</em><a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a><em>]</em><em>, </em><em>Tensor</em><em>]</em>) – A callable that takes a model and returns a
<cite>num_samples x n’ x m</cite>-dim tensor of outcomes to use for constructing
<cite>num_samples</cite> sampled Pareto frontiers.</p></li>
<li><p><strong>num_fantasies</strong> (<em>int</em>) – Number of fantasies to generate. The higher this
number the more accurate the model (at the expense of model
complexity, wall time and memory). Ignored if <cite>X_pending</cite> is <cite>None</cite>.</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>m x d</cite>-dim Tensor of <cite>m</cite> design points that have been
submitted for function evaluation, but have not yet been evaluated.</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.max_value_entropy_search.qMultiObjectiveMaxValueEntropy.set_X_pending">
<span class="sig-name descname"><span class="pre">set_X_pending</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/max_value_entropy_search.html#qMultiObjectiveMaxValueEntropy.set_X_pending"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.max_value_entropy_search.qMultiObjectiveMaxValueEntropy.set_X_pending" title="Link to this definition"></a></dt>
<dd><p>Set pending points.</p>
<p>Informs the acquisition function about pending design points,
fantasizes the model on the pending points and draws max-value samples
from the fantasized model posterior.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – <cite>m x d</cite> Tensor with <cite>m</cite> <cite>d</cite>-dim design points that have
been submitted for evaluation but have not yet been evaluated.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.max_value_entropy_search.qMultiObjectiveMaxValueEntropy.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/max_value_entropy_search.html#qMultiObjectiveMaxValueEntropy.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.max_value_entropy_search.qMultiObjectiveMaxValueEntropy.forward" title="Link to this definition"></a></dt>
<dd><p>Compute max-value entropy at the design points <cite>X</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x 1 x d</cite>-dim Tensor of <cite>batch_shape</cite> t-batches
with <cite>1</cite> <cite>d</cite>-dim design points each.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape</cite>-dim Tensor of MVE values at the given design points <cite>X</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.max_value_entropy_search.qLowerBoundMultiObjectiveMaxValueEntropySearch">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.multi_objective.max_value_entropy_search.</span></span><span class="sig-name descname"><span class="pre">qLowerBoundMultiObjectiveMaxValueEntropySearch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hypercell_bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">estimation_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'LB'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/max_value_entropy_search.html#qLowerBoundMultiObjectiveMaxValueEntropySearch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.max_value_entropy_search.qLowerBoundMultiObjectiveMaxValueEntropySearch" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.multi_objective.joint_entropy_search.LowerBoundMultiObjectiveEntropySearch" title="botorch.acquisition.multi_objective.joint_entropy_search.LowerBoundMultiObjectiveEntropySearch"><code class="xref py py-class docutils literal notranslate"><span class="pre">LowerBoundMultiObjectiveEntropySearch</span></code></a></p>
<p>The acquisition function for the multi-objective Max-value Entropy Search,
where the batches <cite>q &gt; 1</cite> are supported through the lower bound formulation.</p>
<p>This acquisition function computes the mutual information between the observation
at a candidate point <cite>X</cite> and the Pareto optimal outputs.</p>
<p>See <a class="reference internal" href="#tu2022" id="id24"><span>[Tu2022]</span></a> for a discussion on the estimation procedure.</p>
<p>NOTES:
(i) The estimated acquisition value could be negative.</p>
<p>(ii) The lower bound batch acquisition function might not be monotone in the
sense that adding more elements to the batch does not necessarily increase the
acquisition value. Specifically, the acquisition value can become smaller when
more inputs are added.</p>
<p>Lower bound multi-objective max-value entropy search acquisition function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted batch model with ‘M’ number of outputs.</p></li>
<li><p><strong>hypercell_bounds</strong> (<em>Tensor</em>) – A <cite>num_pareto_samples x 2 x J x M</cite>-dim Tensor
containing the hyper-rectangle bounds for integration, where <cite>J</cite> is
the number of hyper-rectangles. In the unconstrained case, this gives
the partition of the dominated space. In the constrained case, this
gives the partition of the feasible dominated space union the
infeasible space.</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>m x d</cite>-dim Tensor of <cite>m</cite> design points that have been
submitted for function evaluation, but have not yet been evaluated.</p></li>
<li><p><strong>estimation_type</strong> (<em>str</em>) – A string to determine which entropy estimate is
computed: “0”, “LB”, “LB2”, or “MC”.</p></li>
<li><p><strong>num_samples</strong> (<em>int</em>) – The number of Monte Carlo samples for the Monte Carlo
estimate.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.max_value_entropy_search.qLowerBoundMultiObjectiveMaxValueEntropySearch.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/max_value_entropy_search.html#qLowerBoundMultiObjectiveMaxValueEntropySearch.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.max_value_entropy_search.qLowerBoundMultiObjectiveMaxValueEntropySearch.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluates qLowerBoundMultiObjectiveMaxValueEntropySearch at the design
points <cite>X</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x q x d</cite>-dim Tensor of <cite>batch_shape</cite> t-batches with <cite>q</cite></p></li>
<li><p><strong>each.</strong> (<em>d-dim design points</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape</cite>-dim Tensor of acquisition values at the given design
points <cite>X</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-botorch.acquisition.multi_objective.monte_carlo">
<span id="multi-objective-monte-carlo-acquisition-functions"></span><h3>Multi-Objective Monte-Carlo Acquisition Functions<a class="headerlink" href="#module-botorch.acquisition.multi_objective.monte_carlo" title="Link to this heading"></a></h3>
<p>Monte-Carlo Acquisition Functions for Multi-objective Bayesian optimization.
In particular, this module contains implementations of
1) qEHVI <a class="reference internal" href="#daulton2020qehvi" id="id25"><span>[Daulton2020qehvi]</span></a>, and
2) qNEHVI <a class="reference internal" href="#daulton2021nehvi" id="id26"><span>[Daulton2021nehvi]</span></a>.</p>
<p>References</p>
<div role="list" class="citation-list">
<div class="citation" id="daulton2020qehvi" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Daulton2020qehvi<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id12">1</a>,<a role="doc-backlink" href="#id25">2</a>,<a role="doc-backlink" href="#id27">3</a>,<a role="doc-backlink" href="#id31">4</a>,<a role="doc-backlink" href="#id35">5</a>)</span>
<p>S. Daulton, M. Balandat, and E. Bakshy. Differentiable Expected Hypervolume
Improvement for Parallel Multi-Objective Bayesian Optimization. Advances in Neural
Information Processing Systems 33, 2020.</p>
</div>
<div class="citation" id="daulton2021nehvi" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Daulton2021nehvi<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id26">1</a>,<a role="doc-backlink" href="#id28">2</a>,<a role="doc-backlink" href="#id32">3</a>)</span>
<p>S. Daulton, M. Balandat, and E. Bakshy. Parallel Bayesian Optimization of
Multiple Noisy Objectives with Expected Hypervolume Improvement. Advances
in Neural Information Processing Systems 34, 2021.</p>
</div>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.monte_carlo.qExpectedHypervolumeImprovement">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.multi_objective.monte_carlo.</span></span><span class="sig-name descname"><span class="pre">qExpectedHypervolumeImprovement</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ref_point</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">partitioning</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fat</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/monte_carlo.html#qExpectedHypervolumeImprovement"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.monte_carlo.qExpectedHypervolumeImprovement" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.multi_objective.base.MultiObjectiveMCAcquisitionFunction" title="botorch.acquisition.multi_objective.base.MultiObjectiveMCAcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiObjectiveMCAcquisitionFunction</span></code></a>, <a class="reference internal" href="utils.html#botorch.utils.multi_objective.hypervolume.SubsetIndexCachingMixin" title="botorch.utils.multi_objective.hypervolume.SubsetIndexCachingMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">SubsetIndexCachingMixin</span></code></a></p>
<p>q-Expected Hypervolume Improvement supporting m&gt;=2 outcomes.</p>
<p>See <a class="reference internal" href="#daulton2020qehvi" id="id27"><span>[Daulton2020qehvi]</span></a> for details.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ref_point</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qEHVI</span> <span class="o">=</span> <span class="n">qExpectedHypervolumeImprovement</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">ref_point</span><span class="p">,</span> <span class="n">partitioning</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qehvi</span> <span class="o">=</span> <span class="n">qEHVI</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted model.</p></li>
<li><p><strong>ref_point</strong> (<em>list</em><em>[</em><em>float</em><em>] </em><em>| </em><em>Tensor</em>) – A list or tensor with <cite>m</cite> elements representing the reference
point (in the outcome space) w.r.t. to which compute the hypervolume.
This is a reference point for the objective values (i.e. after
applying`objective` to the samples).</p></li>
<li><p><strong>partitioning</strong> (<a class="reference internal" href="utils.html#botorch.utils.multi_objective.box_decompositions.non_dominated.NondominatedPartitioning" title="botorch.utils.multi_objective.box_decompositions.non_dominated.NondominatedPartitioning"><em>NondominatedPartitioning</em></a>) – A <cite>NondominatedPartitioning</cite> module that provides the non-
dominated front and a partitioning of the non-dominated space in hyper-
rectangles. If constraints are present, this partitioning must only
include feasible points.</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – The sampler used to draw base samples. If not given,
a sampler is generated using <cite>get_sampler</cite>.</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.multi_objective.objective.MCMultiOutputObjective" title="botorch.acquisition.multi_objective.objective.MCMultiOutputObjective"><em>MCMultiOutputObjective</em></a><em> | </em><em>None</em>) – The MCMultiOutputObjective under which the samples are evaluated.
Defaults to <cite>IdentityMCMultiOutputObjective()</cite>.</p></li>
<li><p><strong>constraints</strong> (<em>list</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of callables, each mapping a Tensor of dimension
<cite>sample_shape x batch-shape x q x m</cite> to a Tensor of dimension
<cite>sample_shape x batch-shape x q</cite>, where negative values imply
feasibility. The acquisition function will compute expected feasible
hypervolume.</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x m x d</cite>-dim Tensor of <cite>m</cite> design points that have
points that have been submitted for function evaluation but have not yet
been evaluated. Concatenated into <cite>X</cite> upon forward call. Copied and set
to have no gradient.</p></li>
<li><p><strong>eta</strong> (<em>Tensor</em><em> | </em><em>float</em>) – The temperature parameter for the sigmoid function used for the
differentiable approximation of the constraints. In case of a float the
same eta is used for every constraint in constraints. In case of a
tensor the length of the tensor must match the number of provided
constraints. The i-th constraint is then estimated with the i-th
eta value.</p></li>
<li><p><strong>fat</strong> (<em>bool</em>) – A Boolean flag indicating whether to use the heavy-tailed approximation
of the constraint indicator.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.monte_carlo.qExpectedHypervolumeImprovement.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/monte_carlo.html#qExpectedHypervolumeImprovement.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.monte_carlo.qExpectedHypervolumeImprovement.forward" title="Link to this definition"></a></dt>
<dd><p>Takes in a <cite>batch_shape x q x d</cite> X Tensor of t-batches with <cite>q</cite> <cite>d</cite>-dim
design points each, and returns a Tensor with shape <cite>batch_shape’</cite>, where
<cite>batch_shape’</cite> is the broadcasted batch shape of model and input <cite>X</cite>. Should
utilize the result of <cite>set_X_pending</cite> as needed to account for pending function
evaluations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.monte_carlo.qNoisyExpectedHypervolumeImprovement">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.multi_objective.monte_carlo.</span></span><span class="sig-name descname"><span class="pre">qNoisyExpectedHypervolumeImprovement</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ref_point</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_baseline</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fat</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prune_baseline</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">incremental_nehvi</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_root</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">marginalize_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/monte_carlo.html#qNoisyExpectedHypervolumeImprovement"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.monte_carlo.qNoisyExpectedHypervolumeImprovement" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="utils.html#botorch.utils.multi_objective.hypervolume.NoisyExpectedHypervolumeMixin" title="botorch.utils.multi_objective.hypervolume.NoisyExpectedHypervolumeMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">NoisyExpectedHypervolumeMixin</span></code></a>, <a class="reference internal" href="#botorch.acquisition.multi_objective.monte_carlo.qExpectedHypervolumeImprovement" title="botorch.acquisition.multi_objective.monte_carlo.qExpectedHypervolumeImprovement"><code class="xref py py-class docutils literal notranslate"><span class="pre">qExpectedHypervolumeImprovement</span></code></a></p>
<p>q-Noisy Expected Hypervolume Improvement supporting m&gt;=2 outcomes.</p>
<p>See <a class="reference internal" href="#daulton2021nehvi" id="id28"><span>[Daulton2021nehvi]</span></a> for details.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ref_point</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qNEHVI</span> <span class="o">=</span> <span class="n">qNoisyExpectedHypervolumeImprovement</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">ref_point</span><span class="p">,</span> <span class="n">train_X</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qnehvi</span> <span class="o">=</span> <span class="n">qNEHVI</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted model.</p></li>
<li><p><strong>ref_point</strong> (<em>list</em><em>[</em><em>float</em><em>] </em><em>| </em><em>Tensor</em>) – A list or tensor with <cite>m</cite> elements representing the reference
point (in the outcome space) w.r.t. to which compute the hypervolume.
This is a reference point for the objective values (i.e. after
applying <cite>objective</cite> to the samples).</p></li>
<li><p><strong>X_baseline</strong> (<em>Tensor</em>) – A <cite>r x d</cite>-dim Tensor of <cite>r</cite> design points that have already
been observed. These points are considered as potential approximate
pareto-optimal design points.</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – The sampler used to draw base samples. If not given,
a sampler is generated using <cite>get_sampler</cite>.
Note: a pareto front is created for each mc sample, which can be
computationally intensive for <cite>m</cite> &gt; 2.</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.multi_objective.objective.MCMultiOutputObjective" title="botorch.acquisition.multi_objective.objective.MCMultiOutputObjective"><em>MCMultiOutputObjective</em></a><em> | </em><em>None</em>) – The MCMultiOutputObjective under which the samples are
evaluated. Defaults to <cite>IdentityMCMultiOutputObjective()</cite>.</p></li>
<li><p><strong>constraints</strong> (<em>list</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of callables, each mapping a Tensor of dimension
<cite>sample_shape x batch-shape x q x m</cite> to a Tensor of dimension
<cite>sample_shape x batch-shape x q</cite>, where negative values imply
feasibility. The acquisition function will compute expected feasible
hypervolume.</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x m x d</cite>-dim Tensor of <cite>m</cite> design points that
have points that have been submitted for function evaluation, but
have not yet been evaluated.</p></li>
<li><p><strong>eta</strong> (<em>Tensor</em><em> | </em><em>float</em>) – The temperature parameter for the sigmoid function used for the
differentiable approximation of the constraints. In case of a float the
same <cite>eta</cite> is used for every constraint in constraints. In case of a
tensor the length of the tensor must match the number of provided
constraints. The i-th constraint is then estimated with the i-th
<cite>eta</cite> value. For more details, on this parameter, see the docs of
<cite>compute_smoothed_feasibility_indicator</cite>.</p></li>
<li><p><strong>fat</strong> (<em>bool</em>) – A Boolean flag indicating whether to use the heavy-tailed approximation
of the constraint indicator.</p></li>
<li><p><strong>prune_baseline</strong> (<em>bool</em>) – If True, remove points in <cite>X_baseline</cite> that are
highly unlikely to be the pareto optimal and better than the
reference point. This can significantly improve computation time and
is generally recommended. In order to customize pruning parameters,
instead manually call <cite>prune_inferior_points_multi_objective</cite> on
<cite>X_baseline</cite> before instantiating the acquisition function.</p></li>
<li><p><strong>alpha</strong> (<em>float</em>) – The hyperparameter controlling the approximate non-dominated
partitioning. The default value of 0.0 means an exact partitioning
is used. As the number of objectives <cite>m</cite> increases, consider increasing
this parameter in order to limit computational complexity.</p></li>
<li><p><strong>cache_pending</strong> (<em>bool</em>) – A boolean indicating whether to use cached box
decompositions (CBD) for handling pending points. This is
generally recommended.</p></li>
<li><p><strong>max_iep</strong> (<em>int</em>) – The maximum number of pending points before the box
decompositions will be recomputed.</p></li>
<li><p><strong>incremental_nehvi</strong> (<em>bool</em>) – A boolean indicating whether to compute the
incremental NEHVI from the <cite>i`th point where `i=1, …, q</cite>
under sequential greedy optimization, or the full qNEHVI over
<cite>q</cite> points.</p></li>
<li><p><strong>cache_root</strong> (<em>bool</em>) – A boolean indicating whether to cache the root
decomposition over <cite>X_baseline</cite> and use low-rank updates.</p></li>
<li><p><strong>marginalize_dim</strong> (<em>int</em><em> | </em><em>None</em>) – A batch dimension that should be marginalized. For example,
this is useful when using a batched fully Bayesian model.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.monte_carlo.qNoisyExpectedHypervolumeImprovement.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/monte_carlo.html#qNoisyExpectedHypervolumeImprovement.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.monte_carlo.qNoisyExpectedHypervolumeImprovement.forward" title="Link to this definition"></a></dt>
<dd><p>Takes in a <cite>batch_shape x q x d</cite> X Tensor of t-batches with <cite>q</cite> <cite>d</cite>-dim
design points each, and returns a Tensor with shape <cite>batch_shape’</cite>, where
<cite>batch_shape’</cite> is the broadcasted batch shape of model and input <cite>X</cite>. Should
utilize the result of <cite>set_X_pending</cite> as needed to account for pending function
evaluations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<p id="module-botorch.acquisition.multi_objective.logei">Multi-objective variants of the LogEI family of acquisition functions, see
<a class="reference internal" href="#ament2023logei" id="id29"><span>[Ament2023logei]</span></a> for details.</p>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.logei.qLogExpectedHypervolumeImprovement">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.multi_objective.logei.</span></span><span class="sig-name descname"><span class="pre">qLogExpectedHypervolumeImprovement</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ref_point</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">partitioning</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fat</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau_relu</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-06</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau_max</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/logei.html#qLogExpectedHypervolumeImprovement"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.logei.qLogExpectedHypervolumeImprovement" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.multi_objective.base.MultiObjectiveMCAcquisitionFunction" title="botorch.acquisition.multi_objective.base.MultiObjectiveMCAcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiObjectiveMCAcquisitionFunction</span></code></a>, <a class="reference internal" href="utils.html#botorch.utils.multi_objective.hypervolume.SubsetIndexCachingMixin" title="botorch.utils.multi_objective.hypervolume.SubsetIndexCachingMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">SubsetIndexCachingMixin</span></code></a></p>
<p>Parallel Log Expected Hypervolume Improvement supporting m&gt;=2 outcomes.</p>
<p>See <a class="reference internal" href="#ament2023logei" id="id30"><span>[Ament2023logei]</span></a> for details and the methodology behind the LogEI family of
acquisition function. Line-by-line differences to the original differentiable
expected hypervolume formulation of <a class="reference internal" href="#daulton2020qehvi" id="id31"><span>[Daulton2020qehvi]</span></a> are described via inline
comments in <cite>forward</cite>.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ref_point</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">acq</span> <span class="o">=</span> <span class="n">qLogExpectedHypervolumeImprovement</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">ref_point</span><span class="p">,</span> <span class="n">partitioning</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">value</span> <span class="o">=</span> <span class="n">acq</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted model.</p></li>
<li><p><strong>ref_point</strong> (<em>list</em><em>[</em><em>float</em><em>] </em><em>| </em><em>Tensor</em>) – A list or tensor with <cite>m</cite> elements representing the reference
point (in the outcome space) w.r.t. to which compute the hypervolume.
This is a reference point for the objective values (i.e. after
applying`objective` to the samples).</p></li>
<li><p><strong>partitioning</strong> (<a class="reference internal" href="utils.html#botorch.utils.multi_objective.box_decompositions.non_dominated.NondominatedPartitioning" title="botorch.utils.multi_objective.box_decompositions.non_dominated.NondominatedPartitioning"><em>NondominatedPartitioning</em></a>) – A <cite>NondominatedPartitioning</cite> module that provides the non-
dominated front and a partitioning of the non-dominated space in hyper-
rectangles. If constraints are present, this partitioning must only
include feasible points.</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – The sampler used to draw base samples. If not given,
a sampler is generated using <cite>get_sampler</cite>.</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.multi_objective.objective.MCMultiOutputObjective" title="botorch.acquisition.multi_objective.objective.MCMultiOutputObjective"><em>MCMultiOutputObjective</em></a><em> | </em><em>None</em>) – The MCMultiOutputObjective under which the samples are evaluated.
Defaults to <cite>IdentityMultiOutputObjective()</cite>.</p></li>
<li><p><strong>constraints</strong> (<em>list</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of callables, each mapping a Tensor of dimension
<cite>sample_shape x batch-shape x q x m</cite> to a Tensor of dimension
<cite>sample_shape x batch-shape x q</cite>, where negative values imply
feasibility. The acquisition function will compute expected feasible
hypervolume.</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x m x d</cite>-dim Tensor of <cite>m</cite> design points that have
points that have been submitted for function evaluation but have not yet
been evaluated. Concatenated into <cite>X</cite> upon forward call. Copied and set
to have no gradient.</p></li>
<li><p><strong>eta</strong> (<em>Tensor</em><em> | </em><em>float</em>) – The temperature parameter for the sigmoid function used for the
differentiable approximation of the constraints. In case of a float the
same eta is used for every constraint in constraints. In case of a
tensor the length of the tensor must match the number of provided
constraints. The i-th constraint is then estimated with the i-th
eta value.</p></li>
<li><p><strong>fat</strong> (<em>bool</em>) – Toggles the logarithmic / linear asymptotic behavior of the smooth
approximation to the ReLU and the maximum.</p></li>
<li><p><strong>tau_relu</strong> (<em>float</em>) – Temperature parameter controlling the sharpness of the
approximation to the ReLU over the <cite>q</cite> candidate points. For further
details, see the comments above the definition of <cite>TAU_RELU</cite>.</p></li>
<li><p><strong>tau_max</strong> (<em>float</em>) – Temperature parameter controlling the sharpness of the
approximation to the <cite>max</cite> operator over the <cite>q</cite> candidate points.
For further details, see the comments above the definition of <cite>TAU_MAX</cite>.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.logei.qLogExpectedHypervolumeImprovement.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/logei.html#qLogExpectedHypervolumeImprovement.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.logei.qLogExpectedHypervolumeImprovement.forward" title="Link to this definition"></a></dt>
<dd><p>Takes in a <cite>batch_shape x q x d</cite> X Tensor of t-batches with <cite>q</cite> <cite>d</cite>-dim
design points each, and returns a Tensor with shape <cite>batch_shape’</cite>, where
<cite>batch_shape’</cite> is the broadcasted batch shape of model and input <cite>X</cite>. Should
utilize the result of <cite>set_X_pending</cite> as needed to account for pending function
evaluations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.logei.qLogNoisyExpectedHypervolumeImprovement">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.multi_objective.logei.</span></span><span class="sig-name descname"><span class="pre">qLogNoisyExpectedHypervolumeImprovement</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ref_point</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_baseline</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prune_baseline</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">incremental_nehvi</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_root</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau_relu</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-06</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau_max</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fat</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">marginalize_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/logei.html#qLogNoisyExpectedHypervolumeImprovement"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.logei.qLogNoisyExpectedHypervolumeImprovement" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="utils.html#botorch.utils.multi_objective.hypervolume.NoisyExpectedHypervolumeMixin" title="botorch.utils.multi_objective.hypervolume.NoisyExpectedHypervolumeMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">NoisyExpectedHypervolumeMixin</span></code></a>, <a class="reference internal" href="#botorch.acquisition.multi_objective.logei.qLogExpectedHypervolumeImprovement" title="botorch.acquisition.multi_objective.logei.qLogExpectedHypervolumeImprovement"><code class="xref py py-class docutils literal notranslate"><span class="pre">qLogExpectedHypervolumeImprovement</span></code></a></p>
<p>q-Log Noisy Expected Hypervolume Improvement supporting m&gt;=2 outcomes.</p>
<p>Based on the differentiable hypervolume formulation of <a class="reference internal" href="#daulton2021nehvi" id="id32"><span>[Daulton2021nehvi]</span></a>.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ref_point</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qNEHVI</span> <span class="o">=</span> <span class="n">qNoisyExpectedHypervolumeImprovement</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">ref_point</span><span class="p">,</span> <span class="n">train_X</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qnehvi</span> <span class="o">=</span> <span class="n">qNEHVI</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted model.</p></li>
<li><p><strong>ref_point</strong> (<em>list</em><em>[</em><em>float</em><em>] </em><em>| </em><em>Tensor</em>) – A list or tensor with <cite>m</cite> elements representing the reference
point (in the outcome space) w.r.t. to which compute the hypervolume.
This is a reference point for the objective values (i.e. after
applying <cite>objective</cite> to the samples).</p></li>
<li><p><strong>X_baseline</strong> (<em>Tensor</em>) – A <cite>r x d</cite>-dim Tensor of <cite>r</cite> design points that have already
been observed. These points are considered as potential approximate
pareto-optimal design points.</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – The sampler used to draw base samples. If not given,
a sampler is generated using <cite>get_sampler</cite>.
Note: a pareto front is created for each mc sample, which can be
computationally intensive for <cite>m</cite> &gt; 2.</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.multi_objective.objective.MCMultiOutputObjective" title="botorch.acquisition.multi_objective.objective.MCMultiOutputObjective"><em>MCMultiOutputObjective</em></a><em> | </em><em>None</em>) – The MCMultiOutputObjective under which the samples are
evaluated. Defaults to <cite>IdentityMultiOutputObjective()</cite>.</p></li>
<li><p><strong>constraints</strong> (<em>list</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of callables, each mapping a Tensor of dimension
<cite>sample_shape x batch-shape x q x m</cite> to a Tensor of dimension
<cite>sample_shape x batch-shape x q</cite>, where negative values imply
feasibility. The acquisition function will compute expected feasible
hypervolume.</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x m x d</cite>-dim Tensor of <cite>m</cite> design points that
have points that have been submitted for function evaluation, but
have not yet been evaluated.</p></li>
<li><p><strong>eta</strong> (<em>Tensor</em><em> | </em><em>float</em>) – The temperature parameter for the sigmoid function used for the
differentiable approximation of the constraints. In case of a float the
same <cite>eta</cite> is used for every constraint in constraints. In case of a
tensor the length of the tensor must match the number of provided
constraints. The i-th constraint is then estimated with the i-th
<cite>eta</cite> value.</p></li>
<li><p><strong>prune_baseline</strong> (<em>bool</em>) – If True, remove points in <cite>X_baseline</cite> that are
highly unlikely to be the pareto optimal and better than the
reference point. This can significantly improve computation time and
is generally recommended. In order to customize pruning parameters,
instead manually call <cite>prune_inferior_points_multi_objective</cite> on
<cite>X_baseline</cite> before instantiating the acquisition function.</p></li>
<li><p><strong>alpha</strong> (<em>float</em>) – The hyperparameter controlling the approximate non-dominated
partitioning. The default value of 0.0 means an exact partitioning
is used. As the number of objectives <cite>m</cite> increases, consider increasing
this parameter in order to limit computational complexity.</p></li>
<li><p><strong>cache_pending</strong> (<em>bool</em>) – A boolean indicating whether to use cached box
decompositions (CBD) for handling pending points. This is
generally recommended.</p></li>
<li><p><strong>max_iep</strong> (<em>int</em>) – The maximum number of pending points before the box
decompositions will be recomputed.</p></li>
<li><p><strong>incremental_nehvi</strong> (<em>bool</em>) – A boolean indicating whether to compute the
incremental NEHVI from the <cite>i`th point where `i=1, …, q</cite>
under sequential greedy optimization, or the full qNEHVI over
<cite>q</cite> points.</p></li>
<li><p><strong>cache_root</strong> (<em>bool</em>) – A boolean indicating whether to cache the root
decomposition over <cite>X_baseline</cite> and use low-rank updates.</p></li>
<li><p><strong>marginalize_dim</strong> (<em>int</em><em> | </em><em>None</em>) – A batch dimension that should be marginalized.</p></li>
<li><p><strong>tau_relu</strong> (<em>float</em>)</p></li>
<li><p><strong>tau_max</strong> (<em>float</em>)</p></li>
<li><p><strong>fat</strong> (<em>bool</em>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.logei.qLogNoisyExpectedHypervolumeImprovement.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/logei.html#qLogNoisyExpectedHypervolumeImprovement.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.logei.qLogNoisyExpectedHypervolumeImprovement.forward" title="Link to this definition"></a></dt>
<dd><p>Takes in a <cite>batch_shape x q x d</cite> X Tensor of t-batches with <cite>q</cite> <cite>d</cite>-dim
design points each, and returns a Tensor with shape <cite>batch_shape’</cite>, where
<cite>batch_shape’</cite> is the broadcasted batch shape of model and input <cite>X</cite>. Should
utilize the result of <cite>set_X_pending</cite> as needed to account for pending function
evaluations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-botorch.acquisition.multi_objective.multi_fidelity">
<span id="multi-objective-multi-fidelity-acquisition-functions"></span><h3>Multi-Objective Multi-Fidelity Acquisition Functions<a class="headerlink" href="#module-botorch.acquisition.multi_objective.multi_fidelity" title="Link to this heading"></a></h3>
<p>Multi-Fidelity Acquisition Functions for Multi-objective Bayesian optimization.</p>
<p>References</p>
<div role="list" class="citation-list">
<div class="citation" id="irshad2021momf" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id33">Irshad2021MOMF</a><span class="fn-bracket">]</span></span>
<p>F. Irshad, S. Karsch, and A. Döpp. Expected hypervolume improvement for
simultaneous multi-objective and multi-fidelity optimization.
arXiv preprint arXiv:2112.13901, 2021.</p>
</div>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.multi_fidelity.MOMF">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.multi_objective.multi_fidelity.</span></span><span class="sig-name descname"><span class="pre">MOMF</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ref_point</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">partitioning</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cost_call</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/multi_fidelity.html#MOMF"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.multi_fidelity.MOMF" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.multi_objective.monte_carlo.qExpectedHypervolumeImprovement" title="botorch.acquisition.multi_objective.monte_carlo.qExpectedHypervolumeImprovement"><code class="xref py py-class docutils literal notranslate"><span class="pre">qExpectedHypervolumeImprovement</span></code></a></p>
<p>MOMF acquisition function supporting m&gt;=2 outcomes.
The model needs to have train_obj that has a fidelity
objective appended to its end.
In the following example we consider a 2-D output space
but the ref_point is 3D because of fidelity objective.</p>
<p>See <a class="reference internal" href="#irshad2021momf" id="id33"><span>[Irshad2021MOMF]</span></a> for details.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ref_point</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cost_func</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">X</span><span class="p">:</span> <span class="mi">5</span> <span class="o">+</span> <span class="n">X</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">momf</span> <span class="o">=</span> <span class="n">MOMF</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">ref_point</span><span class="p">,</span> <span class="n">partitioning</span><span class="p">,</span> <span class="n">cost_func</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">momf_val</span> <span class="o">=</span> <span class="n">momf</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted model. There are two default assumptions in the training
data. <cite>train_X</cite> should have fidelity parameter <cite>s</cite> as the last dimension
of the input and <cite>train_Y</cite> contains a trust objective as its last
dimension.</p></li>
<li><p><strong>ref_point</strong> (<em>list</em><em>[</em><em>float</em><em>] </em><em>| </em><em>Tensor</em>) – A list or tensor with <cite>m+1</cite> elements representing the reference
point (in the outcome space) w.r.t. to which compute the hypervolume.
The ‘+1’ takes care of the trust objective appended to <cite>train_Y</cite>.
This is a reference point for the objective values (i.e. after
applying`objective` to the samples).</p></li>
<li><p><strong>partitioning</strong> (<a class="reference internal" href="utils.html#botorch.utils.multi_objective.box_decompositions.non_dominated.NondominatedPartitioning" title="botorch.utils.multi_objective.box_decompositions.non_dominated.NondominatedPartitioning"><em>NondominatedPartitioning</em></a>) – A <cite>NondominatedPartitioning</cite> module that provides the non-
dominated front and a partitioning of the non-dominated space in hyper-
rectangles. If constraints are present, this partitioning must only
include feasible points.</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – The sampler used to draw base samples. If not given,
a sampler is generated using <cite>get_sampler</cite>.</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.multi_objective.objective.MCMultiOutputObjective" title="botorch.acquisition.multi_objective.objective.MCMultiOutputObjective"><em>MCMultiOutputObjective</em></a><em> | </em><em>None</em>) – The MCMultiOutputObjective under which the samples are evaluated.
Defaults to <cite>IdentityMCMultiOutputObjective()</cite>.</p></li>
<li><p><strong>constraints</strong> (<em>list</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of callables, each mapping a Tensor of dimension
<cite>sample_shape x batch-shape x q x m</cite> to a Tensor of dimension
<cite>sample_shape x batch-shape x q</cite>, where negative values imply
feasibility. The acquisition function will compute expected feasible
hypervolume.</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x m x d</cite>-dim Tensor of <cite>m</cite> design points that have
points that have been submitted for function evaluation but have not yet
been evaluated. Concatenated into <cite>X</cite> upon forward call. Copied and set
to have no gradient.</p></li>
<li><p><strong>cost_call</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – A callable cost function mapping a Tensor of dimension
<cite>batch_shape x q x d</cite> to a cost Tensor of dimension
<cite>batch_shape x q x m</cite>. Defaults to an AffineCostModel with
<cite>C(s) = 1 + s</cite>.</p></li>
<li><p><strong>eta</strong> (<em>Tensor</em><em> | </em><em>float</em>) – The temperature parameter for the sigmoid function used for the
differentiable approximation of the constraints. In case of a float the
same eta is used for every constraint in constraints. In case of a
tensor the length of the tensor must match the number of provided
constraints. The i-th constraint is then estimated with the i-th
eta value.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.multi_fidelity.MOMF.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/multi_fidelity.html#MOMF.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.multi_fidelity.MOMF.forward" title="Link to this definition"></a></dt>
<dd><p>Takes in a <cite>batch_shape x q x d</cite> X Tensor of t-batches with <cite>q</cite> <cite>d</cite>-dim
design points each, and returns a Tensor with shape <cite>batch_shape’</cite>, where
<cite>batch_shape’</cite> is the broadcasted batch shape of model and input <cite>X</cite>. Should
utilize the result of <cite>set_X_pending</cite> as needed to account for pending function
evaluations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-botorch.acquisition.multi_objective.predictive_entropy_search">
<span id="multi-objective-predictive-entropy-search-acquisition-functions"></span><h3>Multi-Objective Predictive Entropy Search Acquisition Functions<a class="headerlink" href="#module-botorch.acquisition.multi_objective.predictive_entropy_search" title="Link to this heading"></a></h3>
<p>Acquisition function for predictive entropy search for multi-objective Bayesian
optimization (PES). The code does not support constraint handling.</p>
<p>NOTE: The PES acquisition might not be differentiable. As a result, we recommend
optimizing the acquisition function using finite differences.</p>
<p>References:</p>
<div role="list" class="citation-list">
<div class="citation" id="garrido-merchan2019" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id34">Garrido-Merchan2019</a><span class="fn-bracket">]</span></span>
<p>E. Garrido-Merchan and D. Hernandez-Lobato. Predictive Entropy Search for
Multi-objective Bayesian Optimization with Constraints. Neurocomputing. 2019.
The computation follows the procedure described in the supplementary material:
<a class="reference external" href="https://www.sciencedirect.com/science/article/abs/pii/S0925231219308525">https://www.sciencedirect.com/science/article/abs/pii/S0925231219308525</a></p>
</div>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.predictive_entropy_search.qMultiObjectivePredictiveEntropySearch">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.multi_objective.predictive_entropy_search.</span></span><span class="sig-name descname"><span class="pre">qMultiObjectivePredictiveEntropySearch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pareto_sets</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_ep_iterations</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">250</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ep_jitter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_jitter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/predictive_entropy_search.html#qMultiObjectivePredictiveEntropySearch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.predictive_entropy_search.qMultiObjectivePredictiveEntropySearch" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">AcquisitionFunction</span></code></a></p>
<p>The acquisition function for Predictive Entropy Search. The code supports
both single and multiple objectives as well as batching.</p>
<p>This acquisition function approximates the mutual information between the
observation at a candidate point <cite>X</cite> and the Pareto optimal input using the
moment-matching procedure known as expectation propagation (EP).</p>
<p>See the Appendix of <a class="reference internal" href="#garrido-merchan2019" id="id34"><span>[Garrido-Merchan2019]</span></a> for the description of the EP
procedure.</p>
<p>IMPORTANT NOTES:
(i) The PES acquisition function estimated using EP is sometimes not
differentiable, and therefore we advise using a finite-difference estimate of
the gradient as opposed to the gradients identified using automatic
differentiation, which occasionally outputs <cite>nan</cite> values.</p>
<p>The source of this differentiability is in the <cite>_update_damping</cite> function, which
finds the damping factor <cite>a</cite> that is used to update the EP parameters
<cite>a * param_new + (1 - a) * param_old</cite>. The damping factor has to ensure
that the updated covariance matrices, <cite>a * cov_f_new + (1 - a) cov_f_old</cite>, is
positive semi-definiteness. We follow the original paper, which identifies
<cite>a</cite> via a successive halving scheme i.e. we check <cite>a=1</cite> then <cite>a=0.5</cite> etc. This
procedure means <cite>a</cite> is a function of the test input <cite>X</cite>. This function is not
differentiable  in <cite>X</cite>.</p>
<ol class="lowerroman simple" start="2">
<li><p>EP could potentially fail for a number of reasons:</p></li>
</ol>
<blockquote>
<div><p>(a) When the sampled Pareto optimal points <cite>x_p</cite> is poor compared to the
training or testing data <cite>x_n</cite>.</p>
<p>(b) When the training or testing data <cite>x_n</cite> is close the Pareto optimal
points <cite>x_p</cite>.</p>
<ol class="loweralpha simple" start="3">
<li><p>When the convergence threshold is set too small.</p></li>
</ol>
<p>Problem (a) occurs because we have to compute the variable:
<cite>alpha = (mean(x_n) - mean(x_p)) / std(x_n - x_p)</cite>, which becomes very
large when <cite>x_n</cite> is better than <cite>x_p</cite> with high-probability. This leads to a
log(0) error when we compute <cite>log(1 - cdf(alpha))</cite>. We have preemptively
clamped some values depending on <cite>1`alpha</cite> in order to mitigate this.</p>
<p>Problem (b) occurs because we have to compute matrix inverses for the
two-dimensional marginals (x_n, x_p). To address this we manually add jitter
to the diagonal of the covariance matrix i.e. <cite>ep_jitter</cite> when training and
<cite>test_jitter</cite> when testing. The default choice is not always appropriate
because the same jitter is used for the inversion of the covariance
and precision matrix, which are on different scales.</p>
<p>TODO: come up with strategy to adaptively update the jitter.</p>
<p>Problem (c) occurs because a smaller threshold usually means that more EP
iterations are required. Running too many EP iterations could lead to
invertibility problems such as in problem (b). Setting a larger threshold
or reducing the number of EP iterations could alleviate this.</p>
</div></blockquote>
<ol class="lowerroman simple" start="3">
<li><p>The estimated acquisition value could be negative.</p></li>
</ol>
<p>Multi-objective predictive entropy search acquisition function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted batched model with <cite>M</cite> number of outputs.</p></li>
<li><p><strong>pareto_sets</strong> (<em>Tensor</em>) – A <cite>num_pareto_samples x P x d</cite>-dim tensor containing the
Pareto optimal set of inputs, where <cite>P</cite> is the number of pareto
optimal points. The points in each sample have to be discrete
otherwise expectation propagation will fail.</p></li>
<li><p><strong>maximize</strong> (<em>bool</em>) – If true, we consider a maximization problem.</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>m x d</cite>-dim Tensor of <cite>m</cite> design points that have been
submitted for function evaluation, but have not yet been evaluated.</p></li>
<li><p><strong>max_ep_iterations</strong> (<em>int</em>) – The maximum number of expectation propagation
iterations. (The minimum number of iterations is set at 3.)</p></li>
<li><p><strong>ep_jitter</strong> (<em>float</em>) – The amount of jitter added for the matrix inversion that
occurs during the expectation propagation update during the training
phase.</p></li>
<li><p><strong>test_jitter</strong> (<em>float</em>) – The amount of jitter added for the matrix inversion that
occurs during the expectation propagation update in the testing
phase.</p></li>
<li><p><strong>threshold</strong> (<em>float</em>) – The convergence threshold for expectation propagation. This
assesses the relative change in the mean and covariance. We default
to one percent change i.e. <cite>threshold = 1e-2</cite>.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.predictive_entropy_search.qMultiObjectivePredictiveEntropySearch.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/predictive_entropy_search.html#qMultiObjectivePredictiveEntropySearch.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.predictive_entropy_search.qMultiObjectivePredictiveEntropySearch.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate qMultiObjectivePredictiveEntropySearch on the candidate set <cite>X</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x q x d</cite>-dim Tensor of t-batches with <cite>q</cite> <cite>d</cite>-dim
design points each.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape’</cite>-dim Tensor of acquisition values at the given design
points <cite>X</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.predictive_entropy_search.log_cdf_robust">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.multi_objective.predictive_entropy_search.</span></span><span class="sig-name descname"><span class="pre">log_cdf_robust</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/predictive_entropy_search.html#log_cdf_robust"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.predictive_entropy_search.log_cdf_robust" title="Link to this definition"></a></dt>
<dd><p>Computes the logarithm of the normal cumulative density robustly. This uses
the approximation log(1-z) ~ -z when z is small:</p>
<dl class="simple">
<dt>if x &gt; 5:</dt><dd><p>log(cdf(x)) = log(1-cdf(-x)) approx -cdf(-x)</p>
</dd>
<dt>else:</dt><dd><p>log(cdf(x)).</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – a <cite>x_shape</cite>-dim Tensor.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
<dl class="simple">
<dt>Returns</dt><dd><p>A <cite>x_shape</cite>-dim Tensor.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-botorch.acquisition.multi_objective.parego">
<span id="parego-multi-objective-acquisition-function-with-chebyshev-scalarization"></span><h3>ParEGO: Multi-Objective Acquisition Function with Chebyshev Scalarization<a class="headerlink" href="#module-botorch.acquisition.multi_objective.parego" title="Link to this heading"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.parego.qLogNParEGO">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.multi_objective.parego.</span></span><span class="sig-name descname"><span class="pre">qLogNParEGO</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_baseline</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scalarization_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fat</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prune_baseline</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_root</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau_relu</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-06</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau_max</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">incremental</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/parego.html#qLogNParEGO"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.parego.qLogNParEGO" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.logei.qLogNoisyExpectedImprovement" title="botorch.acquisition.logei.qLogNoisyExpectedImprovement"><code class="xref py py-class docutils literal notranslate"><span class="pre">qLogNoisyExpectedImprovement</span></code></a>, <a class="reference internal" href="#botorch.acquisition.multi_objective.base.MultiObjectiveMCAcquisitionFunction" title="botorch.acquisition.multi_objective.base.MultiObjectiveMCAcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiObjectiveMCAcquisitionFunction</span></code></a></p>
<p>q-LogNParEGO supporting m &gt;= 2 outcomes. This acquisition function
utilizes qLogNEI to compute the expected improvement over Chebyshev
scalarization of the objectives.</p>
<p>This is adapted from qNParEGO proposed in <a class="reference internal" href="#daulton2020qehvi" id="id35"><span>[Daulton2020qehvi]</span></a> to utilize
log-improvement acquisition functions of <a class="reference internal" href="#ament2023logei" id="id36"><span>[Ament2023logei]</span></a>. See <a class="reference internal" href="utils.html#knowles2005" id="id37"><span>[Knowles2005]</span></a>
for the original ParEGO algorithm.</p>
<p>This implementation assumes maximization of all objectives. If any of the model
outputs are to be minimized, either an <cite>objective</cite> should be used to negate the
model outputs or the <cite>scalarization_weights</cite> should be provided with negative
weights for the outputs to be minimized.</p>
<blockquote>
<div><dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>model: A fitted multi-output model, producing outputs for <cite>m</cite> objectives</dt><dd><p>and any number of outcome constraints.
NOTE: The model posterior must have a <cite>mean</cite> attribute.</p>
</dd>
<dt>X_baseline: A <cite>batch_shape x r x d</cite>-dim Tensor of <cite>r</cite> design points</dt><dd><p>that have already been observed. These points are considered as
the potential best design point.</p>
</dd>
<dt>scalarization_weights: A <cite>m</cite>-dim Tensor of weights to be used in the</dt><dd><p>Chebyshev scalarization. If omitted, samples from the unit simplex.</p>
</dd>
<dt>sampler: The sampler used to draw base samples. See <cite>MCAcquisitionFunction</cite></dt><dd><p>more details.</p>
</dd>
<dt>objective: The MultiOutputMCAcquisitionObjective under which the samples are</dt><dd><p>evaluated before applying Chebyshev scalarization.
Defaults to <cite>IdentityMultiOutputObjective()</cite>.</p>
</dd>
<dt>constraints: A list of constraint callables which map a Tensor of posterior</dt><dd><p>samples of dimension <cite>sample_shape x batch-shape x q x m’</cite>-dim to a
<cite>sample_shape x batch-shape x q</cite>-dim Tensor. The associated constraints
are satisfied if <cite>constraint(samples) &lt; 0</cite>.</p>
</dd>
<dt>X_pending: A <cite>batch_shape x q’ x d</cite>-dim Tensor of <cite>q’</cite> design points</dt><dd><p>that have points that have been submitted for function evaluation
but have not yet been evaluated. Concatenated into <cite>X</cite> upon
forward call. Copied and set to have no gradient.</p>
</dd>
<dt>eta: Temperature parameter(s) governing the smoothness of the sigmoid</dt><dd><p>approximation to the constraint indicators. See the docs of
<cite>compute_(log_)smoothed_constraint_indicator</cite> for details.</p>
</dd>
<dt>fat: Toggles the logarithmic / linear asymptotic behavior of the smooth</dt><dd><p>approximation to the ReLU.</p>
</dd>
<dt>prune_baseline: If True, remove points in <cite>X_baseline</cite> that are</dt><dd><p>highly unlikely to be the best point. This can significantly
improve performance and is generally recommended. In order to
customize pruning parameters, instead manually call
<cite>botorch.acquisition.utils.prune_inferior_points</cite> on <cite>X_baseline</cite>
before instantiating the acquisition function.</p>
</dd>
<dt>cache_root: A boolean indicating whether to cache the root</dt><dd><p>decomposition over <cite>X_baseline</cite> and use low-rank updates.</p>
</dd>
<dt>tau_max: Temperature parameter controlling the sharpness of the smooth</dt><dd><p>approximations to max.</p>
</dd>
<dt>tau_relu: Temperature parameter controlling the sharpness of the smooth</dt><dd><p>approximations to ReLU.</p>
</dd>
<dt>incremental: Whether to compute incremental EI over the pending points</dt><dd><p>or compute EI of the joint batch improvement (including pending
points).</p>
</dd>
</dl>
</dd>
</dl>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>)</p></li>
<li><p><strong>X_baseline</strong> (<em>Tensor</em>)</p></li>
<li><p><strong>scalarization_weights</strong> (<em>Tensor</em><em> | </em><em>None</em>)</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>)</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.multi_objective.objective.MCMultiOutputObjective" title="botorch.acquisition.multi_objective.objective.MCMultiOutputObjective"><em>MCMultiOutputObjective</em></a><em> | </em><em>None</em>)</p></li>
<li><p><strong>constraints</strong> (<em>list</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>)</p></li>
<li><p><strong>eta</strong> (<em>Tensor</em><em> | </em><em>float</em>)</p></li>
<li><p><strong>fat</strong> (<em>bool</em>)</p></li>
<li><p><strong>prune_baseline</strong> (<em>bool</em>)</p></li>
<li><p><strong>cache_root</strong> (<em>bool</em>)</p></li>
<li><p><strong>tau_relu</strong> (<em>float</em>)</p></li>
<li><p><strong>tau_max</strong> (<em>float</em>)</p></li>
<li><p><strong>incremental</strong> (<em>bool</em>)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-botorch.acquisition.knowledge_gradient">
<span id="the-one-shot-knowledge-gradient"></span><h3>The One-Shot Knowledge Gradient<a class="headerlink" href="#module-botorch.acquisition.knowledge_gradient" title="Link to this heading"></a></h3>
<p>Batch Knowledge Gradient (KG) via one-shot optimization as introduced in
<a class="reference internal" href="#balandat2020botorch" id="id38"><span>[Balandat2020botorch]</span></a>. For broader discussion of KG see also <a class="reference internal" href="#frazier2008knowledge" id="id39"><span>[Frazier2008knowledge]</span></a>
and <a class="reference internal" href="#wu2016parallelkg" id="id40"><span>[Wu2016parallelkg]</span></a>.</p>
<div role="list" class="citation-list">
<div class="citation" id="balandat2020botorch" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Balandat2020botorch<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id7">1</a>,<a role="doc-backlink" href="#id38">2</a>)</span>
<p>M. Balandat, B. Karrer, D. R. Jiang, S. Daulton, B. Letham, A. G. Wilson, and
E. Bakshy. BoTorch: A Framework for Efficient Monte-Carlo Bayesian Optimization.
Advances in Neural Information Processing Systems 33, 2020.</p>
</div>
<div class="citation" id="frazier2008knowledge" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id39">Frazier2008knowledge</a><span class="fn-bracket">]</span></span>
<p>P. Frazier, W. Powell, and S. Dayanik. A Knowledge-Gradient policy for
sequential information collection. SIAM Journal on Control and Optimization,
2008.</p>
</div>
<div class="citation" id="wu2016parallelkg" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id40">Wu2016parallelkg</a><span class="fn-bracket">]</span></span>
<p>J. Wu and P. Frazier. The parallel knowledge gradient method for batch
bayesian optimization. NIPS 2016.</p>
</div>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.knowledge_gradient.qKnowledgeGradient">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.knowledge_gradient.</span></span><span class="sig-name descname"><span class="pre">qKnowledgeGradient</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_fantasies</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inner_sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">current_value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/knowledge_gradient.html#qKnowledgeGradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.knowledge_gradient.qKnowledgeGradient" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.monte_carlo.MCAcquisitionFunction" title="botorch.acquisition.monte_carlo.MCAcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">MCAcquisitionFunction</span></code></a>, <a class="reference internal" href="#botorch.acquisition.acquisition.OneShotAcquisitionFunction" title="botorch.acquisition.acquisition.OneShotAcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">OneShotAcquisitionFunction</span></code></a></p>
<p>Batch Knowledge Gradient using one-shot optimization.</p>
<p>This computes the batch Knowledge Gradient using fantasies for the outer
expectation and either the model posterior mean or MC-sampling for the inner
expectation.</p>
<p>In addition to the design variables, the input <cite>X</cite> also includes variables
for the optimal designs for each of the fantasy models. For a fixed number
of fantasies, all parts of <cite>X</cite> can be optimized in a “one-shot” fashion.</p>
<p>q-Knowledge Gradient (one-shot optimization).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted model. Must support fantasizing.</p></li>
<li><p><strong>num_fantasies</strong> (<em>int</em><em> | </em><em>None</em>) – The number of fantasy points to use. More fantasy
points result in a better approximation, at the expense of
memory and wall time. Unused if <cite>sampler</cite> is specified.</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – The sampler used to sample fantasy observations. Optional
if <cite>num_fantasies</cite> is specified.</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><em>MCAcquisitionObjective</em></a><em> | </em><em>None</em>) – The objective under which the samples are evaluated. If
<cite>None</cite>, then the analytic posterior mean is used. Otherwise, the
objective is MC-evaluated (using inner_sampler).</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – An optional PosteriorTransform. If given, this
transforms the posterior before evaluation. If <cite>objective is None</cite>,
then the analytic posterior mean of the transformed posterior is
used. If <cite>objective</cite> is given, the <cite>inner_sampler</cite> is used to draw
samples from the transformed posterior, which are then evaluated under
the <cite>objective</cite>.</p></li>
<li><p><strong>inner_sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – The sampler used for inner sampling. Ignored if the
objective is <cite>None</cite>.</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>m x d</cite>-dim Tensor of <cite>m</cite> design points that have
points that have been submitted for function evaluation
but have not yet been evaluated.</p></li>
<li><p><strong>current_value</strong> (<em>Tensor</em><em> | </em><em>None</em>) – The current value, i.e. the expected best objective
given the observed points <cite>D</cite>. If omitted, forward will not
return the actual KG value, but the expected best objective
given the data set <cite>D u X</cite>.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.knowledge_gradient.qKnowledgeGradient.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/knowledge_gradient.html#qKnowledgeGradient.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.knowledge_gradient.qKnowledgeGradient.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate qKnowledgeGradient on the candidate set <cite>X</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – <p>A <cite>b x (q + num_fantasies) x d</cite> Tensor with <cite>b</cite> t-batches of
<cite>q + num_fantasies</cite> design points each. We split this X tensor
into two parts in the <cite>q</cite> dimension (<cite>dim=-2</cite>). The first <cite>q</cite>
are the q-batch of design points and the last num_fantasies are
the current solutions of the inner optimization problem.</p>
<p><cite>X_fantasies = X[…, -num_fantasies:, :]</cite>
<cite>X_fantasies.shape = b x num_fantasies x d</cite></p>
<p><cite>X_actual = X[…, :-num_fantasies, :]</cite>
<cite>X_actual.shape = b x q x d</cite></p>
</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>A Tensor of shape <cite>b</cite>. For t-batch b, the q-KG value of the design</dt><dd><p><cite>X_actual[b]</cite> is averaged across the fantasy models, where
<cite>X_fantasies[b, i]</cite> is chosen as the final selection for the
<cite>i</cite>-th fantasy model.
NOTE: If <cite>current_value</cite> is not provided, then this is not the
true KG value of <cite>X_actual[b]</cite>, and <cite>X_fantasies[b, : ]</cite> must be
maximized at fixed <cite>X_actual[b]</cite>.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.knowledge_gradient.qKnowledgeGradient.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/knowledge_gradient.html#qKnowledgeGradient.evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.knowledge_gradient.qKnowledgeGradient.evaluate" title="Link to this definition"></a></dt>
<dd><p>Evaluate qKnowledgeGradient on the candidate set <cite>X_actual</cite> by
solving the inner optimization problem.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>b x q x d</cite> Tensor with <cite>b</cite> t-batches of <cite>q</cite> design points
each. Unlike <cite>forward()</cite>, this does not include solutions of the
inner optimization problem.</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – A <cite>2 x d</cite> tensor of lower and upper bounds for each column of
the solutions to the inner problem.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – Additional keyword arguments. This includes the options for
optimization of the inner problem, i.e. <cite>num_restarts</cite>, <cite>raw_samples</cite>,
an <cite>options</cite> dictionary to be passed on to the optimization helpers, and
a <cite>scipy_options</cite> dictionary to be passed to <cite>scipy.minimize</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>A Tensor of shape <cite>b</cite>. For t-batch b, the q-KG value of the design</dt><dd><p><cite>X[b]</cite> is averaged across the fantasy models.
NOTE: If <cite>current_value</cite> is not provided, then this is not the
true KG value of <cite>X[b]</cite>.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.knowledge_gradient.qKnowledgeGradient.get_augmented_q_batch_size">
<span class="sig-name descname"><span class="pre">get_augmented_q_batch_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">q</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/knowledge_gradient.html#qKnowledgeGradient.get_augmented_q_batch_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.knowledge_gradient.qKnowledgeGradient.get_augmented_q_batch_size" title="Link to this definition"></a></dt>
<dd><p>Get augmented q batch size for one-shot optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>q</strong> (<em>int</em>) – The number of candidates to consider jointly.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The augmented size for one-shot optimization (including variables
parameterizing the fantasy solutions).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.knowledge_gradient.qKnowledgeGradient.extract_candidates">
<span class="sig-name descname"><span class="pre">extract_candidates</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X_full</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/knowledge_gradient.html#qKnowledgeGradient.extract_candidates"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.knowledge_gradient.qKnowledgeGradient.extract_candidates" title="Link to this definition"></a></dt>
<dd><p>We only return X as the set of candidates post-optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X_full</strong> (<em>Tensor</em>) – A <cite>b x (q + num_fantasies) x d</cite>-dim Tensor with <cite>b</cite>
t-batches of <cite>q + num_fantasies</cite> design points each.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>b x q x d</cite>-dim Tensor with <cite>b</cite> t-batches of <cite>q</cite> design points each.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.knowledge_gradient.qMultiFidelityKnowledgeGradient">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.knowledge_gradient.</span></span><span class="sig-name descname"><span class="pre">qMultiFidelityKnowledgeGradient</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_fantasies=64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inner_sampler=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">current_value=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cost_aware_utility=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">project=&lt;function</span> <span class="pre">qMultiFidelityKnowledgeGradient.&lt;lambda&gt;&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">expand=&lt;function</span> <span class="pre">qMultiFidelityKnowledgeGradient.&lt;lambda&gt;&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">valfunc_cls=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">valfunc_argfac=None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/knowledge_gradient.html#qMultiFidelityKnowledgeGradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.knowledge_gradient.qMultiFidelityKnowledgeGradient" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.knowledge_gradient.qKnowledgeGradient" title="botorch.acquisition.knowledge_gradient.qKnowledgeGradient"><code class="xref py py-class docutils literal notranslate"><span class="pre">qKnowledgeGradient</span></code></a></p>
<p>Batch Knowledge Gradient for multi-fidelity optimization.</p>
<p>A version of <cite>qKnowledgeGradient</cite> that supports multi-fidelity optimization
via a <cite>CostAwareUtility</cite> and the <cite>project</cite> and <cite>expand</cite> operators. If none
of these are set, this acquisition function reduces to <cite>qKnowledgeGradient</cite>.
Through <cite>valfunc_cls</cite> and <cite>valfunc_argfac</cite>, this can be changed into a custom
multi-fidelity acquisition function (it is only KG if the terminal value is
computed using a posterior mean).</p>
<p>Multi-Fidelity q-Knowledge Gradient (one-shot optimization).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted model. Must support fantasizing.</p></li>
<li><p><strong>num_fantasies</strong> (<em>int</em><em> | </em><em>None</em>) – The number of fantasy points to use. More fantasy
points result in a better approximation, at the expense of
memory and wall time. Unused if <cite>sampler</cite> is specified.</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – The sampler used to sample fantasy observations. Optional
if <cite>num_fantasies</cite> is specified.</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><em>MCAcquisitionObjective</em></a><em> | </em><em>None</em>) – The objective under which the samples are evaluated. If
<cite>None</cite>, then the analytic posterior mean is used. Otherwise, the
objective is MC-evaluated (using inner_sampler).</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – An optional PosteriorTransform. If given, this
transforms the posterior before evaluation. If <cite>objective is None</cite>,
then the analytic posterior mean of the transformed posterior is
used. If <cite>objective</cite> is given, the <cite>inner_sampler</cite> is used to draw
samples from the transformed posterior, which are then evaluated under
the <cite>objective</cite>.</p></li>
<li><p><strong>inner_sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – The sampler used for inner sampling. Ignored if the
objective is <cite>None</cite>.</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>m x d</cite>-dim Tensor of <cite>m</cite> design points that have
points that have been submitted for function evaluation
but have not yet been evaluated.</p></li>
<li><p><strong>current_value</strong> (<em>Tensor</em><em> | </em><em>None</em>) – The current value, i.e. the expected best objective
given the observed points <cite>D</cite>. If omitted, forward will not
return the actual KG value, but the expected best objective
given the data set <cite>D u X</cite>.</p></li>
<li><p><strong>cost_aware_utility</strong> (<a class="reference internal" href="#botorch.acquisition.cost_aware.CostAwareUtility" title="botorch.acquisition.cost_aware.CostAwareUtility"><em>CostAwareUtility</em></a><em> | </em><em>None</em>) – A CostAwareUtility computing the cost-transformed
utility from a candidate set and samples of increases in utility.</p></li>
<li><p><strong>project</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em>) – A callable mapping a <cite>batch_shape x q x d</cite> tensor of design
points to a tensor with shape <cite>batch_shape x q_term x d</cite> projected
to the desired target set (e.g. the target fidelities in case of
multi-fidelity optimization). For the basic case, <cite>q_term = q</cite>.</p></li>
<li><p><strong>expand</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em>) – A callable mapping a <cite>batch_shape x q x d</cite> input tensor to
a <cite>batch_shape x (q + q_e)’ x d</cite>-dim output tensor, where the
<cite>q_e</cite> additional points in each q-batch correspond to
additional (“trace”) observations.</p></li>
<li><p><strong>valfunc_cls</strong> (<em>type</em><em>[</em><a class="reference internal" href="#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><em>AcquisitionFunction</em></a><em>] </em><em>| </em><em>None</em>) – An acquisition function class to be used as the terminal
value function.</p></li>
<li><p><strong>valfunc_argfac</strong> (<em>Callable</em><em>[</em><em>[</em><a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a><em>]</em><em>, </em><em>dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>] </em><em>| </em><em>None</em>) – An argument factory, i.e. callable that maps a <cite>Model</cite>
to a dictionary of kwargs for the terminal value function (e.g.
<cite>best_f</cite> for <cite>ExpectedImprovement</cite>).</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="botorch.acquisition.knowledge_gradient.qMultiFidelityKnowledgeGradient.cost_sampler">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">cost_sampler</span></span><a class="headerlink" href="#botorch.acquisition.knowledge_gradient.qMultiFidelityKnowledgeGradient.cost_sampler" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.knowledge_gradient.qMultiFidelityKnowledgeGradient.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/knowledge_gradient.html#qMultiFidelityKnowledgeGradient.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.knowledge_gradient.qMultiFidelityKnowledgeGradient.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate qMultiFidelityKnowledgeGradient on the candidate set <cite>X</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – <p>A <cite>b x (q + num_fantasies) x d</cite> Tensor with <cite>b</cite> t-batches of
<cite>q + num_fantasies</cite> design points each. We split this X tensor
into two parts in the <cite>q</cite> dimension (<cite>dim=-2</cite>). The first <cite>q</cite>
are the q-batch of design points and the last num_fantasies are
the current solutions of the inner optimization problem.</p>
<p><cite>X_fantasies = X[…, -num_fantasies:, :]</cite>
<cite>X_fantasies.shape = b x num_fantasies x d</cite></p>
<p><cite>X_actual = X[…, :-num_fantasies, :]</cite>
<cite>X_actual.shape = b x q x d</cite></p>
<p>In addition, <cite>X</cite> may be augmented with fidelity parameters as
part of thee <cite>d</cite>-dimension. Projecting fidelities to the target
fidelity is handled by <cite>project</cite>.</p>
</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>A Tensor of shape <cite>b</cite>. For t-batch b, the q-KG value of the design</dt><dd><p><cite>X_actual[b]</cite> is averaged across the fantasy models, where
<cite>X_fantasies[b, i]</cite> is chosen as the final selection for the
<cite>i</cite>-th fantasy model.
NOTE: If <cite>current_value</cite> is not provided, then this is not the
true KG value of <cite>X_actual[b]</cite>, and <cite>X_fantasies[b, : ]</cite> must be
maximized at fixed <cite>X_actual[b]</cite>.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.knowledge_gradient.ProjectedAcquisitionFunction">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.knowledge_gradient.</span></span><span class="sig-name descname"><span class="pre">ProjectedAcquisitionFunction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">base_value_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">project</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/knowledge_gradient.html#ProjectedAcquisitionFunction"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.knowledge_gradient.ProjectedAcquisitionFunction" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">AcquisitionFunction</span></code></a></p>
<p>Defines a wrapper around  an <cite>AcquisitionFunction</cite> that incorporates the project
operator. Typically used to handle value functions in look-ahead methods.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>base_value_function</strong> (<a class="reference internal" href="#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><em>AcquisitionFunction</em></a>) – The wrapped <cite>AcquisitionFunction</cite>.</p></li>
<li><p><strong>project</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em>) – A callable mapping a <cite>batch_shape x q x d</cite> tensor of design
points to a tensor with shape <cite>batch_shape x q_term x d</cite> projected
to the desired target set (e.g. the target fidelities in case of
multi-fidelity optimization). For the basic case, <cite>q_term = q</cite>.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.knowledge_gradient.ProjectedAcquisitionFunction.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/knowledge_gradient.html#ProjectedAcquisitionFunction.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.knowledge_gradient.ProjectedAcquisitionFunction.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate the acquisition function on the candidate set X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>(b) x q x d</cite>-dim Tensor of <cite>(b)</cite> t-batches with <cite>q</cite> <cite>d</cite>-dim
design points each.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>(b)</cite>-dim Tensor of acquisition function values at the given
design points <cite>X</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-botorch.acquisition.multi_step_lookahead">
<span id="multi-step-lookahead-acquisition-functions"></span><h3>Multi-Step Lookahead Acquisition Functions<a class="headerlink" href="#module-botorch.acquisition.multi_step_lookahead" title="Link to this heading"></a></h3>
<p>A general implementation of multi-step look-ahead acquisition function with configurable
value functions. See <a class="reference internal" href="#jiang2020multistep" id="id41"><span>[Jiang2020multistep]</span></a>.</p>
<div role="list" class="citation-list">
<div class="citation" id="jiang2020multistep" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id41">Jiang2020multistep</a><span class="fn-bracket">]</span></span>
<p>S. Jiang, D. R. Jiang, M. Balandat, B. Karrer, J. Gardner, and R. Garnett.
Efficient Nonmyopic Bayesian Optimization via One-Shot Multi-Step Trees.
In Advances in Neural Information Processing Systems 33, 2020.</p>
</div>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.multi_step_lookahead.qMultiStepLookahead">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.multi_step_lookahead.</span></span><span class="sig-name descname"><span class="pre">qMultiStepLookahead</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_sizes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_fantasies</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">samplers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">valfunc_cls</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">valfunc_argfacs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inner_mc_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">collapse_fantasy_base_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_step_lookahead.html#qMultiStepLookahead"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_step_lookahead.qMultiStepLookahead" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.monte_carlo.MCAcquisitionFunction" title="botorch.acquisition.monte_carlo.MCAcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">MCAcquisitionFunction</span></code></a>, <a class="reference internal" href="#botorch.acquisition.acquisition.OneShotAcquisitionFunction" title="botorch.acquisition.acquisition.OneShotAcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">OneShotAcquisitionFunction</span></code></a></p>
<p>MC-based batch Multi-Step Look-Ahead (one-shot optimization).</p>
<p>q-Multi-Step Look-Ahead (one-shot optimization).</p>
<p>Performs a <cite>k</cite>-step lookahead by means of repeated fantasizing.</p>
<p>Allows to specify the stage value functions by passing the respective class
objects via the <cite>valfunc_cls</cite> list. Optionally, <cite>valfunc_argfacs</cite> takes a list
of callables that generate additional kwargs for these constructors. By default,
<cite>valfunc_cls</cite> will be chosen as <cite>[None, …, None, PosteriorMean]</cite>, which
corresponds to the (parallel) multi-step KnowledgeGradient. If, in addition,
<cite>k=1</cite> and <cite>q_1 = 1</cite>, this reduces to the classic Knowledge Gradient.</p>
<p>WARNING: The complexity of evaluating this function is exponential in the number
of lookahead steps!</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted model.</p></li>
<li><p><strong>batch_sizes</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – A list <cite>[q_1, …, q_k]</cite> containing the batch sizes for the
<cite>k</cite> look-ahead steps.</p></li>
<li><p><strong>num_fantasies</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – A list <cite>[f_1, …, f_k]</cite> containing the number of fantasy
points to use for the <cite>k</cite> look-ahead steps.</p></li>
<li><p><strong>samplers</strong> (<em>list</em><em>[</em><a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em>] </em><em>| </em><em>None</em>) – A list of MCSampler objects to be used for sampling fantasies in
each stage.</p></li>
<li><p><strong>valfunc_cls</strong> (<em>list</em><em>[</em><em>type</em><em>[</em><a class="reference internal" href="#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><em>AcquisitionFunction</em></a><em>] </em><em>| </em><em>None</em><em>] </em><em>| </em><em>None</em>) – A list of <cite>k + 1</cite> acquisition function classes to be used as
the (stage + terminal) value functions. Each element (except for the
last one) can be <cite>None</cite>, in which case a zero stage value is assumed for
the respective stage. If <cite>None</cite>, this defaults to
<cite>[None, …, None, PosteriorMean]</cite></p></li>
<li><p><strong>valfunc_argfacs</strong> (<em>list</em><em>[</em><em>TAcqfArgConstructor</em><em> | </em><em>None</em><em>] </em><em>| </em><em>None</em>) – A list of <cite>k + 1</cite> “argument factories”, i.e. callables that
map a <cite>Model</cite> and input tensor <cite>X</cite> to a dictionary of kwargs for the
respective stage value function constructor (e.g. <cite>best_f</cite> for
<cite>ExpectedImprovement</cite>). If None, only the standard (<cite>model</cite>, <cite>sampler</cite>
and <cite>objective</cite>) kwargs will be used.</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><em>MCAcquisitionObjective</em></a><em> | </em><em>None</em>) – The objective under which the output is evaluated. If <cite>None</cite>, use
the model output (requires a single-output model or a posterior
transform). Otherwise the objective is MC-evaluated
(using <cite>inner_sampler</cite>).</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – An optional PosteriorTransform. If given, this
transforms the posterior before evaluation. If <cite>objective is None</cite>,
then the output of the transformed posterior is used. If <cite>objective</cite> is
given, the <cite>inner_sampler</cite> is used to draw samples from the transformed
posterior, which are then evaluated under the <cite>objective</cite>.</p></li>
<li><p><strong>inner_mc_samples</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – A list <cite>[n_0, …, n_k]</cite> containing the number of MC
samples to be used for evaluating the stage value function. Ignored if
the objective is <cite>None</cite>.</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>m x d</cite>-dim Tensor of <cite>m</cite> design points that have points that
have been submitted for function evaluation but have not yet been
evaluated. Concatenated into <cite>X</cite> upon forward call. Copied and set to
have no gradient.</p></li>
<li><p><strong>collapse_fantasy_base_samples</strong> (<em>bool</em>) – If True, collapse_batch_dims of the Samplers
will be applied on fantasy batch dimensions as well, meaning that base
samples are the same in all subtrees starting from the same level.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.multi_step_lookahead.qMultiStepLookahead.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_step_lookahead.html#qMultiStepLookahead.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_step_lookahead.qMultiStepLookahead.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate qMultiStepLookahead on the candidate set X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x q’ x d</cite>-dim Tensor with <cite>q’</cite> design points for each
batch, where <cite>q’ = q_0 + f_1 q_1 + f_2 f_1 q_2 + …</cite>. Here <cite>q_i</cite>
is the number of candidates jointly considered in look-ahead step
<cite>i</cite>, and <cite>f_i</cite> is respective number of fantasies.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The acquisition value for each batch as a tensor of shape <cite>batch_shape</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.multi_step_lookahead.qMultiStepLookahead.get_augmented_q_batch_size">
<span class="sig-name descname"><span class="pre">get_augmented_q_batch_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">q</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_step_lookahead.html#qMultiStepLookahead.get_augmented_q_batch_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_step_lookahead.qMultiStepLookahead.get_augmented_q_batch_size" title="Link to this definition"></a></dt>
<dd><p>Get augmented q batch size for one-shot optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>q</strong> (<em>int</em>) – The number of candidates to consider jointly.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The augmented size for one-shot optimization (including variables
parameterizing the fantasy solutions): <cite>q_0 + f_1 q_1 + f_2 f_1 q_2 + …</cite></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.multi_step_lookahead.qMultiStepLookahead.get_split_shapes">
<span class="sig-name descname"><span class="pre">get_split_shapes</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_step_lookahead.html#qMultiStepLookahead.get_split_shapes"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_step_lookahead.qMultiStepLookahead.get_split_shapes" title="Link to this definition"></a></dt>
<dd><p>Get the split shapes from X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x q_aug x d</cite>-dim tensor including fantasy points.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A 3-tuple <cite>(batch_shape, shapes, sizes)</cite>, where
<cite>shape[i] = f_i x …. x f_1 x batch_shape x q_i x d</cite> and
<cite>size[i] = f_i * … f_1 * q_i</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple[<em>Size</em>, list[<em>Size</em>], list[int]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.multi_step_lookahead.qMultiStepLookahead.get_multi_step_tree_input_representation">
<span class="sig-name descname"><span class="pre">get_multi_step_tree_input_representation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_step_lookahead.html#qMultiStepLookahead.get_multi_step_tree_input_representation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_step_lookahead.qMultiStepLookahead.get_multi_step_tree_input_representation" title="Link to this definition"></a></dt>
<dd><p>Get the multi-step tree representation of X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x q’ x d</cite>-dim Tensor with <cite>q’</cite> design points for each
batch, where <cite>q’ = q_0 + f_1 q_1 + f_2 f_1 q_2 + …</cite>. Here <cite>q_i</cite>
is the number of candidates jointly considered in look-ahead step
<cite>i</cite>, and <cite>f_i</cite> is respective number of fantasies.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list <cite>[X_j, …, X_k]</cite> of tensors, where <cite>X_i</cite> has shape
<cite>f_i x …. x f_1 x batch_shape x q_i x d</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list[<em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.multi_step_lookahead.qMultiStepLookahead.extract_candidates">
<span class="sig-name descname"><span class="pre">extract_candidates</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X_full</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_step_lookahead.html#qMultiStepLookahead.extract_candidates"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_step_lookahead.qMultiStepLookahead.extract_candidates" title="Link to this definition"></a></dt>
<dd><p>We only return X as the set of candidates post-optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X_full</strong> (<em>Tensor</em>) – A <cite>batch_shape x q’ x d</cite>-dim Tensor with <cite>q’</cite> design points for
each batch, where <cite>q’ = q + f_1 q_1 + f_2 f_1 q_2 + …</cite>.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape x q x d</cite>-dim Tensor with <cite>q</cite> design points for each batch.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.multi_step_lookahead.qMultiStepLookahead.get_induced_fantasy_model">
<span class="sig-name descname"><span class="pre">get_induced_fantasy_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_step_lookahead.html#qMultiStepLookahead.get_induced_fantasy_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_step_lookahead.qMultiStepLookahead.get_induced_fantasy_model" title="Link to this definition"></a></dt>
<dd><p>Fantasy model induced by X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x q’ x d</cite>-dim Tensor with <cite>q’</cite> design points for each
batch, where <cite>q’ = q_0 + f_1 q_1 + f_2 f_1 q_2 + …</cite>. Here <cite>q_i</cite>
is the number of candidates jointly considered in look-ahead step
<cite>i</cite>, and <cite>f_i</cite> is respective number of fantasies.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The fantasy model induced by X.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.multi_step_lookahead.warmstart_multistep">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.multi_step_lookahead.</span></span><span class="sig-name descname"><span class="pre">warmstart_multistep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_restarts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raw_samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">full_optimizer</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_step_lookahead.html#warmstart_multistep"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_step_lookahead.warmstart_multistep" title="Link to this definition"></a></dt>
<dd><p>Warm-start initialization for multi-step look-ahead acquisition functions.</p>
<p>For now uses the same q’ as in <cite>full_optimizer</cite>. TODO: allow different <cite>q</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<a class="reference internal" href="#botorch.acquisition.multi_step_lookahead.qMultiStepLookahead" title="botorch.acquisition.multi_step_lookahead.qMultiStepLookahead"><em>qMultiStepLookahead</em></a>) – A qMultiStepLookahead acquisition function.</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – A <cite>2 x d</cite> tensor of lower and upper bounds for each column of features.</p></li>
<li><p><strong>num_restarts</strong> (<em>int</em>) – The number of starting points for multistart acquisition
function optimization.</p></li>
<li><p><strong>raw_samples</strong> (<em>int</em>) – The number of raw samples to consider in the initialization
heuristic.</p></li>
<li><p><strong>full_optimizer</strong> (<em>Tensor</em>) – The full tree of optimizers of the previous iteration of shape
<cite>batch_shape x q’ x d</cite>. Typically obtained by passing
<cite>return_best_only=False</cite> and <cite>return_full_tree=True</cite> into <cite>optimize_acqf</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>num_restarts x q’ x d</cite> tensor for initial points for optimization.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
<p>This is a very simple initialization heuristic.
TODO: Use the observed values to identify the fantasy sub-tree that is closest to
the observed value.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.multi_step_lookahead.make_best_f">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.multi_step_lookahead.</span></span><span class="sig-name descname"><span class="pre">make_best_f</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_step_lookahead.html#make_best_f"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_step_lookahead.make_best_f" title="Link to this definition"></a></dt>
<dd><p>Extract the best observed training input from the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>)</p></li>
<li><p><strong>X</strong> (<em>Tensor</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>dict[str, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-botorch.acquisition.max_value_entropy_search">
<span id="max-value-entropy-search-acquisition-functions"></span><h3>Max-value Entropy Search Acquisition Functions<a class="headerlink" href="#module-botorch.acquisition.max_value_entropy_search" title="Link to this heading"></a></h3>
<p>Acquisition functions for Max-value Entropy Search (MES), General
Information-Based Bayesian Optimization (GIBBON), and
multi-fidelity MES with noisy observations and trace observations.</p>
<p>References</p>
<div role="list" class="citation-list">
<div class="citation" id="moss2021gibbon" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id44">Moss2021gibbon</a><span class="fn-bracket">]</span></span>
<p>Moss, H. B., et al.,
GIBBON: General-purpose Information-Based Bayesian OptimisatioN.
Journal of Machine Learning Research, 2021.</p>
</div>
<div class="citation" id="takeno2020mfmves" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Takeno2020mfmves<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id23">1</a>,<a role="doc-backlink" href="#id45">2</a>,<a role="doc-backlink" href="#id46">3</a>)</span>
<p>S. Takeno, H. Fukuoka, Y. Tsukada, T. Koyama, M. Shiga, I. Takeuchi,
M. Karasuyama. Multi-fidelity Bayesian Optimization with Max-value Entropy
Search and its Parallelization. Proceedings of the 37th International
Conference on Machine Learning, 2020.</p>
</div>
<div class="citation" id="wang2017mves" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Wang2017mves<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id42">1</a>,<a role="doc-backlink" href="#id43">2</a>)</span>
<p>Z. Wang, S. Jegelka, Max-value Entropy Search for Efficient
Bayesian Optimization. Proceedings of the 37th International
Conference on Machine Learning, 2017.</p>
</div>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.max_value_entropy_search.MaxValueBase">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.max_value_entropy_search.</span></span><span class="sig-name descname"><span class="pre">MaxValueBase</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">candidate_set</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_mv_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_gumbel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_inputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/max_value_entropy_search.html#MaxValueBase"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.max_value_entropy_search.MaxValueBase" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">AcquisitionFunction</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>Abstract base class for acquisition functions based on Max-value Entropy Search,
using discrete max posterior sampling.</p>
<p>This class provides the basic building blocks for constructing max-value
entropy-based acquisition functions along the lines of <a class="reference internal" href="#wang2017mves" id="id42"><span>[Wang2017mves]</span></a>.
It provides basic functionality for sampling posterior maximum values from
a surrogate Gaussian process model using a discrete set of candidates. It supports
either exact (w.r.t. the candidate set) sampling, or using a Gumbel approximation.</p>
<p>Subclasses must implement <cite>_compute_information_gain</cite>.</p>
<p>Single-outcome max-value entropy search-based acquisition functions
based on discrete MV sampling.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted single-outcome model.</p></li>
<li><p><strong>candidate_set</strong> (<em>Tensor</em>) – A <cite>n x d</cite> Tensor including <cite>n</cite> candidate points to
discretize the design space. Max values are sampled from the
(joint) model posterior over these points.</p></li>
<li><p><strong>num_mv_samples</strong> (<em>int</em>) – Number of max value samples.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – A PosteriorTransform. If using a multi-output model,
a PosteriorTransform that transforms the multi-output posterior into a
single-output posterior is required.</p></li>
<li><p><strong>use_gumbel</strong> (<em>bool</em>) – If True, use Gumbel approximation to sample the max values.</p></li>
<li><p><strong>maximize</strong> (<em>bool</em>) – If True, consider the problem a maximization problem.</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>m x d</cite>-dim Tensor of <cite>m</cite> design points that have been
submitted for function evaluation but have not yet been evaluated.</p></li>
<li><p><strong>train_inputs</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>n_train x d</cite> Tensor that the model has been fitted on.
Not required if the model is an instance of a GPyTorch ExactGP model.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.max_value_entropy_search.MaxValueBase.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/max_value_entropy_search.html#MaxValueBase.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.max_value_entropy_search.MaxValueBase.forward" title="Link to this definition"></a></dt>
<dd><p>Compute max-value entropy at the design points <cite>X</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x 1 x d</cite>-dim Tensor of <cite>batch_shape</cite> t-batches
with <cite>1</cite> <cite>d</cite>-dim design points each.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape</cite>-dim Tensor of MVE values at the given design points <cite>X</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.max_value_entropy_search.MaxValueBase.set_X_pending">
<span class="sig-name descname"><span class="pre">set_X_pending</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/max_value_entropy_search.html#MaxValueBase.set_X_pending"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.max_value_entropy_search.MaxValueBase.set_X_pending" title="Link to this definition"></a></dt>
<dd><p>Set pending design points.</p>
<p>Set “pending points” to inform the acquisition function of the candidate
points that have been generated but are pending evaluation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – <cite>n x d</cite> Tensor with <cite>n</cite> <cite>d</cite>-dim design points that have
been submitted for evaluation but have not yet been evaluated.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.max_value_entropy_search.qMaxValueEntropy">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.max_value_entropy_search.</span></span><span class="sig-name descname"><span class="pre">qMaxValueEntropy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">candidate_set</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_fantasies</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">16</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_mv_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_y_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">128</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_gumbel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_inputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/max_value_entropy_search.html#qMaxValueEntropy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.max_value_entropy_search.qMaxValueEntropy" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.max_value_entropy_search.MaxValueBase" title="botorch.acquisition.max_value_entropy_search.MaxValueBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">MaxValueBase</span></code></a>, <a class="reference internal" href="#botorch.acquisition.acquisition.MCSamplerMixin" title="botorch.acquisition.acquisition.MCSamplerMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">MCSamplerMixin</span></code></a></p>
<p>The acquisition function for Max-value Entropy Search.</p>
<p>This acquisition function computes the mutual information of max values and
a candidate point X. See <a class="reference internal" href="#wang2017mves" id="id43"><span>[Wang2017mves]</span></a> for a detailed discussion.</p>
<p>The model must be single-outcome. The batch case <cite>q &gt; 1</cite> is supported
through cyclic optimization and fantasies.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">candidate_set</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">bounds</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">candidate_set</span> <span class="o">=</span> <span class="n">bounds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="n">bounds</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">bounds</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">*</span> <span class="n">candidate_set</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">MES</span> <span class="o">=</span> <span class="n">qMaxValueEntropy</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">candidate_set</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mes</span> <span class="o">=</span> <span class="n">MES</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
</pre></div>
</div>
<p>Single-outcome max-value entropy search acquisition function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted single-outcome model.</p></li>
<li><p><strong>candidate_set</strong> (<em>Tensor</em>) – A <cite>n x d</cite> Tensor including <cite>n</cite> candidate points to
discretize the design space. Max values are sampled from the
(joint) model posterior over these points.</p></li>
<li><p><strong>num_fantasies</strong> (<em>int</em>) – Number of fantasies to generate. The higher this
number the more accurate the model (at the expense of model
complexity, wall time and memory). Ignored if <cite>X_pending</cite> is <cite>None</cite>.</p></li>
<li><p><strong>num_mv_samples</strong> (<em>int</em>) – Number of max value samples.</p></li>
<li><p><strong>num_y_samples</strong> (<em>int</em>) – Number of posterior samples at specific design point <cite>X</cite>.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – A PosteriorTransform. If using a multi-output model,
a PosteriorTransform that transforms the multi-output posterior into a
single-output posterior is required.</p></li>
<li><p><strong>use_gumbel</strong> (<em>bool</em>) – If True, use Gumbel approximation to sample the max values.</p></li>
<li><p><strong>maximize</strong> (<em>bool</em>) – If True, consider the problem a maximization problem.</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>m x d</cite>-dim Tensor of <cite>m</cite> design points that have been
submitted for function evaluation but have not yet been evaluated.</p></li>
<li><p><strong>train_inputs</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>n_train x d</cite> Tensor that the model has been fitted on.
Not required if the model is an instance of a GPyTorch ExactGP model.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.max_value_entropy_search.qMaxValueEntropy.set_X_pending">
<span class="sig-name descname"><span class="pre">set_X_pending</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/max_value_entropy_search.html#qMaxValueEntropy.set_X_pending"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.max_value_entropy_search.qMaxValueEntropy.set_X_pending" title="Link to this definition"></a></dt>
<dd><p>Set pending points.</p>
<p>Informs the acquisition function about pending design points,
fantasizes the model on the pending points and draws max-value samples
from the fantasized model posterior.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – <cite>m x d</cite> Tensor with <cite>m</cite> <cite>d</cite>-dim design points that have
been submitted for evaluation but have not yet been evaluated.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.max_value_entropy_search.qLowerBoundMaxValueEntropy">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.max_value_entropy_search.</span></span><span class="sig-name descname"><span class="pre">qLowerBoundMaxValueEntropy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">candidate_set</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_mv_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_gumbel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_inputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/max_value_entropy_search.html#qLowerBoundMaxValueEntropy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.max_value_entropy_search.qLowerBoundMaxValueEntropy" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.max_value_entropy_search.MaxValueBase" title="botorch.acquisition.max_value_entropy_search.MaxValueBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">MaxValueBase</span></code></a></p>
<p>The acquisition function for General-purpose Information-Based
Bayesian Optimisation (GIBBON).</p>
<p>This acquisition function provides a computationally cheap approximation of
the mutual information between max values and a batch of candidate points <cite>X</cite>.
See <a class="reference internal" href="#moss2021gibbon" id="id44"><span>[Moss2021gibbon]</span></a> for a detailed discussion.</p>
<p>The model must be single-outcome, unless using a PosteriorTransform.
q &gt; 1 is supported through greedy batch filling.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">candidate_set</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">bounds</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">candidate_set</span> <span class="o">=</span> <span class="n">bounds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="n">bounds</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">bounds</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">*</span> <span class="n">candidate_set</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qGIBBON</span> <span class="o">=</span> <span class="n">qLowerBoundMaxValueEntropy</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">candidate_set</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">candidates</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">optimize_acqf</span><span class="p">(</span><span class="n">qGIBBON</span><span class="p">,</span> <span class="n">bounds</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
<p>Single-outcome max-value entropy search-based acquisition functions
based on discrete MV sampling.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted single-outcome model.</p></li>
<li><p><strong>candidate_set</strong> (<em>Tensor</em>) – A <cite>n x d</cite> Tensor including <cite>n</cite> candidate points to
discretize the design space. Max values are sampled from the
(joint) model posterior over these points.</p></li>
<li><p><strong>num_mv_samples</strong> (<em>int</em>) – Number of max value samples.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – A PosteriorTransform. If using a multi-output model,
a PosteriorTransform that transforms the multi-output posterior into a
single-output posterior is required.</p></li>
<li><p><strong>use_gumbel</strong> (<em>bool</em>) – If True, use Gumbel approximation to sample the max values.</p></li>
<li><p><strong>maximize</strong> (<em>bool</em>) – If True, consider the problem a maximization problem.</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>m x d</cite>-dim Tensor of <cite>m</cite> design points that have been
submitted for function evaluation but have not yet been evaluated.</p></li>
<li><p><strong>train_inputs</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>n_train x d</cite> Tensor that the model has been fitted on.
Not required if the model is an instance of a GPyTorch ExactGP model.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.max_value_entropy_search.qMultiFidelityMaxValueEntropy">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.max_value_entropy_search.</span></span><span class="sig-name descname"><span class="pre">qMultiFidelityMaxValueEntropy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">candidate_set</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_fantasies=16</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_mv_samples=10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_y_samples=128</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_gumbel=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximize=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cost_aware_utility=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">project=&lt;function</span> <span class="pre">qMultiFidelityMaxValueEntropy.&lt;lambda&gt;&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">expand=&lt;function</span> <span class="pre">qMultiFidelityMaxValueEntropy.&lt;lambda&gt;&gt;</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/max_value_entropy_search.html#qMultiFidelityMaxValueEntropy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.max_value_entropy_search.qMultiFidelityMaxValueEntropy" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.max_value_entropy_search.qMaxValueEntropy" title="botorch.acquisition.max_value_entropy_search.qMaxValueEntropy"><code class="xref py py-class docutils literal notranslate"><span class="pre">qMaxValueEntropy</span></code></a></p>
<p>Multi-fidelity max-value entropy.</p>
<p>The acquisition function for multi-fidelity max-value entropy search
with support for trace observations. See <a class="reference internal" href="#takeno2020mfmves" id="id45"><span>[Takeno2020mfmves]</span></a>
for a detailed discussion of the basic ideas on multi-fidelity MES
(note that this implementation is somewhat different).</p>
<p>The model must be single-outcome.
The batch case <cite>q &gt; 1</cite> is supported through cyclic optimization and fantasies.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">candidate_set</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">bounds</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">candidate_set</span> <span class="o">=</span> <span class="n">bounds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="n">bounds</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">bounds</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">*</span> <span class="n">candidate_set</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">MF_MES</span> <span class="o">=</span> <span class="n">qMultiFidelityMaxValueEntropy</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">candidate_set</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mf_mes</span> <span class="o">=</span> <span class="n">MF_MES</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
</pre></div>
</div>
<p>Single-outcome max-value entropy search acquisition function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted single-outcome model.</p></li>
<li><p><strong>candidate_set</strong> (<em>Tensor</em>) – A <cite>n x d</cite> Tensor including <cite>n</cite> candidate points to
discretize the design space, which will be used to sample the
max values from their posteriors.</p></li>
<li><p><strong>cost_aware_utility</strong> (<a class="reference internal" href="#botorch.acquisition.cost_aware.CostAwareUtility" title="botorch.acquisition.cost_aware.CostAwareUtility"><em>CostAwareUtility</em></a><em> | </em><em>None</em>) – A CostAwareUtility computing the cost-transformed
utility from a candidate set and samples of increases in utility.</p></li>
<li><p><strong>num_fantasies</strong> (<em>int</em>) – Number of fantasies to generate. The higher this
number the more accurate the model (at the expense of model
complexity and performance) and it’s only used when <cite>X_pending</cite>
is not <cite>None</cite>.</p></li>
<li><p><strong>num_mv_samples</strong> (<em>int</em>) – Number of max value samples.</p></li>
<li><p><strong>num_y_samples</strong> (<em>int</em>) – Number of posterior samples at specific design point <cite>X</cite>.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – A PosteriorTransform. If using a multi-output model,
a PosteriorTransform that transforms the multi-output posterior into a
single-output posterior is required.</p></li>
<li><p><strong>use_gumbel</strong> (<em>bool</em>) – If True, use Gumbel approximation to sample the max values.</p></li>
<li><p><strong>maximize</strong> (<em>bool</em>) – If True, consider the problem a maximization problem.</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>m x d</cite>-dim Tensor of <cite>m</cite> design points that have been
submitted for function evaluation but have not yet been evaluated.</p></li>
<li><p><strong>cost_aware_utility</strong> – A CostAwareUtility computing the cost-transformed
utility from a candidate set and samples of increases in utility.</p></li>
<li><p><strong>project</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em>) – A callable mapping a <cite>batch_shape x q x d</cite> tensor of design
points to a tensor of the same shape projected to the desired
target set (e.g. the target fidelities in case of multi-fidelity
optimization).</p></li>
<li><p><strong>expand</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em>) – A callable mapping a <cite>batch_shape x q x d</cite> input tensor to
a <cite>batch_shape x (q + q_e)’ x d</cite>-dim output tensor, where the
<cite>q_e</cite> additional points in each q-batch correspond to
additional (“trace”) observations.</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="botorch.acquisition.max_value_entropy_search.qMultiFidelityMaxValueEntropy.cost_sampler">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">cost_sampler</span></span><a class="headerlink" href="#botorch.acquisition.max_value_entropy_search.qMultiFidelityMaxValueEntropy.cost_sampler" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.max_value_entropy_search.qMultiFidelityMaxValueEntropy.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/max_value_entropy_search.html#qMultiFidelityMaxValueEntropy.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.max_value_entropy_search.qMultiFidelityMaxValueEntropy.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluates <cite>qMultifidelityMaxValueEntropy</cite> at the design points <cite>X</cite></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x 1 x d</cite>-dim Tensor of <cite>batch_shape</cite> t-batches
with <cite>1</cite> <cite>d</cite>-dim design point each.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape</cite>-dim Tensor of MF-MVES values at the design points <cite>X</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.max_value_entropy_search.qMultiFidelityLowerBoundMaxValueEntropy">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.max_value_entropy_search.</span></span><span class="sig-name descname"><span class="pre">qMultiFidelityLowerBoundMaxValueEntropy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">candidate_set</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_fantasies=16</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_mv_samples=10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_y_samples=128</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_gumbel=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximize=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cost_aware_utility=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">project=&lt;function</span> <span class="pre">qMultiFidelityLowerBoundMaxValueEntropy.&lt;lambda&gt;&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">expand=None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/max_value_entropy_search.html#qMultiFidelityLowerBoundMaxValueEntropy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.max_value_entropy_search.qMultiFidelityLowerBoundMaxValueEntropy" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.max_value_entropy_search.qMultiFidelityMaxValueEntropy" title="botorch.acquisition.max_value_entropy_search.qMultiFidelityMaxValueEntropy"><code class="xref py py-class docutils literal notranslate"><span class="pre">qMultiFidelityMaxValueEntropy</span></code></a></p>
<p>Multi-fidelity acquisition function for General-purpose Information-Based
Bayesian optimization (GIBBON).</p>
<p>The acquisition function for multi-fidelity max-value entropy search
with support for trace observations. See <a class="reference internal" href="#takeno2020mfmves" id="id46"><span>[Takeno2020mfmves]</span></a>
for a detailed discussion of the basic ideas on multi-fidelity MES
(note that this implementation is somewhat different). This acquisition function
is similar to <cite>qMultiFidelityMaxValueEntropy</cite> but computes the information gain
from the lower bound described in [Moss2021gibbon].</p>
<p>The model must be single-outcome, unless using a PosteriorTransform.
The batch case <cite>q &gt; 1</cite> is supported through cyclic optimization and fantasies.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">candidate_set</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">bounds</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">candidate_set</span> <span class="o">=</span> <span class="n">bounds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="n">bounds</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">bounds</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">*</span> <span class="n">candidate_set</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">MF_qGIBBON</span> <span class="o">=</span> <span class="n">qMultiFidelityLowerBoundMaxValueEntropy</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">candidate_set</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mf_gibbon</span> <span class="o">=</span> <span class="n">MF_qGIBBON</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
</pre></div>
</div>
<p>Single-outcome max-value entropy search acquisition function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted single-outcome model.</p></li>
<li><p><strong>candidate_set</strong> (<em>Tensor</em>) – A <cite>n x d</cite> Tensor including <cite>n</cite> candidate points to
discretize the design space, which will be used to sample the
max values from their posteriors.</p></li>
<li><p><strong>cost_aware_utility</strong> (<a class="reference internal" href="#botorch.acquisition.cost_aware.CostAwareUtility" title="botorch.acquisition.cost_aware.CostAwareUtility"><em>CostAwareUtility</em></a><em> | </em><em>None</em>) – A CostAwareUtility computing the cost-transformed
utility from a candidate set and samples of increases in utility.</p></li>
<li><p><strong>num_fantasies</strong> (<em>int</em>) – Number of fantasies to generate. The higher this
number the more accurate the model (at the expense of model
complexity and performance) and it’s only used when <cite>X_pending</cite>
is not <cite>None</cite>.</p></li>
<li><p><strong>num_mv_samples</strong> (<em>int</em>) – Number of max value samples.</p></li>
<li><p><strong>num_y_samples</strong> (<em>int</em>) – Number of posterior samples at specific design point <cite>X</cite>.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – A PosteriorTransform. If using a multi-output model,
a PosteriorTransform that transforms the multi-output posterior into a
single-output posterior is required.</p></li>
<li><p><strong>use_gumbel</strong> (<em>bool</em>) – If True, use Gumbel approximation to sample the max values.</p></li>
<li><p><strong>maximize</strong> (<em>bool</em>) – If True, consider the problem a maximization problem.</p></li>
<li><p><strong>cost_aware_utility</strong> – A CostAwareUtility computing the cost-transformed
utility from a candidate set and samples of increases in utility.</p></li>
<li><p><strong>project</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em>) – A callable mapping a <cite>batch_shape x q x d</cite> tensor of design
points to a tensor of the same shape projected to the desired
target set (e.g. the target fidelities in case of multi-fidelity
optimization).</p></li>
<li><p><strong>expand</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – A callable mapping a <cite>batch_shape x q x d</cite> input tensor to
a <cite>batch_shape x (q + q_e)’ x d</cite>-dim output tensor, where the
<cite>q_e</cite> additional points in each q-batch correspond to
additional (“trace”) observations.
NOTE: This is currently not supported. It leads to wrong outputs.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-botorch.acquisition.joint_entropy_search">
<span id="joint-entropy-search-acquisition-functions"></span><h3>Joint Entropy Search Acquisition Functions<a class="headerlink" href="#module-botorch.acquisition.joint_entropy_search" title="Link to this heading"></a></h3>
<p>Acquisition function for joint entropy search (JES).</p>
<div role="list" class="citation-list">
<div class="citation" id="hvarfner2022joint" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id48">Hvarfner2022joint</a><span class="fn-bracket">]</span></span>
<p>C. Hvarfner, F. Hutter, L. Nardi,
Joint Entropy Search for Maximally-informed Bayesian Optimization.
In Proceedings of the Annual Conference on Neural Information
Processing Systems (NeurIPS), 2022.</p>
</div>
<div class="citation" id="tu2022joint" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Tu2022joint<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id47">1</a>,<a role="doc-backlink" href="#id49">2</a>)</span>
<p>B. Tu, A. Gandy, N. Kantas, B. Shafei,
Joint Entropy Search for Multi-objective Bayesian Optimization.
In Proceedings of the Annual Conference on Neural Information
Processing Systems (NeurIPS), 2022.</p>
</div>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.joint_entropy_search.qJointEntropySearch">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.joint_entropy_search.</span></span><span class="sig-name descname"><span class="pre">qJointEntropySearch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimal_inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimal_outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition_noiseless</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">estimation_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'LB'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/joint_entropy_search.html#qJointEntropySearch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.joint_entropy_search.qJointEntropySearch" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">AcquisitionFunction</span></code></a>, <a class="reference internal" href="#botorch.acquisition.acquisition.MCSamplerMixin" title="botorch.acquisition.acquisition.MCSamplerMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">MCSamplerMixin</span></code></a></p>
<p>The acquisition function for the Joint Entropy Search, where the batches
<cite>q &gt; 1</cite> are supported through the lower bound formulation.</p>
<p>This acquisition function computes the mutual information between the observation
at a candidate point <cite>X</cite> and the optimal input-output pair.</p>
<p>See <a class="reference internal" href="#tu2022joint" id="id47"><span>[Tu2022joint]</span></a> for a discussion on the estimation procedure.</p>
<p>Joint entropy search acquisition function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted single-outcome model.</p></li>
<li><p><strong>optimal_inputs</strong> (<em>Tensor</em>) – A <cite>num_samples x d</cite>-dim tensor containing the sampled
optimal inputs of dimension <cite>d</cite>. We assume for simplicity that each
sample only contains one optimal set of inputs.</p></li>
<li><p><strong>optimal_outputs</strong> (<em>Tensor</em>) – A <cite>num_samples x 1</cite>-dim Tensor containing the optimal
set of objectives of dimension <cite>1</cite>.</p></li>
<li><p><strong>condition_noiseless</strong> (<em>bool</em>) – Whether to condition on noiseless optimal observations
<cite>f*</cite> <a class="reference internal" href="#hvarfner2022joint" id="id48"><span>[Hvarfner2022joint]</span></a> or noisy optimal observations <cite>y*</cite>
<a class="reference internal" href="#tu2022joint" id="id49"><span>[Tu2022joint]</span></a>. These are sampled identically, so this only controls
the fashion in which the GP is reshaped as a result of conditioning
on the optimum.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – PosteriorTransform to negate or scalarize the output.</p></li>
<li><p><strong>estimation_type</strong> (<em>str</em>) – estimation_type: A string to determine which entropy
estimate is computed: Lower bound” (“LB”) or “Monte Carlo” (“MC”).
Lower Bound is recommended due to the relatively high variance
of the MC estimator.</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>m x d</cite>-dim Tensor of <cite>m</cite> design points that have been
submitted for function evaluation, but have not yet been evaluated.</p></li>
<li><p><strong>num_samples</strong> (<em>int</em>) – The number of Monte Carlo samples used for the Monte Carlo
estimate.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.joint_entropy_search.qJointEntropySearch.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/joint_entropy_search.html#qJointEntropySearch.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.joint_entropy_search.qJointEntropySearch.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluates qJointEntropySearch at the design points <cite>X</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x q x d</cite>-dim Tensor of <cite>batch_shape</cite> t-batches with <cite>q</cite></p></li>
<li><p><strong>each.</strong> (<em>d-dim design points</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape</cite>-dim Tensor of acquisition values at the given design
points <cite>X</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-botorch.acquisition.predictive_entropy_search">
<span id="predictive-entropy-search-acquisition-functions"></span><h3>Predictive Entropy Search Acquisition Functions<a class="headerlink" href="#module-botorch.acquisition.predictive_entropy_search" title="Link to this heading"></a></h3>
<p>Acquisition function for predictive entropy search (PES). The code utilizes the
implementation designed for the multi-objective batch setting.</p>
<p>NOTE: The PES acquisition might not be differentiable. As a result, we recommend
optimizing the acquisition function using finite differences.</p>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.predictive_entropy_search.qPredictiveEntropySearch">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.predictive_entropy_search.</span></span><span class="sig-name descname"><span class="pre">qPredictiveEntropySearch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimal_inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_ep_iterations</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">250</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ep_jitter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_jitter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/predictive_entropy_search.html#qPredictiveEntropySearch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.predictive_entropy_search.qPredictiveEntropySearch" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.multi_objective.predictive_entropy_search.qMultiObjectivePredictiveEntropySearch" title="botorch.acquisition.multi_objective.predictive_entropy_search.qMultiObjectivePredictiveEntropySearch"><code class="xref py py-class docutils literal notranslate"><span class="pre">qMultiObjectivePredictiveEntropySearch</span></code></a></p>
<p>The acquisition function for Predictive Entropy Search.</p>
<p>This acquisition function approximates the mutual information between the
observation at a candidate point <cite>X</cite> and the optimal set of inputs using
expectation propagation (EP).</p>
<p>NOTES:
(i) The expectation propagation procedure can potentially fail due to the unstable
EP updates. This is however unlikely to happen in the single-objective setting
because we have much fewer EP factors. The jitter added in the training phase
(<cite>ep_jitter</cite>) and testing phase (<cite>test_jitter</cite>) can be increased to prevent
these failures from happening. More details in the description of
<cite>qMultiObjectivePredictiveEntropySearch</cite>.</p>
<ol class="lowerroman simple" start="2">
<li><p>The estimated acquisition value could be negative.</p></li>
</ol>
<p>Predictive entropy search acquisition function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted single-outcome model.</p></li>
<li><p><strong>optimal_inputs</strong> (<em>Tensor</em>) – A <cite>num_samples x d</cite>-dim tensor containing the sampled
optimal inputs of dimension <cite>d</cite>. We assume for simplicity that each
sample only contains one optimal set of inputs.</p></li>
<li><p><strong>maximize</strong> (<em>bool</em>) – If true, we consider a maximization problem.</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>m x d</cite>-dim Tensor of <cite>m</cite> design points that have been
submitted for function evaluation, but have not yet been evaluated.</p></li>
<li><p><strong>max_ep_iterations</strong> (<em>int</em>) – The maximum number of expectation propagation
iterations. (The minimum number of iterations is set at 3.)</p></li>
<li><p><strong>ep_jitter</strong> (<em>float</em>) – The amount of jitter added for the matrix inversion that
occurs during the expectation propagation update during the training
phase.</p></li>
<li><p><strong>test_jitter</strong> (<em>float</em>) – The amount of jitter added for the matrix inversion that
occurs during the expectation propagation update in the testing
phase.</p></li>
<li><p><strong>threshold</strong> (<em>float</em>) – The convergence threshold for expectation propagation. This
assesses the relative change in the mean and covariance. We default
to one percent change i.e. <cite>threshold = 1e-2</cite>.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.predictive_entropy_search.qPredictiveEntropySearch.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/predictive_entropy_search.html#qPredictiveEntropySearch.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.predictive_entropy_search.qPredictiveEntropySearch.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate qPredictiveEntropySearch on the candidate set <cite>X</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x q x d</cite>-dim Tensor of t-batches with <cite>q</cite> <cite>d</cite>-dim
design points each.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape’</cite>-dim Tensor of Predictive Entropy Search values at the
given design points <cite>X</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-botorch.acquisition.active_learning">
<span id="active-learning-acquisition-functions"></span><h3>Active Learning Acquisition Functions<a class="headerlink" href="#module-botorch.acquisition.active_learning" title="Link to this heading"></a></h3>
<p>Active learning acquisition functions.</p>
<div role="list" class="citation-list">
<div class="citation" id="seo2014activedata" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id50">Seo2014activedata</a><span class="fn-bracket">]</span></span>
<p>S. Seo, M. Wallat, T. Graepel, and K. Obermayer. Gaussian process regression:
Active data selection and test point rejection. IJCNN 2000.</p>
</div>
<div class="citation" id="chen2014seqexpdesign" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id51">Chen2014seqexpdesign</a><span class="fn-bracket">]</span></span>
<p>X. Chen and Q. Zhou. Sequential experimental designs for stochastic kriging.
Winter Simulation Conference 2014.</p>
</div>
<div class="citation" id="binois2017repexp" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id52">Binois2017repexp</a><span class="fn-bracket">]</span></span>
<p>M. Binois, J. Huang, R. B. Gramacy, and M. Ludkovski. Replication or
exploration? Sequential design for stochastic simulation experiments.
ArXiv 2017.</p>
</div>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.active_learning.qNegIntegratedPosteriorVariance">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.active_learning.</span></span><span class="sig-name descname"><span class="pre">qNegIntegratedPosteriorVariance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mc_points</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/active_learning.html#qNegIntegratedPosteriorVariance"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.active_learning.qNegIntegratedPosteriorVariance" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">AcquisitionFunction</span></code></a></p>
<p>Batch Integrated Negative Posterior Variance for Active Learning.</p>
<p>This acquisition function quantifies the (negative) integrated posterior variance
(excluding observation noise, computed using MC integration) of the model.
In that, it is a proxy for global model uncertainty, and thus purely focused on
“exploration”, rather the “exploitation” of many of the classic Bayesian
Optimization acquisition functions.</p>
<p>See <a class="reference internal" href="#seo2014activedata" id="id50"><span>[Seo2014activedata]</span></a>, <a class="reference internal" href="#chen2014seqexpdesign" id="id51"><span>[Chen2014seqexpdesign]</span></a>, and <a class="reference internal" href="#binois2017repexp" id="id52"><span>[Binois2017repexp]</span></a>.</p>
<p>q-Integrated Negative Posterior Variance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted model.</p></li>
<li><p><strong>mc_points</strong> (<em>Tensor</em>) – A <cite>batch_shape x N x d</cite> tensor of points to use for
MC-integrating the posterior variance. Usually, these are qMC
samples on the whole design space, but biased sampling directly
allows weighted integration of the posterior variance.</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – The sampler used for drawing fantasy samples. In the basic setting
of a standard GP (default) this is a dummy, since the variance of the
model after conditioning does not actually depend on the sampled values.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – A PosteriorTransform. If using a multi-output model,
a PosteriorTransform that transforms the multi-output posterior into a
single-output posterior is required.</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>n’ x d</cite>-dim Tensor of <cite>n’</cite> design points that have
points that have been submitted for function evaluation but
have not yet been evaluated.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.active_learning.qNegIntegratedPosteriorVariance.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/active_learning.html#qNegIntegratedPosteriorVariance.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.active_learning.qNegIntegratedPosteriorVariance.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate the acquisition function on the candidate set X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>(b) x q x d</cite>-dim Tensor of <cite>(b)</cite> t-batches with <cite>q</cite> <cite>d</cite>-dim
design points each.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>(b)</cite>-dim Tensor of acquisition function values at the given
design points <cite>X</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.active_learning.PairwiseMCPosteriorVariance">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.active_learning.</span></span><span class="sig-name descname"><span class="pre">PairwiseMCPosteriorVariance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/active_learning.html#PairwiseMCPosteriorVariance"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.active_learning.PairwiseMCPosteriorVariance" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.monte_carlo.MCAcquisitionFunction" title="botorch.acquisition.monte_carlo.MCAcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">MCAcquisitionFunction</span></code></a></p>
<p>Variance of difference for Active Learning</p>
<p>Given a model and an objective, calculate the posterior sample variance
of the objective on the difference of pairs of points. See more implementation
details in <cite>forward</cite>. This acquisition function is typically used with a
pairwise model (e.g., PairwiseGP) and a likelihood/link function
on the pair difference (e.g., logistic or probit) for pure exploration</p>
<p>Pairwise Monte Carlo Posterior Variance</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted model.</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><em>MCAcquisitionObjective</em></a>) – An MCAcquisitionObjective representing the link function
(e.g., logistic or probit.) applied on the difference of (usually 1-d)
two samples. Can be implemented via GenericMCObjective.</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – The sampler used for drawing MC samples.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.active_learning.PairwiseMCPosteriorVariance.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/active_learning.html#PairwiseMCPosteriorVariance.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.active_learning.PairwiseMCPosteriorVariance.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate PairwiseMCPosteriorVariance on the candidate set <cite>X</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_size x q x d</cite>-dim Tensor. q should be a multiple of 2.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tensor of shape <cite>batch_size x q</cite> representing the posterior variance
of link function at X that active learning hopes to maximize</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-botorch.acquisition.bayesian_active_learning">
<span id="bayesian-active-learning-acquisition-functions"></span><h3>Bayesian Active Learning Acquisition Functions<a class="headerlink" href="#module-botorch.acquisition.bayesian_active_learning" title="Link to this heading"></a></h3>
<p>Acquisition functions for Bayesian active learning. This includes:
BALD <a class="reference internal" href="#houlsby2011bald" id="id53"><span>[Houlsby2011bald]</span></a> and its batch version <a class="reference internal" href="#kirsch2019batchbald" id="id54"><span>[kirsch2019batchbald]</span></a>.</p>
<p>References</p>
<div role="list" class="citation-list">
<div class="citation" id="kirsch2019batchbald" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>kirsch2019batchbald<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id54">1</a>,<a role="doc-backlink" href="#id55">2</a>)</span>
<p>Andreas Kirsch, Joost van Amersfoort, Yarin Gal.
BatchBALD: Efficient and Diverse Batch Acquisition for Deep Bayesian
Active Learning.
In Proceedings of the Annual Conference on Neural Information
Processing Systems (NeurIPS), 2019.</p>
</div>
</div>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.bayesian_active_learning.check_negative_info_gain">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.bayesian_active_learning.</span></span><span class="sig-name descname"><span class="pre">check_negative_info_gain</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">info_gain</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/bayesian_active_learning.html#check_negative_info_gain"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.bayesian_active_learning.check_negative_info_gain" title="Link to this definition"></a></dt>
<dd><p>Check if the (expected) information gain is negative, raise a warning if so.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>info_gain</strong> (<em>Tensor</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.bayesian_active_learning.FullyBayesianAcquisitionFunction">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.bayesian_active_learning.</span></span><span class="sig-name descname"><span class="pre">FullyBayesianAcquisitionFunction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/bayesian_active_learning.html#FullyBayesianAcquisitionFunction"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.bayesian_active_learning.FullyBayesianAcquisitionFunction" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">AcquisitionFunction</span></code></a></p>
<p>Base class for acquisition functions which require a Fully Bayesian
model treatment.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fully bayesian single-outcome model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.bayesian_active_learning.qBayesianActiveLearningByDisagreement">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.bayesian_active_learning.</span></span><span class="sig-name descname"><span class="pre">qBayesianActiveLearningByDisagreement</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/bayesian_active_learning.html#qBayesianActiveLearningByDisagreement"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.bayesian_active_learning.qBayesianActiveLearningByDisagreement" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.bayesian_active_learning.FullyBayesianAcquisitionFunction" title="botorch.acquisition.bayesian_active_learning.FullyBayesianAcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">FullyBayesianAcquisitionFunction</span></code></a>, <a class="reference internal" href="#botorch.acquisition.acquisition.MCSamplerMixin" title="botorch.acquisition.acquisition.MCSamplerMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">MCSamplerMixin</span></code></a></p>
<p>Batch implementation <a class="reference internal" href="#kirsch2019batchbald" id="id55"><span>[kirsch2019batchbald]</span></a> of BALD <a class="reference internal" href="#houlsby2011bald" id="id56"><span>[Houlsby2011bald]</span></a>,
which maximizes the mutual information between the next observation and the
hyperparameters of the model. Computed by Monte Carlo integration.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model_list_gp_regression.ModelListGP" title="botorch.models.model_list_gp_regression.ModelListGP"><em>ModelListGP</em></a><em> | </em><a class="reference internal" href="models.html#botorch.models.fully_bayesian.SaasFullyBayesianSingleTaskGP" title="botorch.models.fully_bayesian.SaasFullyBayesianSingleTaskGP"><em>SaasFullyBayesianSingleTaskGP</em></a>) – A fully bayesian model (SaasFullyBayesianSingleTaskGP).</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – The sampler used for drawing samples to approximate the entropy
of the Gaussian Mixture posterior.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – A PosteriorTransform. If using a multi-output model,
a PosteriorTransform that transforms the multi-output posterior into a
single-output posterior is required.</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x m x d</cite>-dim Tensor of <cite>m</cite> design points</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.bayesian_active_learning.qBayesianActiveLearningByDisagreement.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/bayesian_active_learning.html#qBayesianActiveLearningByDisagreement.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.bayesian_active_learning.qBayesianActiveLearningByDisagreement.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate qBayesianActiveLearningByDisagreement on the candidate set <cite>X</cite>.
A monte carlo-estimated information gain is computed over a Gaussian Mixture
marginal posterior, and the Gaussian conditional posterior to obtain the
qBayesianActiveLearningByDisagreement on the candidate set <cite>X</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – <cite>batch_shape x q x D</cite>-dim Tensor of input points.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape x num_models</cite>-dim Tensor of BALD values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-botorch.acquisition.preference">
<span id="preference-acquisition-functions"></span><h3>Preference Acquisition Functions<a class="headerlink" href="#module-botorch.acquisition.preference" title="Link to this heading"></a></h3>
<p>Preference acquisition functions. This includes:
Analytical EUBO acquisition function as introduced in <a class="reference internal" href="#lin2022preference" id="id57"><span>[Lin2022preference]</span></a>
and its MC-based generalization qEUBO as proposed in <a class="reference internal" href="#astudillo2023qeubo" id="id58"><span>[Astudillo2023qeubo]</span></a>.</p>
<div role="list" class="citation-list">
<div class="citation" id="astudillo2023qeubo" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Astudillo2023qeubo<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id58">1</a>,<a role="doc-backlink" href="#id61">2</a>)</span>
<p>Astudillo, R., Lin, Z.J., Bakshy, E. and Frazier, P.I. qEUBO: A Decision-Theoretic
Acquisition Function for Preferential Bayesian Optimization. International
Conference on Artificial Intelligence and Statistics (AISTATS), 2023.</p>
</div>
<div class="citation" id="lin2022preference" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Lin2022preference<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id57">1</a>,<a role="doc-backlink" href="#id59">2</a>,<a role="doc-backlink" href="#id60">3</a>)</span>
<p>Lin, Z.J., Astudillo, R., Frazier, P.I. and Bakshy, E. Preference Exploration
for Efficient Bayesian Optimization with Multiple Outcomes. International
Conference on Artificial Intelligence and Statistics (AISTATS), 2022.</p>
</div>
<div class="citation" id="houlsby2011bald" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Houlsby2011bald<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id53">1</a>,<a role="doc-backlink" href="#id56">2</a>,<a role="doc-backlink" href="#id62">3</a>)</span>
<p>Houlsby, N., Huszár, F., Ghahramani, Z. and Lengyel, M.
Bayesian Active Learning for Gaussian Process Classification.
NIPS Workshop on Bayesian optimization, experimental design and bandits:
Theory and applications, 2011.</p>
</div>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.preference.AnalyticExpectedUtilityOfBestOption">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.preference.</span></span><span class="sig-name descname"><span class="pre">AnalyticExpectedUtilityOfBestOption</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pref_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outcome_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">previous_winner</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/preference.html#AnalyticExpectedUtilityOfBestOption"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.preference.AnalyticExpectedUtilityOfBestOption" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.analytic.AnalyticAcquisitionFunction" title="botorch.acquisition.analytic.AnalyticAcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">AnalyticAcquisitionFunction</span></code></a></p>
<p>Analytic Preferential Expected Utility of Best Options, i.e., Analytical EUBO</p>
<p>Analytic implementation of Expected Utility of the Best Option under the
Laplace model (assumes a PairwiseGP is used as the preference model) as
proposed in <a class="reference internal" href="#lin2022preference" id="id59"><span>[Lin2022preference]</span></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pref_model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – The preference model that maps the outcomes (i.e., Y) to
scalar-valued utility.</p></li>
<li><p><strong>outcome_model</strong> (<a class="reference internal" href="models.html#botorch.models.deterministic.DeterministicModel" title="botorch.models.deterministic.DeterministicModel"><em>DeterministicModel</em></a><em> | </em><em>None</em>) – A deterministic model that maps parameters (i.e., X) to
outcomes (i.e., Y). The outcome model f defines the search space of
Y = f(X). If model is None, we are directly calculating EUBO on
the parameter space. When used with <cite>OneSamplePosteriorDrawModel</cite>,
we are obtaining EUBO-zeta as described in <a class="reference internal" href="#lin2022preference" id="id60"><span>[Lin2022preference]</span></a>.</p></li>
<li><p><strong>previous_winner</strong> (<em>Tensor</em><em> | </em><em>None</em>) – Tensor representing the previous winner in the Y space.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.preference.AnalyticExpectedUtilityOfBestOption.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/preference.html#AnalyticExpectedUtilityOfBestOption.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.preference.AnalyticExpectedUtilityOfBestOption.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate analytical EUBO on the candidate set X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x q x d</cite>-dim Tensor, where <cite>q = 2</cite> if <cite>previous_winner</cite>
is not <cite>None</cite>, and <cite>q = 1</cite> otherwise.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The acquisition value for each batch as a tensor of shape <cite>batch_shape</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.preference.qExpectedUtilityOfBestOption">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.preference.</span></span><span class="sig-name descname"><span class="pre">qExpectedUtilityOfBestOption</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pref_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outcome_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/preference.html#qExpectedUtilityOfBestOption"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.preference.qExpectedUtilityOfBestOption" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.monte_carlo.MCAcquisitionFunction" title="botorch.acquisition.monte_carlo.MCAcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">MCAcquisitionFunction</span></code></a></p>
<p>MC-based Expected Utility of Best Option (qEUBO)</p>
<p>This computes qEUBO by
(1) sampling the joint posterior over q points
(2) evaluating the maximum objective value accross the q points
(3) averaging over the samples</p>
<p><cite>qEUBO(X) = E[max Y], Y ~ f(X), where X = (x_1,…,x_q)</cite></p>
<p>MC-based Expected Utility of Best Option (qEUBO) as proposed
in <a class="reference internal" href="#astudillo2023qeubo" id="id61"><span>[Astudillo2023qeubo]</span></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pref_model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – The preference model that maps the outcomes (i.e., Y) to
scalar-valued utility.</p></li>
<li><p><strong>outcome_model</strong> (<a class="reference internal" href="models.html#botorch.models.deterministic.DeterministicModel" title="botorch.models.deterministic.DeterministicModel"><em>DeterministicModel</em></a><em> | </em><em>None</em>) – <dl class="simple">
<dt>A deterministic model that maps parameters (i.e., X) to</dt><dd><p>outcomes (i.e., Y). The outcome model f defines the search space of
Y = f(X). If model is None, we are directly calculating qEUBO on
the parameter space.</p>
</dd>
<dt>sampler: The sampler used to draw base samples. See <cite>MCAcquisitionFunction</cite></dt><dd><p>more details.</p>
</dd>
</dl>
</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><em>MCAcquisitionObjective</em></a><em> | </em><em>None</em>) – The MCAcquisitionObjective under which the samples are evaluated.
Defaults to <cite>IdentityMCObjective()</cite>.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – A PosteriorTransform (optional).</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>m x d</cite>-dim Tensor of <cite>m</cite> design points that have been
submitted for function evaluation but have not yet been evaluated.
Concatenated into X upon forward call. Copied and set
to have no gradient.</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.preference.qExpectedUtilityOfBestOption.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/preference.html#qExpectedUtilityOfBestOption.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.preference.qExpectedUtilityOfBestOption.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate qEUBO on the candidate set <cite>X</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x q x d</cite>-dim Tensor of t-batches with <cite>q</cite>
<cite>d</cite>-dim design points each.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape’</cite>-dim Tensor of qEUBO values at the given design
points <cite>X</cite>, where <cite>batch_shape’</cite> is the broadcasted batch shape
of model and input <cite>X</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.preference.PairwiseBayesianActiveLearningByDisagreement">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.preference.</span></span><span class="sig-name descname"><span class="pre">PairwiseBayesianActiveLearningByDisagreement</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pref_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outcome_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1024</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">std_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/preference.html#PairwiseBayesianActiveLearningByDisagreement"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.preference.PairwiseBayesianActiveLearningByDisagreement" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.monte_carlo.MCAcquisitionFunction" title="botorch.acquisition.monte_carlo.MCAcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">MCAcquisitionFunction</span></code></a></p>
<p>MC Bayesian Active Learning by Disagreement</p>
<p>Monte Carlo implementation of Bayesian Active Learning by Disagreement (BALD)
proposed in <a class="reference internal" href="#houlsby2011bald" id="id62"><span>[Houlsby2011bald]</span></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pref_model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – The preference model that maps the outcomes (i.e., Y) to
scalar-valued utility.</p></li>
<li><p><strong>outcome_model</strong> (<a class="reference internal" href="models.html#botorch.models.deterministic.DeterministicModel" title="botorch.models.deterministic.DeterministicModel"><em>DeterministicModel</em></a><em> | </em><em>None</em>) – A deterministic model that maps parameters (i.e., X) to
outcomes (i.e., Y). The outcome model f defines the search space of
Y = f(X). If model is None, we are directly calculating BALD on
the parameter space.</p></li>
<li><p><strong>num_samples</strong> (<em>int</em><em> | </em><em>None</em>) – number of samples to approximate the conditional_entropy.</p></li>
<li><p><strong>std_noise</strong> (<em>float</em><em> | </em><em>None</em>) – Additional observational noise to include. Defaults to 0.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.preference.PairwiseBayesianActiveLearningByDisagreement.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/preference.html#PairwiseBayesianActiveLearningByDisagreement.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.preference.PairwiseBayesianActiveLearningByDisagreement.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate MC BALD on the candidate set <cite>X</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x 2 x d</cite>-dim Tensor of t-batches with <cite>q=2</cite>
<cite>d</cite>-dim design points each.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape’</cite>-dim Tensor of MC BALD values at the given
design points pair <cite>X</cite>, where <cite>batch_shape’</cite> is the broadcasted
batch shape of model and input <cite>X</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="objectives-and-cost-aware-utilities">
<h2>Objectives and Cost-Aware Utilities<a class="headerlink" href="#objectives-and-cost-aware-utilities" title="Link to this heading"></a></h2>
<section id="module-botorch.acquisition.objective">
<span id="objectives"></span><h3>Objectives<a class="headerlink" href="#module-botorch.acquisition.objective" title="Link to this heading"></a></h3>
<p>Objective Modules to be used with acquisition functions.</p>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.objective.PosteriorTransform">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.objective.</span></span><span class="sig-name descname"><span class="pre">PosteriorTransform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/objective.html#PosteriorTransform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.objective.PosteriorTransform" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>Abstract base class for objectives that transform the posterior.</p>
<p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="field-list simple">
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.objective.PosteriorTransform.evaluate">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/objective.html#PosteriorTransform.evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.objective.PosteriorTransform.evaluate" title="Link to this definition"></a></dt>
<dd><p>Evaluate the transform on a set of outcomes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>Y</strong> (<em>Tensor</em>) – A <cite>batch_shape x q x m</cite>-dim tensor of outcomes.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape x q’ [x m’]</cite>-dim tensor of transformed outcomes.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.objective.PosteriorTransform.forward">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">posterior</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/objective.html#PosteriorTransform.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.objective.PosteriorTransform.forward" title="Link to this definition"></a></dt>
<dd><p>Compute the transformed posterior.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>posterior</strong> – The posterior to be transformed.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The transformed posterior object.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.posterior.Posterior" title="botorch.posteriors.posterior.Posterior">Posterior</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.objective.ScalarizedPosteriorTransform">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.objective.</span></span><span class="sig-name descname"><span class="pre">ScalarizedPosteriorTransform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">weights</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/objective.html#ScalarizedPosteriorTransform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.objective.ScalarizedPosteriorTransform" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">PosteriorTransform</span></code></a></p>
<p>An affine posterior transform for scalarizing multi-output posteriors.</p>
<p>For a Gaussian posterior at a single point (<cite>q=1</cite>) with mean <cite>mu</cite> and
covariance matrix <cite>Sigma</cite>, this yields a single-output posterior with mean
<cite>weights^T * mu</cite> and variance <cite>weights^T Sigma w</cite>.</p>
<p class="rubric">Example</p>
<p>Example for a model with two outcomes:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">posterior_transform</span> <span class="o">=</span> <span class="n">ScalarizedPosteriorTransform</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">EI</span> <span class="o">=</span> <span class="n">ExpectedImprovement</span><span class="p">(</span>
<span class="gp">... </span><span class="n">model</span><span class="p">,</span> <span class="n">best_f</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">posterior_transform</span><span class="o">=</span><span class="n">posterior_transform</span>
<span class="gp">... </span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>weights</strong> (<em>Tensor</em>) – A one-dimensional tensor with <cite>m</cite> elements representing the
linear weights on the outputs.</p></li>
<li><p><strong>offset</strong> (<em>float</em>) – An offset to be added to posterior mean.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.acquisition.objective.ScalarizedPosteriorTransform.scalarize">
<span class="sig-name descname"><span class="pre">scalarize</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#botorch.acquisition.objective.ScalarizedPosteriorTransform.scalarize" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.objective.ScalarizedPosteriorTransform.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/objective.html#ScalarizedPosteriorTransform.evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.objective.ScalarizedPosteriorTransform.evaluate" title="Link to this definition"></a></dt>
<dd><p>Evaluate the transform on a set of outcomes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>Y</strong> (<em>Tensor</em>) – A <cite>batch_shape x q x m</cite>-dim tensor of outcomes.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape x q</cite>-dim tensor of transformed outcomes.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.objective.ScalarizedPosteriorTransform.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">posterior</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/objective.html#ScalarizedPosteriorTransform.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.objective.ScalarizedPosteriorTransform.forward" title="Link to this definition"></a></dt>
<dd><p>Compute the posterior of the affine transformation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>posterior</strong> (<a class="reference internal" href="posteriors.html#botorch.posteriors.gpytorch.GPyTorchPosterior" title="botorch.posteriors.gpytorch.GPyTorchPosterior"><em>GPyTorchPosterior</em></a><em> | </em><a class="reference internal" href="posteriors.html#botorch.posteriors.posterior_list.PosteriorList" title="botorch.posteriors.posterior_list.PosteriorList"><em>PosteriorList</em></a>) – A posterior with the same number of outputs as the
elements in <cite>self.weights</cite>.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A single-output posterior.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.gpytorch.GPyTorchPosterior" title="botorch.posteriors.gpytorch.GPyTorchPosterior">GPyTorchPosterior</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.objective.ExpectationPosteriorTransform">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.objective.</span></span><span class="sig-name descname"><span class="pre">ExpectationPosteriorTransform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_w</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/objective.html#ExpectationPosteriorTransform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.objective.ExpectationPosteriorTransform" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">PosteriorTransform</span></code></a></p>
<p>Transform the <cite>batch x (q * n_w) x m</cite> posterior into a <cite>batch x q x m</cite>
posterior of the expectation. The expectation is calculated over each
consecutive <cite>n_w</cite> block of points in the posterior.</p>
<p>This is intended for use with <cite>InputPerturbation</cite> or <cite>AppendFeatures</cite> for
optimizing the expectation over <cite>n_w</cite> points. This should not be used when
there are constraints present, since this does not take into account
the feasibility of the objectives.</p>
<p>Note: This is different than <cite>ScalarizedPosteriorTransform</cite> in that
this operates over the q-batch dimension.</p>
<p>A posterior transform calculating the expectation over the q-batch
dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_w</strong> (<em>int</em>) – The number of points in the q-batch of the posterior to compute
the expectation over. This corresponds to the size of the
<cite>feature_set</cite> of <cite>AppendFeatures</cite> or the size of the <cite>perturbation_set</cite>
of <cite>InputPerturbation</cite>.</p></li>
<li><p><strong>weights</strong> (<em>Tensor</em><em> | </em><em>None</em>) – An optional <cite>n_w x m</cite>-dim tensor of weights. Can be used to
compute a weighted expectation. Weights are normalized before use.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.objective.ExpectationPosteriorTransform.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/objective.html#ExpectationPosteriorTransform.evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.objective.ExpectationPosteriorTransform.evaluate" title="Link to this definition"></a></dt>
<dd><p>Evaluate the expectation of a set of outcomes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>Y</strong> (<em>Tensor</em>) – A <cite>batch_shape x (q * n_w) x m</cite>-dim tensor of outcomes.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape x q x m</cite>-dim tensor of expectation outcomes.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.objective.ExpectationPosteriorTransform.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">posterior</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/objective.html#ExpectationPosteriorTransform.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.objective.ExpectationPosteriorTransform.forward" title="Link to this definition"></a></dt>
<dd><p>Compute the posterior of the expectation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>posterior</strong> (<a class="reference internal" href="posteriors.html#botorch.posteriors.gpytorch.GPyTorchPosterior" title="botorch.posteriors.gpytorch.GPyTorchPosterior"><em>GPyTorchPosterior</em></a>) – An <cite>m</cite>-outcome joint posterior over <cite>q * n_w</cite> points.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An <cite>m</cite>-outcome joint posterior over <cite>q</cite> expectations.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.gpytorch.GPyTorchPosterior" title="botorch.posteriors.gpytorch.GPyTorchPosterior"><em>GPyTorchPosterior</em></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.objective.MCAcquisitionObjective">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.objective.</span></span><span class="sig-name descname"><span class="pre">MCAcquisitionObjective</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/objective.html#MCAcquisitionObjective"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>Abstract base class for MC-based objectives.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_verify_output_shape</strong> – If True and <cite>X</cite> is given, check that the q-batch
shape of the objectives agrees with that of X.</p></li>
<li><p><strong>_is_mo</strong> – A boolean denoting whether the objectives are multi-output.</p></li>
</ul>
</dd>
</dl>
<p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.objective.MCAcquisitionObjective.forward">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/objective.html#MCAcquisitionObjective.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.objective.MCAcquisitionObjective.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate the objective on the samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples</strong> (<em>Tensor</em>) – A <cite>sample_shape x batch_shape x q x m</cite>-dim Tensors of
samples from a model posterior.</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x q x d</cite>-dim tensor of inputs. Relevant only if
the objective depends on the inputs explicitly.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>sample_shape x batch_shape x q</cite>-dim Tensor of objective
values (assuming maximization).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<p>This method is usually not called directly, but via the objectives.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># `__call__` method:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">samples</span> <span class="o">=</span> <span class="n">sampler</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">outcome</span> <span class="o">=</span> <span class="n">mc_obj</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.objective.IdentityMCObjective">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.objective.</span></span><span class="sig-name descname"><span class="pre">IdentityMCObjective</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/objective.html#IdentityMCObjective"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.objective.IdentityMCObjective" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><code class="xref py py-class docutils literal notranslate"><span class="pre">MCAcquisitionObjective</span></code></a></p>
<p>Trivial objective extracting the last dimension.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">identity_objective</span> <span class="o">=</span> <span class="n">IdentityMCObjective</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">samples</span> <span class="o">=</span> <span class="n">sampler</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">objective</span> <span class="o">=</span> <span class="n">identity_objective</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
</pre></div>
</div>
<p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="field-list simple">
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.objective.IdentityMCObjective.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/objective.html#IdentityMCObjective.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.objective.IdentityMCObjective.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate the objective on the samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples</strong> (<em>Tensor</em>) – A <cite>sample_shape x batch_shape x q x m</cite>-dim Tensors of
samples from a model posterior.</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x q x d</cite>-dim tensor of inputs. Relevant only if
the objective depends on the inputs explicitly.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>sample_shape x batch_shape x q</cite>-dim Tensor of objective
values (assuming maximization).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<p>This method is usually not called directly, but via the objectives.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># `__call__` method:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">samples</span> <span class="o">=</span> <span class="n">sampler</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">outcome</span> <span class="o">=</span> <span class="n">mc_obj</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.objective.LinearMCObjective">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.objective.</span></span><span class="sig-name descname"><span class="pre">LinearMCObjective</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">weights</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/objective.html#LinearMCObjective"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.objective.LinearMCObjective" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><code class="xref py py-class docutils literal notranslate"><span class="pre">MCAcquisitionObjective</span></code></a></p>
<p>Linear objective constructed from a weight tensor.</p>
<p>For input <cite>samples</cite> and <cite>mc_obj = LinearMCObjective(weights)</cite>, this produces
<cite>mc_obj(samples) = sum_{i} weights[i] * samples[…, i]</cite></p>
<p class="rubric">Example</p>
<p>Example for a model with two outcomes:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.75</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear_objective</span> <span class="o">=</span> <span class="n">LinearMCObjective</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">samples</span> <span class="o">=</span> <span class="n">sampler</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">objective</span> <span class="o">=</span> <span class="n">linear_objective</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>weights</strong> (<em>Tensor</em>) – A one-dimensional tensor with <cite>m</cite> elements representing the
linear weights on the outputs.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.objective.LinearMCObjective.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/objective.html#LinearMCObjective.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.objective.LinearMCObjective.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate the linear objective on the samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples</strong> (<em>Tensor</em>) – A <cite>sample_shape x batch_shape x q x m</cite>-dim tensors of
samples from a model posterior.</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x q x d</cite>-dim tensor of inputs. Relevant only if
the objective depends on the inputs explicitly.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>sample_shape x batch_shape x q</cite>-dim tensor of objective values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.objective.GenericMCObjective">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.objective.</span></span><span class="sig-name descname"><span class="pre">GenericMCObjective</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">objective</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/objective.html#GenericMCObjective"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.objective.GenericMCObjective" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><code class="xref py py-class docutils literal notranslate"><span class="pre">MCAcquisitionObjective</span></code></a></p>
<p>Objective generated from a generic callable.</p>
<p>Allows to construct arbitrary MC-objective functions from a generic
callable. In order to be able to use gradient-based acquisition function
optimization it should be possible to backpropagate through the callable.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">generic_objective</span> <span class="o">=</span> <span class="n">GenericMCObjective</span><span class="p">(</span>
<span class="go">        lambda Y, X: torch.sqrt(Y).sum(dim=-1),</span>
<span class="go">    )</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">samples</span> <span class="o">=</span> <span class="n">sampler</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">objective</span> <span class="o">=</span> <span class="n">generic_objective</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>objective</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em> | </em><em>None</em><em>]</em><em>, </em><em>Tensor</em><em>]</em>) – A callable <cite>f(samples, X)</cite> mapping a
<cite>sample_shape x batch-shape x q x m</cite>-dim Tensor <cite>samples</cite> and
an optional <cite>batch-shape x q x d</cite>-dim Tensor <cite>X</cite> to a
<cite>sample_shape x batch-shape x q</cite>-dim Tensor of objective values.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.objective.GenericMCObjective.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/objective.html#GenericMCObjective.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.objective.GenericMCObjective.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate the objective on the samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples</strong> (<em>Tensor</em>) – A <cite>sample_shape x batch_shape x q x m</cite>-dim Tensors of
samples from a model posterior.</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x q x d</cite>-dim tensor of inputs. Relevant only if
the objective depends on the inputs explicitly.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>sample_shape x batch_shape x q</cite>-dim Tensor of objective values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.objective.ConstrainedMCObjective">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.objective.</span></span><span class="sig-name descname"><span class="pre">ConstrainedMCObjective</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">objective</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraints</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">infeasible_cost</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/objective.html#ConstrainedMCObjective"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.objective.ConstrainedMCObjective" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.objective.GenericMCObjective" title="botorch.acquisition.objective.GenericMCObjective"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericMCObjective</span></code></a></p>
<p>Feasibility-weighted objective.</p>
<p>An Objective allowing to maximize some scalable objective on the model
outputs subject to a number of constraints. Constraint feasibilty is
approximated by a sigmoid function.</p>
<blockquote>
<div><p>mc_acq(X) = (
(objective(X) + infeasible_cost) * prod_i (1  - sigmoid(constraint_i(X)))
) - infeasible_cost</p>
</div></blockquote>
<p>See <cite>botorch.utils.objective.apply_constraints</cite> for details on the constraint
handling.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">bound</span> <span class="o">=</span> <span class="mf">0.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">objective</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">Y</span><span class="p">:</span> <span class="n">Y</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># apply non-negativity constraint on f(x)[1]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">constraint</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">Y</span><span class="p">:</span> <span class="n">bound</span> <span class="o">-</span> <span class="n">Y</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">constrained_objective</span> <span class="o">=</span> <span class="n">ConstrainedMCObjective</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="p">[</span><span class="n">constraint</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">samples</span> <span class="o">=</span> <span class="n">sampler</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">objective</span> <span class="o">=</span> <span class="n">constrained_objective</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
</pre></div>
</div>
<p>TODO: Deprecate this as default way to handle constraints with MC acquisition
functions once we have data on how well SampleReducingMCAcquisitionFunction works.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>objective</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em> | </em><em>None</em><em>]</em><em>, </em><em>Tensor</em><em>]</em>) – A callable <cite>f(samples, X)</cite> mapping a
<cite>sample_shape x batch-shape x q x m</cite>-dim Tensor <cite>samples</cite> and
an optional <cite>batch-shape x q x d</cite>-dim Tensor <cite>X</cite> to a
<cite>sample_shape x batch-shape x q</cite>-dim Tensor of objective values.</p></li>
<li><p><strong>constraints</strong> (<em>list</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>]</em>) – A list of callables, each mapping a Tensor of dimension
<cite>sample_shape x batch-shape x q x m</cite> to a Tensor of dimension
<cite>sample_shape x batch-shape x q</cite>, where negative values imply
feasibility.</p></li>
<li><p><strong>infeasible_cost</strong> (<em>Tensor</em><em> | </em><em>float</em>) – The cost of a design if all associated samples are
infeasible.</p></li>
<li><p><strong>eta</strong> (<em>Tensor</em><em> | </em><em>float</em>) – The temperature parameter of the sigmoid function approximating
the constraint. Can be either a float or a 1-dim tensor. In case
of a float the same eta is used for every constraint in
constraints. In case of a tensor the length of the tensor must
match the number of provided constraints. The i-th constraint is
then estimated with the i-th eta value.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.objective.ConstrainedMCObjective.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/objective.html#ConstrainedMCObjective.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.objective.ConstrainedMCObjective.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate the feasibility-weighted objective on the samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples</strong> (<em>Tensor</em>) – A <cite>sample_shape x batch_shape x q x m</cite>-dim Tensors of
samples from a model posterior.</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x q x d</cite>-dim tensor of inputs. Relevant only if
the objective depends on the inputs explicitly.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>sample_shape x batch_shape x q</cite>-dim Tensor of objective values
weighted by feasibility (assuming maximization).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.objective.LearnedObjective">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.objective.</span></span><span class="sig-name descname"><span class="pre">LearnedObjective</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pref_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/objective.html#LearnedObjective"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.objective.LearnedObjective" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><code class="xref py py-class docutils literal notranslate"><span class="pre">MCAcquisitionObjective</span></code></a></p>
<p>Learned preference objective constructed from a preference model.</p>
<p>For input <cite>samples</cite>, it samples each individual sample again from the latent
preference posterior distribution using <cite>pref_model</cite> and return the posterior mean.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_comps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pref_model</span> <span class="o">=</span> <span class="n">PairwiseGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_comps</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">learned_pref_obj</span> <span class="o">=</span> <span class="n">LearnedObjective</span><span class="p">(</span><span class="n">pref_model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">samples</span> <span class="o">=</span> <span class="n">sampler</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">objective</span> <span class="o">=</span> <span class="n">learned_pref_obj</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pref_model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A BoTorch model, which models the latent preference/utility
function. Given an input tensor of size
<cite>sample_size x batch_shape x q x d</cite>, its <cite>posterior</cite> method should
return a <cite>Posterior</cite> object with single outcome representing the
utility values of the input.</p></li>
<li><p><strong>sample_shape</strong> (<em>torch.Size</em><em> | </em><em>None</em>) – Determines the number of preference-model samples drawn
<em>per outcome-model sample</em> when the <cite>LearnedObjective</cite> is called.
Note that this is an additional layer of sampling relative to what
is needed when evaluating most MC acquisition functions in order to
account for uncertainty in the preference model. If <cite>None</cite>, it will
default to <cite>torch.Size([16])</cite>, so that 16 samples will be drawn
from the preference model at each outcome sample. This number is
relatively high because sampling from the preference model is general
cheap relative to generating the outcome model posterior.</p></li>
<li><p><strong>seed</strong> (<em>int</em><em> | </em><em>None</em>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.objective.LearnedObjective.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/objective.html#LearnedObjective.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.objective.LearnedObjective.forward" title="Link to this definition"></a></dt>
<dd><p>Sample each element of samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples</strong> (<em>Tensor</em>) – A <cite>sample_size x batch_shape x q x d</cite>-dim Tensors of
samples from a model posterior.</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>(sample_size * num_samples) x batch_shape x q</cite>-dim Tensor of
objective values sampled from utility posterior using <cite>pref_model</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-botorch.acquisition.multi_objective.objective">
<span id="multi-objective-objectives"></span><h3>Multi-Objective Objectives<a class="headerlink" href="#module-botorch.acquisition.multi_objective.objective" title="Link to this heading"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.objective.MCMultiOutputObjective">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.multi_objective.objective.</span></span><span class="sig-name descname"><span class="pre">MCMultiOutputObjective</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/objective.html#MCMultiOutputObjective"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.objective.MCMultiOutputObjective" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><code class="xref py py-class docutils literal notranslate"><span class="pre">MCAcquisitionObjective</span></code></a></p>
<p>Abstract base class for MC multi-output objectives.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>_is_mo</strong> – A boolean denoting whether the objectives are multi-output.</p>
</dd>
</dl>
<p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.objective.MCMultiOutputObjective.forward">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/objective.html#MCMultiOutputObjective.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.objective.MCMultiOutputObjective.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate the multi-output objective on the samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples</strong> (<em>Tensor</em>) – A <cite>sample_shape x batch_shape x q x m</cite>-dim Tensors of samples from
a model posterior.</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x q x d</cite>-dim Tensors of inputs.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>sample_shape x batch_shape x q x m’</cite>-dim Tensor of objective values with
<cite>m’</cite> the output dimension. This assumes maximization in each output
dimension).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
<p>This method is usually not called directly, but via the objectives.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># `__call__` method:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">samples</span> <span class="o">=</span> <span class="n">sampler</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">outcomes</span> <span class="o">=</span> <span class="n">multi_obj</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.objective.GenericMCMultiOutputObjective">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.multi_objective.objective.</span></span><span class="sig-name descname"><span class="pre">GenericMCMultiOutputObjective</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">objective</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/objective.html#GenericMCMultiOutputObjective"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.objective.GenericMCMultiOutputObjective" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.objective.GenericMCObjective" title="botorch.acquisition.objective.GenericMCObjective"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericMCObjective</span></code></a>, <a class="reference internal" href="#botorch.acquisition.multi_objective.objective.MCMultiOutputObjective" title="botorch.acquisition.multi_objective.objective.MCMultiOutputObjective"><code class="xref py py-class docutils literal notranslate"><span class="pre">MCMultiOutputObjective</span></code></a></p>
<p>Multi-output objective generated from a generic callable.</p>
<p>Allows to construct arbitrary MC-objective functions from a generic
callable. In order to be able to use gradient-based acquisition function
optimization it should be possible to backpropagate through the callable.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>objective</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em> | </em><em>None</em><em>]</em><em>, </em><em>Tensor</em><em>]</em>) – A callable <cite>f(samples, X)</cite> mapping a
<cite>sample_shape x batch-shape x q x m</cite>-dim Tensor <cite>samples</cite> and
an optional <cite>batch-shape x q x d</cite>-dim Tensor <cite>X</cite> to a
<cite>sample_shape x batch-shape x q</cite>-dim Tensor of objective values.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.objective.IdentityMCMultiOutputObjective">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.multi_objective.objective.</span></span><span class="sig-name descname"><span class="pre">IdentityMCMultiOutputObjective</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">outcomes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_outcomes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/objective.html#IdentityMCMultiOutputObjective"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.objective.IdentityMCMultiOutputObjective" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.multi_objective.objective.MCMultiOutputObjective" title="botorch.acquisition.multi_objective.objective.MCMultiOutputObjective"><code class="xref py py-class docutils literal notranslate"><span class="pre">MCMultiOutputObjective</span></code></a></p>
<p>Trivial objective that returns the unaltered samples.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">identity_objective</span> <span class="o">=</span> <span class="n">IdentityMCMultiOutputObjective</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">samples</span> <span class="o">=</span> <span class="n">sampler</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">objective</span> <span class="o">=</span> <span class="n">identity_objective</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
</pre></div>
</div>
<p>Initialize Objective.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>outcomes</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – A list of the <cite>m’</cite> indices that the weights should be
applied to.</p></li>
<li><p><strong>num_outcomes</strong> (<em>int</em><em> | </em><em>None</em>) – The total number of outcomes <cite>m</cite></p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.objective.IdentityMCMultiOutputObjective.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/objective.html#IdentityMCMultiOutputObjective.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.objective.IdentityMCMultiOutputObjective.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate the multi-output objective on the samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples</strong> (<em>Tensor</em>) – A <cite>sample_shape x batch_shape x q x m</cite>-dim Tensors of samples from
a model posterior.</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x q x d</cite>-dim Tensors of inputs.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>sample_shape x batch_shape x q x m’</cite>-dim Tensor of objective values with
<cite>m’</cite> the output dimension. This assumes maximization in each output
dimension).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
<p>This method is usually not called directly, but via the objectives.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># `__call__` method:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">samples</span> <span class="o">=</span> <span class="n">sampler</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">outcomes</span> <span class="o">=</span> <span class="n">multi_obj</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.objective.WeightedMCMultiOutputObjective">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.multi_objective.objective.</span></span><span class="sig-name descname"><span class="pre">WeightedMCMultiOutputObjective</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">weights</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outcomes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_outcomes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/objective.html#WeightedMCMultiOutputObjective"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.objective.WeightedMCMultiOutputObjective" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.multi_objective.objective.IdentityMCMultiOutputObjective" title="botorch.acquisition.multi_objective.objective.IdentityMCMultiOutputObjective"><code class="xref py py-class docutils literal notranslate"><span class="pre">IdentityMCMultiOutputObjective</span></code></a></p>
<p>Objective that reweights samples by given weights vector.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">weighted_objective</span> <span class="o">=</span> <span class="n">WeightedMCMultiOutputObjective</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">samples</span> <span class="o">=</span> <span class="n">sampler</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">objective</span> <span class="o">=</span> <span class="n">weighted_objective</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
</pre></div>
</div>
<p>Initialize Objective.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>weights</strong> (<em>Tensor</em>) – <cite>m’</cite>-dim tensor of outcome weights.</p></li>
<li><p><strong>outcomes</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – A list of the <cite>m’</cite> indices that the weights should be
applied to.</p></li>
<li><p><strong>num_outcomes</strong> (<em>int</em><em> | </em><em>None</em>) – the total number of outcomes <cite>m</cite></p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.objective.WeightedMCMultiOutputObjective.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/objective.html#WeightedMCMultiOutputObjective.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.objective.WeightedMCMultiOutputObjective.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate the multi-output objective on the samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples</strong> (<em>Tensor</em>) – A <cite>sample_shape x batch_shape x q x m</cite>-dim Tensors of samples from
a model posterior.</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x q x d</cite>-dim Tensors of inputs.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>sample_shape x batch_shape x q x m’</cite>-dim Tensor of objective values with
<cite>m’</cite> the output dimension. This assumes maximization in each output
dimension).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
<p>This method is usually not called directly, but via the objectives.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># `__call__` method:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">samples</span> <span class="o">=</span> <span class="n">sampler</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">outcomes</span> <span class="o">=</span> <span class="n">multi_obj</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.objective.FeasibilityWeightedMCMultiOutputObjective">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.multi_objective.objective.</span></span><span class="sig-name descname"><span class="pre">FeasibilityWeightedMCMultiOutputObjective</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_baseline</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraint_idcs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/objective.html#FeasibilityWeightedMCMultiOutputObjective"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.objective.FeasibilityWeightedMCMultiOutputObjective" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.multi_objective.objective.MCMultiOutputObjective" title="botorch.acquisition.multi_objective.objective.MCMultiOutputObjective"><code class="xref py py-class docutils literal notranslate"><span class="pre">MCMultiOutputObjective</span></code></a></p>
<p>Construct a feasibility-weighted objective.</p>
<p>This applies feasibility weighting before calculating the objective value.
Defaults to identity if no constraints or objective is present.</p>
<p>NOTE: By passing in a single-output <cite>MCAcquisitionObjective</cite> as the <cite>objective</cite>,
this can be used as a single-output <cite>MCAcquisitionObjective</cite> as well.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted Model.</p></li>
<li><p><strong>X_baseline</strong> (<em>Tensor</em>) – An <cite>n x d</cite>-dim tensor of points already observed.</p></li>
<li><p><strong>constraint_idcs</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – The outcome indices of the constraints. Constraints are
handled by weighting the samples according to a sigmoid approximation
of feasibility. A positive constraint outcome implies feasibility.</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.multi_objective.objective.MCMultiOutputObjective" title="botorch.acquisition.multi_objective.objective.MCMultiOutputObjective"><em>MCMultiOutputObjective</em></a><em> | </em><em>None</em>) – An optional objective to apply after feasibility-weighting
the samples.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.objective.FeasibilityWeightedMCMultiOutputObjective.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/objective.html#FeasibilityWeightedMCMultiOutputObjective.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.objective.FeasibilityWeightedMCMultiOutputObjective.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate the multi-output objective on the samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples</strong> (<em>Tensor</em>) – A <cite>sample_shape x batch_shape x q x m</cite>-dim Tensors of samples from
a model posterior.</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x q x d</cite>-dim Tensors of inputs.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>sample_shape x batch_shape x q x m’</cite>-dim Tensor of objective values with
<cite>m’</cite> the output dimension. This assumes maximization in each output
dimension).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
<p>This method is usually not called directly, but via the objectives.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># `__call__` method:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">samples</span> <span class="o">=</span> <span class="n">sampler</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">outcomes</span> <span class="o">=</span> <span class="n">multi_obj</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

</section>
<section id="module-botorch.acquisition.cost_aware">
<span id="cost-aware-utility"></span><h3>Cost-Aware Utility<a class="headerlink" href="#module-botorch.acquisition.cost_aware" title="Link to this heading"></a></h3>
<p>Cost functions for cost-aware acquisition functions, e.g. multi-fidelity KG.
To be used in a context where there is an objective/cost tradeoff.</p>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.cost_aware.CostAwareUtility">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.cost_aware.</span></span><span class="sig-name descname"><span class="pre">CostAwareUtility</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/cost_aware.html#CostAwareUtility"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.cost_aware.CostAwareUtility" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>Abstract base class for cost-aware utilities.</p>
<p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="field-list simple">
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.cost_aware.CostAwareUtility.forward">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deltas</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/cost_aware.html#CostAwareUtility.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.cost_aware.CostAwareUtility.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate the cost-aware utility on the candidates and improvements.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x q x d</cite>-dim Tensor of with <cite>q</cite> <cite>d</cite>-dim design
points each for each t-batch.</p></li>
<li><p><strong>deltas</strong> (<em>Tensor</em>) – A <cite>num_fantasies x batch_shape</cite>-dim Tensor of <cite>num_fantasy</cite>
samples from the marginal improvement in utility over the
current state at <cite>X</cite> for each t-batch.</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – A sampler used for sampling from the posterior of the cost
model. Some subclasses ignore this argument.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>num_fantasies x batch_shape</cite>-dim Tensor of cost-transformed utilities.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.cost_aware.GenericCostAwareUtility">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.cost_aware.</span></span><span class="sig-name descname"><span class="pre">GenericCostAwareUtility</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cost</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/cost_aware.html#GenericCostAwareUtility"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.cost_aware.GenericCostAwareUtility" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.cost_aware.CostAwareUtility" title="botorch.acquisition.cost_aware.CostAwareUtility"><code class="xref py py-class docutils literal notranslate"><span class="pre">CostAwareUtility</span></code></a></p>
<p>Generic cost-aware utility wrapping a callable.</p>
<p>Generic cost-aware utility wrapping a callable.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>cost</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em>) – A callable mapping a <cite>batch_shape x q x d’</cite>-dim candidate set
to a <cite>batch_shape</cite>-dim tensor of costs</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.cost_aware.GenericCostAwareUtility.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deltas</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/cost_aware.html#GenericCostAwareUtility.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.cost_aware.GenericCostAwareUtility.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate the cost function on the candidates and improvements.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x q x d’</cite>-dim Tensor of with <cite>q</cite> <cite>d</cite>-dim design
points for each t-batch.</p></li>
<li><p><strong>deltas</strong> (<em>Tensor</em>) – A <cite>num_fantasies x batch_shape</cite>-dim Tensor of <cite>num_fantasy</cite>
samples from the marginal improvement in utility over the
current state at <cite>X</cite> for each t-batch.</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – Ignored.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>num_fantasies x batch_shape</cite>-dim Tensor of cost-weighted utilities.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.cost_aware.InverseCostWeightedUtility">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.cost_aware.</span></span><span class="sig-name descname"><span class="pre">InverseCostWeightedUtility</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cost_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_mean</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cost_objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_cost</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/cost_aware.html#InverseCostWeightedUtility"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.cost_aware.InverseCostWeightedUtility" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.cost_aware.CostAwareUtility" title="botorch.acquisition.cost_aware.CostAwareUtility"><code class="xref py py-class docutils literal notranslate"><span class="pre">CostAwareUtility</span></code></a></p>
<p>A cost-aware utility using inverse cost weighting based on a model.</p>
<p>Computes the cost-aware utility by inverse-weighting samples
<cite>U = (u_1, …, u_N)</cite> of the increase in utility. If <cite>use_mean=True</cite>, this
uses the posterior mean <cite>mean_cost</cite> of the cost model, i.e.
<cite>weighted utility = mean(U) / mean_cost</cite>. If <cite>use_mean=False</cite>, it uses
samples <cite>C = (c_1, …, c_N)</cite> from the posterior of the cost model and
performs the inverse weighting on the sample level:
<cite>weighted utility = mean(u_1 / c_1, …, u_N / c_N)</cite>.</p>
<p>Where values in (u_1, …, u_N) are negative, or for mean(U) &lt; 0, the
weighted utility is instead calculated via scaling by the cost, i.e. if
<cite>use_mean=True</cite>: <cite>weighted_utility = mean(U) * mean_cost</cite> and if
<cite>use_mean=False</cite>:
<cite>weighted utility = mean(u_1 * c_1, u_2 / c_2, u_3 * c_3, …, u_N / c_N)</cite>,
depending on whether (<cite>u_*</cite> &gt;= 0), as with <cite>u_2</cite> and <cite>u_N</cite> in this case, or
(<cite>u_*</cite> &lt; 0) as with <cite>u_1</cite> and <cite>u_3</cite>.</p>
<p>The cost is additive across multiple elements of a q-batch.</p>
<p>Cost-aware utility that weights increase in utility by inverse cost.
For negative increases in utility, the utility is instead scaled by the
cost. See the class description for more information.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cost_model</strong> (<a class="reference internal" href="models.html#botorch.models.deterministic.DeterministicModel" title="botorch.models.deterministic.DeterministicModel"><em>DeterministicModel</em></a><em> | </em><a class="reference internal" href="models.html#botorch.models.gpytorch.GPyTorchModel" title="botorch.models.gpytorch.GPyTorchModel"><em>GPyTorchModel</em></a>) – A model of the cost of evaluating a candidate
set <cite>X</cite>, where <cite>X</cite> are the same features as in the model for the
acquisition function this is to be used with. If no cost_objective
is specified, the outputs are required to be non-negative.</p></li>
<li><p><strong>use_mean</strong> (<em>bool</em>) – If True, use the posterior mean, otherwise use posterior
samples from the cost model.</p></li>
<li><p><strong>cost_objective</strong> (<a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><em>MCAcquisitionObjective</em></a><em> | </em><em>None</em>) – If specified, transform the posterior mean / the
posterior samples from the cost model. This can be used e.g. to
un-transform predictions/samples of a cost model fit on the
log-transformed cost (often done to ensure non-negativity). If the
cost model is multi-output, then by default this will sum the cost
across outputs.</p></li>
<li><p><strong>min_cost</strong> (<em>float</em>) – A value used to clamp the cost samples so that they are not
too close to zero, which may cause numerical issues.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The inverse-cost-weighted utility.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.cost_aware.InverseCostWeightedUtility.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deltas</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_evaluation_mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/cost_aware.html#InverseCostWeightedUtility.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.cost_aware.InverseCostWeightedUtility.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate the cost function on the candidates and improvements. Note
that negative values of <cite>deltas</cite> are instead scaled by the cost, and not
inverse-weighted. See the class description for more information.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x q x d</cite>-dim Tensor of with <cite>q</cite> <cite>d</cite>-dim design
points each for each t-batch.</p></li>
<li><p><strong>deltas</strong> (<em>Tensor</em>) – A <cite>num_fantasies x batch_shape</cite>-dim Tensor of <cite>num_fantasy</cite>
samples from the marginal improvement in utility over the
current state at <cite>X</cite> for each t-batch.</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – A sampler used for sampling from the posterior of the cost
model (required if <cite>use_mean=False</cite>, ignored if <cite>use_mean=True</cite>).</p></li>
<li><p><strong>X_evaluation_mask</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>q x m</cite>-dim boolean tensor indicating which
outcomes should be evaluated for each design in the batch.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>num_fantasies x batch_shape</cite>-dim Tensor of cost-weighted utilities.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-botorch.acquisition.risk_measures">
<span id="risk-measures"></span><h3>Risk Measures<a class="headerlink" href="#module-botorch.acquisition.risk_measures" title="Link to this heading"></a></h3>
<p>Risk Measures implemented as Monte-Carlo objectives, based on Bayesian
optimization of risk measures as introduced in <a class="reference internal" href="#cakmak2020risk" id="id63"><span>[Cakmak2020risk]</span></a>. For a
broader discussion of Monte-Carlo methods for VaR and CVaR risk measures,
see also <a class="reference internal" href="#hong2014review" id="id64"><span>[Hong2014review]</span></a>.</p>
<div role="list" class="citation-list">
<div class="citation" id="cakmak2020risk" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id63">Cakmak2020risk</a><span class="fn-bracket">]</span></span>
<p>S. Cakmak, R. Astudillo, P. Frazier, and E. Zhou. Bayesian Optimization of
Risk Measures. Advances in Neural Information Processing Systems 33, 2020.</p>
</div>
<div class="citation" id="hong2014review" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id64">Hong2014review</a><span class="fn-bracket">]</span></span>
<p>L. J. Hong, Z. Hu, and G. Liu. Monte carlo methods for value-at-risk and
conditional value-at-risk: a review. ACM Transactions on Modeling and
Computer Simulation, 2014.</p>
</div>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.risk_measures.RiskMeasureMCObjective">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.risk_measures.</span></span><span class="sig-name descname"><span class="pre">RiskMeasureMCObjective</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_w</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">preprocessing_function</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/risk_measures.html#RiskMeasureMCObjective"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.risk_measures.RiskMeasureMCObjective" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><code class="xref py py-class docutils literal notranslate"><span class="pre">MCAcquisitionObjective</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>Objective transforming the posterior samples to samples of a risk measure.</p>
<p>The risk measure is calculated over joint q-batch samples from the posterior.
If the q-batch includes samples corresponding to multiple inputs, it is assumed
that first <cite>n_w</cite> samples correspond to first input, second <cite>n_w</cite> samples
correspond to second input etc.</p>
<p>The risk measures are commonly defined for minimization by considering the
upper tail of the distribution, i.e., treating larger values as being undesirable.
BoTorch by default assumes a maximization objective, so the default behavior here
is to calculate the risk measures w.r.t. the lower tail of the distribution.
This can be changed by passing a preprocessing function with
<cite>weights=torch.tensor([-1.0])</cite>.</p>
<p>Transform the posterior samples to samples of a risk measure.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_w</strong> (<em>int</em>) – The size of the <cite>w_set</cite> to calculate the risk measure over.</p></li>
<li><p><strong>preprocessing_function</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – A preprocessing function to apply to the samples
before computing the risk measure. This can be used to scalarize
multi-output samples before calculating the risk measure.
For constrained optimization, this should also apply
feasibility-weighting to samples. Given a <cite>batch x m</cite>-dim
tensor of samples, this should return a <cite>batch</cite>-dim tensor.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.risk_measures.RiskMeasureMCObjective.forward">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/risk_measures.html#RiskMeasureMCObjective.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.risk_measures.RiskMeasureMCObjective.forward" title="Link to this definition"></a></dt>
<dd><p>Calculate the risk measure corresponding to the given samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples</strong> (<em>Tensor</em>) – A <cite>sample_shape x batch_shape x (q * n_w) x m</cite>-dim tensor of
posterior samples. The q-batches should be ordered so that each
<cite>n_w</cite> block of samples correspond to the same input.</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x q x d</cite>-dim tensor of inputs. Ignored.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>sample_shape x batch_shape x q</cite>-dim tensor of risk measure samples.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.risk_measures.CVaR">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.risk_measures.</span></span><span class="sig-name descname"><span class="pre">CVaR</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_w</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">preprocessing_function</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/risk_measures.html#CVaR"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.risk_measures.CVaR" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.risk_measures.RiskMeasureMCObjective" title="botorch.acquisition.risk_measures.RiskMeasureMCObjective"><code class="xref py py-class docutils literal notranslate"><span class="pre">RiskMeasureMCObjective</span></code></a></p>
<p>The Conditional Value-at-Risk risk measure.</p>
<p>The Conditional Value-at-Risk measures the expectation of the worst outcomes
(small rewards or large losses) with a total probability of <cite>1 - alpha</cite>. It
is commonly defined as the conditional expectation of the reward function,
with the condition that the reward is smaller than the corresponding
Value-at-Risk (also defined below).</p>
<dl class="simple">
<dt>Note: Due to the use of a discrete <cite>w_set</cite> of samples, the VaR and CVaR</dt><dd><p>calculated here are (possibly biased) Monte-Carlo approximations of
the true risk measures.</p>
</dd>
</dl>
<p>Transform the posterior samples to samples of a risk measure.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>alpha</strong> (<em>float</em>) – The risk level, float in <cite>(0.0, 1.0]</cite>.</p></li>
<li><p><strong>n_w</strong> (<em>int</em>) – The size of the <cite>w_set</cite> to calculate the risk measure over.</p></li>
<li><p><strong>preprocessing_function</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – A preprocessing function to apply to the samples
before computing the risk measure. This can be used to scalarize
multi-output samples before calculating the risk measure.
For constrained optimization, this should also apply
feasibility-weighting to samples. Given a <cite>batch x m</cite>-dim
tensor of samples, this should return a <cite>batch</cite>-dim tensor.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.risk_measures.CVaR.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/risk_measures.html#CVaR.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.risk_measures.CVaR.forward" title="Link to this definition"></a></dt>
<dd><p>Calculate the CVaR corresponding to the given samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples</strong> (<em>Tensor</em>) – A <cite>sample_shape x batch_shape x (q * n_w) x m</cite>-dim tensor of
posterior samples. The q-batches should be ordered so that each
<cite>n_w</cite> block of samples correspond to the same input.</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x q x d</cite>-dim tensor of inputs. Ignored.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>sample_shape x batch_shape x q</cite>-dim tensor of CVaR samples.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.risk_measures.VaR">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.risk_measures.</span></span><span class="sig-name descname"><span class="pre">VaR</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_w</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">preprocessing_function</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/risk_measures.html#VaR"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.risk_measures.VaR" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.risk_measures.CVaR" title="botorch.acquisition.risk_measures.CVaR"><code class="xref py py-class docutils literal notranslate"><span class="pre">CVaR</span></code></a></p>
<p>The Value-at-Risk risk measure.</p>
<p>Value-at-Risk measures the smallest possible reward (or largest possible loss)
after excluding the worst outcomes with a total probability of <cite>1 - alpha</cite>. It
is commonly used in financial risk management, and it corresponds to the
<cite>1 - alpha</cite> quantile of a given random variable.</p>
<p>Transform the posterior samples to samples of a risk measure.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>alpha</strong> (<em>float</em>) – The risk level, float in <cite>(0.0, 1.0]</cite>.</p></li>
<li><p><strong>n_w</strong> (<em>int</em>) – The size of the <cite>w_set</cite> to calculate the risk measure over.</p></li>
<li><p><strong>preprocessing_function</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – A preprocessing function to apply to the samples
before computing the risk measure. This can be used to scalarize
multi-output samples before calculating the risk measure.
For constrained optimization, this should also apply
feasibility-weighting to samples. Given a <cite>batch x m</cite>-dim
tensor of samples, this should return a <cite>batch</cite>-dim tensor.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.risk_measures.VaR.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/risk_measures.html#VaR.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.risk_measures.VaR.forward" title="Link to this definition"></a></dt>
<dd><p>Calculate the VaR corresponding to the given samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples</strong> (<em>Tensor</em>) – A <cite>sample_shape x batch_shape x (q * n_w) x m</cite>-dim tensor of
posterior samples. The q-batches should be ordered so that each
<cite>n_w</cite> block of samples correspond to the same input.</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x q x d</cite>-dim tensor of inputs. Ignored.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>sample_shape x batch_shape x q</cite>-dim tensor of VaR samples.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.risk_measures.WorstCase">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.risk_measures.</span></span><span class="sig-name descname"><span class="pre">WorstCase</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_w</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">preprocessing_function</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/risk_measures.html#WorstCase"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.risk_measures.WorstCase" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.risk_measures.RiskMeasureMCObjective" title="botorch.acquisition.risk_measures.RiskMeasureMCObjective"><code class="xref py py-class docutils literal notranslate"><span class="pre">RiskMeasureMCObjective</span></code></a></p>
<p>The worst-case risk measure.</p>
<p>Transform the posterior samples to samples of a risk measure.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_w</strong> (<em>int</em>) – The size of the <cite>w_set</cite> to calculate the risk measure over.</p></li>
<li><p><strong>preprocessing_function</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – A preprocessing function to apply to the samples
before computing the risk measure. This can be used to scalarize
multi-output samples before calculating the risk measure.
For constrained optimization, this should also apply
feasibility-weighting to samples. Given a <cite>batch x m</cite>-dim
tensor of samples, this should return a <cite>batch</cite>-dim tensor.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.risk_measures.WorstCase.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/risk_measures.html#WorstCase.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.risk_measures.WorstCase.forward" title="Link to this definition"></a></dt>
<dd><p>Calculate the worst-case measure corresponding to the given samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples</strong> (<em>Tensor</em>) – A <cite>sample_shape x batch_shape x (q * n_w) x m</cite>-dim tensor of
posterior samples. The q-batches should be ordered so that each
<cite>n_w</cite> block of samples correspond to the same input.</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x q x d</cite>-dim tensor of inputs. Ignored.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>sample_shape x batch_shape x q</cite>-dim tensor of worst-case samples.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.risk_measures.Expectation">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.risk_measures.</span></span><span class="sig-name descname"><span class="pre">Expectation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_w</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">preprocessing_function</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/risk_measures.html#Expectation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.risk_measures.Expectation" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.risk_measures.RiskMeasureMCObjective" title="botorch.acquisition.risk_measures.RiskMeasureMCObjective"><code class="xref py py-class docutils literal notranslate"><span class="pre">RiskMeasureMCObjective</span></code></a></p>
<p>The expectation risk measure.</p>
<p>For unconstrained problems, we recommend using the <cite>ExpectationPosteriorTransform</cite>
instead. <cite>ExpectationPosteriorTransform</cite> directly transforms the posterior
distribution over <cite>q * n_w</cite> to a posterior of <cite>q</cite> expectations, significantly
reducing the cost of posterior sampling as a result.</p>
<p>Transform the posterior samples to samples of a risk measure.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_w</strong> (<em>int</em>) – The size of the <cite>w_set</cite> to calculate the risk measure over.</p></li>
<li><p><strong>preprocessing_function</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – A preprocessing function to apply to the samples
before computing the risk measure. This can be used to scalarize
multi-output samples before calculating the risk measure.
For constrained optimization, this should also apply
feasibility-weighting to samples. Given a <cite>batch x m</cite>-dim
tensor of samples, this should return a <cite>batch</cite>-dim tensor.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.risk_measures.Expectation.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/risk_measures.html#Expectation.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.risk_measures.Expectation.forward" title="Link to this definition"></a></dt>
<dd><p>Calculate the expectation corresponding to the given samples.
This calculates the expectation / mean / average of each <cite>n_w</cite> samples
across the q-batch dimension. If <cite>self.weights</cite> is given, the samples
are scalarized across the output dimension before taking the expectation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples</strong> (<em>Tensor</em>) – A <cite>sample_shape x batch_shape x (q * n_w) x m</cite>-dim tensor of
posterior samples. The q-batches should be ordered so that each
<cite>n_w</cite> block of samples correspond to the same input.</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x q x d</cite>-dim tensor of inputs. Ignored.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>sample_shape x batch_shape x q</cite>-dim tensor of expectation samples.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-botorch.acquisition.thompson_sampling">
<span id="thompson-sampling"></span><h3>Thompson Sampling<a class="headerlink" href="#module-botorch.acquisition.thompson_sampling" title="Link to this heading"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.thompson_sampling.PathwiseThompsonSampling">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.thompson_sampling.</span></span><span class="sig-name descname"><span class="pre">PathwiseThompsonSampling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/thompson_sampling.html#PathwiseThompsonSampling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.thompson_sampling.PathwiseThompsonSampling" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">AcquisitionFunction</span></code></a></p>
<p>Single-outcome Thompson Sampling packaged as an (analytic)
acquisition function. Querying the acquisition function gives the summed
values of one or more draws from a pathwise drawn posterior sample, and thus
it maximization yields one (or multiple) Thompson sample(s).</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TS</span> <span class="o">=</span> <span class="n">PathwiseThompsonSampling</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
<p>Single-outcome TS.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted GP model.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – A PosteriorTransform. If using a multi-output model,
a PosteriorTransform that transforms the multi-output posterior into a
single-output posterior is required.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.thompson_sampling.PathwiseThompsonSampling.redraw">
<span class="sig-name descname"><span class="pre">redraw</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/thompson_sampling.html#PathwiseThompsonSampling.redraw"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.thompson_sampling.PathwiseThompsonSampling.redraw" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.thompson_sampling.PathwiseThompsonSampling.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/thompson_sampling.html#PathwiseThompsonSampling.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.thompson_sampling.PathwiseThompsonSampling.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate the pathwise posterior sample draws on the candidate set X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>(b1 x … bk) x 1 x d</cite>-dim batched tensor of <cite>d</cite>-dim design points.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>(b1 x … bk) x [num_models for fully bayesian]</cite>-dim tensor of
evaluations on the posterior sample draws.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-botorch.acquisition.multi_objective.multi_output_risk_measures">
<span id="multi-output-risk-measures"></span><h3>Multi-Output Risk Measures<a class="headerlink" href="#module-botorch.acquisition.multi_objective.multi_output_risk_measures" title="Link to this heading"></a></h3>
<p>Multi-output extensions of the risk measures, implemented as Monte-Carlo
objectives. Except for MVaR, the risk measures are computed over each
output dimension independently. In contrast, MVaR is computed using the
joint distribution of the outputs, and provides more accurate risk estimates.</p>
<p>References</p>
<div role="list" class="citation-list">
<div class="citation" id="prekopa2012mvar" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Prekopa2012MVaR<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id65">1</a>,<a role="doc-backlink" href="#id69">2</a>,<a role="doc-backlink" href="#id70">3</a>,<a role="doc-backlink" href="#id71">4</a>)</span>
<p>A. Prekopa. Multivariate value at risk and related topics.
Annals of Operations Research, 2012.</p>
</div>
<div class="citation" id="cousin2013mvar" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Cousin2013MVaR<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id66">1</a>,<a role="doc-backlink" href="#id68">2</a>)</span>
<p>A. Cousin and E. Di Bernardino. On multivariate extensions of Value-at-Risk.
Journal of Multivariate Analysis, 2013.</p>
</div>
<div class="citation" id="daulton2022mars" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Daulton2022MARS<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id67">1</a>,<a role="doc-backlink" href="#id72">2</a>,<a role="doc-backlink" href="#id73">3</a>)</span>
<p>S. Daulton, S, Cakmak, M. Balandat, M. Osborne, E. Zhou, and E. Bakshy.
Robust multi-objective Bayesian optimization under input noise.
Proceedings of the 39th International Conference on Machine Learning, 2022.</p>
</div>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.multi_output_risk_measures.MultiOutputRiskMeasureMCObjective">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.multi_objective.multi_output_risk_measures.</span></span><span class="sig-name descname"><span class="pre">MultiOutputRiskMeasureMCObjective</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_w</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">preprocessing_function</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/multi_output_risk_measures.html#MultiOutputRiskMeasureMCObjective"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.multi_output_risk_measures.MultiOutputRiskMeasureMCObjective" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.risk_measures.RiskMeasureMCObjective" title="botorch.acquisition.risk_measures.RiskMeasureMCObjective"><code class="xref py py-class docutils literal notranslate"><span class="pre">RiskMeasureMCObjective</span></code></a>, <a class="reference internal" href="#botorch.acquisition.multi_objective.objective.MCMultiOutputObjective" title="botorch.acquisition.multi_objective.objective.MCMultiOutputObjective"><code class="xref py py-class docutils literal notranslate"><span class="pre">MCMultiOutputObjective</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>Objective transforming the multi-output posterior samples to samples
of a multi-output risk measure.</p>
<p>The risk measure is calculated over joint q-batch samples from the posterior.
If the q-batch includes samples corresponding to multiple inputs, it is assumed
that first <cite>n_w</cite> samples correspond to first input, second <cite>n_w</cite> samples
correspond to second input, etc.</p>
<p>Transform the posterior samples to samples of a risk measure.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_w</strong> (<em>int</em>) – The size of the <cite>w_set</cite> to calculate the risk measure over.</p></li>
<li><p><strong>preprocessing_function</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – A preprocessing function to apply to the
samples before computing the risk measure. This can be used to
remove non-objective outcomes or to align all outcomes for
maximization. For constrained optimization, this should also
apply feasibility-weighting to samples. Given a <cite>batch x m</cite>-dim
tensor of samples, this should return a <cite>batch x m’</cite>-dim tensor.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.multi_output_risk_measures.MultiOutputRiskMeasureMCObjective.forward">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/multi_output_risk_measures.html#MultiOutputRiskMeasureMCObjective.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.multi_output_risk_measures.MultiOutputRiskMeasureMCObjective.forward" title="Link to this definition"></a></dt>
<dd><p>Calculate the risk measure corresponding to the given samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples</strong> (<em>Tensor</em>) – A <cite>sample_shape x batch_shape x (q * n_w) x m</cite>-dim tensor of
posterior samples. The q-batches should be ordered so that each
<cite>n_w</cite> block of samples correspond to the same input.</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x q x d</cite>-dim tensor of inputs. Ignored.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>sample_shape x batch_shape x q x m’</cite>-dim tensor of risk measure samples.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.multi_output_risk_measures.MultiOutputExpectation">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.multi_objective.multi_output_risk_measures.</span></span><span class="sig-name descname"><span class="pre">MultiOutputExpectation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_w</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">preprocessing_function</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/multi_output_risk_measures.html#MultiOutputExpectation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.multi_output_risk_measures.MultiOutputExpectation" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.multi_objective.multi_output_risk_measures.MultiOutputRiskMeasureMCObjective" title="botorch.acquisition.multi_objective.multi_output_risk_measures.MultiOutputRiskMeasureMCObjective"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiOutputRiskMeasureMCObjective</span></code></a></p>
<p>A multi-output MC expectation risk measure.</p>
<p>For unconstrained problems, we recommend using the <cite>ExpectationPosteriorTransform</cite>
instead. <cite>ExpectationPosteriorTransform</cite> directly transforms the posterior
distribution over <cite>q * n_w</cite> to a posterior of <cite>q</cite> expectations, significantly
reducing the cost of posterior sampling as a result.</p>
<p>Transform the posterior samples to samples of a risk measure.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_w</strong> (<em>int</em>) – The size of the <cite>w_set</cite> to calculate the risk measure over.</p></li>
<li><p><strong>preprocessing_function</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – A preprocessing function to apply to the
samples before computing the risk measure. This can be used to
remove non-objective outcomes or to align all outcomes for
maximization. For constrained optimization, this should also
apply feasibility-weighting to samples. Given a <cite>batch x m</cite>-dim
tensor of samples, this should return a <cite>batch x m’</cite>-dim tensor.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.multi_output_risk_measures.MultiOutputExpectation.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/multi_output_risk_measures.html#MultiOutputExpectation.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.multi_output_risk_measures.MultiOutputExpectation.forward" title="Link to this definition"></a></dt>
<dd><p>Calculate the expectation of the given samples. Expectation is
calculated over each <cite>n_w</cite> samples in the q-batch dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples</strong> (<em>Tensor</em>) – A <cite>sample_shape x batch_shape x (q * n_w) x m</cite>-dim tensor of
posterior samples. The q-batches should be ordered so that each
<cite>n_w</cite> block of samples correspond to the same input.</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x q x d</cite>-dim tensor of inputs. Ignored.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>sample_shape x batch_shape x q x m’</cite>-dim tensor of expectation samples.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.multi_output_risk_measures.IndependentCVaR">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.multi_objective.multi_output_risk_measures.</span></span><span class="sig-name descname"><span class="pre">IndependentCVaR</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_w</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">preprocessing_function</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/multi_output_risk_measures.html#IndependentCVaR"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.multi_output_risk_measures.IndependentCVaR" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.risk_measures.CVaR" title="botorch.acquisition.risk_measures.CVaR"><code class="xref py py-class docutils literal notranslate"><span class="pre">CVaR</span></code></a>, <a class="reference internal" href="#botorch.acquisition.multi_objective.multi_output_risk_measures.MultiOutputRiskMeasureMCObjective" title="botorch.acquisition.multi_objective.multi_output_risk_measures.MultiOutputRiskMeasureMCObjective"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiOutputRiskMeasureMCObjective</span></code></a></p>
<p>The multi-output Conditional Value-at-Risk risk measure that operates on
each output dimension independently. Since this does not consider the joint
distribution of the outputs (i.e., that the outputs were evaluated on same
perturbed input and are not independent), the risk estimates provided by
<cite>IndependentCVaR</cite> in general are more optimistic than the definition of CVaR
would suggest.</p>
<p>The Conditional Value-at-Risk measures the expectation of the worst outcomes
(small rewards or large losses) with a total probability of <cite>1 - alpha</cite>. It
is commonly defined as the conditional expectation of the reward function,
with the condition that the reward is smaller than the corresponding
Value-at-Risk (also defined below).</p>
<p>NOTE: Due to the use of a discrete <cite>w_set</cite> of samples, the VaR and CVaR
calculated here are (possibly biased) Monte-Carlo approximations of the
true risk measures.</p>
<p>Transform the posterior samples to samples of a risk measure.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>alpha</strong> (<em>float</em>) – The risk level, float in <cite>(0.0, 1.0]</cite>.</p></li>
<li><p><strong>n_w</strong> (<em>int</em>) – The size of the <cite>w_set</cite> to calculate the risk measure over.</p></li>
<li><p><strong>preprocessing_function</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – A preprocessing function to apply to the samples
before computing the risk measure. This can be used to scalarize
multi-output samples before calculating the risk measure.
For constrained optimization, this should also apply
feasibility-weighting to samples. Given a <cite>batch x m</cite>-dim
tensor of samples, this should return a <cite>batch</cite>-dim tensor.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.multi_output_risk_measures.IndependentCVaR.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/multi_output_risk_measures.html#IndependentCVaR.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.multi_output_risk_measures.IndependentCVaR.forward" title="Link to this definition"></a></dt>
<dd><p>Calculate the CVaR corresponding to the given samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples</strong> (<em>Tensor</em>) – A <cite>sample_shape x batch_shape x (q * n_w) x m</cite>-dim tensor of
posterior samples. The q-batches should be ordered so that each
<cite>n_w</cite> block of samples correspond to the same input.</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x q x d</cite>-dim tensor of inputs. Ignored.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>sample_shape x batch_shape x q x m’</cite>-dim tensor of CVaR samples.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.multi_output_risk_measures.IndependentVaR">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.multi_objective.multi_output_risk_measures.</span></span><span class="sig-name descname"><span class="pre">IndependentVaR</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_w</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">preprocessing_function</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/multi_output_risk_measures.html#IndependentVaR"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.multi_output_risk_measures.IndependentVaR" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.multi_objective.multi_output_risk_measures.IndependentCVaR" title="botorch.acquisition.multi_objective.multi_output_risk_measures.IndependentCVaR"><code class="xref py py-class docutils literal notranslate"><span class="pre">IndependentCVaR</span></code></a></p>
<p>The multi-output Value-at-Risk risk measure that operates on each output
dimension independently. For the same reasons as <cite>IndependentCVaR</cite>, the risk
estimates provided by this are in general more optimistic than the definition
of VaR would suggest.</p>
<p>Value-at-Risk measures the smallest possible reward (or largest possible loss)
after excluding the worst outcomes with a total probability of <cite>1 - alpha</cite>. It
is commonly used in financial risk management, and it corresponds to the
<cite>1 - alpha</cite> quantile of a given random variable.</p>
<p>Transform the posterior samples to samples of a risk measure.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>alpha</strong> (<em>float</em>) – The risk level, float in <cite>(0.0, 1.0]</cite>.</p></li>
<li><p><strong>n_w</strong> (<em>int</em>) – The size of the <cite>w_set</cite> to calculate the risk measure over.</p></li>
<li><p><strong>preprocessing_function</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – A preprocessing function to apply to the samples
before computing the risk measure. This can be used to scalarize
multi-output samples before calculating the risk measure.
For constrained optimization, this should also apply
feasibility-weighting to samples. Given a <cite>batch x m</cite>-dim
tensor of samples, this should return a <cite>batch</cite>-dim tensor.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.multi_output_risk_measures.IndependentVaR.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/multi_output_risk_measures.html#IndependentVaR.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.multi_output_risk_measures.IndependentVaR.forward" title="Link to this definition"></a></dt>
<dd><p>Calculate the VaR corresponding to the given samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples</strong> (<em>Tensor</em>) – A <cite>sample_shape x batch_shape x (q * n_w) x m</cite>-dim tensor of
posterior samples. The q-batches should be ordered so that each
<cite>n_w</cite> block of samples correspond to the same input.</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x q x d</cite>-dim tensor of inputs. Ignored.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>sample_shape x batch_shape x q x m’</cite>-dim tensor of VaR samples.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.multi_output_risk_measures.MultiOutputWorstCase">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.multi_objective.multi_output_risk_measures.</span></span><span class="sig-name descname"><span class="pre">MultiOutputWorstCase</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_w</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">preprocessing_function</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/multi_output_risk_measures.html#MultiOutputWorstCase"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.multi_output_risk_measures.MultiOutputWorstCase" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.multi_objective.multi_output_risk_measures.MultiOutputRiskMeasureMCObjective" title="botorch.acquisition.multi_objective.multi_output_risk_measures.MultiOutputRiskMeasureMCObjective"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiOutputRiskMeasureMCObjective</span></code></a></p>
<p>The multi-output worst-case risk measure.</p>
<p>Transform the posterior samples to samples of a risk measure.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_w</strong> (<em>int</em>) – The size of the <cite>w_set</cite> to calculate the risk measure over.</p></li>
<li><p><strong>preprocessing_function</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – A preprocessing function to apply to the
samples before computing the risk measure. This can be used to
remove non-objective outcomes or to align all outcomes for
maximization. For constrained optimization, this should also
apply feasibility-weighting to samples. Given a <cite>batch x m</cite>-dim
tensor of samples, this should return a <cite>batch x m’</cite>-dim tensor.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.multi_output_risk_measures.MultiOutputWorstCase.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/multi_output_risk_measures.html#MultiOutputWorstCase.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.multi_output_risk_measures.MultiOutputWorstCase.forward" title="Link to this definition"></a></dt>
<dd><p>Calculate the worst-case measure corresponding to the given samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples</strong> (<em>Tensor</em>) – A <cite>sample_shape x batch_shape x (q * n_w) x m</cite>-dim tensor of
posterior samples. The q-batches should be ordered so that each
<cite>n_w</cite> block of samples correspond to the same input.</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x q x d</cite>-dim tensor of inputs. Ignored.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>sample_shape x batch_shape x q x m’</cite>-dim tensor of worst-case samples.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.multi_output_risk_measures.MVaR">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.multi_objective.multi_output_risk_measures.</span></span><span class="sig-name descname"><span class="pre">MVaR</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_w</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">expectation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">preprocessing_function</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="keyword-only-separator o"><abbr title="Keyword-only parameters separator (PEP 3102)"><span class="pre">*</span></abbr></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_to_n_w</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filter_dominated</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_counting</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/multi_output_risk_measures.html#MVaR"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.multi_output_risk_measures.MVaR" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.multi_objective.multi_output_risk_measures.MultiOutputRiskMeasureMCObjective" title="botorch.acquisition.multi_objective.multi_output_risk_measures.MultiOutputRiskMeasureMCObjective"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiOutputRiskMeasureMCObjective</span></code></a></p>
<p>The multivariate Value-at-Risk as introduced in <a class="reference internal" href="#prekopa2012mvar" id="id65"><span>[Prekopa2012MVaR]</span></a>.</p>
<p>MVaR is defined as the non-dominated set of points in the extended domain
of the random variable that have multivariate CDF greater than or equal to
<cite>alpha</cite>. Note that MVaR is set valued and the size of the set depends on the
particular realizations of the random variable. <a class="reference internal" href="#cousin2013mvar" id="id66"><span>[Cousin2013MVaR]</span></a> instead
propose to use the expectation of the set-valued MVaR as the multivariate
VaR. We support this alternative with an <cite>expectation</cite> flag.</p>
<p>This supports approximate gradients as discussed in <a class="reference internal" href="#daulton2022mars" id="id67"><span>[Daulton2022MARS]</span></a>.</p>
<p>The multivariate Value-at-Risk.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_w</strong> (<em>int</em>) – The size of the <cite>w_set</cite> to calculate the risk measure over.</p></li>
<li><p><strong>alpha</strong> (<em>float</em>) – The risk level of MVaR, float in <cite>(0.0, 1.0]</cite>. Each MVaR value
dominates <cite>alpha</cite> fraction of all observations.</p></li>
<li><p><strong>expectation</strong> (<em>bool</em>) – If True, returns the expectation of the MVaR set as is
done in <a class="reference internal" href="#cousin2013mvar" id="id68"><span>[Cousin2013MVaR]</span></a>. Otherwise, it returns the union of all
values in the MVaR set. Default: False.</p></li>
<li><p><strong>preprocessing_function</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – A preprocessing function to apply to the
samples before computing the risk measure. This can be used to
remove non-objective outcomes or to align all outcomes for
maximization. For constrained optimization, this should also
apply feasibility-weighting to samples. Given a <cite>batch x m</cite>-dim
tensor of samples, this should return a <cite>batch x m’</cite>-dim tensor.</p></li>
<li><p><strong>pad_to_n_w</strong> (<em>bool</em>) – If True, instead of padding up to <cite>k’</cite>, which is the size of
the largest MVaR set across all batches, we pad the MVaR set up to
<cite>n_w</cite>. This produces a return tensor of known size, however, it may
in general be much larger than the alternative. See <cite>forward</cite> for
more details on the return shape.
NOTE: this is only relevant if <cite>expectation=False</cite>.</p></li>
<li><p><strong>filter_dominated</strong> (<em>bool</em>) – If True, returns the non-dominated subset of
alpha level points (this is MVaR as defined by <a class="reference internal" href="#prekopa2012mvar" id="id69"><span>[Prekopa2012MVaR]</span></a>).
Disabling this will make it faster, and may be preferable if
the dominated points will be filtered out later, e.g., while
calculating the hypervolume. Disabling this is not recommended
if <cite>expectation=True</cite>.</p></li>
<li><p><strong>use_counting</strong> (<em>bool</em>) – If True, uses <cite>get_mvar_set_via_counting</cite> for finding the
MVaR set. This is method is less memory intensive than the vectorized
implementation, which is beneficial when <cite>n_w</cite> is quite large.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.multi_output_risk_measures.MVaR.get_mvar_set_via_counting">
<span class="sig-name descname"><span class="pre">get_mvar_set_via_counting</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/multi_output_risk_measures.html#MVaR.get_mvar_set_via_counting"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.multi_output_risk_measures.MVaR.get_mvar_set_via_counting" title="Link to this definition"></a></dt>
<dd><p>Find MVaR set based on the definition in <a class="reference internal" href="#prekopa2012mvar" id="id70"><span>[Prekopa2012MVaR]</span></a>.</p>
<p>This first calculates the CDF for each point on the extended domain of the
random variable (the grid defined by the given samples), then takes the
values with CDF equal to (rounded if necessary) <cite>alpha</cite>. The non-dominated
subset of these form the MVaR set.</p>
<p>This implementation processes each batch of <cite>Y</cite> in a for loop using a counting
based implementation. It requires less memory than the vectorized implementation
and should be used with large (&gt;128) <cite>n_w</cite> values.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>Y</strong> (<em>Tensor</em>) – A <cite>batch x n_w x m</cite>-dim tensor of outcomes.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch</cite> length list of <cite>k x m</cite>-dim tensor of MVaR values, where <cite>k</cite>
depends on the corresponding batch inputs. Note that MVaR values in general
are not in-sample points.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list[<em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.multi_output_risk_measures.MVaR.get_mvar_set_vectorized">
<span class="sig-name descname"><span class="pre">get_mvar_set_vectorized</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/multi_output_risk_measures.html#MVaR.get_mvar_set_vectorized"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.multi_output_risk_measures.MVaR.get_mvar_set_vectorized" title="Link to this definition"></a></dt>
<dd><p>Find MVaR set based on the definition in <a class="reference internal" href="#prekopa2012mvar" id="id71"><span>[Prekopa2012MVaR]</span></a>.</p>
<p>This first calculates the CDF for each point on the extended domain of the
random variable (the grid defined by the given samples), then takes the
values with CDF equal to (rounded if necessary) <cite>alpha</cite>. The non-dominated
subset of these form the MVaR set.</p>
<p>This implementation uses computes the CDF of each point using highly vectorized
operations. As such, it may use large amounts of memory, particularly when the
batch size and/or <cite>n_w</cite> are large. It is typically faster than the alternative
implementation when computing MVaR of a large batch of points with small to
moderate (&lt;128 for m=2, &lt;64 for m=3) <cite>n_w</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>Y</strong> (<em>Tensor</em>) – A <cite>batch x n_w x m</cite>-dim tensor of observations.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch</cite> length list of <cite>k x m</cite>-dim tensor of MVaR values, where <cite>k</cite>
depends on the corresponding batch inputs. Note that MVaR values in general
are not in-sample points.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list[<em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.multi_output_risk_measures.MVaR.make_differentiable">
<span class="sig-name descname"><span class="pre">make_differentiable</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prepared_samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mvars</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/multi_output_risk_measures.html#MVaR.make_differentiable"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.multi_output_risk_measures.MVaR.make_differentiable" title="Link to this definition"></a></dt>
<dd><p>An experimental approach for obtaining the gradient of the MVaR via
component-wise mapping to original samples. See <a class="reference internal" href="#daulton2022mars" id="id72"><span>[Daulton2022MARS]</span></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prepared_samples</strong> (<em>Tensor</em>) – A <cite>(sample_shape * batch_shape * q) x n_w x m</cite>-dim tensor
of posterior samples. The q-batches should be ordered so that each
<cite>n_w</cite> block of samples correspond to the same input.</p></li>
<li><p><strong>mvars</strong> (<em>Tensor</em>) – A <cite>(sample_shape * batch_shape * q) x k x m</cite>-dim tensor
of padded MVaR values.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The same <cite>mvars</cite> with entries mapped to inputs to produce gradients.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.multi_output_risk_measures.MVaR.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/multi_output_risk_measures.html#MVaR.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.multi_output_risk_measures.MVaR.forward" title="Link to this definition"></a></dt>
<dd><p>Calculate the MVaR corresponding to the given samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples</strong> (<em>Tensor</em>) – A <cite>sample_shape x batch_shape x (q * n_w) x m</cite>-dim tensor of
posterior samples. The q-batches should be ordered so that each
<cite>n_w</cite> block of samples correspond to the same input.</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x q x d</cite>-dim tensor of inputs. Ignored.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>sample_shape x batch_shape x q x m’</cite>-dim tensor of MVaR values,
if <cite>self.expectation=True</cite>.
Otherwise, this returns a <cite>sample_shape x batch_shape x (q * k’) x m’</cite>-dim
tensor, where <cite>k’</cite> is the maximum <cite>k</cite> across all batches that is returned
by <cite>get_mvar_set_…</cite>. Each <cite>(q * k’) x m’</cite> corresponds to the <cite>k</cite> MVaR
values for each <cite>q</cite> batch of <cite>n_w</cite> inputs, padded up to <cite>k’</cite> by repeating
the last element. If <cite>self.pad_to_n_w</cite>, we set <cite>k’ = self.n_w</cite>, producing
a deterministic return shape.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.multi_output_risk_measures.MARS">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.multi_objective.multi_output_risk_measures.</span></span><span class="sig-name descname"><span class="pre">MARS</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_w</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">chebyshev_weights</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">baseline_Y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ref_point</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">preprocessing_function</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/multi_output_risk_measures.html#MARS"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.multi_output_risk_measures.MARS" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.risk_measures.VaR" title="botorch.acquisition.risk_measures.VaR"><code class="xref py py-class docutils literal notranslate"><span class="pre">VaR</span></code></a>, <a class="reference internal" href="#botorch.acquisition.multi_objective.multi_output_risk_measures.MultiOutputRiskMeasureMCObjective" title="botorch.acquisition.multi_objective.multi_output_risk_measures.MultiOutputRiskMeasureMCObjective"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiOutputRiskMeasureMCObjective</span></code></a></p>
<p>MVaR Approximation based on Random Scalarizations as introduced
in <a class="reference internal" href="#daulton2022mars" id="id73"><span>[Daulton2022MARS]</span></a>.</p>
<p>This approximates MVaR via VaR of Chebyshev scalarizations, where each
scalarization corresponds to a point in the MVaR set. As implemented,
this uses one set of scalarization weights to approximate a single MVaR value.
Note that due to the normalization within the Chebyshev scalarization,
the output of this risk measure may not be on the same scale as its inputs.</p>
<p>Transform the posterior samples to samples of a risk measure.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>alpha</strong> (<em>float</em>) – The risk level, float in <cite>(0.0, 1.0]</cite>.</p></li>
<li><p><strong>n_w</strong> (<em>int</em>) – The size of the perturbation set to calculate the risk measure over.</p></li>
<li><p><strong>chebyshev_weights</strong> (<em>Tensor</em><em> | </em><em>list</em><em>[</em><em>float</em><em>]</em>) – The weights to use in the Chebyshev scalarization.
The Chebyshev scalarization is applied before computing VaR.
The weights must be non-negative. See <cite>preprocessing_function</cite> to
support minimization objectives.</p></li>
<li><p><strong>baseline_Y</strong> (<em>Tensor</em><em> | </em><em>None</em>) – An <cite>n’ x d</cite>-dim tensor of baseline outcomes to use in
determining the normalization bounds for Chebyshev scalarization.
It is recommended to set this via <cite>set_baseline_Y</cite> helper.</p></li>
<li><p><strong>ref_point</strong> (<em>Tensor</em><em> | </em><em>list</em><em>[</em><em>float</em><em>] </em><em>| </em><em>None</em>) – An optional MVaR reference point to use in determining
the normalization bounds for Chebyshev scalarization.</p></li>
<li><p><strong>preprocessing_function</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – A preprocessing function to apply to the
samples before computing the risk measure. This can be used to
remove non-objective outcomes or to align all outcomes for
maximization. For constrained optimization, this should also
apply feasibility-weighting to samples.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.multi_output_risk_measures.MARS.set_baseline_Y">
<span class="sig-name descname"><span class="pre">set_baseline_Y</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_baseline</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/multi_output_risk_measures.html#MARS.set_baseline_Y"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.multi_output_risk_measures.MARS.set_baseline_Y" title="Link to this definition"></a></dt>
<dd><p>Set the <cite>baseline_Y</cite> based on the MVaR predictions of the <cite>model</cite>
for <cite>X_baseline</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a><em> | </em><em>None</em>) – The model being used for MARS optimization. Must have a compatible
<cite>InputPerturbation</cite> transform attached. Ignored if <cite>Y_samples</cite> is given.</p></li>
<li><p><strong>X_baseline</strong> (<em>Tensor</em><em> | </em><em>None</em>) – An <cite>n x d</cite>-dim tensor of previously evaluated points.
Ignored if <cite>Y_samples</cite> is given.</p></li>
<li><p><strong>Y_samples</strong> (<em>Tensor</em><em> | </em><em>None</em>) – An optional <cite>(n * n_w) x d</cite>-dim tensor of predictions. If given,
instead of sampling from the model, these are used.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.multi_output_risk_measures.MARS.chebyshev_weights">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">chebyshev_weights</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tensor</span></em><a class="headerlink" href="#botorch.acquisition.multi_objective.multi_output_risk_measures.MARS.chebyshev_weights" title="Link to this definition"></a></dt>
<dd><p>The weights used in Chebyshev scalarization.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.multi_output_risk_measures.MARS.baseline_Y">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">baseline_Y</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#botorch.acquisition.multi_objective.multi_output_risk_measures.MARS.baseline_Y" title="Link to this definition"></a></dt>
<dd><p>Baseline outcomes used in determining the normalization bounds.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.multi_output_risk_measures.MARS.chebyshev_objective">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">chebyshev_objective</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#botorch.acquisition.multi_objective.multi_output_risk_measures.MARS.chebyshev_objective" title="Link to this definition"></a></dt>
<dd><p>The objective for applying the Chebyshev scalarization.</p>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="utilities">
<h2>Utilities<a class="headerlink" href="#utilities" title="Link to this heading"></a></h2>
<section id="module-botorch.acquisition.fixed_feature">
<span id="fixed-feature-acquisition-function"></span><h3>Fixed Feature Acquisition Function<a class="headerlink" href="#module-botorch.acquisition.fixed_feature" title="Link to this heading"></a></h3>
<p>A wrapper around AcquisitionFunctions to fix certain features for optimization.
This is useful e.g. for performing contextual optimization.</p>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.fixed_feature.get_dtype_of_sequence">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.fixed_feature.</span></span><span class="sig-name descname"><span class="pre">get_dtype_of_sequence</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/fixed_feature.html#get_dtype_of_sequence"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.fixed_feature.get_dtype_of_sequence" title="Link to this definition"></a></dt>
<dd><p>Return torch.float32 if everything is single-precision and torch.float64
otherwise.</p>
<p>Numbers (non-tensors) are double-precision.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>values</strong> (<em>Sequence</em><em>[</em><em>Tensor</em><em> | </em><em>float</em><em>]</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>dtype</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.fixed_feature.get_device_of_sequence">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.fixed_feature.</span></span><span class="sig-name descname"><span class="pre">get_device_of_sequence</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/fixed_feature.html#get_device_of_sequence"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.fixed_feature.get_device_of_sequence" title="Link to this definition"></a></dt>
<dd><p>CPU if everything is on the CPU; Cuda otherwise.</p>
<p>Numbers (non-tensors) are considered to be on the CPU.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>values</strong> (<em>Sequence</em><em>[</em><em>Tensor</em><em> | </em><em>float</em><em>]</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>dtype</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.fixed_feature.FixedFeatureAcquisitionFunction">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.fixed_feature.</span></span><span class="sig-name descname"><span class="pre">FixedFeatureAcquisitionFunction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">columns</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/fixed_feature.html#FixedFeatureAcquisitionFunction"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.fixed_feature.FixedFeatureAcquisitionFunction" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">AcquisitionFunction</span></code></a></p>
<p>A wrapper around AcquisitionFunctions to fix a subset of features.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>  <span class="c1"># d = 5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qEI</span> <span class="o">=</span> <span class="n">qExpectedImprovement</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">best_f</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">values</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">columns</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qEI_FF</span> <span class="o">=</span> <span class="n">FixedFeatureAcquisitionFunction</span><span class="p">(</span><span class="n">qEI</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">columns</span><span class="p">,</span> <span class="n">values</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qei</span> <span class="o">=</span> <span class="n">qEI_FF</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>  <span class="c1"># d&#39; = 3</span>
</pre></div>
</div>
<p>Derived Acquisition Function by fixing a subset of input features.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<a class="reference internal" href="#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><em>AcquisitionFunction</em></a>) – The base acquisition function, operating on input
tensors <cite>X_full</cite> of feature dimension <cite>d</cite>.</p></li>
<li><p><strong>d</strong> (<em>int</em>) – The feature dimension expected by <cite>acq_function</cite>.</p></li>
<li><p><strong>columns</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – <cite>d_f &lt; d</cite> indices of columns in <cite>X_full</cite> that are to be
fixed to the provided values.</p></li>
<li><p><strong>values</strong> (<em>Tensor</em><em> | </em><em>Sequence</em><em>[</em><em>Tensor</em><em> | </em><em>float</em><em>]</em>) – The values to which to fix the columns in <cite>columns</cite>. Either
a full <cite>batch_shape x q x d_f</cite> tensor of values (if values are
different for each of the <cite>q</cite> input points), or an array-like of
values that is broadcastable to the input across <cite>t</cite>-batch and
<cite>q</cite>-batch dimensions, e.g. a list of length <cite>d_f</cite> if values
are the same across all <cite>t</cite> and <cite>q</cite>-batch dimensions, or a
combination of <cite>Tensor`s and numbers which can be broadcasted
to form a tensor with trailing dimension size of `d_f</cite>.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.fixed_feature.FixedFeatureAcquisitionFunction.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/fixed_feature.html#FixedFeatureAcquisitionFunction.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.fixed_feature.FixedFeatureAcquisitionFunction.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate base acquisition function under the fixed features.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – Input tensor of feature dimension <cite>d’ &lt; d</cite> such that <cite>d’ + d_f = d</cite>.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Base acquisition function evaluated on tensor <cite>X_full</cite> constructed
by adding <cite>values</cite> in the appropriate places (see
<cite>_construct_X_full</cite>).</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.acquisition.fixed_feature.FixedFeatureAcquisitionFunction.X_pending">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">X_pending</span></span><a class="headerlink" href="#botorch.acquisition.fixed_feature.FixedFeatureAcquisitionFunction.X_pending" title="Link to this definition"></a></dt>
<dd><p>Return the <cite>X_pending</cite> of the base acquisition function.</p>
</dd></dl>

</dd></dl>

</section>
<section id="module-botorch.acquisition.input_constructors">
<span id="constructors-for-acquisition-function-input-arguments"></span><h3>Constructors for Acquisition Function Input Arguments<a class="headerlink" href="#module-botorch.acquisition.input_constructors" title="Link to this heading"></a></h3>
<p>A registry of helpers for generating inputs to acquisition function
constructors programmatically from a consistent input format.</p>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.input_constructors.get_acqf_input_constructor">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.input_constructors.</span></span><span class="sig-name descname"><span class="pre">get_acqf_input_constructor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acqf_cls</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/input_constructors.html#get_acqf_input_constructor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.input_constructors.get_acqf_input_constructor" title="Link to this definition"></a></dt>
<dd><p>Get acquisition function input constructor from registry.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>acqf_cls</strong> (<em>type</em><em>[</em><a class="reference internal" href="#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><em>AcquisitionFunction</em></a><em>]</em>) – The AcquisitionFunction class (not instance) for which
to retrieve the input constructor.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The input constructor associated with <cite>acqf_cls</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Callable</em>[[…], dict[str, <em>Any</em>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.input_constructors.allow_only_specific_variable_kwargs">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.input_constructors.</span></span><span class="sig-name descname"><span class="pre">allow_only_specific_variable_kwargs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">f</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/input_constructors.html#allow_only_specific_variable_kwargs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.input_constructors.allow_only_specific_variable_kwargs" title="Link to this definition"></a></dt>
<dd><p>Decorator for allowing a function to accept keyword arguments that are not
explicitly listed in the function signature, but only specific ones.</p>
<p>This decorator is applied in <cite>acqf_input_constructor</cite> so that all constructors
obtained with <cite>acqf_input_constructor</cite> allow keyword
arguments such as <cite>training_data</cite> and <cite>objective</cite>, even if they do not appear
in the signature of <cite>f</cite>. Any other keyword arguments will raise an error.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>f</strong> (<em>Callable</em><em>[</em><em>[</em><em>...</em><em>]</em><em>, </em><em>T</em><em>]</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Callable</em>[[…], <em>T</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.input_constructors.acqf_input_constructor">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.input_constructors.</span></span><span class="sig-name descname"><span class="pre">acqf_input_constructor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">acqf_cls</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/input_constructors.html#acqf_input_constructor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.input_constructors.acqf_input_constructor" title="Link to this definition"></a></dt>
<dd><p>Decorator for registering acquisition function input constructors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>acqf_cls</strong> (<em>type</em><em>[</em><a class="reference internal" href="#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><em>AcquisitionFunction</em></a><em>]</em>) – The AcquisitionFunction classes (not instances) for which
to register the input constructor.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Callable</em>[[…], <a class="reference internal" href="#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><em>AcquisitionFunction</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.input_constructors.construct_inputs_posterior_mean">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.input_constructors.</span></span><span class="sig-name descname"><span class="pre">construct_inputs_posterior_mean</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/input_constructors.html#construct_inputs_posterior_mean"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.input_constructors.construct_inputs_posterior_mean" title="Link to this definition"></a></dt>
<dd><p>Construct kwargs for PosteriorMean acquisition function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – The model to be used in the acquisition function.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – The posterior transform to be used in the
acquisition function.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dict mapping kwarg names of the constructor to values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict[str, <a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a> | <a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a> | None]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.input_constructors.construct_inputs_best_f">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.input_constructors.</span></span><span class="sig-name descname"><span class="pre">construct_inputs_best_f</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training_data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">best_f</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/input_constructors.html#construct_inputs_best_f"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.input_constructors.construct_inputs_best_f" title="Link to this definition"></a></dt>
<dd><p>Construct kwargs for the acquisition functions requiring <cite>best_f</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – The model to be used in the acquisition function.</p></li>
<li><p><strong>training_data</strong> (<a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em> | </em><em>dict</em><em>[</em><em>Hashable</em><em>, </em><a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em>]</em>) – Dataset(s) used to train the model.
Used to determine default value for <cite>best_f</cite>.</p></li>
<li><p><strong>best_f</strong> (<em>float</em><em> | </em><em>Tensor</em><em> | </em><em>None</em>) – Threshold above (or below) which improvement is defined.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – The posterior transform to be used in the
acquisition function.</p></li>
<li><p><strong>maximize</strong> (<em>bool</em>) – If True, consider the problem a maximization problem.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dict mapping kwarg names of the constructor to values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict[str, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.input_constructors.construct_inputs_ucb">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.input_constructors.</span></span><span class="sig-name descname"><span class="pre">construct_inputs_ucb</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/input_constructors.html#construct_inputs_ucb"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.input_constructors.construct_inputs_ucb" title="Link to this definition"></a></dt>
<dd><p>Construct kwargs for <cite>UpperConfidenceBound</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – The model to be used in the acquisition function.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – The posterior transform to be used in the
acquisition function.</p></li>
<li><p><strong>beta</strong> (<em>float</em><em> | </em><em>Tensor</em>) – Either a scalar or a one-dim tensor with <cite>b</cite> elements (batch mode)
representing the trade-off parameter between mean and covariance</p></li>
<li><p><strong>maximize</strong> (<em>bool</em>) – If True, consider the problem a maximization problem.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dict mapping kwarg names of the constructor to values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict[str, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.input_constructors.construct_inputs_noisy_ei">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.input_constructors.</span></span><span class="sig-name descname"><span class="pre">construct_inputs_noisy_ei</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training_data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_fantasies</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/input_constructors.html#construct_inputs_noisy_ei"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.input_constructors.construct_inputs_noisy_ei" title="Link to this definition"></a></dt>
<dd><p>Construct kwargs for <cite>NoisyExpectedImprovement</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – The model to be used in the acquisition function.</p></li>
<li><p><strong>training_data</strong> (<a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em> | </em><em>dict</em><em>[</em><em>Hashable</em><em>, </em><a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em>]</em>) – Dataset(s) used to train the model.</p></li>
<li><p><strong>num_fantasies</strong> (<em>int</em>) – The number of fantasies to generate. The higher this
number the more accurate the model (at the expense of model
complexity and performance).</p></li>
<li><p><strong>maximize</strong> (<em>bool</em>) – If True, consider the problem a maximization problem.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dict mapping kwarg names of the constructor to values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict[str, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.input_constructors.construct_inputs_qSimpleRegret">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.input_constructors.</span></span><span class="sig-name descname"><span class="pre">construct_inputs_qSimpleRegret</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_baseline</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/input_constructors.html#construct_inputs_qSimpleRegret"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.input_constructors.construct_inputs_qSimpleRegret" title="Link to this definition"></a></dt>
<dd><p>Construct kwargs for qSimpleRegret.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – The model to be used in the acquisition function.</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><em>MCAcquisitionObjective</em></a><em> | </em><em>None</em>) – The objective to be used in the acquisition function.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – The posterior transform to be used in the
acquisition function.</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape, m x d</cite>-dim Tensor of <cite>m</cite> design points
that have points that have been submitted for function evaluation
but have not yet been evaluated.</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – The sampler used to draw base samples. If omitted, uses
the acquisition functions’s default sampler.</p></li>
<li><p><strong>constraints</strong> (<em>list</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of constraint callables which map a Tensor of posterior
samples of dimension <cite>sample_shape x batch-shape x q x m</cite>-dim to a
<cite>sample_shape x batch-shape x q</cite>-dim Tensor. The associated constraints
are considered satisfied if the output is less than zero.</p></li>
<li><p><strong>X_baseline</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x r x d</cite>-dim Tensor of <cite>r</cite> design points
that have already been observed. These points are considered as
the potential best design point. If omitted, checks that all
training_data have the same input features and take the first <cite>X</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dict mapping kwarg names of the constructor to values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict[str, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.input_constructors.construct_inputs_qEI">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.input_constructors.</span></span><span class="sig-name descname"><span class="pre">construct_inputs_qEI</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training_data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">best_f</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/input_constructors.html#construct_inputs_qEI"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.input_constructors.construct_inputs_qEI" title="Link to this definition"></a></dt>
<dd><p>Construct kwargs for the <cite>qExpectedImprovement</cite> constructor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – The model to be used in the acquisition function.</p></li>
<li><p><strong>training_data</strong> (<a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em> | </em><em>dict</em><em>[</em><em>Hashable</em><em>, </em><a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em>]</em>) – Dataset(s) used to train the model.</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><em>MCAcquisitionObjective</em></a><em> | </em><em>None</em>) – The objective to be used in the acquisition function.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – The posterior transform to be used in the
acquisition function.</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>m x d</cite>-dim Tensor of <cite>m</cite> design points that have been
submitted for function evaluation but have not yet been evaluated.
Concatenated into X upon forward call.</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – The sampler used to draw base samples. If omitted, uses
the acquisition functions’s default sampler.</p></li>
<li><p><strong>best_f</strong> (<em>float</em><em> | </em><em>Tensor</em><em> | </em><em>None</em>) – Threshold above (or below) which improvement is defined.</p></li>
<li><p><strong>constraints</strong> (<em>list</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of constraint callables which map a Tensor of posterior
samples of dimension <cite>sample_shape x batch-shape x q x m</cite>-dim to a
<cite>sample_shape x batch-shape x q</cite>-dim Tensor. The associated constraints
are considered satisfied if the output is less than zero.</p></li>
<li><p><strong>eta</strong> (<em>Tensor</em><em> | </em><em>float</em>) – Temperature parameter(s) governing the smoothness of the sigmoid
approximation to the constraint indicators. For more details, on this
parameter, see the docs of <cite>compute_smoothed_feasibility_indicator</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dict mapping kwarg names of the constructor to values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict[str, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.input_constructors.construct_inputs_qLogEI">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.input_constructors.</span></span><span class="sig-name descname"><span class="pre">construct_inputs_qLogEI</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training_data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">best_f</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fat</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau_max</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau_relu</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-06</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/input_constructors.html#construct_inputs_qLogEI"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.input_constructors.construct_inputs_qLogEI" title="Link to this definition"></a></dt>
<dd><p>Construct kwargs for the <cite>qExpectedImprovement</cite> constructor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – The model to be used in the acquisition function.</p></li>
<li><p><strong>training_data</strong> (<a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em> | </em><em>dict</em><em>[</em><em>Hashable</em><em>, </em><a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em>]</em>) – Dataset(s) used to train the model.</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><em>MCAcquisitionObjective</em></a><em> | </em><em>None</em>) – The objective to be used in the acquisition function.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – The posterior transform to be used in the
acquisition function.</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>m x d</cite>-dim Tensor of <cite>m</cite> design points that have been
submitted for function evaluation but have not yet been evaluated.
Concatenated into X upon forward call.</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – The sampler used to draw base samples. If omitted, uses
the acquisition functions’s default sampler.</p></li>
<li><p><strong>best_f</strong> (<em>float</em><em> | </em><em>Tensor</em><em> | </em><em>None</em>) – Threshold above (or below) which improvement is defined.</p></li>
<li><p><strong>constraints</strong> (<em>list</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of constraint callables which map a Tensor of posterior
samples of dimension <cite>sample_shape x batch-shape x q x m</cite>-dim to a
<cite>sample_shape x batch-shape x q</cite>-dim Tensor. The associated constraints
are considered satisfied if the output is less than zero.</p></li>
<li><p><strong>eta</strong> (<em>Tensor</em><em> | </em><em>float</em>) – Temperature parameter(s) governing the smoothness of the sigmoid
approximation to the constraint indicators. For more details, on this
parameter, see the docs of <cite>compute_smoothed_feasibility_indicator</cite>.</p></li>
<li><p><strong>fat</strong> (<em>bool</em>) – Toggles the logarithmic / linear asymptotic behavior of the smooth
approximation to the ReLU.</p></li>
<li><p><strong>tau_max</strong> (<em>float</em>) – Temperature parameter controlling the sharpness of the smooth
approximations to max.</p></li>
<li><p><strong>tau_relu</strong> (<em>float</em>) – Temperature parameter controlling the sharpness of the smooth
approximations to ReLU.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dict mapping kwarg names of the constructor to values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict[str, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.input_constructors.construct_inputs_qNEI">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.input_constructors.</span></span><span class="sig-name descname"><span class="pre">construct_inputs_qNEI</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training_data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_baseline</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prune_baseline</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_root</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/input_constructors.html#construct_inputs_qNEI"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.input_constructors.construct_inputs_qNEI" title="Link to this definition"></a></dt>
<dd><p>Construct kwargs for the <cite>qNoisyExpectedImprovement</cite> constructor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – The model to be used in the acquisition function.</p></li>
<li><p><strong>training_data</strong> (<a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em> | </em><em>dict</em><em>[</em><em>Hashable</em><em>, </em><a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em>]</em>) – Dataset(s) used to train the model.</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><em>MCAcquisitionObjective</em></a><em> | </em><em>None</em>) – The objective to be used in the acquisition function.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – The posterior transform to be used in the
acquisition function.</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>m x d</cite>-dim Tensor of <cite>m</cite> design points that have been
submitted for function evaluation but have not yet been evaluated.
Concatenated into X upon forward call.</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – The sampler used to draw base samples. If omitted, uses
the acquisition functions’s default sampler.</p></li>
<li><p><strong>X_baseline</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x r x d</cite>-dim Tensor of <cite>r</cite> design points
that have already been observed. These points are considered as
the potential best design point. If omitted, checks that all
training_data have the same input features and take the first <cite>X</cite>.</p></li>
<li><p><strong>prune_baseline</strong> (<em>bool</em><em> | </em><em>None</em>) – If True, remove points in <cite>X_baseline</cite> that are
highly unlikely to be the best point. This can significantly
improve performance and is generally recommended.</p></li>
<li><p><strong>constraints</strong> (<em>list</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of constraint callables which map a Tensor of posterior
samples of dimension <cite>sample_shape x batch-shape x q x m</cite>-dim to a
<cite>sample_shape x batch-shape x q</cite>-dim Tensor. The associated constraints
are considered satisfied if the output is less than zero.</p></li>
<li><p><strong>eta</strong> (<em>Tensor</em><em> | </em><em>float</em>) – Temperature parameter(s) governing the smoothness of the sigmoid
approximation to the constraint indicators. For more details, on this
parameter, see the docs of <cite>compute_smoothed_feasibility_indicator</cite>.</p></li>
<li><p><strong>cache_root</strong> (<em>bool</em><em> | </em><em>None</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dict mapping kwarg names of the constructor to values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict[str, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.input_constructors.construct_inputs_qLogNEI">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.input_constructors.</span></span><span class="sig-name descname"><span class="pre">construct_inputs_qLogNEI</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training_data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_baseline</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prune_baseline</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_root</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fat</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau_max</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau_relu</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-06</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">incremental</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/input_constructors.html#construct_inputs_qLogNEI"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.input_constructors.construct_inputs_qLogNEI" title="Link to this definition"></a></dt>
<dd><p>Construct kwargs for the <cite>qLogNoisyExpectedImprovement</cite> constructor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – The model to be used in the acquisition function.</p></li>
<li><p><strong>training_data</strong> (<a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em> | </em><em>dict</em><em>[</em><em>Hashable</em><em>, </em><a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em>]</em>) – Dataset(s) used to train the model.</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><em>MCAcquisitionObjective</em></a><em> | </em><em>None</em>) – The objective to be used in the acquisition function.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – The posterior transform to be used in the
acquisition function.</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>m x d</cite>-dim Tensor of <cite>m</cite> design points that have been
submitted for function evaluation but have not yet been evaluated.
Concatenated into X upon forward call.</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – The sampler used to draw base samples. If omitted, uses
the acquisition functions’s default sampler.</p></li>
<li><p><strong>X_baseline</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x r x d</cite>-dim Tensor of <cite>r</cite> design points
that have already been observed. These points are considered as
the potential best design point. If omitted, checks that all
training_data have the same input features and take the first <cite>X</cite>.</p></li>
<li><p><strong>prune_baseline</strong> (<em>bool</em><em> | </em><em>None</em>) – If True, remove points in <cite>X_baseline</cite> that are
highly unlikely to be the best point. This can significantly
improve performance and is generally recommended.</p></li>
<li><p><strong>constraints</strong> (<em>list</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of constraint callables which map a Tensor of posterior
samples of dimension <cite>sample_shape x batch-shape x q x m</cite>-dim to a
<cite>sample_shape x batch-shape x q</cite>-dim Tensor. The associated constraints
are considered satisfied if the output is less than zero.</p></li>
<li><p><strong>eta</strong> (<em>Tensor</em><em> | </em><em>float</em>) – Temperature parameter(s) governing the smoothness of the sigmoid
approximation to the constraint indicators. For more details, on this
parameter, see the docs of <cite>compute_smoothed_feasibility_indicator</cite>.</p></li>
<li><p><strong>fat</strong> (<em>bool</em>) – Toggles the use of the fat-tailed non-linearities to smoothly approximate
the constraints indicator function.</p></li>
<li><p><strong>tau_max</strong> (<em>float</em>) – Temperature parameter controlling the sharpness of the smooth
approximations to max.</p></li>
<li><p><strong>tau_relu</strong> (<em>float</em>) – Temperature parameter controlling the sharpness of the smooth
approximations to ReLU.</p></li>
<li><p><strong>incremental</strong> (<em>bool</em>) – Whether to compute incremental EI over the pending points
or compute EI of the joint batch improvement (including pending
points).</p></li>
<li><p><strong>cache_root</strong> (<em>bool</em><em> | </em><em>None</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dict mapping kwarg names of the constructor to values.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.input_constructors.construct_inputs_qPI">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.input_constructors.</span></span><span class="sig-name descname"><span class="pre">construct_inputs_qPI</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training_data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">best_f</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/input_constructors.html#construct_inputs_qPI"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.input_constructors.construct_inputs_qPI" title="Link to this definition"></a></dt>
<dd><p>Construct kwargs for the <cite>qProbabilityOfImprovement</cite> constructor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – The model to be used in the acquisition function.</p></li>
<li><p><strong>training_data</strong> (<a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em> | </em><em>dict</em><em>[</em><em>Hashable</em><em>, </em><a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em>]</em>) – Dataset(s) used to train the model.</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><em>MCAcquisitionObjective</em></a><em> | </em><em>None</em>) – The objective to be used in the acquisition function.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – The posterior transform to be used in the
acquisition function.</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>m x d</cite>-dim Tensor of <cite>m</cite> design points that have been
submitted for function evaluation but have not yet been evaluated.
Concatenated into X upon forward call.</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – The sampler used to draw base samples. If omitted, uses
the acquisition functions’s default sampler.</p></li>
<li><p><strong>tau</strong> (<em>float</em>) – The temperature parameter used in the sigmoid approximation
of the step function. Smaller values yield more accurate
approximations of the function, but result in gradients
estimates with higher variance.</p></li>
<li><p><strong>best_f</strong> (<em>float</em><em> | </em><em>Tensor</em><em> | </em><em>None</em>) – The best objective value observed so far (assumed noiseless). Can
be a <cite>batch_shape</cite>-shaped tensor, which in case of a batched model
specifies potentially different values for each element of the batch.</p></li>
<li><p><strong>constraints</strong> (<em>list</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of constraint callables which map a Tensor of posterior
samples of dimension <cite>sample_shape x batch-shape x q x m</cite>-dim to a
<cite>sample_shape x batch-shape x q</cite>-dim Tensor. The associated constraints
are considered satisfied if the output is less than zero.</p></li>
<li><p><strong>eta</strong> (<em>Tensor</em><em> | </em><em>float</em>) – Temperature parameter(s) governing the smoothness of the sigmoid
approximation to the constraint indicators. For more details, on this
parameter, see the docs of <cite>compute_smoothed_feasibility_indicator</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dict mapping kwarg names of the constructor to values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict[str, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.input_constructors.construct_inputs_qUCB">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.input_constructors.</span></span><span class="sig-name descname"><span class="pre">construct_inputs_qUCB</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_baseline</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.2</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/input_constructors.html#construct_inputs_qUCB"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.input_constructors.construct_inputs_qUCB" title="Link to this definition"></a></dt>
<dd><p>Construct kwargs for the <cite>qUpperConfidenceBound</cite> constructor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – The model to be used in the acquisition function.</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><em>MCAcquisitionObjective</em></a><em> | </em><em>None</em>) – The objective to be used in the acquisition function.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – The posterior transform to be used in the
acquisition function.</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>m x d</cite>-dim Tensor of <cite>m</cite> design points that have been
submitted for function evaluation but have not yet been evaluated.
Concatenated into X upon forward call.</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – The sampler used to draw base samples. If omitted, uses
the acquisition functions’s default sampler.</p></li>
<li><p><strong>X_baseline</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x r x d</cite>-dim Tensor of <cite>r</cite> design points
that have already been observed. These points are used to
compute with infeasible cost when there are constraints.</p></li>
<li><p><strong>constraints</strong> (<em>list</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of constraint callables which map a Tensor of posterior
samples of dimension <cite>sample_shape x batch-shape x q x m</cite>-dim to a
<cite>sample_shape x batch-shape x q</cite>-dim Tensor. The associated constraints
are considered satisfied if the output is less than zero.</p></li>
<li><p><strong>beta</strong> (<em>float</em>) – Controls tradeoff between mean and standard deviation in UCB.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dict mapping kwarg names of the constructor to values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict[str, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.input_constructors.construct_inputs_EHVI">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.input_constructors.</span></span><span class="sig-name descname"><span class="pre">construct_inputs_EHVI</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training_data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective_thresholds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y_pmean</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/input_constructors.html#construct_inputs_EHVI"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.input_constructors.construct_inputs_EHVI" title="Link to this definition"></a></dt>
<dd><p>Construct kwargs for <cite>ExpectedHypervolumeImprovement</cite> constructor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>)</p></li>
<li><p><strong>training_data</strong> (<a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em> | </em><em>dict</em><em>[</em><em>Hashable</em><em>, </em><a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em>]</em>)</p></li>
<li><p><strong>objective_thresholds</strong> (<em>Tensor</em>)</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>)</p></li>
<li><p><strong>constraints</strong> (<em>list</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>alpha</strong> (<em>float</em><em> | </em><em>None</em>)</p></li>
<li><p><strong>Y_pmean</strong> (<em>Tensor</em><em> | </em><em>None</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>dict[str, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.input_constructors.construct_inputs_qEHVI">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.input_constructors.</span></span><span class="sig-name descname"><span class="pre">construct_inputs_qEHVI</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training_data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective_thresholds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mc_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">128</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">qmc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/input_constructors.html#construct_inputs_qEHVI"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.input_constructors.construct_inputs_qEHVI" title="Link to this definition"></a></dt>
<dd><p>Construct kwargs for <cite>qExpectedHypervolumeImprovement</cite> and
<cite>qLogExpectedHypervolumeImprovement</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>)</p></li>
<li><p><strong>training_data</strong> (<a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em> | </em><em>dict</em><em>[</em><em>Hashable</em><em>, </em><a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em>]</em>)</p></li>
<li><p><strong>objective_thresholds</strong> (<em>Tensor</em>)</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.multi_objective.objective.MCMultiOutputObjective" title="botorch.acquisition.multi_objective.objective.MCMultiOutputObjective"><em>MCMultiOutputObjective</em></a><em> | </em><em>None</em>)</p></li>
<li><p><strong>constraints</strong> (<em>list</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>alpha</strong> (<em>float</em><em> | </em><em>None</em>)</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>)</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>)</p></li>
<li><p><strong>eta</strong> (<em>float</em>)</p></li>
<li><p><strong>mc_samples</strong> (<em>int</em>)</p></li>
<li><p><strong>qmc</strong> (<em>bool</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>dict[str, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.input_constructors.construct_inputs_qNEHVI">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.input_constructors.</span></span><span class="sig-name descname"><span class="pre">construct_inputs_qNEHVI</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training_data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective_thresholds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_baseline</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fat</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mc_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">128</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">qmc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prune_baseline</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">incremental_nehvi</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_root</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/input_constructors.html#construct_inputs_qNEHVI"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.input_constructors.construct_inputs_qNEHVI" title="Link to this definition"></a></dt>
<dd><p>Construct kwargs for <cite>qNoisyExpectedHypervolumeImprovement</cite>’s constructor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>)</p></li>
<li><p><strong>training_data</strong> (<a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em> | </em><em>dict</em><em>[</em><em>Hashable</em><em>, </em><a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em>]</em>)</p></li>
<li><p><strong>objective_thresholds</strong> (<em>Tensor</em>)</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.multi_objective.objective.MCMultiOutputObjective" title="botorch.acquisition.multi_objective.objective.MCMultiOutputObjective"><em>MCMultiOutputObjective</em></a><em> | </em><em>None</em>)</p></li>
<li><p><strong>X_baseline</strong> (<em>Tensor</em><em> | </em><em>None</em>)</p></li>
<li><p><strong>constraints</strong> (<em>list</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>alpha</strong> (<em>float</em><em> | </em><em>None</em>)</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>)</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>)</p></li>
<li><p><strong>eta</strong> (<em>float</em>)</p></li>
<li><p><strong>fat</strong> (<em>bool</em>)</p></li>
<li><p><strong>mc_samples</strong> (<em>int</em>)</p></li>
<li><p><strong>qmc</strong> (<em>bool</em>)</p></li>
<li><p><strong>prune_baseline</strong> (<em>bool</em>)</p></li>
<li><p><strong>cache_pending</strong> (<em>bool</em>)</p></li>
<li><p><strong>max_iep</strong> (<em>int</em>)</p></li>
<li><p><strong>incremental_nehvi</strong> (<em>bool</em>)</p></li>
<li><p><strong>cache_root</strong> (<em>bool</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>dict[str, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.input_constructors.construct_inputs_qLogNEHVI">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.input_constructors.</span></span><span class="sig-name descname"><span class="pre">construct_inputs_qLogNEHVI</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training_data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective_thresholds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_baseline</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fat</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mc_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">128</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">qmc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prune_baseline</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">incremental_nehvi</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_root</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau_relu</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-06</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau_max</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/input_constructors.html#construct_inputs_qLogNEHVI"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.input_constructors.construct_inputs_qLogNEHVI" title="Link to this definition"></a></dt>
<dd><p>Construct kwargs for <cite>qLogNoisyExpectedHypervolumeImprovement</cite>’s constructor.”</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>)</p></li>
<li><p><strong>training_data</strong> (<a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em> | </em><em>dict</em><em>[</em><em>Hashable</em><em>, </em><a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em>]</em>)</p></li>
<li><p><strong>objective_thresholds</strong> (<em>Tensor</em>)</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.multi_objective.objective.MCMultiOutputObjective" title="botorch.acquisition.multi_objective.objective.MCMultiOutputObjective"><em>MCMultiOutputObjective</em></a><em> | </em><em>None</em>)</p></li>
<li><p><strong>X_baseline</strong> (<em>Tensor</em><em> | </em><em>None</em>)</p></li>
<li><p><strong>constraints</strong> (<em>list</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>alpha</strong> (<em>float</em><em> | </em><em>None</em>)</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>)</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>)</p></li>
<li><p><strong>eta</strong> (<em>float</em>)</p></li>
<li><p><strong>fat</strong> (<em>bool</em>)</p></li>
<li><p><strong>mc_samples</strong> (<em>int</em>)</p></li>
<li><p><strong>qmc</strong> (<em>bool</em>)</p></li>
<li><p><strong>prune_baseline</strong> (<em>bool</em>)</p></li>
<li><p><strong>cache_pending</strong> (<em>bool</em>)</p></li>
<li><p><strong>max_iep</strong> (<em>int</em>)</p></li>
<li><p><strong>incremental_nehvi</strong> (<em>bool</em>)</p></li>
<li><p><strong>cache_root</strong> (<em>bool</em>)</p></li>
<li><p><strong>tau_relu</strong> (<em>float</em>)</p></li>
<li><p><strong>tau_max</strong> (<em>float</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>dict[str, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.input_constructors.construct_inputs_qLogNParEGO">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.input_constructors.</span></span><span class="sig-name descname"><span class="pre">construct_inputs_qLogNParEGO</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training_data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scalarization_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_baseline</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prune_baseline</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_root</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fat</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau_max</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau_relu</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-06</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/input_constructors.html#construct_inputs_qLogNParEGO"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.input_constructors.construct_inputs_qLogNParEGO" title="Link to this definition"></a></dt>
<dd><p>Construct kwargs for the <cite>qLogNoisyExpectedImprovement</cite> constructor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – The model to be used in the acquisition function.</p></li>
<li><p><strong>training_data</strong> (<a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em> | </em><em>dict</em><em>[</em><em>Hashable</em><em>, </em><a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em>]</em>) – Dataset(s) used to train the model.</p></li>
<li><p><strong>scalarization_weights</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>m</cite>-dim Tensor of weights to be used in the
Chebyshev scalarization. If omitted, samples from the unit simplex.</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.multi_objective.objective.MCMultiOutputObjective" title="botorch.acquisition.multi_objective.objective.MCMultiOutputObjective"><em>MCMultiOutputObjective</em></a><em> | </em><em>None</em>) – The MultiOutputMCAcquisitionObjective under which the samples are
evaluated before applying Chebyshev scalarization.
Defaults to <cite>IdentityMultiOutputObjective()</cite>.</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>m x d</cite>-dim Tensor of <cite>m</cite> design points that have been
submitted for function evaluation but have not yet been evaluated.
Concatenated into X upon forward call.</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – The sampler used to draw base samples. If omitted, uses
the acquisition functions’s default sampler.</p></li>
<li><p><strong>X_baseline</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x r x d</cite>-dim Tensor of <cite>r</cite> design points
that have already been observed. These points are considered as
the potential best design point. If omitted, checks that all
training_data have the same input features and take the first <cite>X</cite>.</p></li>
<li><p><strong>prune_baseline</strong> (<em>bool</em><em> | </em><em>None</em>) – If True, remove points in <cite>X_baseline</cite> that are
highly unlikely to be the best point. This can significantly
improve performance and is generally recommended.</p></li>
<li><p><strong>constraints</strong> (<em>list</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of constraint callables which map a Tensor of posterior
samples of dimension <cite>sample_shape x batch-shape x q x m</cite>-dim to a
<cite>sample_shape x batch-shape x q</cite>-dim Tensor. The associated constraints
are considered satisfied if the output is less than zero.</p></li>
<li><p><strong>eta</strong> (<em>Tensor</em><em> | </em><em>float</em>) – Temperature parameter(s) governing the smoothness of the sigmoid
approximation to the constraint indicators. For more details, on this
parameter, see the docs of <cite>compute_smoothed_feasibility_indicator</cite>.</p></li>
<li><p><strong>fat</strong> (<em>bool</em>) – Toggles the use of the fat-tailed non-linearities to smoothly approximate
the constraints indicator function.</p></li>
<li><p><strong>tau_max</strong> (<em>float</em>) – Temperature parameter controlling the sharpness of the smooth
approximations to max.</p></li>
<li><p><strong>tau_relu</strong> (<em>float</em>) – Temperature parameter controlling the sharpness of the smooth
approximations to ReLU.</p></li>
<li><p><strong>cache_root</strong> (<em>bool</em><em> | </em><em>None</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dict mapping kwarg names of the constructor to values.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.input_constructors.construct_inputs_qMES">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.input_constructors.</span></span><span class="sig-name descname"><span class="pre">construct_inputs_qMES</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training_data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">candidate_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/input_constructors.html#construct_inputs_qMES"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.input_constructors.construct_inputs_qMES" title="Link to this definition"></a></dt>
<dd><p>Construct kwargs for <cite>qMaxValueEntropy</cite> constructor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>)</p></li>
<li><p><strong>training_data</strong> (<a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em> | </em><em>dict</em><em>[</em><em>Hashable</em><em>, </em><a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em>]</em>)</p></li>
<li><p><strong>bounds</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>float</em><em>, </em><em>float</em><em>]</em><em>]</em>)</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>)</p></li>
<li><p><strong>candidate_size</strong> (<em>int</em>)</p></li>
<li><p><strong>maximize</strong> (<em>bool</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>dict[str, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.input_constructors.construct_inputs_mf_base">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.input_constructors.</span></span><span class="sig-name descname"><span class="pre">construct_inputs_mf_base</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target_fidelities</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fidelity_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cost_intercept</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_trace_observations</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/input_constructors.html#construct_inputs_mf_base"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.input_constructors.construct_inputs_mf_base" title="Link to this definition"></a></dt>
<dd><p>Construct kwargs for a multifidelity acquisition function’s constructor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>target_fidelities</strong> (<em>dict</em><em>[</em><em>int</em><em>, </em><em>int</em><em> | </em><em>float</em><em>]</em>)</p></li>
<li><p><strong>fidelity_weights</strong> (<em>dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>cost_intercept</strong> (<em>float</em>)</p></li>
<li><p><strong>num_trace_observations</strong> (<em>int</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>dict[str, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.input_constructors.construct_inputs_qKG">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.input_constructors.</span></span><span class="sig-name descname"><span class="pre">construct_inputs_qKG</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training_data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_fantasies</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_current_value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">optimize_objective_kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/input_constructors.html#construct_inputs_qKG"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.input_constructors.construct_inputs_qKG" title="Link to this definition"></a></dt>
<dd><p>Construct kwargs for <cite>qKnowledgeGradient</cite> constructor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>)</p></li>
<li><p><strong>training_data</strong> (<a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em> | </em><em>dict</em><em>[</em><em>Hashable</em><em>, </em><a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em>]</em>)</p></li>
<li><p><strong>bounds</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>float</em><em>, </em><em>float</em><em>]</em><em>]</em>)</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><em>MCAcquisitionObjective</em></a><em> | </em><em>None</em>)</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>)</p></li>
<li><p><strong>num_fantasies</strong> (<em>int</em>)</p></li>
<li><p><strong>with_current_value</strong> (<em>bool</em>)</p></li>
<li><p><strong>optimize_objective_kwargs</strong> (<em>None</em><em> | </em><a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><em>MCAcquisitionObjective</em></a><em> | </em><a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>] </em><em>| </em><em>bool</em><em> | </em><em>int</em><em> | </em><em>dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>Tensor</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>dict[str, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.input_constructors.construct_inputs_qHVKG">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.input_constructors.</span></span><span class="sig-name descname"><span class="pre">construct_inputs_qHVKG</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training_data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective_thresholds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_fantasies</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_pareto</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">optimize_objective_kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/input_constructors.html#construct_inputs_qHVKG"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.input_constructors.construct_inputs_qHVKG" title="Link to this definition"></a></dt>
<dd><p>Construct kwargs for <cite>qKnowledgeGradient</cite> constructor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>)</p></li>
<li><p><strong>training_data</strong> (<a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em> | </em><em>dict</em><em>[</em><em>Hashable</em><em>, </em><a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em>]</em>)</p></li>
<li><p><strong>bounds</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>float</em><em>, </em><em>float</em><em>]</em><em>]</em>)</p></li>
<li><p><strong>objective_thresholds</strong> (<em>Tensor</em>)</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.multi_objective.objective.MCMultiOutputObjective" title="botorch.acquisition.multi_objective.objective.MCMultiOutputObjective"><em>MCMultiOutputObjective</em></a><em> | </em><em>None</em>)</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>)</p></li>
<li><p><strong>num_fantasies</strong> (<em>int</em>)</p></li>
<li><p><strong>num_pareto</strong> (<em>int</em>)</p></li>
<li><p><strong>optimize_objective_kwargs</strong> (<em>None</em><em> | </em><a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><em>MCAcquisitionObjective</em></a><em> | </em><a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>] </em><em>| </em><em>bool</em><em> | </em><em>int</em><em> | </em><em>dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>Tensor</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>dict[str, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.input_constructors.construct_inputs_qMFKG">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.input_constructors.</span></span><span class="sig-name descname"><span class="pre">construct_inputs_qMFKG</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training_data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_fidelities</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fidelity_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cost_intercept</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_trace_observations</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_fantasies</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">optimize_objective_kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/input_constructors.html#construct_inputs_qMFKG"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.input_constructors.construct_inputs_qMFKG" title="Link to this definition"></a></dt>
<dd><p>Construct kwargs for <cite>qMultiFidelityKnowledgeGradient</cite> constructor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>)</p></li>
<li><p><strong>training_data</strong> (<a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em> | </em><em>dict</em><em>[</em><em>Hashable</em><em>, </em><a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em>]</em>)</p></li>
<li><p><strong>bounds</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>float</em><em>, </em><em>float</em><em>]</em><em>]</em>)</p></li>
<li><p><strong>target_fidelities</strong> (<em>dict</em><em>[</em><em>int</em><em>, </em><em>int</em><em> | </em><em>float</em><em>]</em>)</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><em>MCAcquisitionObjective</em></a><em> | </em><em>None</em>)</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>)</p></li>
<li><p><strong>fidelity_weights</strong> (<em>dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>cost_intercept</strong> (<em>float</em>)</p></li>
<li><p><strong>num_trace_observations</strong> (<em>int</em>)</p></li>
<li><p><strong>num_fantasies</strong> (<em>int</em>)</p></li>
<li><p><strong>optimize_objective_kwargs</strong> (<em>None</em><em> | </em><a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><em>MCAcquisitionObjective</em></a><em> | </em><a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>] </em><em>| </em><em>bool</em><em> | </em><em>int</em><em> | </em><em>dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>Tensor</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>dict[str, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.input_constructors.construct_inputs_qMFHVKG">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.input_constructors.</span></span><span class="sig-name descname"><span class="pre">construct_inputs_qMFHVKG</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training_data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_fidelities</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective_thresholds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fidelity_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cost_intercept</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_trace_observations</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_fantasies</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_pareto</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">optimize_objective_kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/input_constructors.html#construct_inputs_qMFHVKG"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.input_constructors.construct_inputs_qMFHVKG" title="Link to this definition"></a></dt>
<dd><p>Construct kwargs for <cite>qMultiFidelityHypervolumeKnowledgeGradient</cite> constructor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>)</p></li>
<li><p><strong>training_data</strong> (<a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em> | </em><em>dict</em><em>[</em><em>Hashable</em><em>, </em><a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em>]</em>)</p></li>
<li><p><strong>bounds</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>float</em><em>, </em><em>float</em><em>]</em><em>]</em>)</p></li>
<li><p><strong>target_fidelities</strong> (<em>dict</em><em>[</em><em>int</em><em>, </em><em>int</em><em> | </em><em>float</em><em>]</em>)</p></li>
<li><p><strong>objective_thresholds</strong> (<em>Tensor</em>)</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.multi_objective.objective.MCMultiOutputObjective" title="botorch.acquisition.multi_objective.objective.MCMultiOutputObjective"><em>MCMultiOutputObjective</em></a><em> | </em><em>None</em>)</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>)</p></li>
<li><p><strong>fidelity_weights</strong> (<em>dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>cost_intercept</strong> (<em>float</em>)</p></li>
<li><p><strong>num_trace_observations</strong> (<em>int</em>)</p></li>
<li><p><strong>num_fantasies</strong> (<em>int</em>)</p></li>
<li><p><strong>num_pareto</strong> (<em>int</em>)</p></li>
<li><p><strong>optimize_objective_kwargs</strong> (<em>None</em><em> | </em><a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><em>MCAcquisitionObjective</em></a><em> | </em><a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>] </em><em>| </em><em>bool</em><em> | </em><em>int</em><em> | </em><em>dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>Tensor</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>dict[str, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.input_constructors.construct_inputs_qMFMES">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.input_constructors.</span></span><span class="sig-name descname"><span class="pre">construct_inputs_qMFMES</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training_data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_fidelities</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_fantasies</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fidelity_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cost_intercept</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_trace_observations</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">candidate_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/input_constructors.html#construct_inputs_qMFMES"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.input_constructors.construct_inputs_qMFMES" title="Link to this definition"></a></dt>
<dd><p>Construct kwargs for <cite>qMultiFidelityMaxValueEntropy</cite> constructor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>)</p></li>
<li><p><strong>training_data</strong> (<a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em> | </em><em>dict</em><em>[</em><em>Hashable</em><em>, </em><a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em>]</em>)</p></li>
<li><p><strong>bounds</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>float</em><em>, </em><em>float</em><em>]</em><em>]</em>)</p></li>
<li><p><strong>target_fidelities</strong> (<em>dict</em><em>[</em><em>int</em><em>, </em><em>int</em><em> | </em><em>float</em><em>]</em>)</p></li>
<li><p><strong>num_fantasies</strong> (<em>int</em>)</p></li>
<li><p><strong>fidelity_weights</strong> (<em>dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>cost_intercept</strong> (<em>float</em>)</p></li>
<li><p><strong>num_trace_observations</strong> (<em>int</em>)</p></li>
<li><p><strong>candidate_size</strong> (<em>int</em>)</p></li>
<li><p><strong>maximize</strong> (<em>bool</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>dict[str, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.input_constructors.construct_inputs_analytic_eubo">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.input_constructors.</span></span><span class="sig-name descname"><span class="pre">construct_inputs_analytic_eubo</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pref_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">previous_winner</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_multiplier</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/input_constructors.html#construct_inputs_analytic_eubo"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.input_constructors.construct_inputs_analytic_eubo" title="Link to this definition"></a></dt>
<dd><p>Construct kwargs for the <cite>AnalyticExpectedUtilityOfBestOption</cite> constructor.</p>
<p><cite>model</cite> is the primary model defined over the parameter space. It can be the
outcome model in BOPE or the preference model in PBO. <cite>pref_model</cite> is the model
defined over the outcome/metric space, which is typically the preference model
in BOPE.</p>
<p>If both model and pref_model exist, we are performing Bayesian Optimization with
Preference Exploration (BOPE). When only pref_model is None, we are performing
preferential BO (PBO).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – The outcome model to be used in the acquisition function in BOPE
when pref_model exists; otherwise, model is the preference model and
we are doing Preferential BO</p></li>
<li><p><strong>pref_model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a><em> | </em><em>None</em>) – The preference model to be used in preference exploration as in
BOPE; if None, we are doing PBO and model is the preference model.</p></li>
<li><p><strong>previous_winner</strong> (<em>Tensor</em><em> | </em><em>None</em>) – The previous winner of the best option.</p></li>
<li><p><strong>sample_multiplier</strong> (<em>float</em><em> | </em><em>None</em>) – The scale factor for the single-sample model.</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.objective.LearnedObjective" title="botorch.acquisition.objective.LearnedObjective"><em>LearnedObjective</em></a><em> | </em><em>None</em>) – Ignored. This argument is allowed to be passed then ignored
because of the way that EUBO is typically used in a BOPE loop.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – Ignored. This argument is allowed to be passed then
ignored because of the way that EUBO is typically used in a BOPE
loop.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dict mapping kwarg names of the constructor to values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict[str, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.input_constructors.construct_inputs_qeubo">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.input_constructors.</span></span><span class="sig-name descname"><span class="pre">construct_inputs_qeubo</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pref_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_multiplier</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/input_constructors.html#construct_inputs_qeubo"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.input_constructors.construct_inputs_qeubo" title="Link to this definition"></a></dt>
<dd><p>Construct kwargs for the <cite>qExpectedUtilityOfBestOption</cite> (qEUBO) constructor.</p>
<p><cite>model</cite> is the primary model defined over the parameter space. It can be the
outcomde model in BOPE or the preference model in PBO. <cite>pref_model</cite> is the model
defined over the outcome/metric space, which is typically the preference model
in BOPE.</p>
<p>If both model and pref_model exist, we are performing Bayesian Optimization with
Preference Exploration (BOPE). When only pref_model is None, we are performing
preferential BO (PBO).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – The outcome model to be used in the acquisition function in BOPE
when pref_model exists; otherwise, model is the preference model and
we are doing Preferential BO</p></li>
<li><p><strong>pref_model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a><em> | </em><em>None</em>) – The preference model to be used in preference exploration as in
BOPE; if None, we are doing PBO and model is the preference model.</p></li>
<li><p><strong>sample_multiplier</strong> (<em>float</em><em> | </em><em>None</em>) – The scale factor for the single-sample model.</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>)</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><em>MCAcquisitionObjective</em></a><em> | </em><em>None</em>)</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>)</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dict mapping kwarg names of the constructor to values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict[str, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.input_constructors.get_best_f_analytic">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.input_constructors.</span></span><span class="sig-name descname"><span class="pre">get_best_f_analytic</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">training_data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/input_constructors.html#get_best_f_analytic"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.input_constructors.get_best_f_analytic" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>training_data</strong> (<a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em> | </em><em>dict</em><em>[</em><em>Hashable</em><em>, </em><a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em>]</em>)</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.input_constructors.get_best_f_mc">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.input_constructors.</span></span><span class="sig-name descname"><span class="pre">get_best_f_mc</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">training_data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/input_constructors.html#get_best_f_mc"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.input_constructors.get_best_f_mc" title="Link to this definition"></a></dt>
<dd><p>Computes the maximum value of the objective over the training data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>training_data</strong> (<a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em> | </em><em>dict</em><em>[</em><em>Hashable</em><em>, </em><a class="reference internal" href="utils.html#botorch.utils.datasets.SupervisedDataset" title="botorch.utils.datasets.SupervisedDataset"><em>SupervisedDataset</em></a><em>]</em>) – Has fields Y, which is evaluated by <cite>objective</cite>, and X,
which is used as <cite>X_baseline</cite>. <cite>Y</cite> is of shape
<cite>batch_shape x q x m</cite>.</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><em>MCAcquisitionObjective</em></a><em> | </em><em>None</em>) – The objective under which to evaluate the training data. If
omitted, uses <cite>IdentityMCObjective</cite>.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – An optional PosteriorTransform to apply to <cite>Y</cite>
before computing the objective.</p></li>
<li><p><strong>constraints</strong> (<em>list</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>] </em><em>| </em><em>None</em>) – For assessing feasibility.</p></li>
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a><em> | </em><em>None</em>) – Used by <cite>compute_best_feasible_objective</cite> when there are no
feasible observations.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A Tensor of shape <cite>batch_shape</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.input_constructors.optimize_objective">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.input_constructors.</span></span><span class="sig-name descname"><span class="pre">optimize_objective</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">acq_function</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">linear_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">qmc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mc_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">512</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed_inner</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post_processing_func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_initial_conditions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sequential</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/input_constructors.html#optimize_objective"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.input_constructors.optimize_objective" title="Link to this definition"></a></dt>
<dd><p>Optimize an objective under the given model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – The model to be used in the objective.</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – A <cite>2 x d</cite> tensor of lower and upper bounds for each column of <cite>X</cite>.</p></li>
<li><p><strong>q</strong> (<em>int</em>) – The cardinality of input sets on which the objective is to be evaluated.</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><em>MCAcquisitionObjective</em></a><em> | </em><em>None</em>) – The objective to optimize.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – The posterior transform to be used in the
acquisition function.</p></li>
<li><p><strong>linear_constraints</strong> (<em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – A tuple of (A, b). Given <cite>k</cite> linear constraints on a
<cite>d</cite>-dimensional space, <cite>A</cite> is <cite>k x d</cite> and <cite>b</cite> is <cite>k x 1</cite> such that
<cite>A x &lt;= b</cite>. (Not used by single task models).</p></li>
<li><p><strong>fixed_features</strong> (<em>dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>] </em><em>| </em><em>None</em>) – A dictionary of feature assignments <cite>{feature_index: value}</cite> to
hold fixed during generation.</p></li>
<li><p><strong>qmc</strong> (<em>bool</em>) – Toggle for enabling (qmc=1) or disabling (qmc=0) use of Quasi Monte Carlo.</p></li>
<li><p><strong>mc_samples</strong> (<em>int</em>) – Integer number of samples used to estimate Monte Carlo objectives.</p></li>
<li><p><strong>seed_inner</strong> (<em>int</em><em> | </em><em>None</em>) – Integer seed used to initialize the sampler passed to MCObjective.</p></li>
<li><p><strong>optimizer_options</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Table used to lookup keyword arguments for the optimizer.</p></li>
<li><p><strong>post_processing_func</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – A function that post-processes an optimization
result appropriately (i.e. according to <cite>round-trip</cite> transformations).</p></li>
<li><p><strong>batch_initial_conditions</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A Tensor of initial values for the optimizer.</p></li>
<li><p><strong>sequential</strong> (<em>bool</em>) – If False, uses joint optimization, otherwise uses sequential
optimization.</p></li>
<li><p><strong>acq_function</strong> (<a class="reference internal" href="#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><em>AcquisitionFunction</em></a><em> | </em><em>None</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tuple containing the best input locations and corresponding objective values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple[<em>Tensor</em>, <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.input_constructors.construct_inputs_qJES">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.input_constructors.</span></span><span class="sig-name descname"><span class="pre">construct_inputs_qJES</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_optima</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition_noiseless</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">estimation_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'LB'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/input_constructors.html#construct_inputs_qJES"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.input_constructors.construct_inputs_qJES" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>)</p></li>
<li><p><strong>bounds</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>float</em><em>, </em><em>float</em><em>]</em><em>]</em>)</p></li>
<li><p><strong>num_optima</strong> (<em>int</em>)</p></li>
<li><p><strong>condition_noiseless</strong> (<em>bool</em>)</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.ScalarizedPosteriorTransform" title="botorch.acquisition.objective.ScalarizedPosteriorTransform"><em>ScalarizedPosteriorTransform</em></a><em> | </em><em>None</em>)</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>)</p></li>
<li><p><strong>estimation_type</strong> (<em>str</em>)</p></li>
<li><p><strong>num_samples</strong> (<em>int</em>)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.input_constructors.construct_inputs_BALD">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.input_constructors.</span></span><span class="sig-name descname"><span class="pre">construct_inputs_BALD</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/input_constructors.html#construct_inputs_BALD"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.input_constructors.construct_inputs_BALD" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>)</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>)</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>)</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.input_constructors.construct_inputs_NIPV">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.input_constructors.</span></span><span class="sig-name descname"><span class="pre">construct_inputs_NIPV</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_mc_points</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">128</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/input_constructors.html#construct_inputs_NIPV"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.input_constructors.construct_inputs_NIPV" title="Link to this definition"></a></dt>
<dd><p>Construct inputs for qNegIntegratedPosteriorVariance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>)</p></li>
<li><p><strong>bounds</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>float</em><em>, </em><em>float</em><em>]</em><em>]</em>)</p></li>
<li><p><strong>num_mc_points</strong> (<em>int</em>)</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>)</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>dict[str, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-botorch.acquisition.penalized">
<span id="penalized-acquisition-function-wrapper"></span><h3>Penalized Acquisition Function Wrapper<a class="headerlink" href="#module-botorch.acquisition.penalized" title="Link to this heading"></a></h3>
<p>Modules to add regularization to acquisition functions.</p>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.penalized.L2Penalty">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.penalized.</span></span><span class="sig-name descname"><span class="pre">L2Penalty</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">init_point</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/penalized.html#L2Penalty"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.penalized.L2Penalty" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>L2 penalty class to be added to any arbitrary acquisition function
to construct a PenalizedAcquisitionFunction.</p>
<p>Initializing L2 regularization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>init_point</strong> (<em>Tensor</em>) – The “1 x dim” reference point against which
we want to regularize.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.penalized.L2Penalty.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/penalized.html#L2Penalty.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.penalized.L2Penalty.forward" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A “batch_shape x q x dim” representing the points to be evaluated.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor of size “batch_shape” representing the acqfn for each q-batch.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.penalized.L1Penalty">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.penalized.</span></span><span class="sig-name descname"><span class="pre">L1Penalty</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">init_point</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/penalized.html#L1Penalty"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.penalized.L1Penalty" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>L1 penalty class to be added to any arbitrary acquisition function
to construct a PenalizedAcquisitionFunction.</p>
<p>Initializing L1 regularization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>init_point</strong> (<em>Tensor</em>) – The “1 x dim” reference point against which
we want to regularize.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.penalized.L1Penalty.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/penalized.html#L1Penalty.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.penalized.L1Penalty.forward" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A “batch_shape x q x dim” representing the points to be evaluated.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor of size “batch_shape” representing the acqfn for each q-batch.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.penalized.GaussianPenalty">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.penalized.</span></span><span class="sig-name descname"><span class="pre">GaussianPenalty</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">init_point</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/penalized.html#GaussianPenalty"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.penalized.GaussianPenalty" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Gaussian penalty class to be added to any arbitrary acquisition function
to construct a PenalizedAcquisitionFunction.</p>
<p>Initializing Gaussian regularization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>init_point</strong> (<em>Tensor</em>) – The “1 x dim” reference point against which
we want to regularize.</p></li>
<li><p><strong>sigma</strong> (<em>float</em>) – The parameter used in gaussian function.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.penalized.GaussianPenalty.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/penalized.html#GaussianPenalty.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.penalized.GaussianPenalty.forward" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A “batch_shape x q x dim” representing the points to be evaluated.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor of size “batch_shape” representing the acqfn for each q-batch.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.penalized.GroupLassoPenalty">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.penalized.</span></span><span class="sig-name descname"><span class="pre">GroupLassoPenalty</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">init_point</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/penalized.html#GroupLassoPenalty"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.penalized.GroupLassoPenalty" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Group lasso penalty class to be added to any arbitrary acquisition function
to construct a PenalizedAcquisitionFunction.</p>
<p>Initializing Group-Lasso regularization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>init_point</strong> (<em>Tensor</em>) – The “1 x dim” reference point against which we want
to regularize.</p></li>
<li><p><strong>groups</strong> (<em>list</em><em>[</em><em>list</em><em>[</em><em>int</em><em>]</em><em>]</em>) – Groups of indices used in group lasso.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.penalized.GroupLassoPenalty.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/penalized.html#GroupLassoPenalty.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.penalized.GroupLassoPenalty.forward" title="Link to this definition"></a></dt>
<dd><p>X should be batch_shape x 1 x dim tensor. Evaluation for q-batch is not
implemented yet.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.penalized.narrow_gaussian">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.penalized.</span></span><span class="sig-name descname"><span class="pre">narrow_gaussian</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">a</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/penalized.html#narrow_gaussian"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.penalized.narrow_gaussian" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>)</p></li>
<li><p><strong>a</strong> (<em>Tensor</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.penalized.nnz_approx">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.penalized.</span></span><span class="sig-name descname"><span class="pre">nnz_approx</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_point</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">a</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/penalized.html#nnz_approx"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.penalized.nnz_approx" title="Link to this definition"></a></dt>
<dd><p>Differentiable relaxation of ||X - target_point||_0</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – An <cite>n x d</cite> tensor of inputs.</p></li>
<li><p><strong>target_point</strong> (<em>Tensor</em>) – A tensor of size <cite>n</cite> corresponding to the target point.</p></li>
<li><p><strong>a</strong> (<em>Tensor</em>) – A scalar tensor that controls the differentiable relaxation.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.penalized.L0Approximation">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.penalized.</span></span><span class="sig-name descname"><span class="pre">L0Approximation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target_point</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">a</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">tkwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/penalized.html#L0Approximation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.penalized.L0Approximation" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Differentiable relaxation of the L0 norm using a Gaussian basis function.</p>
<p>Initializing L0 penalty with differentiable relaxation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>target_point</strong> (<em>Tensor</em>) – A tensor corresponding to the target point.</p></li>
<li><p><strong>a</strong> (<em>float</em>) – A hyperparameter that controls the differentiable relaxation.</p></li>
<li><p><strong>tkwargs</strong> (<em>Any</em>)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.penalized.L0PenaltyApprox">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.penalized.</span></span><span class="sig-name descname"><span class="pre">L0PenaltyApprox</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target_point</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">a</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">tkwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/penalized.html#L0PenaltyApprox"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.penalized.L0PenaltyApprox" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.penalized.L0Approximation" title="botorch.acquisition.penalized.L0Approximation"><code class="xref py py-class docutils literal notranslate"><span class="pre">L0Approximation</span></code></a></p>
<p>Differentiable relaxation of the L0 norm to be added to any arbitrary
acquisition function to construct a PenalizedAcquisitionFunction.</p>
<p>Initializing L0 penalty with differentiable relaxation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>target_point</strong> (<em>Tensor</em>) – A tensor corresponding to the target point.</p></li>
<li><p><strong>a</strong> (<em>float</em>) – A hyperparameter that controls the differentiable relaxation.</p></li>
<li><p><strong>tkwargs</strong> (<em>Any</em>)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.penalized.PenalizedAcquisitionFunction">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.penalized.</span></span><span class="sig-name descname"><span class="pre">PenalizedAcquisitionFunction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">raw_acqf</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">penalty_func</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">regularization_parameter</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/penalized.html#PenalizedAcquisitionFunction"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.penalized.PenalizedAcquisitionFunction" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">AcquisitionFunction</span></code></a></p>
<p>Single-outcome acquisition function regularized by the given penalty.</p>
<dl class="simple">
<dt>The usage is similar to:</dt><dd><p>raw_acqf = NoisyExpectedImprovement(…)
penalty = GroupLassoPenalty(…)
acqf = PenalizedAcquisitionFunction(raw_acqf, penalty)</p>
</dd>
</dl>
<p>Initializing Group-Lasso regularization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>raw_acqf</strong> (<a class="reference internal" href="#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><em>AcquisitionFunction</em></a>) – The raw acquisition function that is going to be regularized.</p></li>
<li><p><strong>penalty_func</strong> (<em>torch.nn.Module</em>) – The regularization function.</p></li>
<li><p><strong>regularization_parameter</strong> (<em>float</em>) – Regularization parameter used in optimization.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.penalized.PenalizedAcquisitionFunction.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/penalized.html#PenalizedAcquisitionFunction.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.penalized.PenalizedAcquisitionFunction.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate the acquisition function on the candidate set X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A <cite>(b) x q x d</cite>-dim Tensor of <cite>(b)</cite> t-batches with <cite>q</cite> <cite>d</cite>-dim
design points each.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>(b)</cite>-dim Tensor of acquisition function values at the given
design points <cite>X</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="botorch.acquisition.penalized.PenalizedAcquisitionFunction.X_pending">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">X_pending</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#botorch.acquisition.penalized.PenalizedAcquisitionFunction.X_pending" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.penalized.PenalizedAcquisitionFunction.set_X_pending">
<span class="sig-name descname"><span class="pre">set_X_pending</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/penalized.html#PenalizedAcquisitionFunction.set_X_pending"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.penalized.PenalizedAcquisitionFunction.set_X_pending" title="Link to this definition"></a></dt>
<dd><p>Informs the acquisition function about pending design points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – <cite>n x d</cite> Tensor with <cite>n</cite> <cite>d</cite>-dim design points that have
been submitted for evaluation but have not yet been evaluated.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.penalized.group_lasso_regularizer">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.penalized.</span></span><span class="sig-name descname"><span class="pre">group_lasso_regularizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/penalized.html#group_lasso_regularizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.penalized.group_lasso_regularizer" title="Link to this definition"></a></dt>
<dd><p>Computes the group lasso regularization function for the given point.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A bxd tensor representing the points to evaluate the regularization at.</p></li>
<li><p><strong>groups</strong> (<em>list</em><em>[</em><em>list</em><em>[</em><em>int</em><em>]</em><em>]</em>) – List of indices of different groups.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Computed group lasso norm of at the given points.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.penalized.L1PenaltyObjective">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.penalized.</span></span><span class="sig-name descname"><span class="pre">L1PenaltyObjective</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">init_point</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/penalized.html#L1PenaltyObjective"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.penalized.L1PenaltyObjective" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>L1 penalty objective class. An instance of this class can be added to any
arbitrary objective to construct a PenalizedMCObjective.</p>
<p>Initializing L1 penalty objective.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>init_point</strong> (<em>Tensor</em>) – The “1 x dim” reference point against which
we want to regularize.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.penalized.L1PenaltyObjective.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/penalized.html#L1PenaltyObjective.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.penalized.L1PenaltyObjective.forward" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – A “batch_shape x q x dim” representing the points to be evaluated.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A “1 x batch_shape x q” tensor representing the penalty for each point.
The first dimension corresponds to the dimension of MC samples.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.penalized.PenalizedMCObjective">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.penalized.</span></span><span class="sig-name descname"><span class="pre">PenalizedMCObjective</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">objective</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">penalty_objective</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">regularization_parameter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">expand_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/penalized.html#PenalizedMCObjective"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.penalized.PenalizedMCObjective" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.objective.GenericMCObjective" title="botorch.acquisition.objective.GenericMCObjective"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericMCObjective</span></code></a></p>
<p>Penalized MC objective.</p>
<p>Allows to construct a penalized MC-objective by adding a penalty term to
the original objective.</p>
<blockquote>
<div><p>mc_acq(X) = objective(X) + penalty_objective(X)</p>
</div></blockquote>
<p>Note: PenalizedMCObjective allows adding penalty at the MCObjective level,
different from the AcquisitionFunction level in PenalizedAcquisitionFunction.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">regularization_parameter</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">init_point</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span> <span class="c1"># assume data dim is 3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">objective</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">Y</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">l1_penalty_objective</span> <span class="o">=</span> <span class="n">L1PenaltyObjective</span><span class="p">(</span><span class="n">init_point</span><span class="o">=</span><span class="n">init_point</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">l1_penalized_objective</span> <span class="o">=</span> <span class="n">PenalizedMCObjective</span><span class="p">(</span>
<span class="go">        objective, l1_penalty_objective, regularization_parameter</span>
<span class="go">    )</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">samples</span> <span class="o">=</span> <span class="n">sampler</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
<span class="go">        objective, l1_penalty_objective, regularization_parameter</span>
</pre></div>
</div>
<p>Penalized MC objective.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>objective</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em> | </em><em>None</em><em>]</em><em>, </em><em>Tensor</em><em>]</em>) – A callable <cite>f(samples, X)</cite> mapping a
<cite>sample_shape x batch-shape x q x m</cite>-dim Tensor <cite>samples</cite> and
an optional <cite>batch-shape x q x d</cite>-dim Tensor <cite>X</cite> to a
<cite>sample_shape x batch-shape x q</cite>-dim Tensor of objective values.</p></li>
<li><p><strong>penalty_objective</strong> (<em>torch.nn.Module</em>) – A torch.nn.Module <cite>f(X)</cite> that takes in a
<cite>batch-shape x q x d</cite>-dim Tensor <cite>X</cite> and outputs a
<cite>1 x batch-shape x q</cite>-dim Tensor of penalty objective values.</p></li>
<li><p><strong>regularization_parameter</strong> (<em>float</em>) – weight of the penalty (regularization) term</p></li>
<li><p><strong>expand_dim</strong> (<em>int</em><em> | </em><em>None</em>) – dim to expand penalty_objective to match with objective when
fully bayesian model is used. If None, no expansion is performed.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.penalized.PenalizedMCObjective.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/penalized.html#PenalizedMCObjective.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.penalized.PenalizedMCObjective.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate the penalized objective on the samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples</strong> (<em>Tensor</em>) – A <cite>sample_shape x batch_shape x q x m</cite>-dim Tensors of
samples from a model posterior.</p></li>
<li><p><strong>X</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x q x d</cite>-dim tensor of inputs. Relevant only if
the objective depends on the inputs explicitly.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>sample_shape x batch_shape x q</cite>-dim Tensor of objective values
with penalty added for each point.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.penalized.L0PenaltyApproxObjective">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.penalized.</span></span><span class="sig-name descname"><span class="pre">L0PenaltyApproxObjective</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target_point</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">a</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">tkwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/penalized.html#L0PenaltyApproxObjective"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.penalized.L0PenaltyApproxObjective" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.penalized.L0Approximation" title="botorch.acquisition.penalized.L0Approximation"><code class="xref py py-class docutils literal notranslate"><span class="pre">L0Approximation</span></code></a></p>
<p>Differentiable relaxation of the L0 norm penalty objective class.
An instance of this class can be added to any arbitrary objective to
construct a PenalizedMCObjective.</p>
<p>Initializing L0 penalty with differentiable relaxation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>target_point</strong> (<em>Tensor</em>) – A tensor corresponding to the target point.</p></li>
<li><p><strong>a</strong> (<em>float</em>) – A hyperparameter that controls the differentiable relaxation.</p></li>
<li><p><strong>tkwargs</strong> (<em>Any</em>)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-botorch.acquisition.prior_guided">
<span id="prior-guided-acquisition-function-wrapper"></span><h3>Prior-Guided Acquisition Function Wrapper<a class="headerlink" href="#module-botorch.acquisition.prior_guided" title="Link to this heading"></a></h3>
<p>Prior-Guided Acquisition Functions</p>
<p>References</p>
<div role="list" class="citation-list">
<div class="citation" id="hvarfner2022" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Hvarfner2022<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id74">1</a>,<a role="doc-backlink" href="#id75">2</a>)</span>
<p>C. Hvarfner, D. Stoll, A. Souza, M. Lindauer, F. Hutter, L. Nardi. PiBO:
Augmenting Acquisition Functions with User Beliefs for Bayesian Optimization.
ICLR 2022.</p>
</div>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.prior_guided.PriorGuidedAcquisitionFunction">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.prior_guided.</span></span><span class="sig-name descname"><span class="pre">PriorGuidedAcquisitionFunction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_exponent</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/prior_guided.html#PriorGuidedAcquisitionFunction"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.prior_guided.PriorGuidedAcquisitionFunction" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">AcquisitionFunction</span></code></a></p>
<p>Class for weighting acquisition functions by a prior distribution.</p>
<p>Supports MC and batch acquisition functions via
SampleReducingAcquisitionFunction.</p>
<p>See <a class="reference internal" href="#hvarfner2022" id="id74"><span>[Hvarfner2022]</span></a> for details.</p>
<p>Initialize the prior-guided acquisition function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<a class="reference internal" href="#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><em>AcquisitionFunction</em></a>) – The base acquisition function.</p></li>
<li><p><strong>prior_module</strong> (<em>Module</em>) – A Module that computes the probability
(or log probability) for the provided inputs.
<cite>prior_module.forward</cite> should take a <cite>batch_shape x q</cite>-dim
tensor of inputs and return a <cite>batch_shape x q</cite>-dim tensor
of probabilities.</p></li>
<li><p><strong>log</strong> (<em>bool</em>) – A boolean that should be true if the acquisition function emits a
log-transformed value and the prior module emits a log probability.</p></li>
<li><p><strong>prior_exponent</strong> (<em>float</em>) – The exponent applied to the prior. This can be used
for example  to decay the effect the prior over time as in
<a class="reference internal" href="#hvarfner2022" id="id75"><span>[Hvarfner2022]</span></a>.</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – <cite>n x d</cite> Tensor with <cite>n</cite> <cite>d</cite>-dim design points that have
been submitted for evaluation but have not yet been evaluated.
Note: X_pending should be provided as an argument to or set on
<cite>PriorGuidedAcquisitionFunction</cite>, but not set on the underlying
acquisition function.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.prior_guided.PriorGuidedAcquisitionFunction.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/prior_guided.html#PriorGuidedAcquisitionFunction.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.prior_guided.PriorGuidedAcquisitionFunction.forward" title="Link to this definition"></a></dt>
<dd><p>Compute the acquisition function weighted by the prior.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-botorch.acquisition.proximal">
<span id="proximal-acquisition-function-wrapper"></span><h3>Proximal Acquisition Function Wrapper<a class="headerlink" href="#module-botorch.acquisition.proximal" title="Link to this heading"></a></h3>
<p>A wrapper around AcquisitionFunctions to add proximal weighting of the
acquisition function.</p>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.acquisition.proximal.ProximalAcquisitionFunction">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.acquisition.proximal.</span></span><span class="sig-name descname"><span class="pre">ProximalAcquisitionFunction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">proximal_weights</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformed_weighting</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/proximal.html#ProximalAcquisitionFunction"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.proximal.ProximalAcquisitionFunction" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">AcquisitionFunction</span></code></a></p>
<p>A wrapper around AcquisitionFunctions to add proximal weighting of the
acquisition function. The acquisition function is
weighted via a squared exponential centered at the last training point,
with varying lengthscales corresponding to <cite>proximal_weights</cite>. Can only be used
with acquisition functions based on single batch models. Acquisition functions
must be positive or <cite>beta</cite> must be specified to apply a SoftPlus transform before
proximal weighting.</p>
<p>Small values of <cite>proximal_weights</cite> corresponds to strong biasing towards recently
observed points, which smoothes optimization with a small potential decrese in
convergence rate.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">EI</span> <span class="o">=</span> <span class="n">ExpectedImprovement</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">best_f</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">proximal_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">EI_proximal</span> <span class="o">=</span> <span class="n">ProximalAcquisitionFunction</span><span class="p">(</span><span class="n">EI</span><span class="p">,</span> <span class="n">proximal_weights</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">eip</span> <span class="o">=</span> <span class="n">EI_proximal</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
</pre></div>
</div>
<p>Derived Acquisition Function weighted by proximity to recently
observed point.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<a class="reference internal" href="#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><em>AcquisitionFunction</em></a>) – The base acquisition function, operating on input tensors
of feature dimension <cite>d</cite>.</p></li>
<li><p><strong>proximal_weights</strong> (<em>Tensor</em>) – A <cite>d</cite> dim tensor used to bias locality
along each axis.</p></li>
<li><p><strong>transformed_weighting</strong> (<em>bool</em><em> | </em><em>None</em>) – If True, the proximal weights are applied in
the transformed input space given by
<cite>acq_function.model.input_transform</cite> (if available), otherwise
proximal weights are applied in real input space.</p></li>
<li><p><strong>beta</strong> (<em>float</em><em> | </em><em>None</em>) – If not None, apply a softplus transform to the base acquisition
function, allows negative base acquisition function values.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.acquisition.proximal.ProximalAcquisitionFunction.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/proximal.html#ProximalAcquisitionFunction.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.proximal.ProximalAcquisitionFunction.forward" title="Link to this definition"></a></dt>
<dd><p>Evaluate base acquisition function with proximal weighting.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – Input tensor of feature dimension <cite>d</cite> .</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Base acquisition function evaluated on tensor <cite>X</cite> multiplied by proximal
weighting.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-botorch.acquisition.factory">
<span id="factory-functions-for-acquisition-functions"></span><h3>Factory Functions for Acquisition Functions<a class="headerlink" href="#module-botorch.acquisition.factory" title="Link to this heading"></a></h3>
<p>Utilities for acquisition functions.</p>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.factory.get_acquisition_function">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.factory.</span></span><span class="sig-name descname"><span class="pre">get_acquisition_function</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acquisition_function_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_observed</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_pending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mc_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">512</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="keyword-only-separator o"><abbr title="Keyword-only parameters separator (PEP 3102)"><span class="pre">*</span></abbr></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prune_baseline</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">marginalize_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_root</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ref_point</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/factory.html#get_acquisition_function"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.factory.get_acquisition_function" title="Link to this definition"></a></dt>
<dd><p>Convenience function for initializing botorch acquisition functions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acquisition_function_name</strong> (<em>str</em>) – Name of the acquisition function.</p></li>
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted model.</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><em>MCAcquisitionObjective</em></a>) – A MCAcquisitionObjective.</p></li>
<li><p><strong>X_observed</strong> (<em>Tensor</em>) – A <cite>m1 x d</cite>-dim Tensor of <cite>m1</cite> design points that have
already been observed.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – A PosteriorTransform (optional).</p></li>
<li><p><strong>X_pending</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>m2 x d</cite>-dim Tensor of <cite>m2</cite> design points whose evaluation
is pending.</p></li>
<li><p><strong>constraints</strong> (<em>list</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of callables, each mapping a Tensor of dimension
<cite>sample_shape x batch-shape x q x m</cite> to a Tensor of dimension
<cite>sample_shape x batch-shape x q</cite>, where negative values imply
feasibility. Used for all acquisition functions except qSR and qUCB.</p></li>
<li><p><strong>eta</strong> (<em>Tensor</em><em> | </em><em>float</em><em> | </em><em>None</em>) – The temperature parameter for the sigmoid function used for the
differentiable approximation of the constraints. In case of a float the
same eta is used for every constraint in constraints. In case of a
tensor the length of the tensor must match the number of provided
constraints. The i-th constraint is then estimated with the i-th
eta value. Used for all acquisition functions except qSR and qUCB.</p></li>
<li><p><strong>mc_samples</strong> (<em>int</em>) – The number of samples to use for (q)MC evaluation of the
acquisition function.</p></li>
<li><p><strong>seed</strong> (<em>int</em><em> | </em><em>None</em>) – If provided, perform deterministic optimization (i.e. the
function to optimize is fixed and not stochastic).</p></li>
<li><p><strong>tau</strong> (<em>float</em>)</p></li>
<li><p><strong>prune_baseline</strong> (<em>bool</em>)</p></li>
<li><p><strong>marginalize_dim</strong> (<em>int</em><em> | </em><em>None</em>)</p></li>
<li><p><strong>cache_root</strong> (<em>bool</em>)</p></li>
<li><p><strong>beta</strong> (<em>float</em><em> | </em><em>None</em>)</p></li>
<li><p><strong>ref_point</strong> (<em>None</em><em> | </em><em>list</em><em>[</em><em>float</em><em>] </em><em>| </em><em>Tensor</em>)</p></li>
<li><p><strong>Y</strong> (<em>Tensor</em><em> | </em><em>None</em>)</p></li>
<li><p><strong>alpha</strong> (<em>float</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The requested acquisition function.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.acquisition.monte_carlo.MCAcquisitionFunction" title="botorch.acquisition.monte_carlo.MCAcquisitionFunction"><em>MCAcquisitionFunction</em></a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">obj</span> <span class="o">=</span> <span class="n">LinearMCObjective</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">acqf</span> <span class="o">=</span> <span class="n">get_acquisition_function</span><span class="p">(</span><span class="s2">&quot;qEI&quot;</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">obj</span><span class="p">,</span> <span class="n">train_X</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="module-botorch.acquisition.utils">
<span id="general-utilities-for-acquisition-functions"></span><h3>General Utilities for Acquisition Functions<a class="headerlink" href="#module-botorch.acquisition.utils" title="Link to this heading"></a></h3>
<p>Utilities for acquisition functions.</p>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.utils.get_acquisition_function">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.utils.</span></span><span class="sig-name descname"><span class="pre">get_acquisition_function</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/utils.html#get_acquisition_function"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.utils.get_acquisition_function" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.utils.repeat_to_match_aug_dim">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.utils.</span></span><span class="sig-name descname"><span class="pre">repeat_to_match_aug_dim</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reference_tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/utils.html#repeat_to_match_aug_dim"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.utils.repeat_to_match_aug_dim" title="Link to this definition"></a></dt>
<dd><p>Repeat target_tensor until it has the same first dimension as reference_tensor
This works regardless of the batch shapes and q.
This is useful as we sometimes modify sample shapes such as in LearnedObjective.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>target_tensor</strong> (<em>Tensor</em>) – A <cite>sample_size x batch_shape x q x m</cite>-dim Tensor</p></li>
<li><p><strong>reference_tensor</strong> (<em>Tensor</em>) – A <cite>(augmented_sample * sample_size) x batch_shape x q</cite>-dim
Tensor. <cite>augmented_sample</cite> could be 1.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The content of <cite>target_tensor</cite> potentially repeated so that its first dimension
matches that of <cite>reference_tensor</cite>.
The shape will be <cite>(augmented_sample * sample_size) x batch_shape x q x m</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">target_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">target_tensor</span>
<span class="go">tensor([[0, 0],</span>
<span class="go">        [1, 1],</span>
<span class="go">        [2, 2]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">repeat_to_match_aug_dim</span><span class="p">(</span><span class="n">target_tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">6</span><span class="p">))</span>
<span class="go">tensor([[0, 0],</span>
<span class="go">        [1, 1],</span>
<span class="go">        [2, 2],</span>
<span class="go">        [0, 0],</span>
<span class="go">        [1, 1],</span>
<span class="go">        [2, 2]])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.utils.compute_best_feasible_objective">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.utils.</span></span><span class="sig-name descname"><span class="pre">compute_best_feasible_objective</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obj</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraints</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_baseline</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">infeasible_obj</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/utils.html#compute_best_feasible_objective"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.utils.compute_best_feasible_objective" title="Link to this definition"></a></dt>
<dd><p>Computes the largest <cite>obj</cite> value that is feasible under the <cite>constraints</cite>. If
<cite>constraints</cite> is None, returns the best unconstrained objective value.</p>
<p>When no feasible observations exist and <cite>infeasible_obj</cite> is not <cite>None</cite>, returns
<cite>infeasible_obj</cite> (potentially reshaped). When no feasible observations exist and
<cite>infeasible_obj</cite> is <cite>None</cite>, uses <cite>model</cite>, <cite>objective</cite>, <cite>posterior_transform</cite>, and
<cite>X_baseline</cite> to infer and return an <cite>infeasible_obj</cite> <cite>M</cite> s.t. <cite>M &lt; min_x f(x)</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples</strong> (<em>Tensor</em>) – <cite>(sample_shape) x batch_shape x q x m</cite>-dim posterior samples.</p></li>
<li><p><strong>obj</strong> (<em>Tensor</em>) – A <cite>(sample_shape) x batch_shape x q</cite>-dim Tensor of MC objective values.</p></li>
<li><p><strong>constraints</strong> (<em>list</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of constraint callables which map posterior samples to
a scalar. The associated constraint is considered satisfied if this
scalar is less than zero.</p></li>
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a><em> | </em><em>None</em>) – A Model, only required when there are no feasible observations.</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><em>MCAcquisitionObjective</em></a><em> | </em><em>None</em>) – An MCAcquisitionObjective, only optionally used when there are no
feasible observations.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – A PosteriorTransform, only optionally used when there are
no feasible observations.</p></li>
<li><p><strong>X_baseline</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A <cite>batch_shape x d</cite>-dim Tensor of baseline points, only required
when there are no feasible observations.</p></li>
<li><p><strong>infeasible_obj</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A Tensor to be returned when no feasible points exist.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>(sample_shape) x batch_shape</cite>-dim Tensor of best feasible objectives.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.utils.get_infeasible_cost">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.utils.</span></span><span class="sig-name descname"><span class="pre">get_infeasible_cost</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/utils.html#get_infeasible_cost"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.utils.get_infeasible_cost" title="Link to this definition"></a></dt>
<dd><p>Get infeasible cost for a model and objective.</p>
<p>For each outcome, computes an infeasible cost <cite>M</cite> such that
<cite>-M &lt; min_x f(x)</cite> almost always, so that feasible points are preferred.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>n x d</cite> Tensor of <cite>n</cite> design points to use in evaluating the
minimum. These points should cover the design space well. The more
points the better the estimate, at the expense of added computation.</p></li>
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted botorch model with <cite>m</cite> outcomes.</p></li>
<li><p><strong>objective</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em> | </em><em>None</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – The objective with which to evaluate the model output.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – A PosteriorTransform (optional).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An <cite>m</cite>-dim tensor of infeasible cost values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">objective</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">Y</span><span class="p">:</span> <span class="n">Y</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">**</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">M</span> <span class="o">=</span> <span class="n">get_infeasible_cost</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">obj</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.utils.prune_inferior_points">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.utils.</span></span><span class="sig-name descname"><span class="pre">prune_inferior_points</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2048</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_frac</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">marginalize_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/utils.html#prune_inferior_points"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.utils.prune_inferior_points" title="Link to this definition"></a></dt>
<dd><p>Prune points from an input tensor that are unlikely to be the best point.</p>
<p>Given a model, an objective, and an input tensor <cite>X</cite>, this function returns
the subset of points in <cite>X</cite> that have some probability of being the best
point under the objective. This function uses sampling to estimate the
probabilities, the higher the number of points <cite>n</cite> in <cite>X</cite> the higher the
number of samples <cite>num_samples</cite> should be to obtain accurate estimates.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted model. Batched models are currently not supported.</p></li>
<li><p><strong>X</strong> (<em>Tensor</em>) – An input tensor of shape <cite>n x d</cite>. Batched inputs are currently not
supported.</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><em>MCAcquisitionObjective</em></a><em> | </em><em>None</em>) – The objective under which to evaluate the posterior.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.PosteriorTransform" title="botorch.acquisition.objective.PosteriorTransform"><em>PosteriorTransform</em></a><em> | </em><em>None</em>) – A PosteriorTransform (optional).</p></li>
<li><p><strong>constraints</strong> (<em>list</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of constraint callables which map a Tensor of posterior
samples of dimension <cite>sample_shape x batch-shape x q x m</cite>-dim to a
<cite>sample_shape x batch-shape x q</cite>-dim Tensor. The associated constraints
are satisfied if <cite>constraint(samples) &lt; 0</cite>.</p></li>
<li><p><strong>num_samples</strong> (<em>int</em>) – The number of samples used to compute empirical
probabilities of being the best point.</p></li>
<li><p><strong>max_frac</strong> (<em>float</em>) – The maximum fraction of points to retain. Must satisfy
<cite>0 &lt; max_frac &lt;= 1</cite>. Ensures that the number of elements in the
returned tensor does not exceed <cite>ceil(max_frac * n)</cite>.</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.base.MCSampler" title="botorch.sampling.base.MCSampler"><em>MCSampler</em></a><em> | </em><em>None</em>) – If provided, will use this customized sampler instead of
automatically constructing one with <cite>num_samples</cite>.</p></li>
<li><p><strong>marginalize_dim</strong> (<em>int</em><em> | </em><em>None</em>) – A batch dimension that should be marginalized.
For example, this is useful when using a batched fully Bayesian
model.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>A <cite>n’ x d</cite> with subset of points in <cite>X</cite>, where</p>
<blockquote>
<div><p>n’ = min(N_nz, ceil(max_frac * n))</p>
</div></blockquote>
<p>with <cite>N_nz</cite> the number of points in <cite>X</cite> that have non-zero (empirical,
under <cite>num_samples</cite> samples) probability of being the best point.</p>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.utils.project_to_target_fidelity">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.utils.</span></span><span class="sig-name descname"><span class="pre">project_to_target_fidelity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_fidelities</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/utils.html#project_to_target_fidelity"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.utils.project_to_target_fidelity" title="Link to this definition"></a></dt>
<dd><p>Project <cite>X</cite> onto the target set of fidelities.</p>
<p>This function assumes that the set of feasible fidelities is a box, so
projecting here just means setting each fidelity parameter to its target
value. If X does not contain the fidelity dimensions, this will insert
them and set them to their target values.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x q x (d or d-d_f)</cite>-dim Tensor of with <cite>q</cite> <cite>d</cite> or
<cite>d-d_f</cite>-dim design points for each t-batch, where d_f is the
number of fidelity dimensions. If the argument <cite>d</cite> is not provided,
<cite>X</cite> must include the fidelity dimensions and have a trailing`X` must
include the fidelity dimensions and have a trailing</p></li>
<li><p><strong>target_fidelities</strong> (<em>dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>] </em><em>| </em><em>None</em>) – A dictionary mapping a subset of columns of <cite>X</cite> (the
fidelity parameters) to their respective target fidelity value. If
omitted, assumes that the last column of X is the fidelity parameter
with a target value of 1.0.</p></li>
<li><p><strong>d</strong> (<em>int</em><em> | </em><em>None</em>) – The total dimension <cite>d</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>A <cite>batch_shape x q x d</cite>-dim Tensor <cite>X_proj</cite> with fidelity parameters</dt><dd><p>projected to the provided fidelity values.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.utils.expand_trace_observations">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.utils.</span></span><span class="sig-name descname"><span class="pre">expand_trace_observations</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fidelity_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_trace_obs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/utils.html#expand_trace_observations"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.utils.expand_trace_observations" title="Link to this definition"></a></dt>
<dd><p>Expand <cite>X</cite> with trace observations.</p>
<p>Expand a tensor of inputs with “trace observations” that are obtained during
the evaluation of the candidate set. This is used in multi-fidelity
optimization. It can be though of as augmenting the <cite>q</cite>-batch with additional
points that are the expected trace observations.</p>
<p>Let <cite>f_i</cite> be the <cite>i</cite>-th fidelity parameter. Then this functions assumes that
for each element of the q-batch, besides the fidelity <cite>f_i</cite>, we will observe
additonal fidelities <cite>f_i1, …, f_iK</cite>, where <cite>K = num_trace_obs</cite>, during
evaluation of the candidate set <cite>X</cite>. Specifically, this function assumes
that <cite>f_ij = (K-j) / (num_trace_obs + 1) * f_i</cite> for all <cite>i</cite>. That is, the
expansion is performed in parallel for all fidelities (it does not expand
out all possible combinations).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x q x d</cite>-dim Tensor of with <cite>q</cite> <cite>d</cite>-dim design points
(incl. the fidelity parameters) for each t-batch.</p></li>
<li><p><strong>fidelity_dims</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – The indices of the fidelity parameters. If omitted,
assumes that the last column of X contains the fidelity parameters.</p></li>
<li><p><strong>num_trace_obs</strong> (<em>int</em>) – The number of trace observations to use.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>A <cite>batch_shape x (q + num_trace_obs x q) x d</cite> Tensor <cite>X_expanded</cite> that</dt><dd><p>expands <cite>X</cite> with trace observations.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.utils.project_to_sample_points">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.utils.</span></span><span class="sig-name descname"><span class="pre">project_to_sample_points</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_points</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/utils.html#project_to_sample_points"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.utils.project_to_sample_points" title="Link to this definition"></a></dt>
<dd><p>Augment <cite>X</cite> with sample points at which to take weighted average.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>batch_shape x 1 x d</cite>-dim Tensor of with one d`-dim design points
for each t-batch.</p></li>
<li><p><strong>sample_points</strong> (<em>Tensor</em>) – <cite>p x d’</cite>-dim Tensor (<cite>d’ &lt; d</cite>) of <cite>d’</cite>-dim sample points at
which to compute the expectation. The <cite>d’</cite>-dims refer to the trailing
columns of X.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>batch_shape x p x d</cite> Tensor where the q-batch includes the <cite>p</cite> sample points.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.utils.get_optimal_samples">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.utils.</span></span><span class="sig-name descname"><span class="pre">get_optimal_samples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_optima</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raw_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1024</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_restarts</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posterior_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_transformed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/utils.html#get_optimal_samples"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.utils.get_optimal_samples" title="Link to this definition"></a></dt>
<dd><p>Draws sample paths from the posterior and maximizes the samples using GD.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>GP</em>) – The model from which samples are drawn.</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – Bounds of the search space. If the model inputs are
normalized, the bounds should be normalized as well.</p></li>
<li><p><strong>num_optima</strong> (<em>int</em>) – The number of paths to be drawn and optimized.</p></li>
<li><p><strong>raw_samples</strong> (<em>int</em>) – The number of candidates randomly sample.
Defaults to 1024.</p></li>
<li><p><strong>num_restarts</strong> (<em>int</em>) – The number of candidates to do gradient-based
optimization on. Defaults to 20.</p></li>
<li><p><strong>posterior_transform</strong> (<a class="reference internal" href="#botorch.acquisition.objective.ScalarizedPosteriorTransform" title="botorch.acquisition.objective.ScalarizedPosteriorTransform"><em>ScalarizedPosteriorTransform</em></a><em> | </em><em>None</em>) – A ScalarizedPosteriorTransform (may e.g. be used to
scalarize multi-output models or negate the objective).</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.objective.MCAcquisitionObjective" title="botorch.acquisition.objective.MCAcquisitionObjective"><em>MCAcquisitionObjective</em></a><em> | </em><em>None</em>) – An MCAcquisitionObjective, used to negate the objective or otherwise
transform sample outputs. Cannot be combined with <cite>posterior_transform</cite>.</p></li>
<li><p><strong>return_transformed</strong> (<em>bool</em>) – If True, return the transformed samples.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The optimal input locations and corresponding outputs, x* and f*.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple[<em>Tensor</em>, <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-botorch.acquisition.multi_objective.utils">
<span id="multi-objective-utilities-for-acquisition-functions"></span><h3>Multi-Objective Utilities for Acquisition Functions<a class="headerlink" href="#module-botorch.acquisition.multi_objective.utils" title="Link to this heading"></a></h3>
<p>Utilities for multi-objective acquisition functions.</p>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.utils.get_default_partitioning_alpha">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.multi_objective.utils.</span></span><span class="sig-name descname"><span class="pre">get_default_partitioning_alpha</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_objectives</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/utils.html#get_default_partitioning_alpha"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.utils.get_default_partitioning_alpha" title="Link to this definition"></a></dt>
<dd><p>Determines an approximation level based on the number of objectives.</p>
<p>If <cite>alpha</cite> is 0, FastNondominatedPartitioning should be used. Otherwise,
an approximate NondominatedPartitioning should be used with approximation
level <cite>alpha</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>num_objectives</strong> (<em>int</em>) – the number of objectives.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The approximation level <cite>alpha</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.utils.prune_inferior_points_multi_objective">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.multi_objective.utils.</span></span><span class="sig-name descname"><span class="pre">prune_inferior_points_multi_objective</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ref_point</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2048</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_frac</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">marginalize_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/utils.html#prune_inferior_points_multi_objective"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.utils.prune_inferior_points_multi_objective" title="Link to this definition"></a></dt>
<dd><p>Prune points from an input tensor that are unlikely to be pareto optimal.</p>
<p>Given a model, an objective, and an input tensor <cite>X</cite>, this function returns
the subset of points in <cite>X</cite> that have some probability of being pareto
optimal, better than the reference point, and feasible. This function uses
sampling to estimate the probabilities, the higher the number of points <cite>n</cite>
in <cite>X</cite> the higher the number of samples <cite>num_samples</cite> should be to obtain
accurate estimates.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – A fitted model. Batched models are currently not supported.</p></li>
<li><p><strong>X</strong> (<em>Tensor</em>) – An input tensor of shape <cite>n x d</cite>. Batched inputs are currently not
supported.</p></li>
<li><p><strong>ref_point</strong> (<em>Tensor</em>) – The reference point.</p></li>
<li><p><strong>objective</strong> (<a class="reference internal" href="#botorch.acquisition.multi_objective.objective.MCMultiOutputObjective" title="botorch.acquisition.multi_objective.objective.MCMultiOutputObjective"><em>MCMultiOutputObjective</em></a><em> | </em><em>None</em>) – The objective under which to evaluate the posterior.</p></li>
<li><p><strong>constraints</strong> (<em>list</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of callables, each mapping a Tensor of dimension
<cite>sample_shape x batch-shape x q x m</cite> to a Tensor of dimension
<cite>sample_shape x batch-shape x q</cite>, where negative values imply
feasibility.</p></li>
<li><p><strong>num_samples</strong> (<em>int</em>) – The number of samples used to compute empirical
probabilities of being the best point.</p></li>
<li><p><strong>max_frac</strong> (<em>float</em>) – The maximum fraction of points to retain. Must satisfy
<cite>0 &lt; max_frac &lt;= 1</cite>. Ensures that the number of elements in the
returned tensor does not exceed <cite>ceil(max_frac * n)</cite>.</p></li>
<li><p><strong>marginalize_dim</strong> (<em>int</em><em> | </em><em>None</em>) – A batch dimension that should be marginalized.
For example, this is useful when using a batched fully Bayesian
model.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>A <cite>n’ x d</cite> with subset of points in <cite>X</cite>, where</p>
<blockquote>
<div><p>n’ = min(N_nz, ceil(max_frac * n))</p>
</div></blockquote>
<p>with <cite>N_nz</cite> the number of points in <cite>X</cite> that have non-zero (empirical,
under <cite>num_samples</cite> samples) probability of being pareto optimal.</p>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.utils.compute_sample_box_decomposition">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.multi_objective.utils.</span></span><span class="sig-name descname"><span class="pre">compute_sample_box_decomposition</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pareto_fronts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">partitioning=&lt;class</span> <span class="pre">'botorch.utils.multi_objective.box_decompositions.dominated.DominatedPartitioning'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximize=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_constraints=0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/utils.html#compute_sample_box_decomposition"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.utils.compute_sample_box_decomposition" title="Link to this definition"></a></dt>
<dd><p>Computes the box decomposition associated with some sampled optimal
objectives. This also supports the single-objective and constrained optimization
setting. An objective <cite>y</cite> is feasible if <cite>y &lt;= 0</cite>.</p>
<p>To take advantage of batch computations, we pad the hypercell bounds with a
<cite>2 x (M + K)</cite>-dim Tensor of zeros <cite>[0, 0]</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pareto_fronts</strong> (<em>Tensor</em>) – A <cite>num_pareto_samples x num_pareto_points x M</cite> dim Tensor
containing the sampled optimal set of objectives.</p></li>
<li><p><strong>partitioning</strong> (<em>type</em><em>[</em><a class="reference internal" href="utils.html#botorch.utils.multi_objective.box_decompositions.box_decomposition.BoxDecomposition" title="botorch.utils.multi_objective.box_decompositions.box_decomposition.BoxDecomposition"><em>BoxDecomposition</em></a><em>]</em>) – A <cite>BoxDecomposition</cite> module that is used to obtain the
hyper-rectangle bounds for integration. In the unconstrained case, this
gives the partition of the dominated space. In the constrained case, this
gives the partition of the feasible dominated space union the infeasible
space.</p></li>
<li><p><strong>maximize</strong> (<em>bool</em>) – If true, the box-decomposition is computed assuming maximization.</p></li>
<li><p><strong>num_constraints</strong> (<em>int</em>) – The number of constraints <cite>K</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>num_pareto_samples x 2 x J x (M + K)</cite>-dim Tensor containing the bounds for
the hyper-rectangles. The number <cite>J</cite> is the smallest number of boxes needed
to partition all the Pareto samples.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.utils.random_search_optimizer">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.multi_objective.utils.</span></span><span class="sig-name descname"><span class="pre">random_search_optimizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_points</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximize</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pop_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1024</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_tries</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/utils.html#random_search_optimizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.utils.random_search_optimizer" title="Link to this definition"></a></dt>
<dd><p>Optimize a function via random search.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.deterministic.GenericDeterministicModel" title="botorch.models.deterministic.GenericDeterministicModel"><em>GenericDeterministicModel</em></a>) – The model.</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – A <cite>2 x d</cite>-dim Tensor containing the input bounds.</p></li>
<li><p><strong>num_points</strong> (<em>int</em>) – The number of optimal points to be outputted.</p></li>
<li><p><strong>maximize</strong> (<em>bool</em>) – If true, we consider a maximization problem.</p></li>
<li><p><strong>pop_size</strong> (<em>int</em>) – The number of function evaluations per try.</p></li>
<li><p><strong>max_tries</strong> (<em>int</em>) – The maximum number of tries.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>A two-element tuple containing</p>
<ul class="simple">
<li><p>A <cite>num_points x d</cite>-dim Tensor containing the collection of optimal inputs.</p></li>
<li><dl class="simple">
<dt>A <cite>num_points x M</cite>-dim Tensor containing the collection of optimal</dt><dd><p>objectives.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple[<em>Tensor</em>, <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="botorch.acquisition.multi_objective.utils.sample_optimal_points">
<span class="sig-prename descclassname"><span class="pre">botorch.acquisition.multi_objective.utils.</span></span><span class="sig-name descname"><span class="pre">sample_optimal_points</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_points</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer=&lt;function</span> <span class="pre">random_search_optimizer&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximize=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_kwargs=None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/acquisition/multi_objective/utils.html#sample_optimal_points"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.acquisition.multi_objective.utils.sample_optimal_points" title="Link to this definition"></a></dt>
<dd><p>Compute a collection of optimal inputs and outputs from samples of a Gaussian
Process (GP).</p>
<p>Steps:
(1) The samples are generated using random Fourier features (RFFs).
(2) The samples are optimized sequentially using an optimizer.</p>
<dl class="simple">
<dt>TODO: We can generalize the GP sampling step to accommodate for other sampling</dt><dd><p>strategies rather than restricting to RFFs e.g. decoupled sampling.</p>
</dd>
<dt>TODO: Currently this defaults to random search optimization, might want to</dt><dd><p>explore some other alternatives.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – The model. This does not support models which include fantasy
observations.</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – A <cite>2 x d</cite>-dim Tensor containing the input bounds.</p></li>
<li><p><strong>num_samples</strong> (<em>int</em>) – The number of GP samples.</p></li>
<li><p><strong>num_points</strong> (<em>int</em>) – The number of optimal points to be outputted.</p></li>
<li><p><strong>optimizer</strong> (<em>Callable</em><em>[</em><em>[</em><a class="reference internal" href="models.html#botorch.models.deterministic.GenericDeterministicModel" title="botorch.models.deterministic.GenericDeterministicModel"><em>GenericDeterministicModel</em></a><em>, </em><em>Tensor</em><em>, </em><em>int</em><em>, </em><em>bool</em><em>, </em><em>Any</em><em>]</em><em>, </em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>]</em><em>]</em>) – A callable that solves the deterministic optimization problem.</p></li>
<li><p><strong>maximize</strong> (<em>bool</em>) – If true, we consider a maximization problem.</p></li>
<li><p><strong>optimizer_kwargs</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – The additional arguments for the optimizer.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>A two-element tuple containing</p>
<ul class="simple">
<li><dl class="simple">
<dt>A <cite>num_samples x num_points x d</cite>-dim Tensor containing the collection of</dt><dd><p>optimal inputs.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>A <cite>num_samples x num_points x M</cite>-dim Tensor containing the collection of</dt><dd><p>optimal objectives.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple[<em>Tensor</em>, <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>

</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="BoTorch API Reference" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="models.html" class="btn btn-neutral float-right" title="botorch.models" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p></p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>